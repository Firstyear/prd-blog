<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
      <title>Firstyear&#x27;s blog-a-log</title>
      <link>https://fy.blackhats.net.au</link>
      <description>Firstyear&#x27;s blog</description>
      <generator>Zola</generator>
      <language>en</language>
      <atom:link href="https://fy.blackhats.net.au/rss.xml" rel="self" type="application/rss+xml"/>
      <lastBuildDate>Tue, 24 Oct 2023 00:00:00 +0000</lastBuildDate>
      <item>
          <title>SSH Key Storage Comparison</title>
          <pubDate>Tue, 24 Oct 2023 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2023-10-24-ssh-key-storage-comparisons/</link>
          <guid>https://fy.blackhats.net.au/blog/2023-10-24-ssh-key-storage-comparisons/</guid>
          <description>&lt;h1 id=&quot;ssh-key-storage&quot;&gt;SSH Key Storage&lt;&#x2F;h1&gt;
&lt;p&gt;A kind reader asked me an interesting question the other day. &amp;quot;What do you think of the choice
of ssh sk keys between ecdsa and ed25519?&amp;quot;. At the same time, within Kanidm we have actually been
discussing the different approaches we could take with ssh key handling in the future between
ssh cas and ssh sk key attestation, especially once we consider service accounts.&lt;&#x2F;p&gt;
&lt;p&gt;As with anything in security we always need to balance the technology with the risks and threats
that we are trying to mitigate or prevent.&lt;&#x2F;p&gt;
&lt;p&gt;Compared to the use of a username and password, using ssh keys to authenticate to a remote server
is significantly more secure. This is especially true if you disable password authentication
methods.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;cryptographic-considerations&quot;&gt;Cryptographic Considerations&lt;&#x2F;h2&gt;
&lt;p&gt;Of course, just using cryptographic authentication isn&#x27;t free. While we no longer have the risks
of passwords, the threats that exist against cryptographic keys are quite different. This means
we now need to ensure that we follow and keep up to date with developments in crytpgraphy.&lt;&#x2F;p&gt;
&lt;p&gt;There are many sites that can assist with key requirements such as &lt;a href=&quot;https:&#x2F;&#x2F;www.keylength.com&quot;&gt;keylength.com&lt;&#x2F;a&gt;.
The following table was generated on 2023-09-25 with the year set to 2030 (meaning these key sizes values are
&lt;em&gt;predicted&lt;&#x2F;em&gt; to be safe until 2030).&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Method&lt;&#x2F;th&gt;&lt;th&gt;Date&lt;&#x2F;th&gt;&lt;th&gt;Symmetric&lt;&#x2F;th&gt;&lt;th&gt;FM&lt;&#x2F;th&gt;&lt;th&gt;DL Key&lt;&#x2F;th&gt;&lt;th&gt;DL Group&lt;&#x2F;th&gt;&lt;th&gt;Elliptic Curve&lt;&#x2F;th&gt;&lt;th&gt;Hash&lt;&#x2F;th&gt;&lt;&#x2F;tr&gt;&lt;&#x2F;thead&gt;&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;Lenstra &#x2F; Verheul&lt;&#x2F;td&gt;&lt;td&gt;2030&lt;&#x2F;td&gt;&lt;td&gt;93&lt;&#x2F;td&gt;&lt;td&gt;2493^2016&lt;&#x2F;td&gt;&lt;td&gt;165&lt;&#x2F;td&gt;&lt;td&gt;2493&lt;&#x2F;td&gt;&lt;td&gt;176&lt;&#x2F;td&gt;&lt;td&gt;186&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;Lenstra Updated &lt;&#x2F;td&gt;&lt;td&gt;2030&lt;&#x2F;td&gt;&lt;td&gt;88&lt;&#x2F;td&gt;&lt;td&gt;1698^2063&lt;&#x2F;td&gt;&lt;td&gt;176&lt;&#x2F;td&gt;&lt;td&gt;1698&lt;&#x2F;td&gt;&lt;td&gt;176&lt;&#x2F;td&gt;&lt;td&gt;176&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;ECRYPT&lt;&#x2F;td&gt;&lt;td&gt;2029-2068&lt;&#x2F;td&gt;&lt;td&gt;256&lt;&#x2F;td&gt;&lt;td&gt;15360&lt;&#x2F;td&gt;&lt;td&gt;512&lt;&#x2F;td&gt;&lt;td&gt;15360&lt;&#x2F;td&gt;&lt;td&gt;512&lt;&#x2F;td&gt;&lt;td&gt;512&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;NIST&lt;&#x2F;td&gt;&lt;td&gt;2019-2030&lt;&#x2F;td&gt;&lt;td&gt;112&lt;&#x2F;td&gt;&lt;td&gt;2048&lt;&#x2F;td&gt;&lt;td&gt;224&lt;&#x2F;td&gt;&lt;td&gt;2048&lt;&#x2F;td&gt;&lt;td&gt;224&lt;&#x2F;td&gt;&lt;td&gt;224&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;ANSSI&lt;&#x2F;td&gt;&lt;td&gt;&amp;gt; 2030&lt;&#x2F;td&gt;&lt;td&gt;128&lt;&#x2F;td&gt;&lt;td&gt;3072&lt;&#x2F;td&gt;&lt;td&gt;200&lt;&#x2F;td&gt;&lt;td&gt;3072&lt;&#x2F;td&gt;&lt;td&gt;256&lt;&#x2F;td&gt;&lt;td&gt;256&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;NSA&lt;&#x2F;td&gt;&lt;td&gt;-&lt;&#x2F;td&gt;&lt;td&gt;256&lt;&#x2F;td&gt;&lt;td&gt;3072&lt;&#x2F;td&gt;&lt;td&gt;-&lt;&#x2F;td&gt;&lt;td&gt;-&lt;&#x2F;td&gt;&lt;td&gt;384&lt;&#x2F;td&gt;&lt;td&gt;384&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;RFC3766 &lt;&#x2F;td&gt;&lt;td&gt;-&lt;&#x2F;td&gt;&lt;td&gt;-&lt;&#x2F;td&gt;&lt;td&gt;-&lt;&#x2F;td&gt;&lt;td&gt;-&lt;&#x2F;td&gt;&lt;td&gt;-&lt;&#x2F;td&gt;&lt;td&gt;-&lt;&#x2F;td&gt;&lt;td&gt;-&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;BSI&lt;&#x2F;td&gt;&lt;td&gt;-&lt;&#x2F;td&gt;&lt;td&gt;-&lt;&#x2F;td&gt;&lt;td&gt;-&lt;&#x2F;td&gt;&lt;td&gt;-&lt;&#x2F;td&gt;&lt;td&gt;-&lt;&#x2F;td&gt;&lt;td&gt;-&lt;&#x2F;td&gt;&lt;td&gt;-&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;&#x2F;tbody&gt;&lt;&#x2F;table&gt;
&lt;ul&gt;
&lt;li&gt;DL - Discrete Logarithm&lt;&#x2F;li&gt;
&lt;li&gt;FM - Factoring Modulus&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;The values here that are important for ssh key generation is the Factoring Modulus (FM) and
Elliptic Curve.Each of these sources is assuming different risks and requirements. You will need to
make your own informed choices about these but reading between the values here your minimum key
size should be at least RSA 2048 and ECDSA P256 &#x2F; ED25519, or if you wish to future proof
you may wish to choose RSA 3072, ECDSA P512 &#x2F; ED448.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;p-256-vs-ed25519&quot;&gt;P-256 vs ED25519&lt;&#x2F;h2&gt;
&lt;p&gt;Our dear reader asked if you should choose ED25519 over ECDSA P-256 as there are two attacks (LadderLeak, Minerva)
that affect ECDSA. I am not a cryptographer, so my view here should be taken with caution, but reading
both papers the authors indicate that these attacks require a large number of signatures to conduct
meaning that outside of research conditions, these may not be viable against ssh keys. The authors
themself validate that these attacks may not be possible outside of research conditions.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;ssh-key-storage-1&quot;&gt;SSH Key Storage&lt;&#x2F;h2&gt;
&lt;p&gt;Since we now have cryptographic keys for authentication we need to care about how we store these.
Storage of keys is just as important as the type of key we use.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;files-on-disk&quot;&gt;Files on Disk&lt;&#x2F;h3&gt;
&lt;p&gt;Most peoples first introduction to ssh keys is storing them as files in their home directory.
If during the generation you entered a passphrase, then this stores the private keys as
encrypted files. If you do not specify a passphrase these are stored unencrypted. Generally it&#x27;s
a good idea to store these with a passphrase so that theft of the private key means an attacker
can not immediately use this for nefarious purposes.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;security-keys&quot;&gt;Security Keys&lt;&#x2F;h3&gt;
&lt;p&gt;Rather than storing ssh keys in files, they can be generated in the secure enclave of
a security key such as a yubikey. Because these are stored in the secure enclave, malware or an
attacker can not take the keys from the machine. Additionally, because of how these keys work, they
will not operate without physical interaction with the key.&lt;&#x2F;p&gt;
&lt;p&gt;Another unique property of these keys is they can strictly enforce that userverification (such as
a PIN or biometric) is validated as well as physical interaction before they can proceed.
This verification requirement is baked into the key at creation time and enforced by the secure unclave so that it can not be bypassed, adding an extra
level of security - changing the key from something you have to something you have and are&#x2F;know.&lt;&#x2F;p&gt;
&lt;p&gt;These keys can also attest (cryptographically prove) that they are in a secure enclave at creation time,
so that for higher security environments they can assert that keys &lt;em&gt;must&lt;&#x2F;em&gt; be hardware backed.&lt;&#x2F;p&gt;
&lt;p&gt;So far we have mentioned these keys are in the secure enclave. By default the actual
private key is stored in a file, encrypted by a secret master key inside the security key. This
is what allows these keys to have &amp;quot;unlimited storage&amp;quot; as keys are loaded and unloaded as needed (the
same way that a TPM works).&lt;&#x2F;p&gt;
&lt;p&gt;However for the most secure environments, they may wish that the key never leaves the enclave even if in a secure encrypted form. Security
keys have extremely limited storage (generally 8 keys, some models up to 25), so this limits the use
of these resident keys. But if they are required, you can create a resident, attested, user verified
key for the highest levels of assurance.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;certificate-authorities&quot;&gt;Certificate Authorities&lt;&#x2F;h3&gt;
&lt;p&gt;ssh keys normally rely on the public key being transferred to the machine to authenticate too. This
leads to strategies like ssh key distribution in kanidm so that a central server can be consulted
for which authorised keys are valid for authentication.&lt;&#x2F;p&gt;
&lt;p&gt;However a ssh certificate authority functions more like TLS where a certificate authority&#x27;s key
is trusted by the servers, and then users are issued an ssh key &lt;em&gt;signed&lt;&#x2F;em&gt; by that authority. When
authenticating to the server since the user certificate is signed by a trusted authority it can be
allowed to proceed.&lt;&#x2F;p&gt;
&lt;p&gt;Since these keys are issued as files they carry some of the same risks as our previous files. However
because there is an authority that can issue the keys, they can be created with a short expiration
as required. This leads to some interesting configurations where an external tool can be used to
issue certificates as required, limited to specific hosts and commands.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;comparison&quot;&gt;Comparison&lt;&#x2F;h2&gt;
&lt;p&gt;As with anything, all of these approaches have pros and cons. It&#x27;s up to you to decide what will be
best in your scenario.&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Key Type&lt;&#x2F;th&gt;&lt;th style=&quot;text-align: center&quot;&gt;Strict Enforcement&lt;&#x2F;th&gt;&lt;th style=&quot;text-align: center&quot;&gt;Exfiltration Possible&lt;&#x2F;th&gt;&lt;th style=&quot;text-align: center&quot;&gt;Expiration&lt;&#x2F;th&gt;&lt;th style=&quot;text-align: center&quot;&gt;Hardware Bound&lt;&#x2F;th&gt;&lt;th style=&quot;text-align: center&quot;&gt;User Verification&lt;&#x2F;th&gt;&lt;&#x2F;tr&gt;&lt;&#x2F;thead&gt;&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;ssh key&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: center&quot;&gt;no&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: center&quot;&gt;yes&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: center&quot;&gt;no&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: center&quot;&gt;no&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: center&quot;&gt;no&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;encrypted ssh key&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: center&quot;&gt;no&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: center&quot;&gt;yes&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: center&quot;&gt;no&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: center&quot;&gt;no&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: center&quot;&gt;yes-ish&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;sk key&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: center&quot;&gt;no&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: center&quot;&gt;no&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: center&quot;&gt;no&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: center&quot;&gt;yes&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: center&quot;&gt;yes&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;attested sk key&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: center&quot;&gt;yes&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: center&quot;&gt;no&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: center&quot;&gt;no&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: center&quot;&gt;yes&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: center&quot;&gt;yes&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;ca key&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: center&quot;&gt;yes&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: center&quot;&gt;yes&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: center&quot;&gt;yes&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: center&quot;&gt;possible&lt;&#x2F;td&gt;&lt;td style=&quot;text-align: center&quot;&gt;yes*&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;&#x2F;tbody&gt;&lt;&#x2F;table&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;* If you use ca keys with sk keys, or your issuing ca provides a form of verification&lt;&#x2F;p&gt;
&lt;p&gt;For some example use cases:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;I am a home user logging into my server&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Use what ever makes you happy&lt;&#x2F;li&gt;
&lt;li&gt;Any ssh key auth is better than a password&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;em&gt;I am logging into production servers&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Use ssh key files with passphrases&lt;&#x2F;li&gt;
&lt;li&gt;sk keys with enforce user verification&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;em&gt;I am a business looking to enforce secure keys for admins&#x2F;developers&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Use attested sk keys with enforced user verification&lt;&#x2F;li&gt;
&lt;li&gt;Deploy an ssh ca that requires authentication to issue certificates&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;em&gt;I am a three letter agency that ...&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Ask your security team, that&#x27;s what they&#x27;re there for.&lt;&#x2F;li&gt;
&lt;li&gt;But also, use attested resident sk keys with enforced user verification&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;There is no perfect answer here, but you need to consider the risks you face and how you want
to mitigate them. The biggest problem of all of this is &lt;em&gt;proof&lt;&#x2F;em&gt;. Once you move from &amp;quot;I want an ssh
key&amp;quot; to &amp;quot;we want to enforce our requirements&amp;quot; this adds extra challenges that only an ssh ca or attested
sk keys can fufil. While it&#x27;s nice to trust our users, strictly enforced requirements are far better
when it comes to security.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;things-not-to-do&quot;&gt;Things Not To Do&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;sshfp-dns-records&quot;&gt;SSHFP DNS Records&lt;&#x2F;h3&gt;
&lt;p&gt;Using SSHFP DNS records is insecure. This is because even if you have DNSSEC, it &lt;a href=&quot;https:&#x2F;&#x2F;sockpuppet.org&#x2F;blog&#x2F;2015&#x2F;01&#x2F;15&#x2F;against-dnssec&#x2F;&quot;&gt;does nothing to protect you.&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;This approaches leaves you open to MITM attacks which is effectively a path to remote unauthorised access.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;ssh-key-distribution-with-ldap-starttls&quot;&gt;SSH Key Distribution with LDAP StartTLS&lt;&#x2F;h3&gt;
&lt;p&gt;When distributing keys with LDAP, you must always use LDAPS. This is because &lt;a href=&quot;&#x2F;2021&#x2F;08&#x2F;12&#x2F;starttls_in_ldap.html&quot;&gt;LDAP with StartTLS is insecure.&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;ssh-key-creation-reference&quot;&gt;SSH Key Creation Reference&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;files-on-disk-1&quot;&gt;Files on Disk&lt;&#x2F;h3&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ssh-keygen -t [rsa | ecdsa | ed25519] -b &amp;lt;bits&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;ssh-keygen -t ed25519
&lt;&#x2F;span&gt;&lt;span&gt;ssh-keygen -t ecdsa -b 512
&lt;&#x2F;span&gt;&lt;span&gt;ssh-keygen -t rsa -b 3072
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;security-keys-basic&quot;&gt;Security Keys (Basic)&lt;&#x2F;h3&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ssh-keygen -t [ecdsa-sk | ed25519-sk]
&lt;&#x2F;span&gt;&lt;span&gt;ssh-keygen -t ecdsa-sk
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;&#x2F; Note: Not all keys support ed25519
&lt;&#x2F;span&gt;&lt;span&gt;ssh-keygen -t ed25519-sk
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;security-keys-user-verified&quot;&gt;Security Keys (User Verified)&lt;&#x2F;h3&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ssh-keygen -t [ecdsa-sk | ed25519-sk] -O verify-required
&lt;&#x2F;span&gt;&lt;span&gt;ssh-keygen -t ecdsa-sk -O verify-required
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;certificate-authority&quot;&gt;Certificate Authority&lt;&#x2F;h3&gt;
</description>
      </item>
      <item>
          <title>Storage Administration Guide</title>
          <pubDate>Fri, 08 Sep 2023 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/pages/storage-admin-guide/</link>
          <guid>https://fy.blackhats.net.au/pages/storage-admin-guide/</guid>
          <description>&lt;h1 id=&quot;storage-administration-guide&quot;&gt;Storage Administration Guide&lt;&#x2F;h1&gt;
&lt;p&gt;This guide will help you understand, configure and maintain storage on Linux servers. The content
of this guide is optimised for reliability and accesibility. This is based not only on my own
experiences but observing the experiences of enterprise customers for many years.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;warnings&quot;&gt;⚠️  Warnings ⚠️&lt;&#x2F;h2&gt;
&lt;p&gt;Making changes to storage entails risks. Linux and it&#x27;s storage tools have no safety barriers.
Mistakes can result in &lt;em&gt;COMPLETE LOSS OF ALL YOUR DATA&lt;&#x2F;em&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;DO NOT COPY PASTE COMMANDS HERE WITHOUT UNDERSTANDING THEM.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;CAREFULLY PLAN YOUR COMMANDS.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;HAVE BACKUPS THAT YOU HAVE TESTED.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Almost all commands in this document require root privilieges.&lt;&#x2F;p&gt;
&lt;p&gt;This document is a work in progress!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;general-advice&quot;&gt;General Advice&lt;&#x2F;h2&gt;
&lt;p&gt;Before executing commands that will change your storage you should analyse your storage,
make notes, and prepare your commands in a notepad before you execute the commands. This
will allow you to review before making changes.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;understanding-your-storage&quot;&gt;Understanding Your Storage&lt;&#x2F;h2&gt;
&lt;p&gt;Before changing your storage configurations you need to understand what you have and what you may
want to achieve.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;list-storage-on-your-system&quot;&gt;List Storage On Your System&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;code&gt;lsblk&lt;&#x2F;code&gt; is the most important command in your toolbox. It allows you to understand the layout and
set of your storage between making changes. It also allows you to check which disks are in use so
that you can &lt;em&gt;avoid&lt;&#x2F;em&gt; them while making changes.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# lsblk
&lt;&#x2F;span&gt;&lt;span&gt;NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTS
&lt;&#x2F;span&gt;&lt;span&gt;sr0     11:0    1  372K  0 rom
&lt;&#x2F;span&gt;&lt;span&gt;vda    254:0    0   10G  0 disk
&lt;&#x2F;span&gt;&lt;span&gt;├─vda1 254:1    0    2M  0 part
&lt;&#x2F;span&gt;&lt;span&gt;├─vda2 254:2    0   33M  0 part &#x2F;boot&#x2F;efi
&lt;&#x2F;span&gt;&lt;span&gt;└─vda3 254:3    0   10G  0 part &#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;vdb    254:16   0   50G  0 disk
&lt;&#x2F;span&gt;&lt;span&gt;vdc    254:32   0   50G  0 disk
&lt;&#x2F;span&gt;&lt;span&gt;vdd    254:48   0   50G  0 disk
&lt;&#x2F;span&gt;&lt;span&gt;vde    254:64   0   50G  0 disk
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# lsblk
&lt;&#x2F;span&gt;&lt;span&gt;NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTS
&lt;&#x2F;span&gt;&lt;span&gt;sr0     11:0    1  372K  0 rom
&lt;&#x2F;span&gt;&lt;span&gt;vda    254:0    0   10G  0 disk &amp;lt;---------- this is a whole disk.
&lt;&#x2F;span&gt;&lt;span&gt;                                           &#x2F;-- these partitions exist on the disk.
&lt;&#x2F;span&gt;&lt;span&gt;├─vda1 254:1    0    2M  0 part            - &amp;lt;- this partition is not mounted
&lt;&#x2F;span&gt;&lt;span&gt;├─vda2 254:2    0   33M  0 part &#x2F;boot&#x2F;efi  | &amp;lt;- this partition is mounted at &#x2F;boot&#x2F;efi
&lt;&#x2F;span&gt;&lt;span&gt;└─vda3 254:3    0   10G  0 part &#x2F;          - &amp;lt;- this partition is mounted on &#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;vdb    254:16   0   50G  0 disk
&lt;&#x2F;span&gt;&lt;span&gt;vdc    254:32   0   50G  0 disk &amp;lt;---------- these disks have no partitions
&lt;&#x2F;span&gt;&lt;span&gt;vdd    254:48   0   50G  0 disk
&lt;&#x2F;span&gt;&lt;span&gt;vde    254:64   0   50G  0 disk
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;view-filesystems-that-mount-at-boot&quot;&gt;View Filesystems That Mount At Boot&lt;&#x2F;h3&gt;
&lt;p&gt;Filesystems are mounted at boot from the &lt;em&gt;F&lt;&#x2F;em&gt;ile&lt;em&gt;S&lt;&#x2F;em&gt;ystem &lt;em&gt;TAB&lt;&#x2F;em&gt;le. These are stored in &lt;code&gt;&#x2F;etc&#x2F;fstab&lt;&#x2F;code&gt;.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# cat &#x2F;etc&#x2F;fstab
&lt;&#x2F;span&gt;&lt;span&gt;UUID=ef76b8e7-6017-4757-bd51-3e0e662d408b &#x2F; xfs defaults 0 1
&lt;&#x2F;span&gt;&lt;span&gt;UUID=F6F5-05FB &#x2F;boot&#x2F;efi vfat defaults 0 0
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This is arranged as a white-space separted table.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;- The path or identifier of the device to mount
&lt;&#x2F;span&gt;&lt;span&gt;|                                                          
&lt;&#x2F;span&gt;&lt;span&gt;|                                         &#x2F;- where to mount the filesystem
&lt;&#x2F;span&gt;&lt;span&gt;|                                         |                   
&lt;&#x2F;span&gt;&lt;span&gt;|                                         |    &#x2F;- the type of filesysetm on the device
&lt;&#x2F;span&gt;&lt;span&gt;|                                         |    |              
&lt;&#x2F;span&gt;&lt;span&gt;|                                         |    |   &#x2F;- mount options for the filesystem to be mounted
&lt;&#x2F;span&gt;&lt;span&gt;|                                         |    |   |          
&lt;&#x2F;span&gt;&lt;span&gt;|                                         |    |   |        &#x2F;- dump to tape on crash. set to 0
&lt;&#x2F;span&gt;&lt;span&gt;|                                         |    |   |        |
&lt;&#x2F;span&gt;&lt;span&gt;|                                         |    |   |        | &#x2F;- order of filesystem checks at boot.
&lt;&#x2F;span&gt;&lt;span&gt;|                                         |    |   |        | |  0 = do not check
&lt;&#x2F;span&gt;&lt;span&gt;|                                         |    |   |        | |  1 = check first
&lt;&#x2F;span&gt;&lt;span&gt;|                                         |    |   |        | |  2 = check second ...
&lt;&#x2F;span&gt;&lt;span&gt;v                                         v    v   v        v v
&lt;&#x2F;span&gt;&lt;span&gt;UUID=ef76b8e7-6017-4757-bd51-3e0e662d408b &#x2F;    xfs defaults 0 1
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;dev&#x2F;disk&#x2F;by-id&#x2F;wwn-0x5001b448bd8e7de2    &#x2F;mnt xfs defaults 0 0
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;show-disk-path-or-identifiers&quot;&gt;Show Disk Path Or Identifiers&lt;&#x2F;h3&gt;
&lt;p&gt;Linux allows disks to be referenced by different aliases that can be more accessible or unique
to help prevent mistakes. For example, &lt;code&gt;vda&lt;&#x2F;code&gt; and &lt;code&gt;sda&lt;&#x2F;code&gt; are very similar but &lt;code&gt;virtio-pci-0000:04:00.0&lt;&#x2F;code&gt;
or &lt;code&gt;wwn-0x5000cca0bbefc231&lt;&#x2F;code&gt; are distinct and uniquely identify the device. In addition if you move
the device between different ports (e.g. changing sata ports, or sas ports) then some of these identifiers
will stay stable between those changes.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;show-disks-by-identifiers&quot;&gt;Show disks by identifiers&lt;&#x2F;h4&gt;
&lt;p&gt;Disk by ID are a stable identifier that should not change between systems or connection of the device.&lt;&#x2F;p&gt;
&lt;p&gt;These are commonly used in ZFS pools or administration commands.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# ls -l &#x2F;dev&#x2F;disk&#x2F;by-id
&lt;&#x2F;span&gt;&lt;span&gt;lrwxrwxrwx 1 root root  9 Sep  7 08:51 scsi-1ATA_WDC_WDS200T1R0A-68A4W0_223609A005A5 -&amp;gt; ..&#x2F;..&#x2F;sdg
&lt;&#x2F;span&gt;&lt;span&gt;lrwxrwxrwx 1 root root 10 Sep  7 08:51 scsi-1ATA_WDC_WDS200T1R0A-68A4W0_223609A005A5-part1 -&amp;gt; ..&#x2F;..&#x2F;sdg1
&lt;&#x2F;span&gt;&lt;span&gt;lrwxrwxrwx 1 root root 10 Sep  7 08:51 scsi-1ATA_WDC_WDS200T1R0A-68A4W0_223609A005A5-part9 -&amp;gt; ..&#x2F;..&#x2F;sdg9
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;span&gt;lrwxrwxrwx 1 root root  9 Sep  7 08:51 wwn-0x5001b448bd8e7de2 -&amp;gt; ..&#x2F;..&#x2F;sdg
&lt;&#x2F;span&gt;&lt;span&gt;lrwxrwxrwx 1 root root 10 Sep  7 08:51 wwn-0x5001b448bd8e7de2-part1 -&amp;gt; ..&#x2F;..&#x2F;sdg1
&lt;&#x2F;span&gt;&lt;span&gt;lrwxrwxrwx 1 root root 10 Sep  7 08:51 wwn-0x5001b448bd8e7de2-part9 -&amp;gt; ..&#x2F;..&#x2F;sdg9
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h4 id=&quot;show-disks-by-uuid&quot;&gt;Show disks by UUID&lt;&#x2F;h4&gt;
&lt;p&gt;Generally only partitions with filesystems will have a UUID - this will not show &amp;quot;devices&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;UUID&#x27;s are a stable identifier that should not change between systems or connection of the device.&lt;&#x2F;p&gt;
&lt;p&gt;These are commonly used in &lt;code&gt;&#x2F;etc&#x2F;fstab&lt;&#x2F;code&gt; for mounting filesystems. These are used with
the &lt;code&gt;fstab&lt;&#x2F;code&gt; syntax of &lt;code&gt;UUID=&amp;lt; ... &amp;gt;&lt;&#x2F;code&gt;&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# ls -l &#x2F;dev&#x2F;disk&#x2F;by-uuid
&lt;&#x2F;span&gt;&lt;span&gt;lrwxrwxrwx 1 root root 15 Sep  7 08:51 DA2C-4E2B -&amp;gt; ..&#x2F;..&#x2F;nvme1n1p1
&lt;&#x2F;span&gt;&lt;span&gt;lrwxrwxrwx 1 root root 10 Sep  7 08:51 e3967de9-6cab-4387-8a58-aa6b34dba39f -&amp;gt; ..&#x2F;..&#x2F;dm-9
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h4 id=&quot;show-disks-by-their-physical-attachment-path&quot;&gt;Show disks by their physical attachment path&lt;&#x2F;h4&gt;
&lt;p&gt;These are commonly used to locate the type of device, and where it may be attached on a system.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# ls -l &#x2F;dev&#x2F;disk&#x2F;by-path
&lt;&#x2F;span&gt;&lt;span&gt;lrwxrwxrwx 1 root root  9 Sep  7 08:51 pci-0000:00:17.0-ata-8.0 -&amp;gt; ..&#x2F;..&#x2F;sdg
&lt;&#x2F;span&gt;&lt;span&gt;lrwxrwxrwx 1 root root 10 Sep  7 08:51 pci-0000:00:17.0-ata-8.0-part1 -&amp;gt; ..&#x2F;..&#x2F;sdg1
&lt;&#x2F;span&gt;&lt;span&gt;lrwxrwxrwx 1 root root 10 Sep  7 08:51 pci-0000:00:17.0-ata-8.0-part9 -&amp;gt; ..&#x2F;..&#x2F;sdg9
&lt;&#x2F;span&gt;&lt;span&gt;lrwxrwxrwx 1 root root 13 Sep  7 08:51 pci-0000:01:00.0-nvme-1 -&amp;gt; ..&#x2F;..&#x2F;nvme0n1
&lt;&#x2F;span&gt;&lt;span&gt;lrwxrwxrwx 1 root root 15 Sep  7 08:51 pci-0000:01:00.0-nvme-1-part1 -&amp;gt; ..&#x2F;..&#x2F;nvme0n1p1
&lt;&#x2F;span&gt;&lt;span&gt;lrwxrwxrwx 1 root root 15 Sep  7 08:51 pci-0000:01:00.0-nvme-1-part2 -&amp;gt; ..&#x2F;..&#x2F;nvme0n1p2
&lt;&#x2F;span&gt;&lt;span&gt;lrwxrwxrwx 1 root root 15 Sep  7 08:51 pci-0000:01:00.0-nvme-1-part3 -&amp;gt; ..&#x2F;..&#x2F;nvme0n1p3
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;what-storage-setup-do-i-want&quot;&gt;What Storage Setup Do I Want?&lt;&#x2F;h2&gt;
&lt;p&gt;Here are some questions that may help you to decide how to configure the storage in your system.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;i-m-installing-my-favourite-distro-on-a-laptop-workstation&quot;&gt;I&#x27;m Installing My Favourite Distro On A Laptop&#x2F;Workstation&lt;&#x2F;h3&gt;
&lt;ul&gt;
&lt;li&gt;You should use GPT for partitioning.&lt;&#x2F;li&gt;
&lt;li&gt;You should use LVM to allow resizing partitions, creating raid or changing disks in the future.&lt;&#x2F;li&gt;
&lt;li&gt;Split Home vs Root OR combined Home + Root is a personal preference.&lt;&#x2F;li&gt;
&lt;li&gt;If you want fast and highly reliable storage -&amp;gt; Choose XFS&lt;&#x2F;li&gt;
&lt;li&gt;If you want features like snapshots -&amp;gt; Choose BTRFS&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h3 id=&quot;i-m-adding-non-root-disks-to-my-workstation-server&quot;&gt;I&#x27;m Adding Non-Root Disks To My Workstation&#x2F;Server&lt;&#x2F;h3&gt;
&lt;h4 id=&quot;i-want-highly-reliable-fault-tolerant-storage&quot;&gt;I Want Highly Reliable, Fault Tolerant Storage&lt;&#x2F;h4&gt;
&lt;ul&gt;
&lt;li&gt;Use ZFS&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h4 id=&quot;i-can-not-afford-to-lose-data-ever&quot;&gt;I Can Not Afford To Lose Data Ever.&lt;&#x2F;h4&gt;
&lt;ul&gt;
&lt;li&gt;Use ZFS&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h4 id=&quot;i-want-one-giant-pool-of-storage-that-i-will-expand-in-future&quot;&gt;I Want One Giant Pool Of Storage That I Will Expand In Future&lt;&#x2F;h4&gt;
&lt;ul&gt;
&lt;li&gt;Use ZFS&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h4 id=&quot;i-plan-to-add-remove-change-disks-again-when-ever-i-feel-like&quot;&gt;I Plan To Add&#x2F;Remove&#x2F;Change Disks Again When Ever I Feel Like&lt;&#x2F;h4&gt;
&lt;ul&gt;
&lt;li&gt;Use LVM+RAID&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h4 id=&quot;i-just-want-disks-mounted-like-a-chaos-goblin&quot;&gt;I Just Want Disks Mounted Like A Chaos Goblin&lt;&#x2F;h4&gt;
&lt;ul&gt;
&lt;li&gt;You should use GPT for partitioning.&lt;&#x2F;li&gt;
&lt;li&gt;You should use LVM to allow resizing partitions, creating raid or changing disks in the future.&lt;&#x2F;li&gt;
&lt;li&gt;If you want fast and highly reliable storage -&amp;gt; Choose XFS&lt;&#x2F;li&gt;
&lt;li&gt;If you want features like snapshots -&amp;gt; Choose BTRFS&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;managing-single-disks&quot;&gt;Managing Single Disks&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;reload-partition-tables&quot;&gt;Reload partition tables&lt;&#x2F;h3&gt;
&lt;p&gt;After making changes to partition tables, you may need to force the kernel to re-read them so that
they are reflected in commands like &lt;code&gt;lsblk&lt;&#x2F;code&gt;&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# partprobe
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;zfs&quot;&gt;ZFS&lt;&#x2F;h2&gt;
&lt;p&gt;todo!();&lt;&#x2F;p&gt;
&lt;h2 id=&quot;lvm&quot;&gt;LVM&lt;&#x2F;h2&gt;
&lt;p&gt;LVM is a Logical Volume Manager for Linux. It allows dynamically changing storage without downtime,
and the ability to warp and shape into complex and weird disk layouts and geometries. It has excellent
observability into the state of storage, and you should consider it a &amp;quot;must have&amp;quot; on all systems.&lt;&#x2F;p&gt;
&lt;p&gt;LVM&#x27;s single limitation is you can not use it for &lt;code&gt;&#x2F;boot&lt;&#x2F;code&gt; or &lt;code&gt;EFI System Partitions&lt;&#x2F;code&gt;. These
must remain as &amp;quot;true&amp;quot; partitions. If in doubt, trust your installer.&lt;&#x2F;p&gt;
&lt;p&gt;LVM combines a set of physical volumes (PV) into a volume group (VG). A volume group contains a pool of available
storage. logical volumes (LV) can then be created within that volume group that consume that storage.
Each logical volume can have it&#x27;s own characteristics like raid levels. Logical volumes due to
how they work may span multiple physical volumes since an LV consumes space from the VG which can
allocate anywhere in the PV&#x27;s available. This can be visualised as:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;┌──────┐ ┌──────────────────────┐           
&lt;&#x2F;span&gt;&lt;span&gt;│  LV  │ │          LV          │           
&lt;&#x2F;span&gt;&lt;span&gt;└──────┘ └──────────────────────┘           
&lt;&#x2F;span&gt;&lt;span&gt;┌──────────────────────────────────────────┐
&lt;&#x2F;span&gt;&lt;span&gt;│                    VG                    │
&lt;&#x2F;span&gt;&lt;span&gt;└──────────────────────────────────────────┘
&lt;&#x2F;span&gt;&lt;span&gt;┌────────────┐ ┌────────────┐ ┌────────────┐
&lt;&#x2F;span&gt;&lt;span&gt;│     PV     │ │     PV     │ │     PV     │
&lt;&#x2F;span&gt;&lt;span&gt;└────────────┘ └────────────┘ └────────────┘
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Here we have two LV&#x27;s within a VG. The VG is made from 3 PVs. The storage of the LV&#x27;s may be anywhere
within the pool of PV&#x27;s that exist. This allows PVs to be added or removed dynamically as the LV
content can be moved at any time.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;general-lvm-administration&quot;&gt;General LVM Administration&lt;&#x2F;h3&gt;
&lt;h4 id=&quot;read-the-man-pages&quot;&gt;Read The Man Pages&lt;&#x2F;h4&gt;
&lt;p&gt;LVM has some of the &lt;em&gt;best man pages&lt;&#x2F;em&gt; ever put onto a Linux system. They are worth reading to understand
the options you have for commands!&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;HINT: Some flavours of OpenSUSE may not have man pages. To fix this:&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# $EDITOR &#x2F;etc&#x2F;zypp&#x2F;zypp.conf
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;span&gt;rpm.install.excludedocs = no
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Ensure man is installed, and reinstall lvm2 to make sure it&#x27;s man pages are present.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# zypper install -f man lvm2
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h4 id=&quot;opensuse-install-lvm-tools&quot;&gt;OpenSUSE - Install LVM Tools&lt;&#x2F;h4&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# zypper in lvm2
&lt;&#x2F;span&gt;&lt;span&gt;# reboot
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;blockquote&gt;
&lt;p&gt;NOTE: In some cases you may need to install kernel-default so that dm-raid&#x27;s kernel module exists.
This can be because kernel-default-base may lack the module.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;h4 id=&quot;show-all-physical-volumes&quot;&gt;Show all Physical Volumes&lt;&#x2F;h4&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# pvs
&lt;&#x2F;span&gt;&lt;span&gt;  PV         VG   Fmt  Attr PSize  PFree
&lt;&#x2F;span&gt;&lt;span&gt;  &#x2F;dev&#x2F;vdb   vg00 lvm2 a--  50.00g 50.00g
&lt;&#x2F;span&gt;&lt;span&gt;  &#x2F;dev&#x2F;vdc   vg00 lvm2 a--  50.00g 50.00g
&lt;&#x2F;span&gt;&lt;span&gt;  &#x2F;dev&#x2F;vdd   vg00 lvm2 a--  50.00g 50.00g
&lt;&#x2F;span&gt;&lt;span&gt;  &#x2F;dev&#x2F;vde   vg00 lvm2 a--  50.00g 50.00g
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h4 id=&quot;show-all-volume-groups&quot;&gt;Show all Volume Groups&lt;&#x2F;h4&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# vgs
&lt;&#x2F;span&gt;&lt;span&gt;  VG   #PV #LV #SN Attr   VSize   VFree
&lt;&#x2F;span&gt;&lt;span&gt;  vg00   4   0   0 wz--n- 199.98g 199.98g
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h4 id=&quot;show-all-logical-volumes&quot;&gt;Show all Logical Volumes&lt;&#x2F;h4&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# lvs
&lt;&#x2F;span&gt;&lt;span&gt;  LV      VG   Attr       LSize  Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert
&lt;&#x2F;span&gt;&lt;span&gt;  lv_raid vg00 rwi-a-r--- 80.00g
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Show the internal details of LVs&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# lvs -a
&lt;&#x2F;span&gt;&lt;span&gt;  LV                 VG   Attr       LSize  Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert
&lt;&#x2F;span&gt;&lt;span&gt;  lv_raid            vg00 rwi-a-r--- 80.00g                                    18.80
&lt;&#x2F;span&gt;&lt;span&gt;  [lv_raid_rimage_0] vg00 Iwi-aor--- 40.00g
&lt;&#x2F;span&gt;&lt;span&gt;  [lv_raid_rimage_1] vg00 Iwi-aor--- 40.00g
&lt;&#x2F;span&gt;&lt;span&gt;  [lv_raid_rimage_2] vg00 Iwi-aor--- 40.00g
&lt;&#x2F;span&gt;&lt;span&gt;  [lv_raid_rmeta_0]  vg00 ewi-aor---  4.00m
&lt;&#x2F;span&gt;&lt;span&gt;  [lv_raid_rmeta_1]  vg00 ewi-aor---  4.00m
&lt;&#x2F;span&gt;&lt;span&gt;  [lv_raid_rmeta_2]  vg00 ewi-aor---  4.00m
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Show the internal details of LVs and which devices are backing their storage.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# lvs -a -o +devices
&lt;&#x2F;span&gt;&lt;span&gt;  LV                 VG   Attr       LSize  Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert Devices
&lt;&#x2F;span&gt;&lt;span&gt;  lv_raid            vg00 rwi-a-r--- 80.00g                                    21.35            lv_raid_rimage_0(0),lv_raid_rimage_1(0),lv_raid_rimage_2(0)
&lt;&#x2F;span&gt;&lt;span&gt;  [lv_raid_rimage_0] vg00 Iwi-aor--- 40.00g                                                     &#x2F;dev&#x2F;vdb(1)
&lt;&#x2F;span&gt;&lt;span&gt;  [lv_raid_rimage_1] vg00 Iwi-aor--- 40.00g                                                     &#x2F;dev&#x2F;vdc(1)
&lt;&#x2F;span&gt;&lt;span&gt;  [lv_raid_rimage_2] vg00 Iwi-aor--- 40.00g                                                     &#x2F;dev&#x2F;vdd(1)
&lt;&#x2F;span&gt;&lt;span&gt;  [lv_raid_rmeta_0]  vg00 ewi-aor---  4.00m                                                     &#x2F;dev&#x2F;vdb(0)
&lt;&#x2F;span&gt;&lt;span&gt;  [lv_raid_rmeta_1]  vg00 ewi-aor---  4.00m                                                     &#x2F;dev&#x2F;vdc(0)
&lt;&#x2F;span&gt;&lt;span&gt;  [lv_raid_rmeta_2]  vg00 ewi-aor---  4.00m                                                     &#x2F;dev&#x2F;vdd(0)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;using-lvm-for-raid&quot;&gt;Using LVM For Raid&lt;&#x2F;h3&gt;
&lt;p&gt;First you need to select your devices that will become the PV&#x27;s&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# lsblk
&lt;&#x2F;span&gt;&lt;span&gt;NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTS
&lt;&#x2F;span&gt;&lt;span&gt;sr0     11:0    1  372K  0 rom
&lt;&#x2F;span&gt;&lt;span&gt;vda    254:0    0   10G  0 disk
&lt;&#x2F;span&gt;&lt;span&gt;├─vda1 254:1    0    2M  0 part
&lt;&#x2F;span&gt;&lt;span&gt;├─vda2 254:2    0   33M  0 part &#x2F;boot&#x2F;efi
&lt;&#x2F;span&gt;&lt;span&gt;└─vda3 254:3    0   10G  0 part &#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;vdb    254:16   0   50G  0 disk ----
&lt;&#x2F;span&gt;&lt;span&gt;vdc    254:32   0   50G  0 disk | &amp;lt;-- I will use these 4 devices.
&lt;&#x2F;span&gt;&lt;span&gt;vdd    254:48   0   50G  0 disk |
&lt;&#x2F;span&gt;&lt;span&gt;vde    254:64   0   50G  0 disk ----
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Create PVs on each member device.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# pvcreate &#x2F;dev&#x2F;vdb
&lt;&#x2F;span&gt;&lt;span&gt;# pvcreate &#x2F;dev&#x2F;disk&#x2F;by-path&#x2F;virtio-pci-0000\:09\:00.0
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Create a VG containing all the PVs&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;vgcreate &amp;lt;name of vg&amp;gt; &amp;lt;path to pv&amp;gt; [&amp;lt;path to pv&amp;gt; ...]
&lt;&#x2F;span&gt;&lt;span&gt;# vgcreate vg00 &#x2F;dev&#x2F;vdb &#x2F;dev&#x2F;vdc &#x2F;dev&#x2F;vdd &#x2F;dev&#x2F;vde
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Create a new LV that is at your prefered raid level.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;If you have two PV&#x27;s choose raid 1&lt;&#x2F;li&gt;
&lt;li&gt;If you have three or more choose between raid 5 or raid 10&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;In each case, LVM will make sure that the data of the LV is correctly split to PV&#x27;s to ensure redundancy.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Raid 1 mirrors. It has no performance changes.&lt;&#x2F;li&gt;
&lt;li&gt;Raid 5&#x2F;6 have better &lt;em&gt;write&lt;&#x2F;em&gt; performance but lower &lt;em&gt;read&lt;&#x2F;em&gt; performance compared to raid 10.&lt;&#x2F;li&gt;
&lt;li&gt;Raid 10 has better &lt;em&gt;read&lt;&#x2F;em&gt; performance but lower &lt;em&gt;write&lt;&#x2F;em&gt; performance compared to raid 5&#x2F;6&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;lvcreate [options] -n &amp;lt;name of LV&amp;gt; --type &amp;lt;type&amp;gt; [-L|-l] &amp;lt;size of lv&amp;gt; --raidintegrity y &amp;lt;VG to create the LV in&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;## Create an lv that consumes all space in the VG
&lt;&#x2F;span&gt;&lt;span&gt;## NOTE: you may need to reduce this from 100% with raidintegrity to allow LVM the space
&lt;&#x2F;span&gt;&lt;span&gt;## to create the LV.
&lt;&#x2F;span&gt;&lt;span&gt;# lvcreate -n lv_raid --type raid10 -l 100%FREE --raidintegrity y vg00
&lt;&#x2F;span&gt;&lt;span&gt;## Create an lv that provides 80G of raid storage, but consumers more of the VG underneath
&lt;&#x2F;span&gt;&lt;span&gt;# lvcreate -n lv_raid --type raid5 -L 80G --raidintegrity y vg00
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;blockquote&gt;
&lt;p&gt;HINT: The raidintegrity flag enables checksums of extents to allow detection of potential disk corruption&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;You can then use &lt;code&gt;lvs&lt;&#x2F;code&gt; to show the state of the sync process of the LV.&lt;&#x2F;p&gt;
&lt;p&gt;Once created you can make a new filesystem on the volume.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;mkfs.&amp;lt;fs name&amp;gt; &#x2F;dev&#x2F;&amp;lt;vg name&amp;gt;&#x2F;&amp;lt;lv name&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;# mkfs.xfs &#x2F;dev&#x2F;vg00&#x2F;lv_raid
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This can then be added to &lt;code&gt;&#x2F;etc&#x2F;fstab&lt;&#x2F;code&gt; to mount on boot.&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;HINT: &lt;code&gt;&#x2F;dev&#x2F;&amp;lt;vg name&amp;gt;&#x2F;&amp;lt;lv name&amp;gt;&lt;&#x2F;code&gt; paths will never change and can be used reliably in fstab&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# $EDITOR &#x2F;etc&#x2F;fstab
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;dev&#x2F;vg00&#x2F;lv_raid  &#x2F;mnt&#x2F;raid    xfs defaults 0 0
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;managing-lvm-raid&quot;&gt;Managing LVM Raid&lt;&#x2F;h3&gt;
&lt;h4 id=&quot;replacing-a-working-disk&quot;&gt;Replacing a Working Disk&lt;&#x2F;h4&gt;
&lt;p&gt;If you want to expand your array, or just replace an old piece of disk media you can do this
live.&lt;&#x2F;p&gt;
&lt;p&gt;Attach the new disk and locate it with &lt;code&gt;lsblk&lt;&#x2F;code&gt;. Note it&#x27;s name, path or other identifier.&lt;&#x2F;p&gt;
&lt;p&gt;Locate the disk you want to replace by it&#x27;s path or identifier.&lt;&#x2F;p&gt;
&lt;p&gt;Create a new PV on the new disk.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# pvcreate &#x2F;dev&#x2F;vdf
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Extend the VG with the new PV&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# vgextend vg00 &#x2F;dev&#x2F;vdf
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Check the pv was added to the vg&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# pvs
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Move the extents from the original device, to the new device.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;## This blocks and monitors the move. If you ctrl-c it continues in the background.
&lt;&#x2F;span&gt;&lt;span&gt;# pvmove &#x2F;dev&#x2F;vde &#x2F;dev&#x2F;vdf
&lt;&#x2F;span&gt;&lt;span&gt;## Run the move in the background
&lt;&#x2F;span&gt;&lt;span&gt;# pvmove -b &#x2F;dev&#x2F;vde &#x2F;dev&#x2F;vdf
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If backgrounded, you can monitor the move with:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# lvs -a
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h4 id=&quot;replacing-a-corrupted-missing-disk&quot;&gt;Replacing a Corrupted&#x2F;Missing Disk&lt;&#x2F;h4&gt;
&lt;p&gt;When checking lvs if a disk is corrupted or missing you will see errors such as:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# lvs
&lt;&#x2F;span&gt;&lt;span&gt;  WARNING: Couldn&amp;#39;t find device with uuid weDidc-rBve-EL25-NqTG-X2n6-fGmW-FGCs9l.
&lt;&#x2F;span&gt;&lt;span&gt;  WARNING: VG vg00 is missing PV weDidc-rBve-EL25-NqTG-X2n6-fGmW-FGCs9l (last written to &#x2F;dev&#x2F;vdd).
&lt;&#x2F;span&gt;&lt;span&gt;  WARNING: Couldn&amp;#39;t find all devices for LV vg00&#x2F;lv_raid_rimage_2 while checking used and assumed devices.
&lt;&#x2F;span&gt;&lt;span&gt;  WARNING: Couldn&amp;#39;t find all devices for LV vg00&#x2F;lv_raid_rmeta_2 while checking used and assumed devices.
&lt;&#x2F;span&gt;&lt;span&gt;  LV      VG   Attr       LSize  Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert
&lt;&#x2F;span&gt;&lt;span&gt;  lv_raid vg00 rwi-a-r-p- 99.98g                                    100.00
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Create a new PV on a replacement disk, and add it to the vg.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# pvcreate &#x2F;dev&#x2F;path&#x2F;to&#x2F;disk
&lt;&#x2F;span&gt;&lt;span&gt;# vgextend vg00 &#x2F;dev&#x2F;path&#x2F;to&#x2F;disk
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The logical volume must be active to initiate the replacement:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# lvchange -ay vg00&#x2F;lv_raid
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Replace the failed device allocating the needed extents.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;## To any free device in the VG
&lt;&#x2F;span&gt;&lt;span&gt;# lvconvert --repair vg00&#x2F;lv_raid
&lt;&#x2F;span&gt;&lt;span&gt;## To a specific PV
&lt;&#x2F;span&gt;&lt;span&gt;# lvconvert --repair vg00&#x2F;lv_raid &#x2F;dev&#x2F;vde
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You can view the progress of the repair with &lt;code&gt;lvs&lt;&#x2F;code&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Instruct the vg to remove the missing device metadata now that the replacement is complete.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# vgreduce --removemissing vg00
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
</description>
      </item>
      <item>
          <title>Starting with Rage on OpenSUSE</title>
          <pubDate>Fri, 26 May 2023 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2023-05-26-starting-with-rage-on-opensuse/</link>
          <guid>https://fy.blackhats.net.au/blog/2023-05-26-starting-with-rage-on-opensuse/</guid>
          <description>&lt;h1 id=&quot;starting-with-rage-on-opensuse&quot;&gt;Starting with Rage on OpenSUSE&lt;&#x2F;h1&gt;
&lt;p&gt;Rage is a rust implementation of Age, a modern, simple and secure file encryption tool. It
is easier to use than other tools like GPG, and being written in a memory safe language it
avoids many of the exploits that may occur in C based tools.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;installing-rage&quot;&gt;Installing Rage&lt;&#x2F;h2&gt;
&lt;p&gt;You can install rage on leap or tumbleweed from zypper&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;zypper install rage-encryption
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Alternately you can install from cargo with&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;cargo install rage
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;key-management&quot;&gt;Key management&lt;&#x2F;h2&gt;
&lt;p&gt;The recipient must generate a key. This can be either a rage key, or an ssh key which is of the
form &lt;code&gt;ssh-rsa&lt;&#x2F;code&gt; or &lt;code&gt;ssh-ed25519&lt;&#x2F;code&gt;.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# The public key is displayed.
&lt;&#x2F;span&gt;&lt;span&gt;rage-keygen -o ~&#x2F;rage.key
&lt;&#x2F;span&gt;&lt;span&gt;# age1y2lc7x59jcqvrpf3ppmnj3f93ytaegfkdnl5vrdyv83l8ekcae4sexgwkg
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;To use ssh keys, you can generate a key with:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ssh-keygen -t ed25519
&lt;&#x2F;span&gt;&lt;span&gt;# cat &#x2F;root&#x2F;.ssh&#x2F;id_ed25519.pub
&lt;&#x2F;span&gt;&lt;span&gt;ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIE1kWXiYIn&#x2F;VWzo0DlnIp3cRx&#x2F;kZd6d9WbwehKJpPx1R
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;encrypting-to-a-public-key&quot;&gt;Encrypting to a public key&lt;&#x2F;h2&gt;
&lt;p&gt;You encrypt a file to the owner of the public key with:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;rage -e -r &amp;lt;pub key&amp;gt; -o &amp;lt;encrypted output&amp;gt; &amp;lt;input&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;# With their rage public key.
&lt;&#x2F;span&gt;&lt;span&gt;rage -e -r age1y2lc7x59jcqvrpf3ppmnj3f93ytaegfkdnl5vrdyv83l8ekcae4sexgwkg -o ~&#x2F;encyrpted.age data
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Alternately, if you want to allow the content of the encrypted file to be base64 for emailing (note the -a):&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;rage -e -a -r &amp;lt;pub key&amp;gt; -o &amp;lt;encrypted output&amp;gt; &amp;lt;input&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;# With their rage public key.
&lt;&#x2F;span&gt;&lt;span&gt;rage -e -a -r age1y2lc7x59jcqvrpf3ppmnj3f93ytaegfkdnl5vrdyv83l8ekcae4sexgwkg \
&lt;&#x2F;span&gt;&lt;span&gt;    -o ~&#x2F;encyrpted.age data
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# cat &#x2F;tmp&#x2F;encrypted
&lt;&#x2F;span&gt;&lt;span&gt;-----BEGIN AGE ENCRYPTED FILE-----
&lt;&#x2F;span&gt;&lt;span&gt;YWdlLWVuY3J5cHRpb24ub3JnL3YxCi0+IFgyNTUxOSByaDNTNHR0dlI5RkRudmpH
&lt;&#x2F;span&gt;&lt;span&gt;NEUrT1RrQ3pZdjM5alRVYThDeG5xdTBxd1EwCjYxVGkwV05ibXlWeUN3MWVuNTBC
&lt;&#x2F;span&gt;&lt;span&gt;Qk1SdEwyd3J1RjgrNVkxem5pbHJscVEKLT4gTyI7WFQtZ3JlYXNlIEZDXyBiICFV
&lt;&#x2F;span&gt;&lt;span&gt;NgpoTlJ5ME95azMycE5GbS9oS0h6a280RlRTRHNKbE9mMGZjTmFCUjB6aWEwZGxU
&lt;&#x2F;span&gt;&lt;span&gt;Rjg1RkZmdkhBSkU4Y1dZdEM3CjV0VXl4dE5Qd3E0SU1GSXNIejQKLS0tIFhscDBn
&lt;&#x2F;span&gt;&lt;span&gt;MlBiTmxPekthY1RabVcxN0JkQnJsd3RKUkpTKzRkelZ1eDFXSk0KHzCOyBZHPe&#x2F;P
&lt;&#x2F;span&gt;&lt;span&gt;cV3Fez6yusycXcm83Bt+N2yHTG2utOGxfmIxb5c=
&lt;&#x2F;span&gt;&lt;span&gt;-----END AGE ENCRYPTED FILE-----
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The ssh public key can be encrypted to if the public key is in a file&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;rage -e -a -R &amp;lt;path to public key&amp;gt; -o &amp;lt;encrypted output&amp;gt; &amp;lt;input&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Using the ssh public key in a file
&lt;&#x2F;span&gt;&lt;span&gt;rage -e -a -R ~&#x2F;id_ed25519.pub -o &#x2F;tmp&#x2F;ssh-encrypted data
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;decrypting-a-file&quot;&gt;Decrypting a file&lt;&#x2F;h2&gt;
&lt;p&gt;The recipient can then decrypt with:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;rage -d -i &amp;lt;path to private key&amp;gt; -o &amp;lt;decrypted output&amp;gt; &amp;lt;encrypted input&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;rage -d -i ~&#x2F;rage.key -o &#x2F;tmp&#x2F;decrypted &#x2F;tmp&#x2F;encrypted
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# cat &#x2F;tmp&#x2F;decrypted
&lt;&#x2F;span&gt;&lt;span&gt;hello
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;With an ssh private key&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;rage -d -i &amp;lt;path to ssh private key&amp;gt; -o &amp;lt;decrypted output&amp;gt; &amp;lt;encrypted input&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;rage -d -i ~&#x2F;.ssh&#x2F;id_ed25519 -o &#x2F;tmp&#x2F;ssh-decrypted &#x2F;tmp&#x2F;ssh-encrypted
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;encrypt-to-multiple-recipients&quot;&gt;Encrypt to multiple recipients&lt;&#x2F;h2&gt;
&lt;p&gt;Rage can encrypt to multiple identities at a time.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;rage -e -a -R &amp;lt;first ssh pub key&amp;gt; -R &amp;lt;second pub key&amp;gt; ... -o &amp;lt;encrypted output&amp;gt; &amp;lt;input&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;rage -e -a -r &amp;lt;first pub key&amp;gt; -r &amp;lt;second pub key&amp;gt; ... -o &amp;lt;encrypted output&amp;gt; &amp;lt;input&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;rage -e -a -R &amp;lt;first ssh pub key&amp;gt; -r &amp;lt;first rage pub key&amp;gt; ... -o &amp;lt;encrypted output&amp;gt; &amp;lt;input&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;rage -e -a -R &#x2F;root&#x2F;.ssh&#x2F;id_ed25519.pub \
&lt;&#x2F;span&gt;&lt;span&gt;    -r age1h8equ4vs5pyp8ykw0z8m9n8m3psy6swme52ztth0v66frgu65ussm8gq0t \
&lt;&#x2F;span&gt;&lt;span&gt;    -r age1y2lc7x59jcqvrpf3ppmnj3f93ytaegfkdnl5vrdyv83l8ekcae4sexgwkg \
&lt;&#x2F;span&gt;&lt;span&gt;    -o &#x2F;tmp&#x2F;ssh-encrypted hello
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&lt;em&gt;all&lt;&#x2F;em&gt; of the associated keys can decrypt this file.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;rage -d -i &#x2F;root&#x2F;.ssh&#x2F;id_ed25519 -o &#x2F;tmp&#x2F;ssh-decrypted &#x2F;tmp&#x2F;ssh-encrypted
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;rage -d -i ~&#x2F;rage.key -o &#x2F;tmp&#x2F;decrypted &#x2F;tmp&#x2F;ssh-encrypted
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;using-a-passphrase-instead-of-a-key&quot;&gt;Using a passphrase instead of a key&lt;&#x2F;h2&gt;
&lt;p&gt;Rage can encrypt with a passphrase:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;rage -e -p -o &amp;lt;encrypted output&amp;gt; &amp;lt;input&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;rage -e -p -o &#x2F;tmp&#x2F;passphrase-encrypted data
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Decrypted with (passphrase is detected and prompted for):&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;rage -d -o &amp;lt;decrypted output&amp;gt; &amp;lt;encrypted input&amp;gt; 
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;rage -d -o &#x2F;tmp&#x2F;decrypted &#x2F;tmp&#x2F;passphrase-encrypted
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
</description>
      </item>
      <item>
          <title>About</title>
          <pubDate>Sat, 22 Apr 2023 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/pages/about/</link>
          <guid>https://fy.blackhats.net.au/pages/about/</guid>
          <description>&lt;h1 id=&quot;about&quot;&gt;About&lt;&#x2F;h1&gt;
&lt;p&gt;I&#x27;m William (Firstyear), a software engineer in Brisbane, Australia.
I&#x27;m part of the &lt;a href=&quot;http:&#x2F;&#x2F;www.port389.org&quot;&gt;389 Directory Server&lt;&#x2F;a&gt; team,
working for SUSE Labs. I&#x27;m always happy to talk LDAP and programming,
and am very happy to help out with your issues and queries.&lt;&#x2F;p&gt;
&lt;p&gt;I can be contacted about entries on my blog at william at blackhats dot
net dot au. If there is anything you would like to see on this blog, I&#x27;d
be happy to hear from you.&lt;&#x2F;p&gt;
&lt;p&gt;Happy reading!&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Using a TPM for SSH keys on OpenSUSE Tumbleweed</title>
          <pubDate>Thu, 20 Apr 2023 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2023-04-20-using-a-tpm-for-ssh-keys-on-opensuse-tumbleweed/</link>
          <guid>https://fy.blackhats.net.au/blog/2023-04-20-using-a-tpm-for-ssh-keys-on-opensuse-tumbleweed/</guid>
          <description>&lt;h1 id=&quot;using-a-tpm-for-ssh-keys-on-opensuse-tumbleweed&quot;&gt;Using a TPM for SSH keys on OpenSUSE Tumbleweed&lt;&#x2F;h1&gt;
&lt;p&gt;In some environments it is required to store ssh private keys in a way
where they can not be extracted from the machine. Trusted Platform
Modules (TPM) are an excellent way to achieve this. While other guides
exist online for how to configure this for other distributions, this
will focus on OpenSUSE Tumbleweed.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;install-packages&quot;&gt;Install Packages&lt;&#x2F;h2&gt;
&lt;p&gt;The following is required to be installed.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;zypper install tpm2-pkcs11 tpm2.0-tools tpm2-0-tss libtpm2_pkcs11-0
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;ul&gt;
&lt;li&gt;tpm2-pkcs11 - tools to configure the ssh key in the TPM&lt;&#x2F;li&gt;
&lt;li&gt;tpm2.0-tools - tools for TPM introspection&lt;&#x2F;li&gt;
&lt;li&gt;tpm2-0-tss - udev rules and tss group&lt;&#x2F;li&gt;
&lt;li&gt;libtpm2_pkcs11-0 - library for ssh to access TPM via pkcs&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;check-the-tpm-exists&quot;&gt;Check the TPM exists&lt;&#x2F;h2&gt;
&lt;p&gt;You can check the TPM exists and is working with:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ls -l &#x2F;dev&#x2F;tpm*
&lt;&#x2F;span&gt;&lt;span&gt;# crw-rw---- 1 tss root  10,   224 Apr 19 18:39 &#x2F;dev&#x2F;tpm0
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;To check the supported algorithms on the TPM:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;tpm2_getcap algorithms
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If this command errors, your TPM may be misconfigured or you may not
have access to the TPM.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;HINT&lt;&#x2F;em&gt;: You can add a TPM to a KVM virtual machine with virt-install
with the line:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;--tpm backend.type=emulator,backend.version=2.0,model=tpm-tis
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;From virt-manager you can add the TPM via &amp;quot;Add Hardware&amp;quot;, &amp;quot;TPM&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;Editing the virtual machine xml directly a TPM can be defined with:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&amp;lt;domain type=&amp;#39;kvm&amp;#39;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;  &amp;lt;devices&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;lt;tpm model=&amp;#39;tpm-tis&amp;#39;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;      &amp;lt;backend type=&amp;#39;emulator&amp;#39; version=&amp;#39;2.0&amp;#39;&#x2F;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;lt;&#x2F;tpm&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;  &amp;lt;&#x2F;devices&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&#x2F;domain&amp;gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;allow-user-access&quot;&gt;Allow User Access&lt;&#x2F;h2&gt;
&lt;p&gt;Add your user to the tss group&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;usermod -a -G tss username
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;configure-the-ssh-key&quot;&gt;Configure the SSH key&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;em&gt;NOTE&lt;&#x2F;em&gt; Be sure to perform these steps as your user - not as root!&lt;&#x2F;p&gt;
&lt;p&gt;Initialise the tpm pkcs store - note the id in the output.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;tpm2_ptool init
&lt;&#x2F;span&gt;&lt;span&gt;# action: Created
&lt;&#x2F;span&gt;&lt;span&gt;# id: 1
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Using the id from the above output, you can use that to create a new
token. Note here that the userpin is the pin for using the ssh key. The
sopin is the recovery password incase you lose the pin and need to reset
it.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;tpm2_ptool addtoken --pid=1 --label=ssh --userpin=&amp;quot;&amp;quot; --sopin=&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;tpm2_ptool addkey --label=ssh --userpin=&amp;quot;&amp;quot; --algorithm=ecc256
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If you want to use a different key algorithm, other choices are rsa2048,
rsa3072, rsa4096, ecc256, ecc384, ecc521.&lt;&#x2F;p&gt;
&lt;p&gt;Now you can view the public key with:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ssh-keygen -D &#x2F;usr&#x2F;lib64&#x2F;pkcs11&#x2F;libtpm2_pkcs11.so.0
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;It&#x27;s a good idea to store this into a file for later:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ssh-keygen -D &#x2F;usr&#x2F;lib64&#x2F;pkcs11&#x2F;libtpm2_pkcs11.so.0 | tee ~&#x2F;.ssh&#x2F;id_ecdsa_tpm.pub
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;using-the-ssh-key&quot;&gt;Using the SSH Key&lt;&#x2F;h2&gt;
&lt;p&gt;You can modify your ssh configuration to always use the key. You will be
prompted for the userpin to access the ssh key as required.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# ~&#x2F;.ssh&#x2F;config
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;PKCS11Provider &#x2F;usr&#x2F;lib64&#x2F;pkcs11&#x2F;libtpm2_pkcs11.so.0
&lt;&#x2F;span&gt;&lt;span&gt;PasswordAuthentication no
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
</description>
      </item>
      <item>
          <title>How Hype Will Turn Your Security Key Into Junk</title>
          <pubDate>Thu, 02 Feb 2023 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2023-02-02-how-hype-will-turn-your-security-key-into-junk/</link>
          <guid>https://fy.blackhats.net.au/blog/2023-02-02-how-hype-will-turn-your-security-key-into-junk/</guid>
          <description>&lt;h1 id=&quot;how-hype-will-turn-your-security-key-into-junk&quot;&gt;How Hype Will Turn Your Security Key Into Junk&lt;&#x2F;h1&gt;
&lt;p&gt;In the last few months there has been a lot of hype about &amp;quot;passkeys&amp;quot;
and how they are going to change authentication forever. But that hype
will come at a cost.&lt;&#x2F;p&gt;
&lt;p&gt;Obsession with passkeys are about to turn your security keys (yubikeys,
feitian, nitrokeys, ...) into obsolete and useless junk.&lt;&#x2F;p&gt;
&lt;p&gt;It all comes down to one thing - resident keys.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-is-a-resident-key&quot;&gt;What is a Resident Key&lt;&#x2F;h2&gt;
&lt;p&gt;To understand the problem, we need to understand what a
discoverable&#x2F;resident key is.&lt;&#x2F;p&gt;
&lt;p&gt;You have probably seen that most keys support an &#x27;unlimited&#x27; number of
accounts. This is achieved by sending a &amp;quot;key wrapped key&amp;quot; to the
security key. When the Relying Party (Authentication Server) wants to
authenticate your security key, it will provide you a &amp;quot;credential id&amp;quot;.
That credential ID is an encrypted blob that only your security key can
decrypt. If your security key can decrypt that blob it yields a private
key that is specific to that single RP that you can use for signatures.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;┌────────────────┐            ┌────────────────┐          ┌────────────────┐ 
&lt;&#x2F;span&gt;&lt;span&gt;│ Relying Party  │      │     │    Browser     │     │    │  Security Key  │ 
&lt;&#x2F;span&gt;&lt;span&gt;└────────────────┘            └────────────────┘          └────────────────┘ 
&lt;&#x2F;span&gt;&lt;span&gt;                        │                            │                       
&lt;&#x2F;span&gt;&lt;span&gt;     1. Send                                                                 
&lt;&#x2F;span&gt;&lt;span&gt;   Credential ──────────┼───────▶                    │                       
&lt;&#x2F;span&gt;&lt;span&gt;       IDs                                                                   
&lt;&#x2F;span&gt;&lt;span&gt;                        │      2. Forward to─────────┼─────▶   3. Decrypt    
&lt;&#x2F;span&gt;&lt;span&gt;                               Security Key                   Credential ID  
&lt;&#x2F;span&gt;&lt;span&gt;                        │                            │       with Master Key 
&lt;&#x2F;span&gt;&lt;span&gt;                                                                    │        
&lt;&#x2F;span&gt;&lt;span&gt;                        │                            │              │        
&lt;&#x2F;span&gt;&lt;span&gt;                                                                    │        
&lt;&#x2F;span&gt;&lt;span&gt;                        │                            │              ▼        
&lt;&#x2F;span&gt;&lt;span&gt;                                                            4. Sign Challenge
&lt;&#x2F;span&gt;&lt;span&gt;                        │                            │       with Decrypted  
&lt;&#x2F;span&gt;&lt;span&gt;                                                                   Key       
&lt;&#x2F;span&gt;&lt;span&gt;                        │                            │              │        
&lt;&#x2F;span&gt;&lt;span&gt;                                                                    │        
&lt;&#x2F;span&gt;&lt;span&gt;                        │                            │              │        
&lt;&#x2F;span&gt;&lt;span&gt;                                                                    ▼        
&lt;&#x2F;span&gt;&lt;span&gt;                        │          6. Return  ◀──────┼───────── 5. Return    
&lt;&#x2F;span&gt;&lt;span&gt;                 ◀──────────────── Signature                    Signature    
&lt;&#x2F;span&gt;&lt;span&gt;                        │                            │                       
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This is what is called a non-resident or non-discoverable credential.
The reason is that the private key can &lt;em&gt;not be discovered&lt;&#x2F;em&gt; by the security
key without the Credential ID provided to it externally. This is because
the private keys are &lt;em&gt;not resident&lt;&#x2F;em&gt; inside the security enclave - only
the master key is.&lt;&#x2F;p&gt;
&lt;p&gt;Contrast to this, a resident key or discoverable credential is one where
the private key is &lt;em&gt;stored&lt;&#x2F;em&gt; in the security key itself. This allows the
security key to discover (hence the name) what private keys might be
used in the authentication.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;┌────────────────┐            ┌────────────────┐          ┌────────────────┐ 
&lt;&#x2F;span&gt;&lt;span&gt;│ Relying Party  │      │     │    Browser     │     │    │  Security Key  │ 
&lt;&#x2F;span&gt;&lt;span&gt;└────────────────┘            └────────────────┘          └────────────────┘ 
&lt;&#x2F;span&gt;&lt;span&gt;                        │                            │                       
&lt;&#x2F;span&gt;&lt;span&gt;  1. Send Empty                                                              
&lt;&#x2F;span&gt;&lt;span&gt;   CredID list──────────┼───────▶                    │                       
&lt;&#x2F;span&gt;&lt;span&gt;                                 2. Query  ───────────────▶                  
&lt;&#x2F;span&gt;&lt;span&gt;                        │      Security Key          │      3. Discover Keys 
&lt;&#x2F;span&gt;&lt;span&gt;                                                                 for RP      
&lt;&#x2F;span&gt;&lt;span&gt;                        │       4. Select a ◀────────┼─────                  
&lt;&#x2F;span&gt;&lt;span&gt;                               Security Key                                  
&lt;&#x2F;span&gt;&lt;span&gt;                        │                   ─────────┼────▶ 5. Sign Challenge
&lt;&#x2F;span&gt;&lt;span&gt;                                                            with Resident Key
&lt;&#x2F;span&gt;&lt;span&gt;                        │                            │             │         
&lt;&#x2F;span&gt;&lt;span&gt;                                                                   │         
&lt;&#x2F;span&gt;&lt;span&gt;                        │                            │             │         
&lt;&#x2F;span&gt;&lt;span&gt;                                                                   ▼         
&lt;&#x2F;span&gt;&lt;span&gt;                        │         7. Return  ◀───────┼──────── 6. Return     
&lt;&#x2F;span&gt;&lt;span&gt;                ◀──────────────── Signature                    Signature     
&lt;&#x2F;span&gt;&lt;span&gt;                        │                            │                       
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;                        │                            │                       
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;                        │                            │                       
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now, the primary difference here is that resident&#x2F;discoverable keys
consume &lt;em&gt;space&lt;&#x2F;em&gt; on the security key to store them since they need to
persist - there is no credential id to rely on to decrypt with our
master key!&lt;&#x2F;p&gt;
&lt;h3 id=&quot;are-non-resident-keys-less-secure&quot;&gt;Are non-resident keys less secure?&lt;&#x2F;h3&gt;
&lt;p&gt;A frequent question here is if non resident keys are less secure than
resident ones. Credential ID&#x27;s as key wrapped keys are secure since
they are encrypted with aes128 and hmaced. This prevents them being
tampered with or decrypted by an external source. If aes128 were broken
and someone could decrypt your private-key in abscence of your security
key, they probably could also break TLS encyrption, attack ssh and do
much worse. Your key wrapped keys rely on the same security features
that TLS relies on.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;how-does-userverification-factor-in-here&quot;&gt;How does userverification factor in here?&lt;&#x2F;h3&gt;
&lt;p&gt;Another frequent question (or confusion) is that a credential needs to be resident
to enforce userVerification. That&#x27;s not the case! Your device can assert not just
presence by touch, but that it&#x27;s really you holding the device by internally
validating a PIN or biometric. This is governed by the userVerification flags
which are seperate to residency. This allows your device to be &amp;quot;a self contained
multifactor authenticator&amp;quot;. Very cool!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;resident-keys-and-your-security-key&quot;&gt;Resident Keys and Your Security Key&lt;&#x2F;h2&gt;
&lt;p&gt;Now that we know what a resident key is, we can look at how these work
with your security keys.&lt;&#x2F;p&gt;
&lt;p&gt;Since resident keys store their key in the device, this needs to consume
&lt;em&gt;space&lt;&#x2F;em&gt; inside the security key. Generally, resident key slots are at a
premium on a security key. Nitrokeys for example only support 8 resident
keys. Yubikeys generally support between 20 and 32. Some keys support
&lt;em&gt;no&lt;&#x2F;em&gt; resident keys at all.&lt;&#x2F;p&gt;
&lt;p&gt;The other problem is what CTAP standard your key implements. There are
three versions - CTAP2.0, CTAP2.1PRE and CTAP2.1.&lt;&#x2F;p&gt;
&lt;p&gt;In CTAP2.1 (the latest) and CTAP2.1PRE you can individually manage, update and delete
specific resident keys from your device.&lt;&#x2F;p&gt;
&lt;p&gt;In CTAP2.0 however, you can not. You can not delete a
residentkey without &lt;em&gt;resetting the whole device&lt;&#x2F;em&gt;. Resetting the device
also resets your master key, meaning all your non-resident keys will no
longer work either. This makes resident keys on a CTAP2.0
device a serious commitment. You really don&#x27;t want to accidentally fill
up that limited space you have!&lt;&#x2F;p&gt;
&lt;p&gt;In most cases, your key is &lt;em&gt;very likely&lt;&#x2F;em&gt; to be CTAP2.0. For example
some manufacturers like yubico, they&#x27;re keys CTAP version is defined
by their firmware version. I have multiple yk5 series keys that have
different levels of CTAP support.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;so-why-are-resident-keys-a-problem&quot;&gt;So Why Are Resident Keys a Problem?&lt;&#x2F;h2&gt;
&lt;p&gt;On their own, and used carefully resident keys are great for certain
applications. The problem is the hype and obsession with &lt;em&gt;passkeys&lt;&#x2F;em&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;In 2022 Apple annouced their passkeys feature on MacOS&#x2F;iOS allowing the
use of touchid&#x2F;faceid as a webauthn authenticator similar to your
security key. Probably quite wisely, rather than calling them
&amp;quot;touchid&amp;quot; or &amp;quot;credentials&amp;quot; or &amp;quot;authenticators&amp;quot; Apple chose to have
a nicer name for users. Honestly passkeys is a good name rather than
&amp;quot;webauthn authenticator&amp;quot; or &amp;quot;security key&amp;quot;. It evokes a similar
concept to passwords which people are highly accustomed to, while also
being different enough with the &#x27;key&#x27; to indicate that it operates in
a different way.&lt;&#x2F;p&gt;
&lt;p&gt;The problem (from an external view) is that passkeys was a branding or
naming term of something - but overnight authentication thought leaders
needed to be &lt;em&gt;on the hype&lt;&#x2F;em&gt;. &amp;quot;What is a passkey?&amp;quot;. Since Apple didn&#x27;t
actually define it, this left a void for our thought leaders to answer
that question for users hungry to know &amp;quot;what indeed is a passkey?&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;As a creator of a relying party and the webauthn library for Rust, we
defined passkeys as the name for &amp;quot;all possible authenticators&amp;quot; that a
person may choose to use. We wanted to support the goal to remove and
eliminate passwords, and passkeys are a nice name for this.&lt;&#x2F;p&gt;
&lt;p&gt;Soon after that, some community members took to referring to passkeys to
mean &amp;quot;credentials that are synchronised between multiple devices&amp;quot;.
This definition is at the least, not harmful, even if it doesn&#x27;t
express that there are many possible types of authenticators that can be
used.&lt;&#x2F;p&gt;
&lt;p&gt;Some months later a person took the stage at FIDO&#x27;s Authenticate
conference and annouced &amp;quot;a passkey is a resident key&amp;quot;. Because of the
scale and size of the platform, this definition has now stuck. This
definition has become so invasive that even &lt;em&gt;FIDO&lt;&#x2F;em&gt; now use it as &lt;a href=&quot;https:&#x2F;&#x2F;fidoalliance.org&#x2F;passkeys&#x2F;#faq&quot;&gt;their
definition&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;Part of the reason this definition is hyped is because it works with an
upcoming browser feature that allows autocomplete of a username and
webauthn credential if the key is resident. You don&#x27;t have to type your
username. This now means that we have webauthn libraries pushing for
residentkey as a requirement for all registrations, and many people will
follow this advice without seeing the problem.&lt;&#x2F;p&gt;
&lt;p&gt;The problem is that security keys with their finite storage and lack of
credential management will fill up &lt;em&gt;rapidly&lt;&#x2F;em&gt;. In my password manager I
have more than 150 stored passwords. If all of these were to become
resident keys I would need to buy at least 5 yubikeys to store all the
accounts, and then another 5-10 as &amp;quot;backups&amp;quot;. I really don&#x27;t want to
have to juggle and maintain 10 to 15 yubikeys ...&lt;&#x2F;p&gt;
&lt;p&gt;This is an awful user experience to put it mildly. People who choose to
use security keys, now won&#x27;t be able to due to passkeys resident key
requirements. What will also confuse users is this comes on the tail of
FIDO certified keys marketing with statements (which are true with
non-resident keys) like:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;Infinite key pair storage&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;There is no limit to the number of accounts registered in [redacted]
FIDO® Security Key.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;To add further insult, an expressed goal of the Webauthn Work Group is
that users should always be free to choose any authenticator they wish
without penalty. Passkeys forcing key residency flies directly in the
face of this.&lt;&#x2F;p&gt;
&lt;p&gt;This leaves few authenticator types which will work properly in this
passkey world. Apples own passkeys, Android passkeys, password managers
that support webauthn, Windows with TPM 2.0, and Chromium based browsers
on MacOS (because of how they use the touchid as a TPM).&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-can-be-done&quot;&gt;What Can Be Done?&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;submit-to-the-webauth-wg-browsers-to-change-rk-preferred-to-exclude-security-keys&quot;&gt;Submit to the Webauth WG &#x2F; Browsers to change rk=preferred to exclude security keys&lt;&#x2F;h3&gt;
&lt;p&gt;Rather than passkeys being resident keys, passkeys could be expanded to
be all possible authenticators where some subset opportunistically are
resident. This puts passwordless front and center with residency as a
bonus ui&#x2F;ux for those who opt to use devices that support unlimited
resident keys.&lt;&#x2F;p&gt;
&lt;p&gt;Currently there are three levels of request an RP can make to request
resident keys. Discouraged, Preferred and Required. Here is what happens
with different authenticator types when you submit each level.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;                           ┌────────────────────┬────────────────────┬────────────────────┐
&lt;&#x2F;span&gt;&lt;span&gt;                           │      Roaming       │      Platform      │      Platform      │
&lt;&#x2F;span&gt;&lt;span&gt;                           │   Authenticator    │   Authenticator    │   Authenticator    │
&lt;&#x2F;span&gt;&lt;span&gt;                           │     (Yubikey)      │(Android Behaviour) │  (iOS Behaviour)   │
&lt;&#x2F;span&gt;&lt;span&gt;                           └────────────────────┴────────────────────┴────────────────────┘
&lt;&#x2F;span&gt;&lt;span&gt;    ┌────────────────────┐ ┌────────────────────┬────────────────────┬────────────────────┐
&lt;&#x2F;span&gt;&lt;span&gt;    │                    │ │                    │                    │                    │
&lt;&#x2F;span&gt;&lt;span&gt;    │   rk=discouraged   │ │      RK false      │     RK false       │      RK true       │
&lt;&#x2F;span&gt;&lt;span&gt;    │                    │ │                    │                    │                    │
&lt;&#x2F;span&gt;&lt;span&gt;    ├────────────────────┤ ├────────────────────┼────────────────────┼────────────────────┤
&lt;&#x2F;span&gt;&lt;span&gt;    │                    │ │                    │                    │                    │
&lt;&#x2F;span&gt;&lt;span&gt;    │   rk=preferred     │ │      RK true (!)   │      RK true       │      RK true       │
&lt;&#x2F;span&gt;&lt;span&gt;    │                    │ │                    │                    │                    │
&lt;&#x2F;span&gt;&lt;span&gt;    ├────────────────────┤ ├────────────────────┼────────────────────┼────────────────────┤
&lt;&#x2F;span&gt;&lt;span&gt;    │                    │ │                    │                    │                    │
&lt;&#x2F;span&gt;&lt;span&gt;    │    rk=required     │ │      RK true       │      RK true       │      RK true       │
&lt;&#x2F;span&gt;&lt;span&gt;    │                    │ │                    │                    │                    │
&lt;&#x2F;span&gt;&lt;span&gt;    └────────────────────┘ └────────────────────┴────────────────────┴────────────────────┘
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Notice that in rk=preferred the three columns behave the same as
rk=required?&lt;&#x2F;p&gt;
&lt;p&gt;Rather than passkeys setting rk=required, if rk=preferred were softened
so that on preferred meant &amp;quot;create a resident key only if storage is
unlimited&amp;quot; then we would have a situation where Android&#x2F;iOS would
always get resident keys, and security keys would not have space
consumed.&lt;&#x2F;p&gt;
&lt;p&gt;However, so far the WG is resistant to this change. It is not out of the
question that browsers could implement this change externally, but that
would in reality be down to the chrome team to decide.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;insist-on-your-passkey-library-setting-rk-discouraged&quot;&gt;Insist on your Passkey library setting rk=discouraged&lt;&#x2F;h3&gt;
&lt;p&gt;Rather than rk=required which excludes security keys, rk=discouraged is
the next best thing. Yes it means that android users won&#x27;t get
conditional UI. But what do we prefer - some people have to type a
username (that already has provisions to autocomplete anyway). Or do we
damage and exclude security keys completely?&lt;&#x2F;p&gt;
&lt;h3 id=&quot;contact-fido-and-request-rk-storage-as-a-certification-feature&quot;&gt;Contact FIDO and request RK storage as a certification feature&lt;&#x2F;h3&gt;
&lt;p&gt;Currently FIDO doesn&#x27;t mandate any amount of storage requirements for
certified devices. Given that FIDO also seem to want resident keys, then
they should also mandate that certified devices have the ability to
store thousands of resident keys. This way as a consumer you can pick
and select certified devices.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;something-else&quot;&gt;Something Else?&lt;&#x2F;h3&gt;
&lt;p&gt;If you have other ideas on how to improve this let me know!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;&#x2F;h2&gt;
&lt;p&gt;The hype around passkeys being resident keys will prevent - or severly
hinder - users of security keys from choosing the authenticator they
want to use online in the future.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Why are PBKDF2-SHA256 and PBKDF2_SHA256 different in 389-ds?</title>
          <pubDate>Fri, 25 Nov 2022 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2022-11-25-why-are-pbkdf2-sha256-and-pbkdf2-sha256-different-in-389-ds/</link>
          <guid>https://fy.blackhats.net.au/blog/2022-11-25-why-are-pbkdf2-sha256-and-pbkdf2-sha256-different-in-389-ds/</guid>
          <description>&lt;h1 id=&quot;why-are-pbkdf2-sha256-and-pbkdf2-sha256-different-in-389-ds&quot;&gt;Why are PBKDF2-SHA256 and PBKDF2_SHA256 different in 389-ds?&lt;&#x2F;h1&gt;
&lt;p&gt;In a mailing list discussion recently it came up about what password
hash format should you use in 389-ds. Confusingly we have two PBKDF2
SHA256 implementations, which has a bit of history.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;too-lazy-didn-t-read&quot;&gt;Too Lazy, Didn&#x27;t Read&lt;&#x2F;h2&gt;
&lt;p&gt;Use PBKDF2-SHA256. (hyphen, not underscore).&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-s-pbkdf2-anyway&quot;&gt;What&#x27;s PBKDF2 anyway?&lt;&#x2F;h2&gt;
&lt;p&gt;Passwords are a shared-knowledge secret, so knowledge of the password
allows you to authenticate as the person. When we store that secret, we
don&#x27;t want it stored in a form where a person can steal and use it.
This is why we don&#x27;t store passwords cleartext - A rogue admin or a
database breach would leak your passwords (and people do love to re-use
their passwords over many websites ...)&lt;&#x2F;p&gt;
&lt;p&gt;Because of this authentication experts recommend &lt;em&gt;hashing&lt;&#x2F;em&gt; your
password. A one-way hash function given an input, will always produce
the same output, but given the hash output, you can not derive the
input.&lt;&#x2F;p&gt;
&lt;p&gt;However, this also isn&#x27;t the full story. Simply hashing your password
isn&#x27;t enough because people have found many other attacks. These
include things like rainbow tables which are a compressed and
precomputed &amp;quot;lookup&amp;quot; of hash outputs to their inputs. You can also
bruteforce dictionaries of common passwords to see if they match. All of
these processes for an attacker use their CPU to generate these tables
or bruteforce the passwords.&lt;&#x2F;p&gt;
&lt;p&gt;Most hashes though are designed to be &lt;em&gt;fast&lt;&#x2F;em&gt; and in many cases your CPU
has hardware to accelerate and speed these up. All this does is mean
that if you use a &lt;em&gt;verification hash&lt;&#x2F;em&gt; for storing passwords then an
attacker just can attack your stored passwords even faster.&lt;&#x2F;p&gt;
&lt;p&gt;To combat this, what authentication experts truly recommend is &lt;em&gt;key
derivation functions&lt;&#x2F;em&gt;. A key derivation function is similar to a hash
where an input always yields the same output, but a KDF also intends to
be resource consuming. This can be ram or cpu time for example. The
intent is that an attacker bruteforcing your KDF hashed passwords should
have to expend a large amount of CPU time and resources, while also
producing far fewer results.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;how-is-this-related-to-vs&quot;&gt;How is this related to - vs _?&lt;&#x2F;h2&gt;
&lt;p&gt;In 389-ds when I implemented PBKDF2_SHA256 I specifically chose to use
the &#x27;_&#x27; (underscore) to not conflict to &#x27;-&#x27; which is the OpenLDAP
PBKDF2 scheme. We have differences in how we store our PBKDF2_SHA256 in
the userPassword value so they aren&#x27;t compatible. At the time since I
was writing the module in C it was easier to use our own internal format
than to attempt C String manipulation which is a common source of
vulnerabilities. I opted to use a binary array with fixed lengths and
offsets so that we could do bound checks rather than attempting to split
a string with delimiters (and yes, I accounted for endianness in the
design).&lt;&#x2F;p&gt;
&lt;p&gt;The issue however is that after we implemented this we ran into a
problem with NSS (the cryptographic library) that 389-ds uses. NSS
PBKDF2 implementation is flawed, and is 4 times slower (I think, I
can&#x27;t find the original report from RedHat Bugzilla) than OpenSSL for
the same result. This means that for 389-ds to compute a password hash
in say ... 1 second, OpenSSL can do the same in 0.25 seconds. Since we
have response time objectives we wish to meet, this forced 389-ds to use
fewer PBKDF2 rounds, well below the NIST SP800-63b recommendations.&lt;&#x2F;p&gt;
&lt;p&gt;For a long time we accepted this because it was still a significant
improvement over our previous salted sha256 single round implementation,
and we hoped the NSS developers would resolve the issue. However, they
did not fix it and did not accept it was a security issue.&lt;&#x2F;p&gt;
&lt;p&gt;Since then, we&#x27;ve added support for Rust into 389-ds and had a growing
interest to migrate from OpenLDAP to 389-ds. To support this, I added
support for OpenLDAP formatted password hashes to be directly imported
to 389-ds with a Rust plugin called pwdchan that is now part of 389-ds
by default. In this plugin we used the OpenSSL cryptographic provider
which does not have the same limitations as NSS, meaning we can increase
the number of PBKDF2 rounds to the NIST SP800-63b recommendations
without sacrificing large amounts of (wasted) CPU time.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;&#x2F;h2&gt;
&lt;p&gt;Use PBKDF2-SHA256.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;It&#x27;s written in Rust.&lt;&#x2F;li&gt;
&lt;li&gt;It meets NIST SP800-63b recommendations.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</description>
      </item>
      <item>
          <title>Why Decentralised ID Won&#x27;t Work</title>
          <pubDate>Thu, 17 Nov 2022 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2022-11-17-why-decentralised-id-won-t-work/</link>
          <guid>https://fy.blackhats.net.au/blog/2022-11-17-why-decentralised-id-won-t-work/</guid>
          <description>&lt;h1 id=&quot;why-decentralised-id-won-t-work&quot;&gt;Why Decentralised ID Won&#x27;t Work&lt;&#x2F;h1&gt;
&lt;p&gt;Thanks to a number of &lt;a href=&quot;https:&#x2F;&#x2F;www.abc.net.au&#x2F;news&#x2F;2022-09-27&#x2F;optus-data-breach-cyber-attack-hacker-ransom-sorry&#x2F;101476316&quot;&gt;high
profile&lt;&#x2F;a&gt;
and damaging &lt;a href=&quot;https:&#x2F;&#x2F;www.abc.net.au&#x2F;news&#x2F;2022-11-09&#x2F;medibank-data-release-dark-web-hackers&#x2F;101632088&quot;&gt;security
incidents&lt;&#x2F;a&gt;
in Australia people have once again been discussing Decentralised ID
(DID). As someone who has spent most of the career working on identity
management, I&#x27;m here to tell you why &lt;em&gt;it will not work&lt;&#x2F;em&gt;.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-is-decentralised-id-trying-to-do&quot;&gt;What Is Decentralised ID Trying To Do?&lt;&#x2F;h2&gt;
&lt;p&gt;To understand what DID is trying to achieve we have to look at what a
&amp;quot;centralised&amp;quot; system is doing.&lt;&#x2F;p&gt;
&lt;p&gt;Lets consider an account holder like Google. You create an account with
them, and you store your name and some personal data, as well as a
method of authentication, such as a password and OTP, or Webauthn.&lt;&#x2F;p&gt;
&lt;p&gt;Now you go to some other website and it says &amp;quot;login with Google&amp;quot;. That
site redirects to Google, who authenticates you, and then the website
trusts Google to say &amp;quot;yes or no&amp;quot; that &amp;quot;you are who you say you are&amp;quot;.
You can consent to this website seeing details about you like an email
address or name.&lt;&#x2F;p&gt;
&lt;p&gt;A decentralised system works differently. You present a signed metadata
statement about yourself to the website, and that cryptograhic signature
can be traced back to your signing private key. This cryptograhic proof
attests that you are the profile&#x2F;account holder.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-does-did-claim-to-achieve&quot;&gt;What Does DID Claim To Achieve?&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;That you are the only authority who can modify your own identity and
data.&lt;&#x2F;li&gt;
&lt;li&gt;You control who can access (view) that data.&lt;&#x2F;li&gt;
&lt;li&gt;Cryptographic verification that an identity is who they claim to be.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;this-will-never-work&quot;&gt;This Will Never Work&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;no-consideration-of-human-behaviour&quot;&gt;No Consideration Of Human Behaviour&lt;&#x2F;h3&gt;
&lt;p&gt;DID systems do not consider human behaviour in their design.&lt;&#x2F;p&gt;
&lt;p&gt;I can not put it better, than &lt;a href=&quot;https:&#x2F;&#x2F;bradleymonk.com&#x2F;w&#x2F;images&#x2F;9&#x2F;91&#x2F;The_truth_about_Unix_Don_Norman.pdf&quot;&gt;Don Norman, in his paper &amp;quot;The Truth
about
Unix&amp;quot;&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;System designers take note. Design the system for the person, not for
the computer, not even for yourself. People are also information
processing systems, with varying degrees of knowledge, varying degrees
of experience. Friendly systems treat users as intelligent adults who,
like normal adults, are forgetful, distracted, thinking of other things,
and not quite as knowledgeable about the world as they themselves would
like to be.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;People are not &amp;quot;stupid&amp;quot;. They are distracted and busy. This means they
will lose their keys. They will be affected by &lt;a href=&quot;https:&#x2F;&#x2F;www.abc.net.au&#x2F;news&#x2F;2022-02-28&#x2F;qld-flood-brisbane-residents-assess-damage&#x2F;100869034&quot;&gt;events out of their
control&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;In a centralised system there are ways to recover your account when you
lose your password&#x2F;keys. There are systems to verify you, and help you
restore from damage.&lt;&#x2F;p&gt;
&lt;p&gt;In a DID system, if you lose your key, you lose everything. There is no
recovery process.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;gpg-already-failed&quot;&gt;GPG Already Failed&lt;&#x2F;h3&gt;
&lt;p&gt;DID is effectively a modern rehash of GPG - including it&#x27;s problems.
&lt;a href=&quot;https:&#x2F;&#x2F;latacora.micro.blog&#x2F;2019&#x2F;07&#x2F;16&#x2F;the-pgp-problem.html&quot;&gt;Many others
have&lt;&#x2F;a&gt;
lamented &lt;a href=&quot;https:&#x2F;&#x2F;words.filippo.io&#x2F;giving-up-on-long-term-pgp&#x2F;&quot;&gt;at length
about&lt;&#x2F;a&gt;. These
people have spent their lives studying cryptograhpic systems, and they
have given up on it. Pretty much every issue they report here, applies
to DID and all it&#x27;s topics.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;long-term-keys&quot;&gt;Long Term Keys&lt;&#x2F;h3&gt;
&lt;p&gt;One of the biggest issues in DID is that the identity is rooted in a
private key that is held by an individual. This encourages long-term
keys, which have a large blast radius (complete take over of your
identity). This causes dramatic failure modes. To further this, it also
prevents improvement of the cryptograhic quality of the key. When I
started in IT RSA 1024 bit was secure. Now it&#x27;s not. Keys need to be
short lived and disposable.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;you-won-t-own-your-own-data&quot;&gt;You Won&#x27;t Own Your Own Data&lt;&#x2F;h3&gt;
&lt;p&gt;When you send a DID signed document to a provider, lets say your Bank to
open a new account, what do you think they will do with that data?&lt;&#x2F;p&gt;
&lt;p&gt;They won&#x27;t destroy it and ask you for it every time you need it. They
will store a copy on their servers for their records. There are often
&lt;em&gt;extremely good reasons&lt;&#x2F;em&gt; they need to store that data as well.&lt;&#x2F;p&gt;
&lt;p&gt;Which means that your signed document of data is performative, and the
data will just be used and extracted as usual.&lt;&#x2F;p&gt;
&lt;p&gt;DID does not solve the problem of data locality or retention. Regulation
and oversight does.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;trust-is-a-social-problem&quot;&gt;Trust Is A Social Problem&lt;&#x2F;h3&gt;
&lt;p&gt;You can&#x27;t solve social problems with technology.&lt;&#x2F;p&gt;
&lt;p&gt;The whole point of DID is about solving &lt;em&gt;trust&lt;&#x2F;em&gt;. Who do you &lt;em&gt;trust&lt;&#x2F;em&gt; to
store (modify) or view your personal information?&lt;&#x2F;p&gt;
&lt;p&gt;In a DID world, you need to be &amp;quot;your own personal central data
authority&amp;quot; (because apparently you can&#x27;t trust anyone else). That
means you need to store your data, protect it from destruction and
secure it from compromise.&lt;&#x2F;p&gt;
&lt;p&gt;In the current world, for all of Google&#x27;s and many other companies
flaws, they still have dedicated security teams, specialists in risk
analysis, and people who have dedicated themselves to protecting your
accounts and your data.&lt;&#x2F;p&gt;
&lt;p&gt;The problem is that most software engineers fall into the fallacy that
because they are an expert in their subject matter, they are now an
expert on identity and computer security. They are likely not security
experts (the same people love to mansplain authentication to me
frequently, and generally this only serves to inform me that they
actually do not understand authentication).&lt;&#x2F;p&gt;
&lt;p&gt;Why should anyone trust your DID account, when you likely have no data
hygiene and insecure key storage? Why should a Bank? Why should Google?
Your workplace? No one has a reason to trust you and your signatures.&lt;&#x2F;p&gt;
&lt;p&gt;Yes there are problems with centralised identity systems - but DID does
not address them, and actually may make them significantly worse.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;your-verification-mark-means-nothing&quot;&gt;Your Verification Mark Means Nothing&lt;&#x2F;h3&gt;
&lt;p&gt;Some DID sites claim things like &amp;quot;being able to prove ownership of an
account&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;How does this proof work? Can people outside of the DID community
explain these proofs? Can your accountant? You Taxi driver?&lt;&#x2F;p&gt;
&lt;p&gt;What this will boil down to a green tick that people will trust. It
doesn&#x27;t take a lot of expertise to realise that the source code for
this tick can be faked pretty easily since it&#x27;s simply a boolean check.&lt;&#x2F;p&gt;
&lt;p&gt;These verification marks come back to &amp;quot;trust&amp;quot;, which DID does not
solve. You need to &lt;em&gt;trust&lt;&#x2F;em&gt; the site you are viewing to render things in
a certain way, the same way you have to &lt;em&gt;trust&lt;&#x2F;em&gt; them not to go and
impersonate you.&lt;&#x2F;p&gt;
&lt;p&gt;Even if you made a DID private key with ED25519 and signed some toots,
Mastodon instance owners could still impersonate you if they wanted.&lt;&#x2F;p&gt;
&lt;p&gt;And to further this, how is the average person expected to verify your
signatures? HTTPS has already shown that the majority of the public does
not have the specific indepth knowledge to assess the legitimacy of a
certificate authority. How are we expecting people to now verify every
other person as their own CA?&lt;&#x2F;p&gt;
&lt;p&gt;The concept of web of trust is a performative act.&lt;&#x2F;p&gt;
&lt;p&gt;Even &lt;a href=&quot;https:&#x2F;&#x2F;xkcd.com&#x2F;1181&#x2F;&quot;&gt;XKCD nailed this&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;&#x2F;h2&gt;
&lt;p&gt;DID won&#x27;t work.&lt;&#x2F;p&gt;
&lt;p&gt;There are certainly issues with central authorities, and DID solves none
of them.&lt;&#x2F;p&gt;
&lt;p&gt;It is similar to &lt;a href=&quot;&#x2F;blog&#x2F;html&#x2F;2021&#x2F;05&#x2F;12&#x2F;compiler_bootstrapping_can_we_trust_rust.html&quot;&gt;bootstraping
compilers&lt;&#x2F;a&gt;.
It is a problem that is easy to articulate, emotionally catchy, requires
widespread boring social solutions, but tech bros try to solve it
unendingly with hyper-complex-technical solutions that won&#x27;t work.&lt;&#x2F;p&gt;
&lt;p&gt;You&#x27;re better off just adding FIDO2 keys to your accounts and moving
on.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Where to start with linux authentication?</title>
          <pubDate>Wed, 24 Aug 2022 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2022-08-24-where-to-start-with-linux-authentication/</link>
          <guid>https://fy.blackhats.net.au/blog/2022-08-24-where-to-start-with-linux-authentication/</guid>
          <description>&lt;h1 id=&quot;where-to-start-with-linux-authentication&quot;&gt;Where to start with linux authentication?&lt;&#x2F;h1&gt;
&lt;p&gt;Recently I was asked about where someone could learn how linux
authentication works as a &amp;quot;big picture&amp;quot; and how all the parts
communicate. There aren&#x27;t too many great resources on this sadly, so
I&#x27;ve decided to write this up.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;who-are-you&quot;&gt;Who ... are you?&lt;&#x2F;h2&gt;
&lt;p&gt;The first component in linux identity is NSS or nsswitch (not to be
confused with NSS the cryptography library ... ). nsswitch (name
service switch) is exposed by glibc as a method to resolve uid&#x2F;gid
numbers and names and to then access details of the account. nsswitch
can have &amp;quot;modules&amp;quot; that are stacked, where the first module with an
answer, provides the response.&lt;&#x2F;p&gt;
&lt;p&gt;An example of nsswitch.conf is:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;passwd: compat sss
&lt;&#x2F;span&gt;&lt;span&gt;group:  compat sss
&lt;&#x2F;span&gt;&lt;span&gt;shadow: compat sss
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;hosts:      files mdns dns
&lt;&#x2F;span&gt;&lt;span&gt;networks:   files dns
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;services:   files usrfiles
&lt;&#x2F;span&gt;&lt;span&gt;protocols:  files usrfiles
&lt;&#x2F;span&gt;&lt;span&gt;rpc:        files usrfiles
&lt;&#x2F;span&gt;&lt;span&gt;ethers:     files
&lt;&#x2F;span&gt;&lt;span&gt;netmasks:   files
&lt;&#x2F;span&gt;&lt;span&gt;netgroup:   files nis
&lt;&#x2F;span&gt;&lt;span&gt;publickey:  files
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;bootparams: files
&lt;&#x2F;span&gt;&lt;span&gt;automount:  files nis
&lt;&#x2F;span&gt;&lt;span&gt;aliases:    files
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This is of the format &amp;quot;service: module module ...&amp;quot;. An example here
is when a program does &amp;quot;gethostbyname&amp;quot; (a dns lookup) it accesses the
&amp;quot;host&amp;quot; service, then resolves via files (&#x2F;etc&#x2F;hosts) then mdns (aka
avahi, bonjour), and then dns.&lt;&#x2F;p&gt;
&lt;p&gt;The three lines that matter for identities though, are passwd, group,
and shadow. Most commonly you will use the [files]{.title-ref} module
which uses [&#x2F;etc&#x2F;passwd]{.title-ref} and [&#x2F;etc&#x2F;shadow]{.title-ref} to
satisfy requests. The [compat]{.title-ref} module is identical but with
some extra syntaxes allowed for NIS compatibility. Another common module
in nsswitch is [sss]{.title-ref} which accesses System Services Security
Daemon (SSSD). For my own IDM projects we use the [kanidm]{.title-ref}
nsswitch module.&lt;&#x2F;p&gt;
&lt;p&gt;You can test these with calls to [getent]{.title-ref} to see how
nsswitch is resolving some identity, for example:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# getent passwd william
&lt;&#x2F;span&gt;&lt;span&gt;william:x:654401105:654401105:William:&#x2F;home&#x2F;william:&#x2F;bin&#x2F;zsh
&lt;&#x2F;span&gt;&lt;span&gt;# getent passwd 654401105
&lt;&#x2F;span&gt;&lt;span&gt;william:x:654401105:654401105:William:&#x2F;home&#x2F;william:&#x2F;bin&#x2F;zsh
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# getent group william
&lt;&#x2F;span&gt;&lt;span&gt;william:x:654401105:william
&lt;&#x2F;span&gt;&lt;span&gt;# getent group 654401105
&lt;&#x2F;span&gt;&lt;span&gt;william:x:654401105:william
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Notice that both the uid (name) and uidnumber work to resolve the
identity.&lt;&#x2F;p&gt;
&lt;p&gt;These modules are dynamic libraries, and you can find them with:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# ls -al &#x2F;usr&#x2F;lib[64]&#x2F;libnss_*
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;When a process wishes to resole something with nsswitch, the calling
process (for example apache) calls to glibc which then loads these
dylibs at runtime, and they are executed and called. This is often why
the addition of new nsswitch modules in a distro is guarded and audited
because these modules can end up in &lt;em&gt;every&lt;&#x2F;em&gt; processes memory space! This
also has impacts on security as every module, and by inheritence every
process, may need access [&#x2F;etc&#x2F;passwd]{.title-ref} or the network to do
resolution of identities. Some modules improve this situation like sss,
and we will give that it&#x27;s own section of this blog.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;prove-yourself&quot;&gt;Prove yourself!&lt;&#x2F;h2&gt;
&lt;p&gt;If nsswitch answers &amp;quot;who are you&amp;quot;, then pam (pluggable authentication
modules) is &amp;quot;prove yourself&amp;quot;. It&#x27;s what actually checks if your
credentials are valid and can login or not. Pam works by having
&amp;quot;services&amp;quot; that contact (you guessed it) modules. Most linux distros
have a folder (&#x2F;etc&#x2F;pam.d&#x2F;) which contains all the service definitions
(there is a subtely different syntax in &#x2F;etc&#x2F;pam.conf which is not often
used in linux). So lets consider when you ssh to a machine. ssh contacts
pam and says &amp;quot;I am the ssh service, can you please authorise this
identity for me&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;Because this is the &amp;quot;ssh service&amp;quot; pam will open the named config,
&#x2F;etc&#x2F;pam.d&#x2F;SERVICE_NAME, in this case &#x2F;etc&#x2F;pam.d&#x2F;ssh. This example is
taken from Fedora, because Fedora and RHEL are very common
distributions. Every distribution has their own &amp;quot;tweaks&amp;quot; and variants
to these files, which certainly helps to make the landscape even more
confusing.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# cat &#x2F;etc&#x2F;pam.d&#x2F;ssh
&lt;&#x2F;span&gt;&lt;span&gt;#%PAM-1.0
&lt;&#x2F;span&gt;&lt;span&gt;auth       include      system-auth
&lt;&#x2F;span&gt;&lt;span&gt;account    include      system-auth
&lt;&#x2F;span&gt;&lt;span&gt;password   include      system-auth
&lt;&#x2F;span&gt;&lt;span&gt;session    optional     pam_keyinit.so revoke
&lt;&#x2F;span&gt;&lt;span&gt;session    required     pam_limits.so
&lt;&#x2F;span&gt;&lt;span&gt;session    include      system-auth
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Note the &amp;quot;include&amp;quot; line that is repeated four times for auth, account,
password and session. These include system-auth, so lets look at that.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# cat &#x2F;etc&#x2F;pam.d&#x2F;system-auth
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;auth        required                                     pam_env.so
&lt;&#x2F;span&gt;&lt;span&gt;auth        required                                     pam_faildelay.so delay=2000000
&lt;&#x2F;span&gt;&lt;span&gt;auth        [default=1 ignore=ignore success=ok]         pam_usertype.so isregular
&lt;&#x2F;span&gt;&lt;span&gt;auth        [default=1 ignore=ignore success=ok]         pam_localuser.so
&lt;&#x2F;span&gt;&lt;span&gt;auth        sufficient                                   pam_unix.so nullok
&lt;&#x2F;span&gt;&lt;span&gt;auth        [default=1 ignore=ignore success=ok]         pam_usertype.so isregular
&lt;&#x2F;span&gt;&lt;span&gt;auth        sufficient                                   pam_sss.so forward_pass
&lt;&#x2F;span&gt;&lt;span&gt;auth        required                                     pam_deny.so
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;account     required                                     pam_unix.so
&lt;&#x2F;span&gt;&lt;span&gt;account     sufficient                                   pam_localuser.so
&lt;&#x2F;span&gt;&lt;span&gt;account     sufficient                                   pam_usertype.so issystem
&lt;&#x2F;span&gt;&lt;span&gt;account     [default=bad success=ok user_unknown=ignore] pam_sss.so
&lt;&#x2F;span&gt;&lt;span&gt;account     required                                     pam_permit.so
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;session     optional                                     pam_keyinit.so revoke
&lt;&#x2F;span&gt;&lt;span&gt;session     required                                     pam_limits.so
&lt;&#x2F;span&gt;&lt;span&gt;-session    optional                                     pam_systemd.so
&lt;&#x2F;span&gt;&lt;span&gt;session     [success=1 default=ignore]                   pam_succeed_if.so service in crond quiet use_uid
&lt;&#x2F;span&gt;&lt;span&gt;session     required                                     pam_unix.so
&lt;&#x2F;span&gt;&lt;span&gt;session     optional                                     pam_sss.so
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;password    requisite                                    pam_pwquality.so local_users_only
&lt;&#x2F;span&gt;&lt;span&gt;password    sufficient                                   pam_unix.so yescrypt shadow nullok use_authtok
&lt;&#x2F;span&gt;&lt;span&gt;password    sufficient                                   pam_sss.so use_authtok
&lt;&#x2F;span&gt;&lt;span&gt;password    required                                     pam_deny.so
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;So, first we are in the &amp;quot;auth phase&amp;quot;. This is where pam will check the
auth modules for your username and password (or other forms of
authentication) until a success is returned. We start at
[pam_env.so]{.title-ref}, that &amp;quot;passes but isn&#x27;t finished&amp;quot; so we go
to faildelay etc. Each of these modules is consulted in turn, with the
result of the module, and the &amp;quot;rule&amp;quot; (required, sufficient or custom)
being smooshed together to create &amp;quot;success and we are complete&amp;quot;,
&amp;quot;success but keep going&amp;quot;, &amp;quot;fail but keep going&amp;quot; or &amp;quot;fail and we are
complete&amp;quot;. In this example, the only modules that can actually
authenticate a user are [pam_unix.so]{.title-ref} and
[pam_sss.so]{.title-ref}, and if neither of them provide a &amp;quot;success and
complete&amp;quot;, then [pam_deny.so]{.title-ref} is hit which always yields a
&amp;quot;fail and complete&amp;quot;. This phase however has only verified your
&lt;em&gt;credentials&lt;&#x2F;em&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;The second phase is the &amp;quot;account phase&amp;quot; which really should be
&amp;quot;authorisation&amp;quot;. The modules are checked once again, to determine if
the module will allow or deny access to your user account to access this
system. Similar rules apply where each modules result and the rules of
the config combine to create a success&#x2F;fail and continue&#x2F;complete
result.&lt;&#x2F;p&gt;
&lt;p&gt;The third phase is the &amp;quot;session phase&amp;quot;. Each pam module can influence
and setup things into the newly spawned session of the user. An example
here is you can see [pam_limits.so]{.title-ref} which is what applies
cpu&#x2F;memory&#x2F;filedescriptor limits to the created shell session.&lt;&#x2F;p&gt;
&lt;p&gt;The fourth module is &amp;quot;password&amp;quot;. This isn&#x27;t actually used in the
authentication process - this stack is called when you issue the
&amp;quot;passwd&amp;quot; command to update the users password. Each module is
consulted in turn for knowledge of the account, and if they are able to
alter the credentials. If this fails you will recieve a generic
&amp;quot;authentication token manipulation error&amp;quot;, which really just means
&amp;quot;some module in the stack failed, but we wont tell you which&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;Again, these modules are all dylibs and can be found commonly in
[&#x2F;usr&#x2F;lib64&#x2F;security&#x2F;]{.title-ref}. Just like nsswitch, applications
that use pam are linked to [libpam.so]{.title-ref}, which inturn with
load modules from [&#x2F;usr&#x2F;lib64&#x2F;security&#x2F;]{.title-ref} at runtime. Given
that [&#x2F;etc&#x2F;shadow]{.title-ref} is root-read-only, and anything that
wants to verify passwords needs to ... read this file, this generally
means that any pam module is effectively running in root memory space on
any system. Once again, this is why distributions carefully audit and
control what packages can supply a pam module given the high level of
access these require. Once again, because of how pam modules work this
also generally means that the process will need network access to call
out to external identity services depending on the pam modules in use.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-about-that-network-auth&quot;&gt;What about that network auth?&lt;&#x2F;h2&gt;
&lt;p&gt;Now that we&#x27;ve covered the foundations of how processes and daemons
will find details of a user and verify their credentials, lets look at
SSSD which is a specific implementation of an identity resolving daemon.&lt;&#x2F;p&gt;
&lt;p&gt;As mentioned, both nsswitch and pam have the limitation that the dylibs
run in the context of the calling application, which often meant in the
past with modules like [pam_ldap.so]{.title-ref} would be running in the
process space of root applications, requiring network access and having
to parse asn.1 (a library commonly used for remote code execution that
sometimes has the side effect of encoding and decoding binary
structures).&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;┌ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┐                        
&lt;&#x2F;span&gt;&lt;span&gt;  root: uid 0             │                  
&lt;&#x2F;span&gt;&lt;span&gt;│                   │                        
&lt;&#x2F;span&gt;&lt;span&gt;                          │                  
&lt;&#x2F;span&gt;&lt;span&gt;│  ┌─────────────┐  │         ┌─────────────┐
&lt;&#x2F;span&gt;&lt;span&gt;   │             │        │   │             │
&lt;&#x2F;span&gt;&lt;span&gt;│  │             │  │         │             │
&lt;&#x2F;span&gt;&lt;span&gt;   │             │        │   │             │
&lt;&#x2F;span&gt;&lt;span&gt;│  │    SSHD     │──┼────────▶│    LDAP     │
&lt;&#x2F;span&gt;&lt;span&gt;   │             │        │   │             │
&lt;&#x2F;span&gt;&lt;span&gt;│  │             │  │         │             │
&lt;&#x2F;span&gt;&lt;span&gt;   │             │        │   │             │
&lt;&#x2F;span&gt;&lt;span&gt;│  └─────────────┘  │         └─────────────┘
&lt;&#x2F;span&gt;&lt;span&gt;                          │                  
&lt;&#x2F;span&gt;&lt;span&gt;│                   │ Network                
&lt;&#x2F;span&gt;&lt;span&gt;                          │                  
&lt;&#x2F;span&gt;&lt;span&gt;└ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┘                        
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;SSSD changes this by having a daemon running locally which can be
accessed by a unix socket. This allows the pam and nsswitch modules to
be thin veneers with minimal functionality and surface area, who then
contact an isolated daemon that does the majority of the work. This has
a ton of security benefits not limited to reducing the need for the root
process to decode untrusted input from the network.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;┌ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┐      ┌ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┐                         
&lt;&#x2F;span&gt;&lt;span&gt;  root: uid 0                sssd: uid 123            │                  
&lt;&#x2F;span&gt;&lt;span&gt;│                   │      │                   │                         
&lt;&#x2F;span&gt;&lt;span&gt;                                                      │                  
&lt;&#x2F;span&gt;&lt;span&gt;│  ┌─────────────┐  │      │  ┌─────────────┐  │          ┌─────────────┐
&lt;&#x2F;span&gt;&lt;span&gt;   │             │            │             │         │   │             │
&lt;&#x2F;span&gt;&lt;span&gt;│  │             │  │      │  │             │  │          │             │
&lt;&#x2F;span&gt;&lt;span&gt;   │             │            │             │         │   │             │
&lt;&#x2F;span&gt;&lt;span&gt;│  │    SSHD     │──┼──────┼─▶│    SSSD     │──┼─────────▶│    LDAP     │
&lt;&#x2F;span&gt;&lt;span&gt;   │             │            │             │         │   │             │
&lt;&#x2F;span&gt;&lt;span&gt;│  │             │  │      │  │             │  │          │             │
&lt;&#x2F;span&gt;&lt;span&gt;   │             │            │             │         │   │             │
&lt;&#x2F;span&gt;&lt;span&gt;│  └─────────────┘  │      │  └─────────────┘  │          └─────────────┘
&lt;&#x2F;span&gt;&lt;span&gt;                                                      │                  
&lt;&#x2F;span&gt;&lt;span&gt;│                   │      │                   │  Network                
&lt;&#x2F;span&gt;&lt;span&gt;                                                      │                  
&lt;&#x2F;span&gt;&lt;span&gt;└ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┘      └ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┘                         
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Another major benefit of this is that SSSD can cache responses from the
network in a secure way, allowing the client to resolve identities when
offline. This even includes caching passwords!&lt;&#x2F;p&gt;
&lt;p&gt;As a result this is why SSSD ends up taking on so much surface area of
authentication on many distros today. With a thicc local daemon which
does the more complicated tasks and work to actually identify and
resolve users, and the ability to use a variety of authentication
backends it is becoming widely deployed and will displace pam_ldap and
pam_krb5 in the majority of network based authentication scenarioes.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;inside-the-beast&quot;&gt;Inside the beast&lt;&#x2F;h2&gt;
&lt;p&gt;SSSD is internally built from a combination of parts that coordinate.
It&#x27;s useful to know how to debug these if something goes wrong:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# &#x2F;etc&#x2F;sssd&#x2F;sssd.conf
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;&#x2F;change the log level of communication between the pam module and the sssd daemon
&lt;&#x2F;span&gt;&lt;span&gt;[pam]
&lt;&#x2F;span&gt;&lt;span&gt;debug_level = ...
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;&#x2F; change the log level of communication between the nsswitch module and the sssd daemon
&lt;&#x2F;span&gt;&lt;span&gt;[nss]
&lt;&#x2F;span&gt;&lt;span&gt;debug_level = ...
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;&#x2F; change the log level of processing the operations that relate to this authentication provider domain ```
&lt;&#x2F;span&gt;&lt;span&gt;[domain&#x2F;AD]
&lt;&#x2F;span&gt;&lt;span&gt;debug_level = ...
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now we&#x27;ve just introduced a new concept - a SSSD domain. This is
different to a &amp;quot;domain&amp;quot; per Active Directory. A SSSD domain is just
&amp;quot;an authentication provider&amp;quot;. A single instance of SSSD can consume
identities from multiple domains at the same time. In a majority of
configurations however, a single domain is configured.&lt;&#x2F;p&gt;
&lt;p&gt;In the majority of cases if you have an issue with SSSD it is likely to
be in the domain section so this is always the first place to look for
debugging.&lt;&#x2F;p&gt;
&lt;p&gt;Each domain can configure different providers of the &amp;quot;identity&amp;quot;,
&amp;quot;authentication&amp;quot;, &amp;quot;access&amp;quot; and &amp;quot;chpass&amp;quot;. For example a
configuration in [&#x2F;etc&#x2F;sssd&#x2F;sssd.conf]{.title-ref}&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;[domain&#x2F;default]
&lt;&#x2F;span&gt;&lt;span&gt;id_provider = ldap
&lt;&#x2F;span&gt;&lt;span&gt;auth_provider = ldap
&lt;&#x2F;span&gt;&lt;span&gt;access_provider = ldap
&lt;&#x2F;span&gt;&lt;span&gt;chpass_provider = ldap
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The [id_provider]{.title-ref} is the backend of the domain that resolves
names and uid&#x2F;gid numbers to identities.&lt;&#x2F;p&gt;
&lt;p&gt;The [auth_provider]{.title-ref} is the backend that validates the
password of an identity.&lt;&#x2F;p&gt;
&lt;p&gt;The [access_provider]{.title-ref} is the backend that describes if an
identity is allowed to access this system or not.&lt;&#x2F;p&gt;
&lt;p&gt;The [chpass_provider]{.title-ref} is the backend that password changes
and updates are sent to.&lt;&#x2F;p&gt;
&lt;p&gt;As you can see there is a lot of flexibility in this design. For example
you could use krb5 as the auth provider, but send password changes via
ldap.&lt;&#x2F;p&gt;
&lt;p&gt;Because of this design SSSD links to and consumes identity management
libraries from many other sources such as samba (ad), ldap and kerberos.
This means in some limited cases you may need to apply debugging
knowledge from the relevant backend to solve an issue in SSSD.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;common-issues&quot;&gt;Common Issues&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;performance&quot;&gt;Performance&lt;&#x2F;h3&gt;
&lt;p&gt;In some cases SSSD can be very slow to resolve a user&#x2F;group on first
login, but then becomes &amp;quot;faster&amp;quot; after the login completes. In
addition sometimes you may see excessive or high query load on an LDAP
server during authentication as well. This is due to an issue with how
groups and users are resolved where to resolve a user, you need to
resolve it&#x27;s group memberships. Then each group is resolved, but for
unix-tools to display a group you need to resolve it&#x27;s members. Of
course it&#x27;s members are users and these need resolving ... I hope you
can see this is recursive. In some worst cases this can lead to a
situation where when a single user logs on, the full LDAP&#x2F;AD directory
is enumerated, which can take minutes in some cases.&lt;&#x2F;p&gt;
&lt;p&gt;To prevent this set:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ignore_group_members = False
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This prevents groups resolving their members. As a results groups appear
to have no members, but users will always display the groups they are
member-of. Since almost all applications work using this &amp;quot;member-of&amp;quot;
pattern, there are very few negative outcomes from this.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;cache-clearing&quot;&gt;Cache Clearing&lt;&#x2F;h3&gt;
&lt;p&gt;SSSD has a local cache of responses from network services. It ships with
a cache management tool [sss_cache]{.title-ref}. This allows records to
be marked as [invalid]{.title-ref} so that a reload from the network
occurs as soon as possible.&lt;&#x2F;p&gt;
&lt;p&gt;There are two flaws here. In some cases this appears to have &amp;quot;no
effect&amp;quot; where invalid records continue to be served. In addition, the
[sss_cache]{.title-ref} tool when called with [-E]{.title-ref} for
everything, does not always actually invalidate everything.&lt;&#x2F;p&gt;
&lt;p&gt;A common source of advice in these cases is to stop sssd, remove all the
content under [&#x2F;var&#x2F;lib&#x2F;sss&#x2F;db]{.title-ref} (but not the folder itself)
and then start sssd.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;debugging-kerberos&quot;&gt;Debugging Kerberos&lt;&#x2F;h3&gt;
&lt;p&gt;Kerberos can be notoriously hard to debug. This is because it doesn&#x27;t
have a real verbose&#x2F;debug mode, at least not obviously. To get debug
output you need to set an environment variable.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;KRB5_TRACE=&#x2F;dev&#x2F;stderr kinit user@domain
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This works on &lt;em&gt;any&lt;&#x2F;em&gt; proccess that links to kerberos, so it works on
389-ds, sssd, and many other applications so you can use this to trace
what&#x27;s going wrong.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;&#x2F;h2&gt;
&lt;p&gt;That&#x27;s all for now, I&#x27;ll probably keep updating this post over time :)&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Exploring Webauthn Use Cases</title>
          <pubDate>Mon, 13 Jun 2022 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2022-06-13-exploring-webauthn-use-cases/</link>
          <guid>https://fy.blackhats.net.au/blog/2022-06-13-exploring-webauthn-use-cases/</guid>
          <description>&lt;h1 id=&quot;exploring-webauthn-use-cases&quot;&gt;Exploring Webauthn Use Cases&lt;&#x2F;h1&gt;
&lt;p&gt;Webauthn is viewed by many people and companies as the future of
authentication on the internet and within our workplaces. It has the
support of many device manufacturers, browser vendors and authentication
providers.&lt;&#x2F;p&gt;
&lt;p&gt;But for Webauthn&#x27;s lofty goals and promises, as a standard it has many
fractured parts. Many of the features it claims at best don&#x27;t work, at
worst, present possible security risks. The standard itself is quite
confusing, uses dense and obtuse language, and laid out in a very
piecemeal way. This makes it hard to see the full picture to construct a
proper security and use cases analysis.&lt;&#x2F;p&gt;
&lt;p&gt;As the author of both a relying party (
&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&quot;&gt;Kanidm&lt;&#x2F;a&gt; ) and the &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;webauthn-rs&quot;&gt;Webauthn Library
for Rust&lt;&#x2F;a&gt; I want to describe
these problems.&lt;&#x2F;p&gt;
&lt;p&gt;To understand the issues, we first need to explore how Webauthn works,
and then the potential use cases. While not an exhaustive list of all
the ways Webauthn could be used, I am trying to cover the ways that I
have seen in the wild, and how people have requested we want to use
these.&lt;&#x2F;p&gt;
&lt;p&gt;Generally, I will try to use &lt;em&gt;accessible&lt;&#x2F;em&gt; language versions of terms,
rather than the Webauthn standard terms, as the language in the standard
is confusing &#x2F; misleading - even if you have read the standard multiple
times.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;use-cases&quot;&gt;Use Cases&lt;&#x2F;h2&gt;
&lt;p&gt;To understand the limitations of Webauthn, we need to examine how
Webauthn would be used by an identity provider. The identity provider
takes the pieces from Webauthn and their own elements and creates a work
flow for the user to interact with. We will turn these into use cases.&lt;&#x2F;p&gt;
&lt;p&gt;Remember, the goal of webauthn is to enable all people, from various
cultural, social and educational backgrounds to authenticate securely,
so it&#x27;s critical these processes are clear, accessible, and
transparent.&lt;&#x2F;p&gt;
&lt;p&gt;For the extremely detailed versions of these use cases, see the end of
this post.&lt;&#x2F;p&gt;
&lt;p&gt;A really important part of these use cases is attestation. Attestation
is the same as the little gold star sticker that you found on Nintendo
game boxes. It&#x27;s a &amp;quot;certificate of authenticity&amp;quot;. Without
attestation, the authenticator that we are communicating with could be
anything. It could be a yubikey, Apple&#x27;s touchid, a custom-rolled
software token, or even a private key you calculated on pen and paper.
Attestation is a cryptograhic &amp;quot;certificate of authenticity&amp;quot; which
tells us exactly whom produced that device and if it can be trusted.&lt;&#x2F;p&gt;
&lt;p&gt;This is really important, because within Webauthn many things are done
on the authenticator such as user-verification. Rather than just
touching the token, you may have to enter a PIN or use a fingerprint.
But the server never sees that PIN or fingerprint - the authenticator
just sends us a true&#x2F;false flag if the verification occured and was
valid. So for us to trust this flag (and many others), we need to know
that the token is made by someone we trust, so that we know that flag
&lt;em&gt;means&lt;&#x2F;em&gt; something.&lt;&#x2F;p&gt;
&lt;p&gt;Without this attestation, all we know is that &amp;quot;there is some kind of
cryptograhic key that the user can access&amp;quot; and we have no other
information about where it might be stored, or how it works. With
attestation we can make stronger informed assertions about the
properties of the authenticators our users are using.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;security-token-public&quot;&gt;Security Token (Public)&lt;&#x2F;h3&gt;
&lt;p&gt;In this use case, we want our authenticator to be a single factor to
compliment an existing password. This is the &amp;quot;classic&amp;quot; security key
use case, that was originally spawned by U2F. Instead of an
authenticator, a TOTP scheme could alternately be used where either the
TOTP or authenticator plus the password is sufficient to grant access.&lt;&#x2F;p&gt;
&lt;p&gt;Generally in this use case, most identity providers do not care about
attestation of the authenticator, what is more important is that some
kind of non-password authentication exists and is present.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;security-token-corporate&quot;&gt;Security Token (Corporate)&lt;&#x2F;h3&gt;
&lt;p&gt;This is the same as the public use case, except that in many
corporations we may want to define a list of trusted providers of
tokens. It&#x27;s important to us here that these tokens have a vetted or
audited supply chain, and we have an understanding of &amp;quot;where&amp;quot; the
cryptographic material may reside.&lt;&#x2F;p&gt;
&lt;p&gt;For this example, we likely want attestation, as well as the ability to
ensure these credentials are not recoverable or transferable between
authenticators. Resident Key may or may not be required in these cases.&lt;&#x2F;p&gt;
&lt;p&gt;Since these are guided by policy, we likely want to have our user
interfaces guide our users to register or use the correct keys since we
have a stricter list of what is accepted. For example, there is no point
in the UI showing a prompt for caBLE (phone authenticator) when we know
that only a USB key is accepted!&lt;&#x2F;p&gt;
&lt;h3 id=&quot;passkey-public&quot;&gt;PassKey (Public)&lt;&#x2F;h3&gt;
&lt;p&gt;A passkey is the &amp;quot;Apple terminology&amp;quot; for a cryptographic credential
that can exist between multiple devices, and potentially even between
multiple Apple accounts. This are intended to be a &amp;quot;single factor&amp;quot;
replacement to passwords. They can be airdropped and moved between
devices, and at the least in their usage with iOS devices, they &lt;em&gt;can&lt;&#x2F;em&gt;
perform user verification, but it may not be required for the identity
provider to verify this. This is because even as a single factor, these
credentials &lt;em&gt;do&lt;&#x2F;em&gt; resolve many of the weaknesses of passwords even if
user verification did not occur (and even if it did occur it can not be
verified, for reasons we will explore in this post).&lt;&#x2F;p&gt;
&lt;p&gt;It is likely we will see Google and Microsoft develop similar. 1Password
is already progressing to allow webauthn in their wallets.&lt;&#x2F;p&gt;
&lt;p&gt;In this scenario, all we care about is having some kind of credential
that is stronger than a password. It&#x27;s a single factor, and we don&#x27;t
know anything about the make or model of the device. User verification
might be performed, but we don&#x27;t intend to verify if it is.&lt;&#x2F;p&gt;
&lt;p&gt;Nothing is really stopping a U2F style token like a yubikey being a
passkey, but that relies on the identity provider to allow multiple
devices and to have work flows to enrol them across different devices.
It&#x27;s also unclear how this will work from an identity provider when
someone has say a Microsoft Surface and an Apple iPhone.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;passwordless-mfa-public&quot;&gt;Passwordless MFA (Public)&lt;&#x2F;h3&gt;
&lt;p&gt;In this example, rather than having our authenticator as a single
factor, we want it to be truly multifactor. This allows the user to
login with nothing but their authenticator, and we have a secure
multifactor work flow. This is a stronger level of authentication, where
we are verifying not just possession of the private key, but also the
identity of who is using it.&lt;&#x2F;p&gt;
&lt;p&gt;As a result, we need to strictly verify that the authenticator did a
valid user verification.&lt;&#x2F;p&gt;
&lt;p&gt;Given that the authenticator is now the &amp;quot;sole&amp;quot; authenticator (even if
multi-factor) we are more likely to want attestation here using privacy
features granted through indirect attestation. That way we can have a
broad list of known good security token providers that we accept.
Without attestation we are unable to know if the user verification
provided can be trusted.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;passwordless-mfa-corporate&quot;&gt;Passwordless MFA (Corporate)&lt;&#x2F;h3&gt;
&lt;p&gt;Again, this is similar to above. We narrow and focus this use case with
a stricter attestation list of what is valid. We also again want to
strictly control and prevent cryptographic material being moved, so we
want to ensure these are not transferrable. We may want resident keys to
be used here too since we have a higher level of trust in our devices
now too. Again, we also will want to be able to strictly guide UI&#x27;s due
to our knowledge of exactly what devices we accept.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;usernameless&quot;&gt;Usernameless&lt;&#x2F;h3&gt;
&lt;p&gt;Usernameless is similar to passwordless but &lt;em&gt;requires&lt;&#x2F;em&gt; resident keys as
the username of the account is bound to the key and discovered by the
client. Otherwise many of the features of passwordless apply.&lt;&#x2F;p&gt;
&lt;p&gt;It&#x27;s worth noting that due to the complexity and limitations of
resident key management &lt;em&gt;it is not feasible&lt;&#x2F;em&gt; for any public service
provider to currently use usernameless credentials on a broad scale
without significant risk of credential loss. As a result, we limit our
use case to corporate only, as they are the only entities in the
position to effectively manage these issues.&lt;&#x2F;p&gt;
&lt;p&gt;Due to the implementation of passkeys and passwordless in the broader
world, the line is blurred between these, so we will assume that
passkeys and passwordless may sometimes attempt to be used in a
usernameless workflow (for example conditional UI)&lt;&#x2F;p&gt;
&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;&#x2F;h3&gt;
&lt;p&gt;Let&#x27;s assemble a score card now. We&#x27;ll define the use cases, the
features, and what they require and if webauthn can provide them.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;                         Security Token   Sec Tok (Corp)   PassKey       Passwordless     PwLess (Corp)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;&lt;strong&gt;User Verification&lt;&#x2F;strong&gt;      no &#x2F; ???         no &#x2F; ???         no &#x2F; ???      required &#x2F; ???   required &#x2F; ???
&lt;strong&gt;UV Policy&lt;&#x2F;strong&gt;              no &#x2F; ???         no &#x2F; ???         no &#x2F; ???      no &#x2F; ???         maybe &#x2F; ???
&lt;strong&gt;Attestation&lt;&#x2F;strong&gt;            no &#x2F; ???         required &#x2F; ???   no &#x2F; ???      required &#x2F; ???   required &#x2F; ???
&lt;strong&gt;Bound to Device &#x2F; HW&lt;&#x2F;strong&gt;   no &#x2F; ???         required &#x2F; ???   no &#x2F; ???      required &#x2F; ???   required &#x2F; ???
&lt;strong&gt;Resident Key&lt;&#x2F;strong&gt;           no &#x2F; ???         maybe &#x2F; ???      no &#x2F; ???      maybe &#x2F; ???      maybe &#x2F; ???
&lt;strong&gt;UI Selection&lt;&#x2F;strong&gt;           maybe &#x2F; ???      maybe &#x2F; ???      no &#x2F; ???      maybe &#x2F; ???      required &#x2F; ???
&lt;strong&gt;Update PII&lt;&#x2F;strong&gt;             no &#x2F; ???         no &#x2F; ???         maybe &#x2F; ???   maybe &#x2F; ???      maybe &#x2F; ???
&lt;strong&gt;Result&lt;&#x2F;strong&gt;                 ???              ???              ???           ???              ???&lt;&#x2F;p&gt;
&lt;p&gt;: Webauthn Score Card&lt;&#x2F;p&gt;
&lt;p&gt;Now, I already know some of the answers to these, so lets fill in what
we DO know.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;                            Security Token   Sec Tok (Corp)   PassKey       Passwordless     PwLess (Corp)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;&lt;strong&gt;User Verification&lt;&#x2F;strong&gt;         no &#x2F; ???         no &#x2F; ???         no &#x2F; ???      required &#x2F; ???   required &#x2F; ???
&lt;strong&gt;UV Policy&lt;&#x2F;strong&gt;                 no &#x2F; ???         no &#x2F; ???         no &#x2F; ???      no &#x2F; ???         maybe &#x2F; ???
&lt;strong&gt;Attestation&lt;&#x2F;strong&gt;               no &#x2F; ✅          required &#x2F; ???   no &#x2F; ???      required &#x2F; ???   required &#x2F; ???
&lt;strong&gt;Bound to Device &#x2F; HW&lt;&#x2F;strong&gt;      no &#x2F; ✅          required &#x2F; ???   no &#x2F; ✅       required &#x2F; ???   required &#x2F; ???
&lt;strong&gt;Resident Key&lt;&#x2F;strong&gt;              no &#x2F; ✅          maybe &#x2F; ???      no &#x2F; ✅       no &#x2F; ✅          maybe &#x2F; ???
&lt;strong&gt;Authenticator Selection&lt;&#x2F;strong&gt;   maybe &#x2F; ???      maybe &#x2F; ???      no &#x2F; ???      maybe &#x2F; ???      required &#x2F; ???
&lt;strong&gt;Update PII&lt;&#x2F;strong&gt;                no &#x2F; ✅          no &#x2F; ✅          maybe &#x2F; ???   maybe &#x2F; ???      maybe &#x2F; ???
&lt;strong&gt;Result&lt;&#x2F;strong&gt;                    ???              ???              ???           ???              ???&lt;&#x2F;p&gt;
&lt;p&gt;: Webauthn Score Card&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-problems&quot;&gt;The Problems&lt;&#x2F;h2&gt;
&lt;p&gt;Now lets examine the series of issues that exist within Webauthn, and
how they impact our ability to successfully implement the above.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;authenticator-selection&quot;&gt;Authenticator Selection&lt;&#x2F;h3&gt;
&lt;p&gt;Today, there is no features in Webauthn that allow an identity provider
at registration to pre-indicate what transports are known to be valid
for authenticators that are registering. This is contrast to
authentication, where a complete list of valid transports can be
provided to help the browser select the correct device to use in the
authentication.&lt;&#x2F;p&gt;
&lt;p&gt;As a result, the only toggle you have is &amp;quot;platform&amp;quot; vs
&amp;quot;cross-platform&amp;quot;. Consider we have company issued yubikeys. We know
these can only work via USB because that is the model we have chosen.&lt;&#x2F;p&gt;
&lt;p&gt;However, during a registration because we can only indicate
&amp;quot;cross-platform&amp;quot; it is completely valid for a user to &lt;em&gt;attempt&lt;&#x2F;em&gt; to
register say their iPhone via caBLE, or use another key via NFC. The
user may then become &amp;quot;confused&amp;quot; why their other keys didn&#x27;t work for
registration - the UI said they were allowed to use it! This is a lack
of constraint.&lt;&#x2F;p&gt;
&lt;p&gt;This process could be easily streamlined by allowing transports to be
specified in registration, but there is resistance to this &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;w3c&#x2F;webauthn&#x2F;issues&#x2F;1716&quot;&gt;from the
working group.&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;A real world example of this has already occurred, where the email
provider &lt;a href=&quot;https:&#x2F;&#x2F;www.fastmail.com&#x2F;&quot;&gt;FastMail&lt;&#x2F;a&gt; used specific language
around &amp;quot;Security Tokens&amp;quot; including graphics of usb security keys in
their documentation. Because of this lack of ability to specify
transports in the registration process, once caBLE was released this
means that FastMail now has to &amp;quot;rush&amp;quot; to respond to update their
UI&#x2F;Docs to work out how to communicate this to users. They don&#x27;t have a
choice in temporarily excluding this either which may lead to user
confusion.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;user-verification-inconsistent-confusing&quot;&gt;User Verification Inconsistent &#x2F; Confusing&lt;&#x2F;h3&gt;
&lt;p&gt;For our security key work flows we would like to construct a situation
where the authenticator is a single factor, and the users password or
something else is the other factor. This means the authenticator should
only require interaction to touch it, and no PIN or biometric is needed.&lt;&#x2F;p&gt;
&lt;p&gt;There are some major barriers here sadly. Remember, we want to create a
&lt;em&gt;consistent&lt;&#x2F;em&gt; user experience so that people can become confident in the
process they are using.&lt;&#x2F;p&gt;
&lt;p&gt;The problem is CTAP2.1 - this changes the behaviour of user verification
&#x27;discouraged&#x27; so that even when you are registering a credential, you
always need to enter a PIN or biometrics. However, when authenticating,
you never need the PIN or biometric.&lt;&#x2F;p&gt;
&lt;p&gt;There is &lt;em&gt;no communication&lt;&#x2F;em&gt; of the fact that the verification is only
needed due to it being registration.&lt;&#x2F;p&gt;
&lt;p&gt;Surveying users showed about 60% expect when you need to enter your
PIN&#x2F;biometric at registration that it will be &lt;em&gt;required&lt;&#x2F;em&gt; during future
authentication. When it is not present during future authentications
this confuses people, and trains them that the PIN&#x2F;biometrics is an
inconsistent and untrustworthy dialog. Sometimes it is there - sometimes
it is not.&lt;&#x2F;p&gt;
&lt;p&gt;When you combine this with the fact that UV=preferred on most RP&#x27;s is
not validating the UV status, we now have effectively trained all our
users that user verification can appear and disappear and not to worry
about it, it&#x27;s fine, it&#x27;s just &lt;em&gt;inconsistent&lt;&#x2F;em&gt; so they never will
consider it a threat.&lt;&#x2F;p&gt;
&lt;p&gt;It also means that when we try to adopt passwordless it will be &lt;em&gt;harder&lt;&#x2F;em&gt;
to convince users this is safe since they may believe that this
inconsistent usage of user verification on their authenticators is
something that can be easily bypassed.&lt;&#x2F;p&gt;
&lt;p&gt;How can you trust that the PIN&#x2F;biometric means something, when it is
sometimes there and sometimes not?&lt;&#x2F;p&gt;
&lt;p&gt;This forces us even in our security key work flows to force
UV=preferred, and to &lt;em&gt;go beyond the standard&lt;&#x2F;em&gt; to enforce user
verification checks are consistent based on their application at
registration. This means any CTAP2.1 device, even though it does NOT
need a PIN as a single factor authenticator, will require one as a
security key to create a consistent user experience and so we can build
trust in our user base.&lt;&#x2F;p&gt;
&lt;p&gt;At this point since we are effectively forcing UV to always occur, why
not just transition to Passwordless?&lt;&#x2F;p&gt;
&lt;p&gt;It is worth noting that for &lt;em&gt;almost all identity providers&lt;&#x2F;em&gt; today, that
the use of UV=preferred is bypassable, as the user verification is not
checked and there is no guidance in the specification to check this.
This has affected Microsoft Azure, Nextcloud, and others&lt;&#x2F;p&gt;
&lt;p&gt;As a result, the only trustworthy UV policies are required, or preferred
with checks that go beyond the standard. As far as I am aware, only
Webauthn-RS providers these stricter requirement checks.&lt;&#x2F;p&gt;
&lt;p&gt;Discouraged could be used here, but needs user guidance and training to
support it due to the inconsistent dialogs with CTAP2.1.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;user-verification-policy&quot;&gt;User Verification Policy&lt;&#x2F;h3&gt;
&lt;p&gt;Especially in our passwordless scenarios, as an identity provider we may
wish to define policy about what user verification methods we allow from
users. For example we may wish for PIN only rather than allowing
biometrics. We may also wish to express the policy on the length of the
PIN as well.&lt;&#x2F;p&gt;
&lt;p&gt;However, nothing in the response an authenticator provides you with this
information about what user verification method was used. Instead
webauthn defines the &lt;a href=&quot;https:&#x2F;&#x2F;www.w3.org&#x2F;TR&#x2F;webauthn-3&#x2F;#sctn-uvm-extension&quot;&gt;User Verification Method
extension&lt;&#x2F;a&gt; which
can allow an identity provider to request the device to provide what UVM
was provided.&lt;&#x2F;p&gt;
&lt;p&gt;Sadly, nothing supports it in the wild. Experience with Webauthn-RS
shows that it is never honoured or provided when requested. This is true
of most extensions in Webauthn. For bonus marks did you know all
extensions only are answered when you request attestation (this is not
mentioned anywhere in the specification!)&lt;&#x2F;p&gt;
&lt;p&gt;As a corporate environment, we can kind-of control this through strict
attestation lists, but as a public identity provider with attestation it
is potentially not possible to know or enforce this due to extensions
being widely unsupported and not implemented.&lt;&#x2F;p&gt;
&lt;p&gt;The reason this is &amp;quot;kind-of&amp;quot; is that yubikeys support PIN and some
models also support biometrics, but there is no distinction in their
attestation. This means if we only wanted PIN auth, we could not use
yubikeys since there is no way to distinguish these. Additionally,
things like minimum PIN length can&#x27;t be specified since we don&#x27;t know
what manufacturers support this extension. Devices like yubikeys have an
inbuilt minimum length of 8, but again we don&#x27;t know if they&#x27;ll use
PIN given the availability of biometrics.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;resident-keys-can-t-be-verified&quot;&gt;Resident Keys can&#x27;t be verified&lt;&#x2F;h3&gt;
&lt;p&gt;Resident Keys is where we know that the key material lives &lt;em&gt;only&lt;&#x2F;em&gt; within
the cryptographic processor of the authenticator. For example, a yubikey
by default produces a key wrapped key, where the CredentialID is itself
the encrypted private key, and only that yubikey can decrypt that
CredentialID to use it as the private key. In very strict security
environments, this may present a risk because an attacker &lt;em&gt;could&lt;&#x2F;em&gt;
bruteforce the CredentialID to decrypt the private key, allowing the
attacker to then use the credential. (It would take millions of years,
but you know, some people have to factor that into their risk models).&lt;&#x2F;p&gt;
&lt;p&gt;To avoid this, you can request the device create a resident key - a
private key that never leaves the device. The CredentialID is just a
&amp;quot;reference&amp;quot; to allow the device to look up the Credential but it does
not contain the private key itself.&lt;&#x2F;p&gt;
&lt;p&gt;The problem is that there is no &lt;em&gt;signal&lt;&#x2F;em&gt; in the attestation or response
that indicates if a resident key was created by the device.&lt;&#x2F;p&gt;
&lt;p&gt;You can request to find out if this was created with the &lt;a href=&quot;https:&#x2F;&#x2F;www.w3.org&#x2F;TR&#x2F;webauthn-3&#x2F;#sctn-authenticator-credential-properties-extension&quot;&gt;Credential
Properties&lt;&#x2F;a&gt;
extension.&lt;&#x2F;p&gt;
&lt;p&gt;The devil however, is in the details. Notably:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;&amp;quot;This client registration extension facilitates reporting certain
credential properties known by the client&amp;quot;&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;A client extension means that this extension is processed by the web
browser, and exists in a section of the response that is unsigned, and
can not be verified. This means it is open to client side JS tampering
and forgery. This means we &lt;em&gt;can not&lt;&#x2F;em&gt; trust the output of this property.&lt;&#x2F;p&gt;
&lt;p&gt;As a result, there is &lt;em&gt;no simple way to verify a resident key was
created&lt;&#x2F;em&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;To make this better, the request to create the resident key &lt;em&gt;is not
signed and can be stripped by client side javascript&lt;&#x2F;em&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;So any compromised javascript (which Webauthn assumes is trusted) can
strip a registration request for a resident key, cause a key-wrapped-key
to be created, and then &amp;quot;assert&amp;quot; pretty promise I swear it&#x27;s resident
by faking the response to the extension.&lt;&#x2F;p&gt;
&lt;p&gt;The only way to guarantee you have a resident key, is to validate
attestation from an authenticator that &lt;em&gt;exclusively&lt;&#x2F;em&gt; makes resident keys
(e.g. Apple iOS). Anything else, you can not assert is a true resident
key. Even if you subsequently attempt client side discovery of
credentials, that is not the same property as the key being resident.
This is a trap that many identity providers may not know they are
exposed to.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;resident-keys-can-t-be-administered&quot;&gt;Resident Keys can&#x27;t be administered&lt;&#x2F;h3&gt;
&lt;p&gt;To compound the inability to verify creation of a resident key, the
behaviour of resident keys (RK) for most major devices is undefined. For
example a Yubikey has limited storage for RKs but I have been unable to
find documenation about:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;How many RKs can exist on an authenticator.&lt;&#x2F;li&gt;
&lt;li&gt;If the maximum number is created and we attempt to create more, does
it act like a ring buffer and remove the oldest, or simply fail to
create more?&lt;&#x2F;li&gt;
&lt;li&gt;If it is possible to update usernames or other personal information
related to the RKs in this device?&lt;&#x2F;li&gt;
&lt;li&gt;Any API&#x27;s or tooling to list, audit, delete or manage RK&#x27;s on the
device.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;These are &lt;em&gt;basic&lt;&#x2F;em&gt; things that are critical for users and administrators,
and they simply do not exist. This complete absence of tooling makes
RK&#x27;s effectively useless to most users and deployments since we have no
method to manage, audit, modify or delete RK&#x27;s.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;bound-to-device-hardware&quot;&gt;Bound to Device &#x2F; Hardware&lt;&#x2F;h3&gt;
&lt;p&gt;For the years leading up to 2022, Webauthn and it&#x27;s design generally
assumed a one to one relationship between the hardware of an
authenticator, and the public keys it produced. However, that has now
changed with the introduction of Apple Passkeys.&lt;&#x2F;p&gt;
&lt;p&gt;What is meant by &amp;quot;bound to device&amp;quot; is that given a public key, only a
single hardware authenticator exists that has access to the private key
to sign something. This generally means that the cryptographic
operations, and the private key itself, are only ever known to the
secure enclave of the account.&lt;&#x2F;p&gt;
&lt;p&gt;Apple&#x27;s Passkeys change this, allowing a private key to be distributed
between multiple devices of an Apple account, but also the ability to
transfer the private key to other nearby devices via airdrop. This means
the private key is no longer bound to a single physical device.&lt;&#x2F;p&gt;
&lt;p&gt;When we design a security policy this kind of detail matters, where some
identity providers can accept the benefits of a cryptographic
authentication even if the private key is not hardware backed, but other
identity providers must require that private keys are securely stored in
hardware.&lt;&#x2F;p&gt;
&lt;p&gt;The major issue in Webauthn is that the specification does not really
have the necessary parts in place to manage these effectively.&lt;&#x2F;p&gt;
&lt;p&gt;As an identity provider there is no way to currently indicate that you
require a hardware bound credential (or perhaps you want to require
passkeys only!). Because of this lack of control, Apple&#x27;s
implementation relies on another signal - a request for attestation.&lt;&#x2F;p&gt;
&lt;p&gt;If you do &lt;em&gt;not&lt;&#x2F;em&gt; request attestation, a passkey is created.&lt;&#x2F;p&gt;
&lt;p&gt;If you do request attestation (direct or indirect), a hardware bound key
is created.&lt;&#x2F;p&gt;
&lt;p&gt;When the credential is created, there are a new set of &amp;quot;backup state&amp;quot;
bits that can indicate if the credential can be moved between devices.
These are stored in the same set of bits that stores user verification
bits, meaning that to trust them, you need attestation (which Apple
can&#x27;t provide!). At the very least, the attested Apple credentials that
are hardware bound, do correctly show they are &lt;em&gt;not&lt;&#x2F;em&gt; backup capable and
are still resident keys.&lt;&#x2F;p&gt;
&lt;p&gt;Because of this, I expect to see that passkeys and related technology is
treated in the manner as initially described - a single-factor
replacement to passwords. Where you need stronger MFA in the style of a
passwordless credential, it will not currently be possible to achieve
this with Apple Passkeys.&lt;&#x2F;p&gt;
&lt;p&gt;It&#x27;s worth noting that it&#x27;s unclear how other vendors will act here.
Some may produce passkeys that are attested, meaning that reliance on
the backup state bits will become more important, but there is also a
risk that vendors will not implement this correctly.&lt;&#x2F;p&gt;
&lt;p&gt;Importantly some testing in pre-release versions showed that if passkeys
are enabled, and you request an attested credential, the registration
fails blocking the bound credential creation. This will need retesting
to be sure of the behaviour in the final iOS 16 release, but this could
be a show stopper for BYOD users if not fixed. (20220614: We have
confirmed that passkeys do block the creation of attested device bound
credentials).&lt;&#x2F;p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;⚠️ - risks exist&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;✅ - works&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;❌ - broken&#x2F;untrustworthy&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;                        Security Token   Sec Tok (Corp)        PassKey      Passwordless    PwLess (Corp)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;&lt;strong&gt;User Verification&lt;&#x2F;strong&gt;         no &#x2F; ⚠️          no &#x2F; ⚠️               no &#x2F; ⚠️      required &#x2F; ✅   required &#x2F; ✅
&lt;strong&gt;UV Policy&lt;&#x2F;strong&gt;                 no &#x2F; ✅          no &#x2F; ✅               no &#x2F; ✅      no &#x2F; ✅         maybe &#x2F; ❌
&lt;strong&gt;Attestation&lt;&#x2F;strong&gt;               no &#x2F; ✅          required &#x2F; ⚠️         no &#x2F; ✅      required &#x2F; ⚠️   required &#x2F; ⚠️
&lt;strong&gt;Bound to Device &#x2F; HW&lt;&#x2F;strong&gt;      no &#x2F; ✅          required &#x2F; ⚠️         no &#x2F; ✅      required &#x2F; ⚠️   required &#x2F; ⚠️
&lt;strong&gt;Resident Key&lt;&#x2F;strong&gt;              no &#x2F; ✅          maybe &#x2F; ❌            no &#x2F; ✅      no &#x2F; ✅         maybe &#x2F; ❌
&lt;strong&gt;Authenticator Selection&lt;&#x2F;strong&gt;   maybe &#x2F; ❌       maybe &#x2F; ❌            no &#x2F; ✅      maybe &#x2F; ❌      required &#x2F; ❌
&lt;strong&gt;Update PII&lt;&#x2F;strong&gt;                no &#x2F; ✅          no &#x2F; ✅               maybe &#x2F; ❌   maybe &#x2F; ❌      maybe &#x2F; ❌
&lt;strong&gt;Result&lt;&#x2F;strong&gt;                    ⚠️ 1, 2, 7       ⚠️ 1, 2, 4, 5, 6, 7   ⚠️ 1, 2, 8   ⚠️ 4, 5, 7, 8   ⚠️ 4, 5, 6, 7, 8&lt;&#x2F;p&gt;
&lt;p&gt;: Webauthn Score Card&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;User Verification in discouraged may incorrectly request UV,
training users that UV prompts are &amp;quot;optional&amp;quot;.&lt;&#x2F;li&gt;
&lt;li&gt;UV preferred, is bypassable in almost all implementations.&lt;&#x2F;li&gt;
&lt;li&gt;No method to request a UV policy including min PIN length or UV
classes.&lt;&#x2F;li&gt;
&lt;li&gt;Existence of PassKeys on the device account, WILL prevent attested
credentials from being created.&lt;&#x2F;li&gt;
&lt;li&gt;Currently relies on vendor specific attestation behaviour.&lt;&#x2F;li&gt;
&lt;li&gt;No way to validate a resident key is created without assumed vendor
specific behaviours, or other out of band checks.&lt;&#x2F;li&gt;
&lt;li&gt;Unable to request constraints for authenticators that are used in
the interaction.&lt;&#x2F;li&gt;
&lt;li&gt;Vendors often do not provide the ability to update PII on resident
keys if used in these contexts&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;A very interesting take away from this however, is that &amp;quot;Passkeys&amp;quot;
that Apple have created, are actually identical to &amp;quot;Security Tokens&amp;quot;
in how they operate and are validated, meaning that for all intents and
purposes they are the same scenario just with or without a password as
the MFA element.&lt;&#x2F;p&gt;
&lt;p&gt;As we can see, from our use cases all of the scenarios have some kind of
issues. They vary in severity and whom the issue affects, but they
generally are all subtle and may have implications on identity
providers. Generally the &amp;quot;trend&amp;quot; from these issues though, is that it
feels like the Webauthn WG have abandoned authenticators as &amp;quot;security
tokens&amp;quot; and are pushing more toward Passkeys as Single Factor or
Passwordless scenarios. This is probably &amp;quot;a good thing&amp;quot;, but it&#x27;s not
been communicated clearly and there are still issues that exist in the
Passkey and Passwordless scenarios.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;bonus-other-skeletons&quot;&gt;Bonus - Other Skeletons&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;javascript-is-considered-trusted&quot;&gt;Javascript is considered trusted&lt;&#x2F;h3&gt;
&lt;p&gt;Because Javascript is considered trusted, a large number of properties
of Webauthn in its communication are open to tampering which means that
they infact, can not be trusted. Because we can&#x27;t trust the JS or the
user not to tamper with their environment, we need to only trust
properties that are from the browser or authenticator, and then signed.
As a result, regardless of whom we are, we need to assume this in our
threat models that anything on a webpage, can and will be altered. If
the browser or authenticator are compromised, we have different issues,
and different defences.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;insecure-crypto&quot;&gt;Insecure Crypto&lt;&#x2F;h3&gt;
&lt;p&gt;Windows Hello especially relies on TPM&#x27;s that have their attestation
signed with sha1. Sha1 is considered broken, meaning that it could be
possible to forge attestations trivially of these credentials. Newer
TPM&#x27;s may not have this limitation.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;unclear-what-is-is-not-security-property&quot;&gt;Unclear what is &#x2F; is not security property&lt;&#x2F;h3&gt;
&lt;p&gt;A large limitation of Webauthn is that it is unclear what &lt;em&gt;is&lt;&#x2F;em&gt; or &lt;em&gt;is
not&lt;&#x2F;em&gt; a security property within the registration and authentication
messages. For now, we&#x27;ll focus on the registration. This is presented
with all the options and structures expanded that are relevant. Imagine
you are an identity provider implementing a webauthn library and you see
the following.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;PublicKeyCredentialCreationOptions {
&lt;&#x2F;span&gt;&lt;span&gt;    rp = &amp;quot;relying party identifier&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    user {
&lt;&#x2F;span&gt;&lt;span&gt;        id = &amp;quot;user id&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;        displayName = &amp;quot;user display name&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;    challenge = [0xAB, 0xCD, ... ]
&lt;&#x2F;span&gt;&lt;span&gt;    PublicKeyCredentialParameters = [
&lt;&#x2F;span&gt;&lt;span&gt;        {
&lt;&#x2F;span&gt;&lt;span&gt;            type = &amp;quot;public-key&amp;quot;;
&lt;&#x2F;span&gt;&lt;span&gt;            alg =&amp;quot;ECDSA w&#x2F; SHA-256&amp;quot; | ... | &amp;quot;RSASSA-PKCS1-v1_5 using SHA-1&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;        }, ...
&lt;&#x2F;span&gt;&lt;span&gt;    ]
&lt;&#x2F;span&gt;&lt;span&gt;    timeout = 60000
&lt;&#x2F;span&gt;&lt;span&gt;    excludeCredentials = [
&lt;&#x2F;span&gt;&lt;span&gt;        {
&lt;&#x2F;span&gt;&lt;span&gt;            type = &amp;quot;public-key&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;            id = [0x00, 0x01, ... ]
&lt;&#x2F;span&gt;&lt;span&gt;            transports = [ &amp;quot;usb&amp;quot; | &amp;quot;ble&amp;quot; | &amp;quot;internal&amp;quot; | &amp;quot;nfc&amp;quot;, ... ]
&lt;&#x2F;span&gt;&lt;span&gt;        }
&lt;&#x2F;span&gt;&lt;span&gt;    ]
&lt;&#x2F;span&gt;&lt;span&gt;    authenticatorSelection = {
&lt;&#x2F;span&gt;&lt;span&gt;        authenticatorAttachment = &amp;quot;platform&amp;quot; | &amp;quot;cross-platform&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;        userVerification = &amp;quot;discouraged&amp;quot; | default=&amp;quot;preferred&amp;quot; | &amp;quot;required&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;        requireResidentKey = boolean
&lt;&#x2F;span&gt;&lt;span&gt;    };
&lt;&#x2F;span&gt;&lt;span&gt;    attestation = default=&amp;quot;none&amp;quot; | &amp;quot;indirect&amp;quot; | &amp;quot;direct&amp;quot; | &amp;quot;enterprise&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    extensions = ...
&lt;&#x2F;span&gt;&lt;span&gt;};
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now, reading this structure, which elements do you think are security
properties that you can rely upon to be strictly enforced, and have
cryptographic acknowledgement of that being enforced?&lt;&#x2F;p&gt;
&lt;p&gt;Well, only the following are signed cryptographically by the
authenticator:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;PublicKeyCredentialCreationOptions {
&lt;&#x2F;span&gt;&lt;span&gt;    rp = &amp;quot;relying party identifier&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    challenge = [0xAB, 0xCD, ... ]
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;We can assert the credential algorithm used by checking it (provided we
are webauthn level 2 compliant or greater). And we can only check if the
userVerification happened or not through the returned attestation. This
means the following aren&#x27;t signed (for the aware, extensions are
something we&#x27;ll cover seperately).&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;PublicKeyCredentialCreationOptions {
&lt;&#x2F;span&gt;&lt;span&gt;    user {
&lt;&#x2F;span&gt;&lt;span&gt;        id = &amp;quot;user id&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;        displayName = &amp;quot;user display name&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;    timeout = 60000
&lt;&#x2F;span&gt;&lt;span&gt;    excludeCredentials = [
&lt;&#x2F;span&gt;&lt;span&gt;        {
&lt;&#x2F;span&gt;&lt;span&gt;            type = &amp;quot;public-key&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;            id = [0x00, 0x01, ... ]
&lt;&#x2F;span&gt;&lt;span&gt;            transports = [ &amp;quot;usb&amp;quot; | &amp;quot;ble&amp;quot; | &amp;quot;internal&amp;quot; | &amp;quot;nfc&amp;quot;, ... ]
&lt;&#x2F;span&gt;&lt;span&gt;        }
&lt;&#x2F;span&gt;&lt;span&gt;    ]
&lt;&#x2F;span&gt;&lt;span&gt;    authenticatorSelection = {
&lt;&#x2F;span&gt;&lt;span&gt;        authenticatorAttachment = &amp;quot;platform&amp;quot; | &amp;quot;cross-platform&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;        requireResidentKey = boolean
&lt;&#x2F;span&gt;&lt;span&gt;    };
&lt;&#x2F;span&gt;&lt;span&gt;};
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This means that from our registration we can not know or assert:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;If an excluded credential was used or not&lt;&#x2F;li&gt;
&lt;li&gt;If a resident key was really created&lt;&#x2F;li&gt;
&lt;li&gt;If the created credential is platform or cross platform&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h3 id=&quot;extensions&quot;&gt;Extensions&lt;&#x2F;h3&gt;
&lt;p&gt;Most extensions are not implemented at all in the wild, making them flat
out useless.&lt;&#x2F;p&gt;
&lt;p&gt;Many others are client extensions, meaning they are run in your browser
and are not signed, and can be freely tampered with without verification
as javascript is trusted.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;extremely-detailed-use-cases&quot;&gt;Extremely Detailed Use Cases&lt;&#x2F;h2&gt;
&lt;p&gt;The use cases we detail here are significantly richer and more detailed
than the ones in the
&lt;a href=&quot;https:&#x2F;&#x2F;www.w3.org&#x2F;TR&#x2F;webauthn-3&#x2F;#sctn-use-cases&quot;&gt;specification&lt;&#x2F;a&gt;
(2022-04-13).&lt;&#x2F;p&gt;
&lt;p&gt;Each workflow has two parts. A registration (on-boarding) and
authentication. Most of the parameters for webauthn revolve around the
behaviour at registration, with authentication being a much more similar
work flow regardless of credential type.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;security-token-public-1&quot;&gt;Security Token (Public)&lt;&#x2F;h3&gt;
&lt;p&gt;Registration:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;The user indicates they wish to enroll a security token&lt;&#x2F;li&gt;
&lt;li&gt;The identity provider issues a challenge&lt;&#x2F;li&gt;
&lt;li&gt;The browser lists which authenticators attached to the device
&lt;em&gt;could&lt;&#x2F;em&gt; be registered&lt;&#x2F;li&gt;
&lt;li&gt;The user interacts with the authenticator (&lt;em&gt;note&lt;&#x2F;em&gt; a pin should not
be requested, but fingerprint is okay since it&#x27;s &amp;quot;transparent&amp;quot;)&lt;&#x2F;li&gt;
&lt;li&gt;The authenticator releases the signed public key&lt;&#x2F;li&gt;
&lt;li&gt;The authenticator is added to the users account&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;Authentication:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;The user enters their username&lt;&#x2F;li&gt;
&lt;li&gt;The user provides their password and it is validated (&lt;em&gt;note&lt;&#x2F;em&gt; we
could do this after webauthn)&lt;&#x2F;li&gt;
&lt;li&gt;The user indicates they wish to use a security token&lt;&#x2F;li&gt;
&lt;li&gt;The identity provider issues a webauthn challenge, limited by the
list of authenticators and transports we know are valid for the
authenticators associated.&lt;&#x2F;li&gt;
&lt;li&gt;The browser offers the list of authenticators that can proceed&lt;&#x2F;li&gt;
&lt;li&gt;The user interacts with the authenticator (&lt;em&gt;note&lt;&#x2F;em&gt; a pin should not
be requested, but fingerprint is okay since it&#x27;s &amp;quot;transparent&amp;quot;)&lt;&#x2F;li&gt;
&lt;li&gt;The authenticator releases the signature&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;h3 id=&quot;security-token-corporate-1&quot;&gt;Security Token (Corporate)&lt;&#x2F;h3&gt;
&lt;p&gt;Registration:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;The user indicates they wish to enroll a security token&lt;&#x2F;li&gt;
&lt;li&gt;The identity provider issues a challenge, with a list of what
transports of &lt;em&gt;known&lt;&#x2F;em&gt; approved authenticators exist that could be
used.&lt;&#x2F;li&gt;
&lt;li&gt;The browser lists which authenticators attached to the device
&lt;em&gt;could&lt;&#x2F;em&gt; be registered, per the transport list&lt;&#x2F;li&gt;
&lt;li&gt;The user interacts with the authenticator (&lt;em&gt;note&lt;&#x2F;em&gt; a pin should not
be requested, but fingerprint is okay since it&#x27;s &amp;quot;transparent&amp;quot;)&lt;&#x2F;li&gt;
&lt;li&gt;The authenticator releases the signed public key&lt;&#x2F;li&gt;
&lt;li&gt;The identity provider examines the attestation and asserts it is
from a trusted manufacturer&lt;&#x2F;li&gt;
&lt;li&gt;The identity provider examines the enrollment, and asserts it is
bound to the hardware (IE not a passkey&#x2F;backup)&lt;&#x2F;li&gt;
&lt;li&gt;The authenticator is added to the users account&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;Authentication:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;As per Security Token (public)&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;h3 id=&quot;passkey-public-1&quot;&gt;PassKey (Public)&lt;&#x2F;h3&gt;
&lt;p&gt;Registration:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;The user indicates they wish to enroll a token&lt;&#x2F;li&gt;
&lt;li&gt;The identity provider issues a challenge&lt;&#x2F;li&gt;
&lt;li&gt;The browser lists which authenticators attached to the device
&lt;em&gt;could&lt;&#x2F;em&gt; be registered&lt;&#x2F;li&gt;
&lt;li&gt;The user interacts with the authenticator (&lt;em&gt;note&lt;&#x2F;em&gt; a pin should not
be requested, but fingerprint is okay since it&#x27;s &amp;quot;transparent&amp;quot;)&lt;&#x2F;li&gt;
&lt;li&gt;The authenticator releases the signed public key&lt;&#x2F;li&gt;
&lt;li&gt;The authenticator is added to the users account&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;Authentication:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;The user enters their username&lt;&#x2F;li&gt;
&lt;li&gt;The identity provider issues a webauthn challenge, limited by the
list of authenticators and transports we know are valid for the
authenticators associated.&lt;&#x2F;li&gt;
&lt;li&gt;The browser offers the list of authenticators that can proceed&lt;&#x2F;li&gt;
&lt;li&gt;The user interacts with the authenticator (&lt;em&gt;note&lt;&#x2F;em&gt; a pin should not
be requested, but fingerprint is okay since it&#x27;s &amp;quot;transparent&amp;quot;)&lt;&#x2F;li&gt;
&lt;li&gt;The authenticator releases the signature&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;h3 id=&quot;passwordless-public&quot;&gt;Passwordless (Public)&lt;&#x2F;h3&gt;
&lt;p&gt;Registration:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;The user indicates they wish to enroll a security token&lt;&#x2F;li&gt;
&lt;li&gt;The identity provider issues a challenge&lt;&#x2F;li&gt;
&lt;li&gt;The browser lists which authenticators attached to the device
&lt;em&gt;could&lt;&#x2F;em&gt; be registered&lt;&#x2F;li&gt;
&lt;li&gt;The user interacts with the authenticator - user verification MUST
be provided i.e. pin or biometric.&lt;&#x2F;li&gt;
&lt;li&gt;The authenticator releases the signed public key&lt;&#x2F;li&gt;
&lt;li&gt;The identity provider asserts that user verification occured&lt;&#x2F;li&gt;
&lt;li&gt;(Optional) The identity provider examines the attestation and
asserts it is from a trusted manufacturer&lt;&#x2F;li&gt;
&lt;li&gt;The authenticator is added to the users account&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;Authentication:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;The user enters their username&lt;&#x2F;li&gt;
&lt;li&gt;The identity provider issues a webauthn challenge&lt;&#x2F;li&gt;
&lt;li&gt;The browser offers the list of authenticators that can proceed&lt;&#x2F;li&gt;
&lt;li&gt;The user interacts with the authenticator - user verification MUST
be provided i.e. pin or biometric.&lt;&#x2F;li&gt;
&lt;li&gt;The authenticator releases the signature&lt;&#x2F;li&gt;
&lt;li&gt;The identity provider asserts that user verification occured&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;h3 id=&quot;passwordless-corporate&quot;&gt;Passwordless (Corporate)&lt;&#x2F;h3&gt;
&lt;p&gt;Registration:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;The user indicates they wish to enroll a security token&lt;&#x2F;li&gt;
&lt;li&gt;The identity provider issues a challenge, with a list of what
transports of &lt;em&gt;known&lt;&#x2F;em&gt; approved authenticators exist that could be
used.&lt;&#x2F;li&gt;
&lt;li&gt;The browser lists which authenticators attached to the device
&lt;em&gt;could&lt;&#x2F;em&gt; be registered, per the transport list&lt;&#x2F;li&gt;
&lt;li&gt;The user interacts with the authenticator - user verification MUST
be provided i.e. pin or biometric.&lt;&#x2F;li&gt;
&lt;li&gt;The authenticator releases the signed public key&lt;&#x2F;li&gt;
&lt;li&gt;The identity provider examines the attestation and asserts it is
from a trusted manufacturer&lt;&#x2F;li&gt;
&lt;li&gt;(Optional) The identity provider asserts that a resident key was
created&lt;&#x2F;li&gt;
&lt;li&gt;The identity provider examines the enrollment, and asserts it is
bound to the hardware (IE not a passkey&#x2F;backup)&lt;&#x2F;li&gt;
&lt;li&gt;The identity provider asserts that user verification occured&lt;&#x2F;li&gt;
&lt;li&gt;(Optional) The identity provider asserts the verification method
complies to policy&lt;&#x2F;li&gt;
&lt;li&gt;The authenticator is added to the users account&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;Authentication:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;As per Passwordless (public)&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;h3 id=&quot;usernameless-1&quot;&gt;Usernameless&lt;&#x2F;h3&gt;
&lt;p&gt;Registration&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;The user indicates they wish to enroll a security token&lt;&#x2F;li&gt;
&lt;li&gt;The identity provider issues a challenge, with a list of what
transports of &lt;em&gt;known&lt;&#x2F;em&gt; approved authenticators exist that could be
used.&lt;&#x2F;li&gt;
&lt;li&gt;The browser lists which authenticators attached to the device
&lt;em&gt;could&lt;&#x2F;em&gt; be registered, per the transport list&lt;&#x2F;li&gt;
&lt;li&gt;The user interacts with the authenticator - user verification MUST
be provided i.e. pin or biometric.&lt;&#x2F;li&gt;
&lt;li&gt;The authenticator releases the signed public key&lt;&#x2F;li&gt;
&lt;li&gt;The identity provider examines the attestation and asserts it is
from a trusted manufacturer&lt;&#x2F;li&gt;
&lt;li&gt;The identity provider asserts that a resident key was created&lt;&#x2F;li&gt;
&lt;li&gt;The identity provider examines the enrollment, and asserts it is
bound to the hardware (IE not a passkey&#x2F;backup)&lt;&#x2F;li&gt;
&lt;li&gt;The identity provider asserts that user verification occured&lt;&#x2F;li&gt;
&lt;li&gt;(Optional) The identity provider asserts the verification method
complies to policy&lt;&#x2F;li&gt;
&lt;li&gt;The authenticator is added to the users account&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;Authentication:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;The identity provider issues a webauthn challenge&lt;&#x2F;li&gt;
&lt;li&gt;The browser offers the list of authenticators that can proceed&lt;&#x2F;li&gt;
&lt;li&gt;The user interacts with the authenticator - user verification MUST
be provided i.e. pin or biometric.&lt;&#x2F;li&gt;
&lt;li&gt;The authenticator releases the signature&lt;&#x2F;li&gt;
&lt;li&gt;The identity provider asserts that user verification occured&lt;&#x2F;li&gt;
&lt;li&gt;The identity provider extracts and uses the provided username that
was supplied&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
</description>
      </item>
      <item>
          <title>Enable caBLE on your iPhone for testing</title>
          <pubDate>Mon, 04 Apr 2022 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2022-04-04-enable-cable-on-your-iphone-for-testing/</link>
          <guid>https://fy.blackhats.net.au/blog/2022-04-04-enable-cable-on-your-iphone-for-testing/</guid>
          <description>&lt;h1 id=&quot;enable-cable-on-your-iphone-for-testing&quot;&gt;Enable caBLE on your iPhone for testing&lt;&#x2F;h1&gt;
&lt;p&gt;caBLE allows a nearby device (such as your iPhone) to be used an a
webauthn authenticator. Given my work on
&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;webauthn-rs&quot;&gt;WebauthnRS&lt;&#x2F;a&gt; I naturally wanted
to test this! When I initially tried to test caBLE with webauthn via my
iPhone, I recieved an error that the operation wasn&#x27;t available at this
time. There was no other information available.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;debugging&quot;&gt;Debugging&lt;&#x2F;h2&gt;
&lt;p&gt;After some digging into Console.app, I found the log message from
AuthenticationServicesAgent which stated:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;&amp;quot;Syncing platform authenticator must be enabled to register a platform
public key credential; this can be enabled in Settings &amp;gt; Developer.&amp;quot;&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;enabling-developer-settings&quot;&gt;Enabling Developer Settings&lt;&#x2F;h2&gt;
&lt;p&gt;Run Xcode.app on your mac. On your iPhone close and reopen settings.
Then search for &amp;quot;developer&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;Inside of that menu enable [Syncing Platform Authenticator]{.title-ref}
and [Additional Logging]{.title-ref} under [PassKit]{.title-ref}.&lt;&#x2F;p&gt;
&lt;p&gt;After that you should be able to test caBLE!&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Documentation PR&#x27;s Welcome - Why Docs Are Not A Beginner Friendly Task</title>
          <pubDate>Tue, 15 Mar 2022 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2022-03-15-documentation-pr-s-welcome-why-docs-are-not-a-beginner-friendly-task/</link>
          <guid>https://fy.blackhats.net.au/blog/2022-03-15-documentation-pr-s-welcome-why-docs-are-not-a-beginner-friendly-task/</guid>
          <description>&lt;h1 id=&quot;documentation-pr-s-welcome-why-docs-are-not-a-beginner-friendly-task&quot;&gt;Documentation PR&#x27;s Welcome - Why Docs Are Not A Beginner Friendly Task&lt;&#x2F;h1&gt;
&lt;p&gt;Recently I was reporting a usability issue with a library, mainly
related to it&#x27;s confusing or absent documentation. A friend of mine saw
the exchange and commented (quite accurately) that it went along the
lines of:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Me: This library should improve it&#x27;s documentation&lt;&#x2F;li&gt;
&lt;li&gt;Project: PR&#x27;s welcome&lt;&#x2F;li&gt;
&lt;li&gt;Me: I can&#x27;t write the docs because I don&#x27;t know how this works
without documentation&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;My friend also commented &lt;em&gt;&amp;quot;[this] is probably the realest interaction
I&#x27;ve seen in a while.&amp;quot;&lt;&#x2F;em&gt; and &lt;em&gt;&amp;quot;It kinda shakes up the idea that if
people want something in OSS they should do it themselves, and that docs
are the easiest way to contribute&amp;quot;&lt;&#x2F;em&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;I completely agree with these observations.&lt;&#x2F;p&gt;
&lt;p&gt;Documentation writing is not a task for a drive by contributor, or a
beginner. Documentation writing is a skill in and of itself, that
requires many things. From my perspective, I believe documentation
writing requires:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Linguistic ability - to express ideas clearly to a diverse audience
of readers.&lt;&#x2F;li&gt;
&lt;li&gt;Emotional intelligence - to empathise with their audience and to
think &amp;quot;what would help them in these words&amp;quot;?&lt;&#x2F;li&gt;
&lt;li&gt;Technical knowledge - the understanding of the problem space to know
how to write the correct documentation.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Generally, when someone is a beginner to a project they lack an
understanding of the project audience so they aren&#x27;t able to empathise
with &amp;quot;what could be useful for a reader&amp;quot;. They also tend to lack the
depth and breath of technical knowledge to know &lt;em&gt;what&lt;&#x2F;em&gt; to write for the
documentation since by definition, they are a newcommer to this project.&lt;&#x2F;p&gt;
&lt;p&gt;A great way to connect with a beginner is to listen to their
frustrations and what challenges the encountered with your project.
First, connect how that frustration could be either a failing of the
user interface and it&#x27;s design (even an API is a user interface).
Second, only once you have eliminated design limitations, then consider
it to be a documentation problem. As the project contributor, you are in
a better position to write documentation than a beginner.&lt;&#x2F;p&gt;
&lt;p&gt;Telling someone, especially a beginner, &amp;quot;docs PR&#x27;s welcome&amp;quot; is both
belitting to the skill that is technical writing, but also generally
considered in opensource to mean &amp;quot;I don&#x27;t give a shit about your
problem, fuck off&amp;quot;.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>How CTAP2.0 made UserVerification even more confusing</title>
          <pubDate>Wed, 19 Jan 2022 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2022-01-19-how-ctap2-0-made-userverification-even-more-confusing/</link>
          <guid>https://fy.blackhats.net.au/blog/2022-01-19-how-ctap2-0-made-userverification-even-more-confusing/</guid>
          <description>&lt;h1 id=&quot;how-ctap2-0-made-userverification-even-more-confusing&quot;&gt;How CTAP2.0 made UserVerification even more confusing&lt;&#x2F;h1&gt;
&lt;p&gt;I have previously written about how &lt;a href=&quot;..&#x2F;..&#x2F;..&#x2F;2020&#x2F;11&#x2F;21&#x2F;webauthn_userverificationpolicy_curiosities.html&quot;&gt;Webauthn introduces a false sense
of
security&lt;&#x2F;a&gt;
with how it manages UserVerification (UV) by default. To summarise, when
you request &amp;quot;preferred&amp;quot; which means &amp;quot;perform UV if possible&amp;quot;, it can
be bypassed since relying parties&#x27;s (RP) do &lt;em&gt;not&lt;&#x2F;em&gt; check if UV was
actually performed, and Webauthn makes no recommendations on how to
store credentials in a manner that allows future checking to ensure UV
is requested or validated correctly.&lt;&#x2F;p&gt;
&lt;p&gt;From this, in Webauthn-RS we made the recommendation that you use either
&amp;quot;required&amp;quot; to enforce all credentials have performed UV, or
&amp;quot;discouraged&amp;quot; to request that &lt;em&gt;no&lt;&#x2F;em&gt; UV is performed by credentials
during authentication or registration.&lt;&#x2F;p&gt;
&lt;p&gt;At the same time, in the Webauthn-RS project we begun to store two
important pieces of credential metadata beyond the Webauthn
specification - the result of UV from registration, and the policy that
was requested at the time of registration. We did this because we had
noticed there were classes of credentials, that even in &amp;quot;discouraged&amp;quot;
would always verify themself at registration and authentication. Because
of this property, we would enforce that since UV was performed at
registration, we could continue to enforce UV on a per credential basis
to detect possible credential compromise, and to further strengthen the
security of credentials used with Webauthn-RS.&lt;&#x2F;p&gt;
&lt;p&gt;This created 3 workflows:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Required - At registration and authentication UV is always required&lt;&#x2F;li&gt;
&lt;li&gt;Discouraged + no UV - At registration and authentication UV is never
required&lt;&#x2F;li&gt;
&lt;li&gt;Discouraged + always UV - At registration and authentication UV is
always required&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;a-bug-report&quot;&gt;A bug report ...&lt;&#x2F;h2&gt;
&lt;p&gt;We recieved a bug that an authenticator was failing to work with
Webauthn-RS, because at registration it would always force UV, but
during authentication it would &lt;em&gt;never&lt;&#x2F;em&gt; request UV. This was triggering
our inconsistent credential detection, indicating the credential was
possibly compromised.&lt;&#x2F;p&gt;
&lt;p&gt;In this situation, the authenticator used an open-source firmware, so I
was able to look at the source and identify the programming issue.
During registration UV is &lt;em&gt;always&lt;&#x2F;em&gt; required, but during &amp;quot;discouraged&amp;quot;
in authentication it&#x27;s &lt;em&gt;never&lt;&#x2F;em&gt; required matching the reported bug.&lt;&#x2F;p&gt;
&lt;p&gt;The author of the library then directed me to the fact that in
&lt;a href=&quot;https:&#x2F;&#x2F;fidoalliance.org&#x2F;specs&#x2F;fido-v2.0-ps-20190130&#x2F;fido-client-to-authenticator-protocol-v2.0-ps-20190130.html#authenticatorMakeCredential&quot;&gt;CTAP2.0&lt;&#x2F;a&gt;
this behaviour is &lt;em&gt;enshrined in the specification&lt;&#x2F;em&gt;.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;why-is-this-behaviour-bad&quot;&gt;Why is this behaviour bad?&lt;&#x2F;h2&gt;
&lt;p&gt;I performed a quick poll on twitter, and asked about 5 non-technical
friends about this. The question I asked was:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;You go to a website, and you&#x27;re asked to setup a yubikey. When you
register the key you&#x27;re asked for a pin. Do you now expect the pin to be
required when you authenticate to that website with that yubikey now?&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;From the 31 votes on twitter, the result was 60% (21 &#x2F; 30) that &amp;quot;yes&amp;quot;
this PIN will always be required. From the people I asked directly, they
all responded &amp;quot;yes&amp;quot;. (This is in no way an official survey or
significant numbers, but it&#x27;s an initial indication)&lt;&#x2F;p&gt;
&lt;p&gt;Humans expect things to behave in a &lt;em&gt;consistent&lt;&#x2F;em&gt; manner. When you take
an action one time, something will always continue to behave in that
way. The issue we are presented with in this situation is that CTAP2.0
fundamentally breaks this association by changing the behaviour between
registration and authentication. It also is not communicated that the
different is registration vs authentication, or even &lt;em&gt;why&lt;&#x2F;em&gt; this
behaviour is changed.&lt;&#x2F;p&gt;
&lt;p&gt;As a result, this confuses users (&amp;quot;Why is my pin not always
required?!&amp;quot;) and this can at worst cause users to be apathetic about
the UV check, where it could be downgraded from &amp;quot;required&#x2F;preferred&amp;quot;
to &amp;quot;discouraged&amp;quot; and the user would not notice or care about &amp;quot;why is
this different?&amp;quot;. Because RP&#x27;s that strictly follow the Webauthn
specification are open to UV bypass, CTAP2.0 in this case has helped to
open the door for users to be tricked into this.&lt;&#x2F;p&gt;
&lt;p&gt;The other issue is that for a library like Webauthn-RS we lose the
ability to detect credential compromise or attempts to bypass UV when in
discouraged, since now UV is not consistently enforced across all
classes of authenticators.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;can-it-be-fixed&quot;&gt;Can it be fixed?&lt;&#x2F;h2&gt;
&lt;p&gt;No. There are changes in CTAP2.1 that can set the token to be &amp;quot;always
verified&amp;quot; and for extensions to be sent that always enforce UV of that
credential, but none of these assist the CTAP2.0 case where none of
these elements exist.&lt;&#x2F;p&gt;
&lt;p&gt;As an RP library author we have to assume and work out ways to interact
with credentials that are CTAP2.0_pre, CTAP2.0, CTAP2.1, vendor
developed and more. We have to find a way to use the elements at hand to
create a consistent user interface, that also embed security elements
that can not be bypassed or downgraded.&lt;&#x2F;p&gt;
&lt;p&gt;I spent a lot of time thinking about how to resolve this, but I can only
conclude that CTAP2.0 has made &amp;quot;discouraged&amp;quot; less meaningful by adding
in this confusing behaviour.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;is-this-the-end-of-the-world&quot;&gt;Is this the end of the world?&lt;&#x2F;h2&gt;
&lt;p&gt;Not at all. But it does undermine users trust in the systems we are
building, where people may end up believing that UV is pointless and
never checked. There are a lot of smart bad-people out there and they
may utilise this in attacks (especially when combined with the fact that
RP&#x27;s who strictly follow the Webauthn standard are already open to UV
bypass in many cases).&lt;&#x2F;p&gt;
&lt;p&gt;If the goal we have is to move to a passwordless world, we need people
to trust their devices behave in a manner that is predictable and that
they understand. By making UV sometimes there, sometimes not, it will be
a much higher barrier to convince people they can trust these devices as
a self contained multifactor authenticator.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;i-use-an-authentication-provider-what-can-i-do&quot;&gt;I use an authentication provider, what can I do?&lt;&#x2F;h2&gt;
&lt;p&gt;If possible, setup your authentication provider to have UV required.
This will cause some credentials to no longer work in your environment,
but it will ensure that every authenticator has a consistent experience.
In most cases, your authentication provider is likely to be standards
compliant, and will not perform the extended verification discussed
below meaning that &amp;quot;preferred&amp;quot; is bypassable, and &amp;quot;discouraged&amp;quot; can
have inconsistent UV requests from users.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-can-an-rp-do&quot;&gt;What can an RP do?&lt;&#x2F;h2&gt;
&lt;p&gt;Because of this change, there are really only three workflows now that
are actually consistent for users where we can enforce UV properties are
observed correctly.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Required - At registration and authentication UV is always required&lt;&#x2F;li&gt;
&lt;li&gt;Preferred + with UV - At registration and authentication UV is
always required&lt;&#x2F;li&gt;
&lt;li&gt;Preferred + no UV - At registration and authentication UV should not
be required&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;The way that this is achieved is an extension to the Webauthn
specification. When you register a credential you &lt;em&gt;must&lt;&#x2F;em&gt; store the state
of the UV boolean at registration, and you &lt;em&gt;must&lt;&#x2F;em&gt; store the policy that
was requested at registration. During authentication the following is
checked in place of the webauthn defined UV check:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;if credential.registration_policy == required OR authentication.policy == required {
&lt;&#x2F;span&gt;&lt;span&gt;    assert(authentication.uv == true)
&lt;&#x2F;span&gt;&lt;span&gt;} else if credential.registration_policy == preferred AND credential.registration_uv == true {
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; We either sent authentication.policy preferred or discouraged, but the user registered
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; with UV so we enforce that behaviour.
&lt;&#x2F;span&gt;&lt;span&gt;    assert(authentication.uv == true)
&lt;&#x2F;span&gt;&lt;span&gt;} else {
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; Do not check uv.
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;There is a single edge case in this work flow - since we now send
&amp;quot;preferred&amp;quot; it&#x27;s possible that a credential that registered without
UV (IE via Firefox which doesn&#x27;t support CTAP2.0_pre or greater) will
be moved to using a platform that does support CTAP2.0_pre or greater,
and it will begin to request UV. It is however possible in this scenario
that once the credential begins to provide UV we can then store the
credential.uv as true and enforce that for future authentications.&lt;&#x2F;p&gt;
&lt;p&gt;The primary issue with this is that we will begin to ask for the user&#x27;s
PIN more often with credentials which may lead to frustration.
Biometrics this is less of a concern as the &amp;quot;touch&amp;quot; action is always
required anyway. However I think this is acceptable since it&#x27;s more
important for a consistent set of behaviours to exist.&lt;&#x2F;p&gt;
&lt;p&gt;Previously I have stated that &amp;quot;preferred&amp;quot; should not be used since it
is bypassable, but with the extensions to Webauthn above where policy
and uv at registration are stored and validated, preferred gains a
proper meaning and can be checked and enforced.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;&#x2F;h2&gt;
&lt;p&gt;In the scenarioes where &amp;quot;discouraged&amp;quot; and &amp;quot;preferred&amp;quot; may be used,
UV is meaningless in the current definition of the Webauthn
specification when paired with the various versions of CTAP. It&#x27;s
merely a confusing annoyance that we present to users seemingly at
random, that is trivially bypassed, adds little to no security value and
at worst undermines user trust in the systems we are trying to build.&lt;&#x2F;p&gt;
&lt;p&gt;When we are building authentication systems, we must always think about
and consider the humans who will be using these systems, and the
security properties that we actually provide in these systems.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Nextcloud - Unable to Open Photos Library</title>
          <pubDate>Tue, 21 Dec 2021 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2021-12-21-nextcloud-unable-to-open-photos-library/</link>
          <guid>https://fy.blackhats.net.au/blog/2021-12-21-nextcloud-unable-to-open-photos-library/</guid>
          <description>&lt;h1 id=&quot;nextcloud-unable-to-open-photos-library&quot;&gt;Nextcloud - Unable to Open Photos Library&lt;&#x2F;h1&gt;
&lt;p&gt;I noticed since macos 11.6.2 that Nextcloud has been unable to sync my
photos library. Looking into this error in Console.app I saw:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;error   kernel  System Policy: Nextcloud(798) deny(1) file-read-data &#x2F;Users&#x2F;william&#x2F;Pictures&#x2F;Photos Library.photoslibrary
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;It seems that Nextcloud is not &lt;em&gt;sandboxed&lt;&#x2F;em&gt; which means that macos
enforces stricter permissions on what this can or can not access, which
is what prevented the photos library from syncing.&lt;&#x2F;p&gt;
&lt;p&gt;To resolve this you can go to System Preferences -&amp;gt; Security and
Privacy -&amp;gt; Privacy -&amp;gt; Full Disk Access and then grant Nextcloud.app
full disk access which will allow it to read the filesystem.&lt;&#x2F;p&gt;
&lt;p&gt;I tried to allow this via the files and folders access but I was unable
to add&#x2F;remove new items to this list.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Transactional Operations in Rust</title>
          <pubDate>Sun, 14 Nov 2021 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2021-11-14-transactional-operations-in-rust/</link>
          <guid>https://fy.blackhats.net.au/blog/2021-11-14-transactional-operations-in-rust/</guid>
          <description>&lt;h1 id=&quot;transactional-operations-in-rust&quot;&gt;Transactional Operations in Rust&lt;&#x2F;h1&gt;
&lt;p&gt;Earlier I was chatting to Yoshua, the author of this &lt;a href=&quot;https:&#x2F;&#x2F;blog.yoshuawuyts.com&#x2F;async-cancellation-1&#x2F;&quot;&gt;async
cancellation&lt;&#x2F;a&gt; blog
about the section on halt-safety. The blog is a great read so I highly
recommend it! The section on halt-safety is bang on correct too, but I
wanted to expand on this topic further from what they have written.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;memory-safety-vs-application-safety&quot;&gt;Memory Safety vs Application Safety&lt;&#x2F;h2&gt;
&lt;p&gt;Yoshua provides the following code example in their blog:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;&#x2F; Regardless of where in the function we stop execution, destructors will be
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;&#x2F; run and resources will be cleaned up.
&lt;&#x2F;span&gt;&lt;span&gt;async fn do_something(path: PathBuf) -&amp;gt; io::Result&amp;lt;Output&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;                                        &#x2F;&#x2F; 1. the future is not guaranteed to progress after instantiation
&lt;&#x2F;span&gt;&lt;span&gt;    let file = fs::open(&amp;amp;path).await?;  &#x2F;&#x2F; 2. `.await` and 3. `?` can cause the function to halt
&lt;&#x2F;span&gt;&lt;span&gt;    let res = parse(file).await;        &#x2F;&#x2F; 4. `.await` can the function to halt
&lt;&#x2F;span&gt;&lt;span&gt;    res                                 &#x2F;&#x2F; 5. execution has finished, return a value
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;In the example, we can see that at each await point the async behaviour
could cause the function to return. This would be similar to the
non-async code of:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;fn do_something(path: PathBuf) -&amp;gt; io::Result&amp;lt;Output&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;    let file = fs::open(&amp;amp;path)?;  &#x2F;&#x2F; 1. `?` will return an Err if present
&lt;&#x2F;span&gt;&lt;span&gt;    let res = parse(file);        &#x2F;&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;    res                           &#x2F;&#x2F; 2. res may be an Err at this point.
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;In this example we can see that both cancelation &lt;em&gt;or&lt;&#x2F;em&gt; and Err condition
could both cause our function to return, regardless of async or not. In
this example, since there are no side-effects, it&#x27;s not a big deal, but
let&#x27;s consider a different example that does have side-effects:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;fn do_something(path: PathBuf, files_read_counter: &amp;amp;Mutex&amp;lt;u64&amp;gt;) -&amp;gt; io::Result&amp;lt;Output&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;    let mut guard = files_read_counter.lock();
&lt;&#x2F;span&gt;&lt;span&gt;    let file = fs::open(&amp;amp;path)?;  &#x2F;&#x2F; 1. `?` will return an Err if present
&lt;&#x2F;span&gt;&lt;span&gt;    guard += 1;                   &#x2F;&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;    let res = parse(file);        &#x2F;&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;    res                           &#x2F;&#x2F; 2. res may be an Err at this point.
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This is a nonsensical example, but it illustrates the point. The files
read is incremented &lt;em&gt;before&lt;&#x2F;em&gt; we know that the success occured. Even
though this is memory safe, it&#x27;s created an inconsistent data point
that is not reflective of the true state. It&#x27;s trivial to resolve when
we look at this (relocation of the guard increment), but in a larger
example it may not be as easy:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;&#x2F; This is more psuedo rust vs actual rust for simplicities sake.
&lt;&#x2F;span&gt;&lt;span&gt;fn do_something(...) -&amp;gt; Result&amp;lt;..., ...&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;    let mut guard = map.lock();
&lt;&#x2F;span&gt;&lt;span&gt;    guard
&lt;&#x2F;span&gt;&lt;span&gt;        .values_mut()
&lt;&#x2F;span&gt;&lt;span&gt;        .try_for_each(|(k, v)| {
&lt;&#x2F;span&gt;&lt;span&gt;            v.update(...)
&lt;&#x2F;span&gt;&lt;span&gt;        })
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;In our example we have a fallible value update function, which is inside
our locked datastructure. It would be very simple to see a situation
where while updating some values, an error is encountered somewhere into
the set, and then an Err returned. But what happens to the entries we
&lt;em&gt;did&lt;&#x2F;em&gt; update? Since we return from the Err here, the guard will be
dropped, and the lock successfully released, meaning that we have only
partially updated our map in this situation. This kind of behaviour can
still be defended against as a programmer, but it requires us as humans
to bear this cognitive load to ensure our application is behaving
safely. This is the difference between memory and application safety.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;databases&quot;&gt;Databases&lt;&#x2F;h2&gt;
&lt;p&gt;Databases have confronted this problem for many decades now, and a key
logical approach is ACID compliance:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Atomicity - each operation is a single unit that fails or succeeds
together&lt;&#x2F;li&gt;
&lt;li&gt;Consistency - between each unit, the data always moves from a valid
state to another valid state&lt;&#x2F;li&gt;
&lt;li&gt;Isolation - multiple concurrent operations should behave as though
they are executed in serial&lt;&#x2F;li&gt;
&lt;li&gt;Durability - the success of a unit is persisted in the event of
future errors IE power-loss&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;For software, we tend to care more for ACI in this example, but of
course if we are writing a database in Rust, it would be important to
consider D.&lt;&#x2F;p&gt;
&lt;p&gt;When we look at our examples from before, these both fail the atomicity
and consistency checks (but they are correctly isolated due to the mutex
which enforces serialisation).&lt;&#x2F;p&gt;
&lt;h2 id=&quot;acid-in-software&quot;&gt;ACID in Software&lt;&#x2F;h2&gt;
&lt;p&gt;If we treat a top level functional call as our outer operation, and the
inner functions as the units comprising this operation, then we can
start to look at calls to functions as a transactional entity, where the
call to a single operation either succeeds or fails, and the functions
within that are [unsafe]{.title-ref} (aka [spicy]{.title-ref} 🌶 ) due to
the fact they can create inconsistent states. We want to write our
functions in a way that [spicy]{.title-ref} functions can only be
contained within operations and creates an environment where either the
full operation succeeds or fails, and then ensures that consistency is
maintained.&lt;&#x2F;p&gt;
&lt;p&gt;An approach that can be used is software transactional memory. There are
multiple ways to structure this, but copy-on-write is a common technique
to achieve this. An example of a copy-on-write cell type is in
&lt;a href=&quot;https:&#x2F;&#x2F;crates.io&#x2F;crates&#x2F;concread&quot;&gt;concread&lt;&#x2F;a&gt;. This type allows for ACI
(but not D) compliance.&lt;&#x2F;p&gt;
&lt;p&gt;Due to the design of this type, we can seperate functions that are
acquiring the guard (operations) and the functions that comprise that
operation as they are a passed a transaction that is in progress. For
example:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;&#x2F; This is more psuedo rust vs actual rust for simplicities sake.
&lt;&#x2F;span&gt;&lt;span&gt;fn update_map(write_txn: &amp;amp;mut WriteTxn&amp;lt;Map&amp;lt;..., ...&amp;gt;&amp;gt;) -&amp;gt; Result&amp;lt;..., ...&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;    write_txn
&lt;&#x2F;span&gt;&lt;span&gt;        .values_mut()
&lt;&#x2F;span&gt;&lt;span&gt;        .try_for_each(|(k, v)| {
&lt;&#x2F;span&gt;&lt;span&gt;            v.update(...)
&lt;&#x2F;span&gt;&lt;span&gt;        })
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;fn do_something(...) -&amp;gt; Result&amp;lt;..., ...&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;    let write_txn = data.write();
&lt;&#x2F;span&gt;&lt;span&gt;    let res = update_map(write_txn)?;
&lt;&#x2F;span&gt;&lt;span&gt;    write_txn.commit();
&lt;&#x2F;span&gt;&lt;span&gt;    Ok(res)
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Here we can already see a difference in our approach. We know that for
update_map to be called we must be within a transaction - we can not
&amp;quot;hold it wrong&amp;quot;, and the compiler checks this for us. We can also see
that we invert drop on the write_txn guard from &amp;quot;implicit commit&amp;quot; to a
drop being a rollback operation. The commit only occurs &lt;em&gt;explicitly&lt;&#x2F;em&gt; and
takes ownership of the write_txn preventing it being used any further
without a new transaction. As a result in our example, if update_map
were to fail, we would implicitly rollback our data.&lt;&#x2F;p&gt;
&lt;p&gt;Another benefit in this example is async, thread and concurrency safety.
While the write_txn is held, no other writes can proceed (serialised).
Readers are also isolated and guaranteed that their data will not
chainge for the duration of that operation (until a new read is
acquired). Even in our async examples, we would be able to correctly
rollback during an async cancelation or error condition.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;future-work&quot;&gt;Future Work&lt;&#x2F;h2&gt;
&lt;p&gt;At the moment the copy on write structures in concread only can protect
single datastructures, so for more complex data type you end up with a
struct containing many transactional cow types. There is some work going
on to allow the creation of a manager that can allow arbitary structures
of multiple datatypes to be protected under a single transaction
manager, however this work is extremely [unsafe]{.title-ref} though due
to the potential for memory safety violations with incorrect
construction of the structures. For more details see the &lt;a href=&quot;https:&#x2F;&#x2F;docs.rs&#x2F;concread&#x2F;0.2.19&#x2F;concread&#x2F;internals&#x2F;index.html&quot;&gt;concread
internals&lt;&#x2F;a&gt;
, &lt;a href=&quot;https:&#x2F;&#x2F;docs.rs&#x2F;concread&#x2F;0.2.19&#x2F;concread&#x2F;internals&#x2F;lincowcell&#x2F;trait.LinCowCellCapable.html&quot;&gt;concread linear
cowcell&lt;&#x2F;a&gt;
and, &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;concread&#x2F;blob&#x2F;master&#x2F;src&#x2F;internals&#x2F;bptree&#x2F;cursor.rs#L76&quot;&gt;concread impl
lincowcell&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;&#x2F;h2&gt;
&lt;p&gt;Within async and sync programming, we can have cancellations or errors
at any time - ensuring our applications are consistent in the case of
errors which &lt;em&gt;will&lt;&#x2F;em&gt; happen, is challenging. By treating our internal
APIs as a transactional interface, and applying database techniques we
can create systems that are &amp;quot;always consistent&amp;quot;. It is possible to
create these interfaces in a way that the Rust compiler can support us
through it&#x27;s type system to ensure we are using the correct
transactional interfaces as we write our programs - helping us to move
from just memory safety to broader application safety.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Results from the OpenSUSE 2021 Rust Survey</title>
          <pubDate>Fri, 08 Oct 2021 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2021-10-08-results-from-the-opensuse-2021-rust-survey/</link>
          <guid>https://fy.blackhats.net.au/blog/2021-10-08-results-from-the-opensuse-2021-rust-survey/</guid>
          <description>&lt;h1 id=&quot;results-from-the-opensuse-2021-rust-survey&quot;&gt;Results from the OpenSUSE 2021 Rust Survey&lt;&#x2F;h1&gt;
&lt;p&gt;From September the 8th to October the 7th, OpenSUSE has helped me host a
survey on how developers are using Rust in their environments. As the
maintainer of the Rust packages in SUSE and OpenSUSE it was important
for me to get a better understanding of how people are using Rust so
that we can make decisions that match how the community is working.&lt;&#x2F;p&gt;
&lt;p&gt;First, to every single one of the 1360 people who responded to this
survey, thank you! This exceeded my expectations and it means a lot to
have had so many people take the time to help with this.&lt;&#x2F;p&gt;
&lt;p&gt;All the data can be &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;Firstyear&#x2F;rust-survey&#x2F;tree&#x2F;main&#x2F;2021&quot;&gt;found
here&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-did-you-want-to-answer&quot;&gt;What did you want to answer?&lt;&#x2F;h2&gt;
&lt;p&gt;I had assistance from a psychology researcher at a local university to
construct the survey and her help guided the structure and many of the
questions. An important element of this was that the questions provided
shouldn&#x27;t influence people into a certain answer, and that meant
questions were built in a way to get a fair response that didn&#x27;t lead
people into a certain outcome or response pattern. As a result, it&#x27;s
likely that the reasons for the survey was not obvious to the
participants.&lt;&#x2F;p&gt;
&lt;p&gt;What we wanted to determine from this survey:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;How are developers installing rust toolchains so that we can attract
them to OpenSUSE by reducing friction?&lt;&#x2F;li&gt;
&lt;li&gt;In what ways are people using distribution rust packages in their
environments (contrast to rustup)?&lt;&#x2F;li&gt;
&lt;li&gt;Should our rust package include developer facing tools, or is it
just another component of a build pipeline?&lt;&#x2F;li&gt;
&lt;li&gt;When people create or distribute rust software, how are they
managing their dependencies, and do we need to provide tools to
assist?&lt;&#x2F;li&gt;
&lt;li&gt;Based on the above, how can we make it easier for people to
distribute rust software in packages as a distribution?&lt;&#x2F;li&gt;
&lt;li&gt;How do developers manage security issues in rust libraries, and how
can this be integrated to reduce packaging friction?&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;lets-get-to-the-data&quot;&gt;Lets get to the data&lt;&#x2F;h2&gt;
&lt;p&gt;As mentioned there were 1360 responses. Questions were broken into three
broad categories.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Attitude&lt;&#x2F;li&gt;
&lt;li&gt;Developers&lt;&#x2F;li&gt;
&lt;li&gt;Distributors&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h3 id=&quot;attitude&quot;&gt;Attitude&lt;&#x2F;h3&gt;
&lt;p&gt;This section was intended to be a gentle introduction to the survey,
rather than answering any specific question. This section had 413
non-answers, which I will exclude for now.&lt;&#x2F;p&gt;
&lt;p&gt;We asked three questions:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Rust is important to my work or projects (1 disagree - 5 agree)&lt;&#x2F;li&gt;
&lt;li&gt;Rust will become more important in my work or projects in the
future.  (1 disagree - 5 agree)&lt;&#x2F;li&gt;
&lt;li&gt;Rust will become more important to other developers and projects in
the future (1 disagree - 5 agree)&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;rsurvey&#x2F;1.png&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;rsurvey&#x2F;2.png&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;rsurvey&#x2F;3.png&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;From this there is strong support that rust is important to individuals
today. It&#x27;s likely this is biased as the survey was distributed mainly
in rust communities, however, we still had 202 responses that were less
than 3. Once we look at the future questions we see strong belief that
rust will become more important. Again this is likely to be biased due
to the communities the survey was distributed within, but we still see
small numbers of people responding that rust will not be important to
others or themself in the future.&lt;&#x2F;p&gt;
&lt;p&gt;As this section was not intended to answer any questions, I have chosen
not to use the responses of this section in other areas of the analysis.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;developers&quot;&gt;Developers&lt;&#x2F;h3&gt;
&lt;p&gt;This section was designed to help answer the following questions:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;How are people installing rust toolchains so that we can attract
them to OpenSUSE by reducing friction?&lt;&#x2F;li&gt;
&lt;li&gt;In what ways are people using distribution rust packages in their
environments (contrast to rustup)?&lt;&#x2F;li&gt;
&lt;li&gt;Should our rust package include developer facing tools, or is it
just another component of a build pipeline?&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;We asked the following questions:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;As a developer, I use Rust on the following platforms while
programming.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;On your primary development platform, how did you install your Rust
toolchain?&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;The following features or tools are important in my development environment (do not use 1 - use a lot 5)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;:   -   Integrated Development Environments with Language Features
&lt;&#x2F;span&gt;&lt;span&gt;        (syntax highlight, errors, completion, type checking
&lt;&#x2F;span&gt;&lt;span&gt;    -   Debugging tools (lldb, gdb)
&lt;&#x2F;span&gt;&lt;span&gt;    -   Online Documentation (doc.rust-lang.org, docs.rs)
&lt;&#x2F;span&gt;&lt;span&gt;    -   Offline Documentation (local)
&lt;&#x2F;span&gt;&lt;span&gt;    -   Build Caching (sccache)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Generally we wanted to know what platforms people were using so that we
could establish what people on linux were using &lt;em&gt;today&lt;&#x2F;em&gt; vs what people
on other platforms were using, and then knowing what other platforms are
doing we can make decisions about how to proceed.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;rsurvey&#x2F;4.png&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;There were 751 people who responded that they were a developer in this
section. We can see Linux is the most popular platform used while
programming, but for &amp;quot;Linux only&amp;quot; (derived by selecting responses that
only chose Linux and no other platforms) this number is about equal to
Mac and Windows. Given the prevalence of containers and other online
linux environments it would make sense that developers access multiple
platforms from their preferred OS, which is why there are many responses
that selected multiple platforms for their work.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;rsurvey&#x2F;5.png&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;From the next question we see overwhelming support of rustup as the
preferred method to install rust on most developer machines. As we did
not ask &amp;quot;why&amp;quot; we can only speculate on the reasons for this decision.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;rsurvey&#x2F;6.png&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;When we isolate this to &amp;quot;Linux only&amp;quot;, we see a slight proportion
increase in package manager installed rust environments, but there
remains a strong tendancy for rustup to be the preferred method of
installation.&lt;&#x2F;p&gt;
&lt;p&gt;This may indicate that even within Linux distros with their package
manager capabilities, and even with distributions try to provide rapid
rust toolchain updates, that developers still prefer to use rust from
rustup. Again, we can only speculate to why this is, but it already
starts to highlight that distribution packaged rust is unlikely to be
used as a developer facing tool.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;rsurvey&#x2F;7.png&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;rsurvey&#x2F;8.png&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;rsurvey&#x2F;9.png&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Once we start to look at features of rust that developers rely on we see
a very interesting distribution. I have not included all charts here.
Some features are strongly used (IDE rls, online docs) where others seem
to be more distributed in attitude (debuggers, offline docs, build
caching). From the strongly supported features when we filter this by
linux users using distribution packaged rust, we see a similar (but not
as strong) trend for importance of IDE features. The other features like
debuggers, offline docs and build caching all remain very distributed.
This shows that tools like rls for IDE integration are very important,
but with only a small number of developers using packaged rust as
developers versus rustup it may not be an important area to support with
limited packaging resources and time. It&#x27;s very likely that developers
who are on other distributions, mac or windows are more comfortable with
a rustup based installation process.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;distributors&quot;&gt;Distributors&lt;&#x2F;h3&gt;
&lt;p&gt;This section was designed to help answer the following questions:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Should our rust package include developer facing tools, or is it
just another component of a build pipeline?&lt;&#x2F;li&gt;
&lt;li&gt;When people create or distribute rust software, how are they
managing their dependencies, and do we need to provide tools to
assist?&lt;&#x2F;li&gt;
&lt;li&gt;Based on the above, how can we make it easier for people to
distribute rust software in packages as a distribution?&lt;&#x2F;li&gt;
&lt;li&gt;How do developers manage security issues in rust libraries, and how
can this be integrated to reduce packaging friction?&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;We asked the following questions:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Which platforms (operating systems) do you target for Rust software&lt;&#x2F;li&gt;
&lt;li&gt;How do you or your team&#x2F;community build or provide Rust software for
people to use?&lt;&#x2F;li&gt;
&lt;li&gt;In your release process, how do you manage your Rust dependencies?&lt;&#x2F;li&gt;
&lt;li&gt;In your ideal workflow, how would you prefer to manager your Rust
dependencies?&lt;&#x2F;li&gt;
&lt;li&gt;How do you manage security updates in your Rust dependencies?&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;rsurvey&#x2F;10.png&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Our first question here really shows the popularity of Linux as a target
platform for running rust with 570 out of 618 responses indicating they
target Linux as a platform.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;rsurvey&#x2F;11.png&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Once we look at the distribution methods, both building projects to
packages and using distribution packaged rust in containers fall well
behind the use of rustup in containers and locally installed rust tools.
However if we observe container packaged rust and packaged rust binaries
(which likely use the distro rust toolchains) we have 205 uses of the
rust package out of 1280 uses, where we see 59 out of 680 from
developers. This does indicate a tendancy that the rust package in a
distribution is more likely to be used in a build pipeline over
developer use - but rustup still remains most popular. I would speculate
that this is because developers want to recreate the same process on
their development systems as their target systems which would likely
involve rustup as the method to ensure the identical toolchains are
installed.&lt;&#x2F;p&gt;
&lt;p&gt;The next questions were focused on rust dependencies - as a staticly
linked language, this changes the approach to how libraries can be
managed. To answer how we as a distribution should support people in the
way they want to manage libraries, we need to know how they use it
today, and how they would ideally prefer to manage this in the future.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;rsurvey&#x2F;12.png&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;rsurvey&#x2F;13.png&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;In both the current process and ideal processes we see a large tendancy
to online library use from crates.io, and in both cases vendoring
(pre-downloading) comes in second place. Between the current process and
ideal process, we see a small reduction in online library use to the
other options. As a distribution, since we can not provide online access
to crates, we can safely assume most online crates users would move to
vendoring if they had to work offline for packaging as it&#x27;s the most
similar process available.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;rsurvey&#x2F;14.png&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;rsurvey&#x2F;15.png&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;We can also look at some other relationships here. People who provide
packages still tend to ideally prefer online crates usage, with
distribution libraries coming in second place here. There is still
significant momentum for packagers to want to use vendoring or online
dependencies though. When we look at ideal management strategies for
container builds, we see distribution packages being much less popular,
and online libraries still remaining at the top.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;rsurvey&#x2F;16.png&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Finally, when we look at how developers are managing their security
updates, we see a really healthy statistic that many people are using
tools like cargo audit and cargo outdated to proactively update their
dependencies. Very few people rely on distribution packages for their
updates however. But it remains that we see 126 responses from users who
aren&#x27;t actively following security issues which again highlights a need
for distributions who do provide rust packaged software to be proactive
to detect issues that may exist.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;outcomes&quot;&gt;Outcomes&lt;&#x2F;h2&gt;
&lt;p&gt;By now we have looked at a lot of the survey and the results, so it&#x27;s
time to answer our questions.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;How are people installing rust toolchains so that we can attract
them to OpenSUSE by reducing friction?&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Developers are preferring the use of rustup over all other sources.
Being what&#x27;s used on linux and other platforms, we should consider
packaging and distributing rustup to give options to users (who may wish
to avoid the [curl | sh]{.title-ref} method.) I&#x27;ve already started the
process to include this in OpenSUSE tumbleweed.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;In what ways are people using distribution rust packages in their
environments (contrast to rustup)?&lt;&#x2F;li&gt;
&lt;li&gt;Should our rust package include developer facing tools, or is it
just another component of a build pipeline?&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Generally developers tend strongly to rustup for their toolchains, where
distribution rust seems to be used more in build pipelines. As a result
of the emphasis on online docs and rustup, we can likely remove offline
documentation and rls from the distribution packages as they are either
not being used or have very few users and is not worth the distribution
support cost and maintainer time. We would likely be better to encourage
users to use rustup for developer facing needs instead.&lt;&#x2F;p&gt;
&lt;p&gt;To aid this argument, it appears that rls updates have been not
functioning in OpenSUSE tumbleweed for a few weeks due to a packaging
mistake, and no one has reported the issue - this means that the
&amp;quot;scream test&amp;quot; failed. The lack of people noticing this again shows
developer tools are not where our focus should be.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;When people create or distribute rust software, how are they
managing their dependencies, and do we need to provide tools to
assist?&lt;&#x2F;li&gt;
&lt;li&gt;Based on the above, how can we make it easier for people to
distribute rust software in packages as a distribution?&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Distributors prefer cargo and it&#x27;s native tools, and this is likely an
artifact of the tight knit tooling that exists in the rust community.
Other options don&#x27;t seem to have made a lot of headway, and even within
distribution packaging where you may expect stronger desire for packaged
libraries, we see a high level of support for cargo directly to manage
rust dependencies. From this I think it shows that efforts to package
rust crates have not been effective to attract developers who are
currently used to a very different workflow.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;How do developers manage security issues in rust libraries, and how
can this be integrated to reduce packaging friction?&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Here we see that many people are proactive in updating their libraries,
but there still exists many who don&#x27;t actively manage this. As a
result, automating tools like cargo audit inside of build pipelines will
likely help packagers, and also matches their existing and known tools.
Given that many people will be performing frequent updates of their
libraries or upstream releases, we&#x27;ll need to also ensure that the
process to update and commit updates to packages is either fully
automated or at least has a minimal hands on contact as possible. When
combined with the majority of developers and distributors prefering
online crates for dependencies, encouraging people to secure these
existing workflows will likely be a smaller step for them. Since rust is
staticly linked, we can also target our security efforts at leaf
(consuming) packages rather than the libraries themself.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;closing&quot;&gt;Closing&lt;&#x2F;h2&gt;
&lt;p&gt;Again, thank you to everyone who answered the survey. It&#x27;s now time for
me to go and start to do some work based on this data!&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Gnome 3 compare to MacOs</title>
          <pubDate>Sun, 12 Sep 2021 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2021-09-12-gnome-3-compare-to-macos/</link>
          <guid>https://fy.blackhats.net.au/blog/2021-09-12-gnome-3-compare-to-macos/</guid>
          <description>&lt;h1 id=&quot;gnome-3-compare-to-macos&quot;&gt;Gnome 3 compare to MacOs&lt;&#x2F;h1&gt;
&lt;p&gt;An assertion I have made in the past is that to me &amp;quot;Gnome 3 feels like
MacOs with rough edges&amp;quot;. After some discussions with others, I&#x27;m
finally going to write this up with examples.&lt;&#x2F;p&gt;
&lt;p&gt;It&#x27;s worth pointing out that in my opinion, Gnome 3 is probably still
the best desktop experience on Linux today for a variety of reasons -
it&#x27;s just that for me, these rough edges really take away from that
being a good experience for me.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;high-level-structure-comparison&quot;&gt;High Level Structure Comparison&lt;&#x2F;h2&gt;
&lt;p&gt;Here&#x27;s a pair of screenshots of MacOS 11.5.2 and Gnome 40.4. In both we
have the settings menu open of the respective environment. Both are set
to the resolution of 1680x1050, with the Mac using scaling from retina
(2880x1800) to this size.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;gnome_v_macos&#x2F;gnome-settings-1.png&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;gnome_v_macos&#x2F;macos-settings-1.png&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;From this view, we can already make some observations. Both of these
have a really similar structure which when we look at appears like this:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;gnome_v_macos&#x2F;skeleton.png&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The skeleton overall looks really similar, if not identical. We have a
top bar that provides a system tray and status and a system context in
the top left, as well as application context.&lt;&#x2F;p&gt;
&lt;p&gt;Now we can look at some of the details of each of the platforms at a
high level from this skeleton.&lt;&#x2F;p&gt;
&lt;p&gt;We can see on the Mac that the &amp;quot;top menu bar&amp;quot; takes 2.6% of our
vertical screen real-estate. Our system context is provided by the small
Apple logo in the top left that opens to a menu of various platform
options.&lt;&#x2F;p&gt;
&lt;p&gt;Next to that, we can see that our system preferences uses that top menu
bar to provide our application context menus like edit, view, window and
help. Further, on the right side of this we have a series of icons for
our system - some of these from third party applications like nextcloud,
and others coming from macos showing our backup status, keyboard, audio,
battery, wifi time and more. This is using the space at the top of our
screen really effectively, it doesn&#x27;t feel wasted, and adds context to
what we are doing.&lt;&#x2F;p&gt;
&lt;p&gt;If we now look at Gnome we can see a different view. Our menu bar takes
3.5% of our vertical screen realestate, and the dark colour already
feels like it is &amp;quot;dominating&amp;quot; visually. In that we have very little
effective horizontal space use. The activities button (system context)
takes us to our overview screen, and selecting the &amp;quot;settings&amp;quot; item
which is our current application has no response or menu displayed.&lt;&#x2F;p&gt;
&lt;p&gt;The system tray doesn&#x27;t allow 3rd party applications, and the overview
only shows our network and audio status and our clock (battery may be
displayed on a laptop). To find more context about our system requires
interaction with the single component at the top right, limiting our
ability to interact with a specific element (network, audio etc) or
understand our systems state quickly.&lt;&#x2F;p&gt;
&lt;p&gt;Already we can start to see some differences here.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;UI elements in MacOS are smaller and consume less screen space.&lt;&#x2F;li&gt;
&lt;li&gt;Large amounts of non-functional dead space in Gnome&lt;&#x2F;li&gt;
&lt;li&gt;Elements are visually more apparently and able to be seen at a high
level, where Gnome&#x27;s require interaction to find details&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;system-preferences-vs-settings&quot;&gt;System Preferences vs Settings&lt;&#x2F;h2&gt;
&lt;p&gt;Let&#x27;s compare the system preferences and Settings now. These are still
similar, but not as close as our overall skeleton and this is where we
start to see more about the different approaches to design in each.&lt;&#x2F;p&gt;
&lt;p&gt;The MacOS system preferences has all of it&#x27;s top level options
displayed in a grid, with an easily accesible search function and
forward and back navigation aides. This make it easy to find the
relevant area that is required, and everything is immediately accessible
and clear. Searching for items dims the application and begins to
highlight elements that contain the relevant topic, helping to guide you
to the location and establishing to the user where they can go in the
future without the need to search. Inside any menu of the system
preferences, search is always accesible and in the same consistent
location of the application.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;gnome_v_macos&#x2F;macos-settings-search.png&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;When we look at Gnome, in the settings application we see that not all
available settings are displayed - the gutter column on the left is a
scrollable UI element, but with no scroll bars present, this could be
missed by a user that the functionality is present. Items like
&amp;quot;Applications&amp;quot; which have a &amp;quot;&amp;gt;&amp;quot; present confusingly changes the
gutter context to a list of applications rather than remaining at the
top level when selected like all other items that don&#x27;t have the
&amp;quot;&amp;gt;&amp;quot;. Breaking the users idea of consistency, when in these
sub-gutters, the search icon is replaced with the &amp;quot;back&amp;quot; navigation
icon, meaning you can not search when in a sub-gutter.&lt;&#x2F;p&gt;
&lt;p&gt;Finally, even visually we can see that the settings is physically larger
as a window, with much larger fonts and the title bar containing much
more dead space. The search icon (when present) requires interaction
before the search text area appears adding extra clicks and interactions
to achieve the task.&lt;&#x2F;p&gt;
&lt;p&gt;When we do search, the results are replaced into the gutter element.
Screen lock here is actually in a sub-gutter menu for privacy, and not
discoverable at the top level as an element. The use of nested gutters
here adds confusion about where items are due to all the gutter content
changes.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;gnome_v_macos&#x2F;gnome-settings-search.png&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Again we are starting to see differences here:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;MacOS search uses greater visual feedback to help guide users to
where they need to be&lt;&#x2F;li&gt;
&lt;li&gt;Gnome hides many options in sub-menus, or with very few graphical
guides which hinders discovery of items&lt;&#x2F;li&gt;
&lt;li&gt;Again, the use of dead space in Gnome vs the greater use of space in
MacOS&lt;&#x2F;li&gt;
&lt;li&gt;Gnome requires more interactions to &amp;quot;get around&amp;quot; in general&lt;&#x2F;li&gt;
&lt;li&gt;Gnome applications visually are larger and take up more space of the
screen&lt;&#x2F;li&gt;
&lt;li&gt;Gnome changes the UI and layout in subtle and inconsistent ways that
rely on contextual knowledge of &amp;quot;where&amp;quot; you currently are in the
application&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;context-menus&quot;&gt;Context Menus&lt;&#x2F;h2&gt;
&lt;p&gt;Lets have a look at some of the menus that exist in the system tray area
now. For now I&#x27;ll focus on audio, but these differences broadly apply
to all of the various items here on MacOS and Gnome.&lt;&#x2F;p&gt;
&lt;p&gt;On MacOS when we select our audio icon in the system tray, we are
presented with a menu that contains the current volume, the current
audio output device (including options for network streaming) and a link
to the system preferencs control panel for further audio settings that
may exist. We aren&#x27;t overwhelmed with settings or choices, but we do
have the ability to change our common options and shortcut links to get
to the extended settings if needed.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;gnome_v_macos&#x2F;macos-audio-1.png&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;A common trick in MacOS though is holding the option key during
interactions. Often this can display power-user or extended
capabilities. When done on the audio menu, we are also able to then
control our input device selection.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;gnome_v_macos&#x2F;macos-audio-2.png&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;On Gnome, in the system tray there is only a single element, that
controls audio, power, network and more.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;gnome_v_macos&#x2F;gnome-audio-1.png&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;All we can do in this menu is control the volume - that&#x27;s it. There are
no links to direct audio settings, device management, and there are no
&amp;quot;hidden&amp;quot; shortcuts (like option) that allows greater context or
control.&lt;&#x2F;p&gt;
&lt;p&gt;To summarise our differences:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;MacOS provides topic-specific system tray menus, with greater
functionality and links to further settings&lt;&#x2F;li&gt;
&lt;li&gt;Gnome has a combined menu, that is limited in functionality, and has
only a generic link to settings&lt;&#x2F;li&gt;
&lt;li&gt;Gnome lacks the ability to gain extended options for power-users to
view extra settings or details&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;file-browser&quot;&gt;File Browser&lt;&#x2F;h2&gt;
&lt;p&gt;Finally lets look at the file browser. For fairness, I&#x27;ve changed
Gnome&#x27;s default layout to &amp;quot;list&amp;quot; to match my own usage in finder.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;gnome_v_macos&#x2F;macos-files-1.png&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;We can already see a number of useful elements here. We have the ability
to &amp;quot;tree&amp;quot; folders through the &amp;quot;&amp;gt;&amp;quot; icon, and rows of the browser
alternate white&#x2F;grey to help us visually identify lines horizontally.
The rows are small and able to have (in this screenshot) 16 rows of
content on the screen simultaneously. Finally, not shown here, but MacOS
finder can use tabs for browsing different locations. And as before, we
have our application context menu in the top bar with a large amount of
actions available.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;gnome_v_macos&#x2F;gnome-files-1.png&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Gnomes rows are all white with extremely faint grey lines to delineate,
making it hard to horizontally track items if the window was expanded.
The icons are larger, and there is no ability to tree the files and
folders. We can only see ~10 rows on screen despite the similar size of
the windows presented here. Finally, the extended options are hidden in
the &amp;quot;burger&amp;quot; menu next to the application close.&lt;&#x2F;p&gt;
&lt;p&gt;A theme should be apparent here:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Both MacOS and Gnome share a very similar skeleton of how this
application is laid out&lt;&#x2F;li&gt;
&lt;li&gt;MacOS makes better use of visual elements to help your eye track
across spaces to make connections&lt;&#x2F;li&gt;
&lt;li&gt;Gnome has a lot of dead space still and larger text and icons which
takes greater amounts of screen space&lt;&#x2F;li&gt;
&lt;li&gt;Due to the application context and other higher level items, MacOS
is &amp;quot;faster&amp;quot; to get to where you need to go&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;keyboard-shortcuts&quot;&gt;Keyboard Shortcuts&lt;&#x2F;h2&gt;
&lt;p&gt;Keyboard shortcuts are something that aide powerusers to achieve tasks
quicker, but the challenge is often &lt;em&gt;finding&lt;&#x2F;em&gt; what shortcuts exist to
use them. Lets look at how MacOS and Gnome solve this.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;gnome_v_macos&#x2F;macos-shortcut-1.png&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Here in MacOS, anytime we open a menu, we can see the shortcut listed
next to the menu item that is present, including disabled items (that
are dimmed). Each shortcut&#x27;s symbols match the symbols of the keyboard
allowing these to be cross-language and accessible. And since we are in
a menu, we remain in the context of our Application and able to then
immediately use the menu or shortcut.&lt;&#x2F;p&gt;
&lt;p&gt;In fact, even if we select the help menu and search a new topic, rather
than take us away from menu&#x27;s, MacOS opens the menu and points us to
where we are trying to go, allowing us to find the action we want &lt;em&gt;and&lt;&#x2F;em&gt;
learn it&#x27;s shortcut!&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;gnome_v_macos&#x2F;macos-shortcut-2.png&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;This is great, because it means in the process of getting help, we are
shown how to perform the action for future interactions. Because of the
nature of MacOS human interface guidelines this pattern exists for &lt;em&gt;all&lt;&#x2F;em&gt;
applications on the platform, including third party ones helping to
improve accessibility of these features.&lt;&#x2F;p&gt;
&lt;p&gt;Gnome however takes a really different approach. Keyboard shortcuts are
listed as a menu item from our burger menu.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;gnome_v_macos&#x2F;gnome-shortcut-1.png&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;When we select it, our applications context is taken away and replaced
with a dictionary of keyboard shortcuts, spread over three pages.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;gnome_v_macos&#x2F;gnome-shortcut-2.png&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I think the use of the keyboard icons here is excellent, but because we
are now in a dictionary of shortcuts, it&#x27;s hard to find what we want to
use, and we &amp;quot;taken away&amp;quot; from the context of the actions we are trying
to perform in our application. Again, we have to perform more
interactions to find the information that we are looking for in our
applications, and we aren&#x27;t able to easily link the action to the
shortcut in this style of presentation. We can&#x27;t transfer our knowledge
of the &amp;quot;menus&amp;quot; into a shortcut that we can use without going through a
reference manual.&lt;&#x2F;p&gt;
&lt;p&gt;Another issue here is this becomes the responsibility of each
application to create these references and provide them, rather than
being an automatically inherited feature through the adherence to human
interface guidelines.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;&#x2F;h2&gt;
&lt;p&gt;Honestly, I could probably keep making these comparisons all day. Gnome
3 and MacOS really do feel very similar to me. From style of keyboard
shortcuts, layout of the UI, the structure of it&#x27;s applications and
even it&#x27;s approach to windowing feels identical to MacOS. However while
it looks similar on a surface level, there are many rough edges, excess
interactions, poor use of screen space and visual elements.&lt;&#x2F;p&gt;
&lt;p&gt;MacOS certainly has it&#x27;s flaws, and makes it&#x27;s mistakes. But from a
ease of use perspective, it tries to get out of the way and show you how
to use the computer for yourself. MacOS takes a back seat to the usage
of the computer.&lt;&#x2F;p&gt;
&lt;p&gt;Gnome however feels like it wants to be front and centre. It needs you
to know all the time &amp;quot;you&#x27;re using Gnome!&amp;quot;. It takes you on a small
adventure tour to complete simple actions or to discover new things. It
even feels like Gnome has tried to reduce &amp;quot;complexity&amp;quot; so much that
they have thrown away many rich features and interactions that could
make a computer easier to use and interact with.&lt;&#x2F;p&gt;
&lt;p&gt;So for me, this is why I feel that Gnome is like MacOS with rough edges.
There are many small, subtle and frustrating user interactions like this
all through out the Gnome 3 experience that just aren&#x27;t present in
MacOS.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>StartTLS in LDAP</title>
          <pubDate>Thu, 12 Aug 2021 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2021-08-12-starttls-in-ldap/</link>
          <guid>https://fy.blackhats.net.au/blog/2021-08-12-starttls-in-ldap/</guid>
          <description>&lt;h1 id=&quot;starttls-in-ldap&quot;&gt;StartTLS in LDAP&lt;&#x2F;h1&gt;
&lt;p&gt;LDAP as a protocol is a binary protocol which uses ASN.1 BER encoded
structures to communicate between a client and server, to query
directory information (ie users, groups, locations, etc).&lt;&#x2F;p&gt;
&lt;p&gt;When this was created there was little consideration to security with
regard to person-in-the-middle attacks (aka mitm: meddler in the middle,
interception). As LDAP has become used not just as a directory service
for accessing information, but now as an authentication and
authorisation system it&#x27;s important that the content of these
communications is secure from tampering or observation.&lt;&#x2F;p&gt;
&lt;p&gt;There have been a number of introduced methods to try and assist with
this situation. These are:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;StartTLS&lt;&#x2F;li&gt;
&lt;li&gt;SASL with encryption layers&lt;&#x2F;li&gt;
&lt;li&gt;LDAPS (LDAP over TLS)&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Other protocols of a similar age also have used StartTLS such as SMTP
and IMAP. However recent &lt;a href=&quot;https:&#x2F;&#x2F;nostarttls.secvuln.info&#x2F;&quot;&gt;research&lt;&#x2F;a&gt;
has (again) shown issues with correct StartTLS handling, and recommends
using SMTPS or IMAPS.&lt;&#x2F;p&gt;
&lt;p&gt;Today the same is true of LDAP - the only secure method of communication
to an LDAP server is LDAPS. In this blog, I&#x27;ll be exploring the issues
that exist with StartTLS (I will not cover SASL or GSSAPI).&lt;&#x2F;p&gt;
&lt;h2 id=&quot;how-does-starttls-work&quot;&gt;How does StartTLS work?&lt;&#x2F;h2&gt;
&lt;p&gt;StartTLS works by starting a plaintext (unencrypted) connection to the
LDAP server, and then by upgrading that connection to begin TLS within
the existing connection.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;┌───────────┐                            ┌───────────┐
&lt;&#x2F;span&gt;&lt;span&gt;│           │                            │           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │─────────open tcp 389──────▶│           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │◀────────────ok─────────────│           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │                            │           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │                            │           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │────────ldap starttls──────▶│           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │◀──────────success──────────│           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │                            │           │
&lt;&#x2F;span&gt;&lt;span&gt;│  Client   │                            │  Server   │
&lt;&#x2F;span&gt;&lt;span&gt;│           │──────tls client hello─────▶│           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │◀─────tls server hello──────│           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │────────tls key xchg───────▶│           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │◀────────tls finish─────────│           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │                            │           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │──────TLS(ldap bind)───────▶│           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │                            │           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │                            │           │
&lt;&#x2F;span&gt;&lt;span&gt;└───────────┘                            └───────────┘
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;As we can see in LDAP StartTLS we establish a valid plaintext tcp
connection, and then we send and LDAP message containing a StartTLS
extended operation. If successful, we begin a TLS handshake over the
connection, and when complete, our traffic is now encrypted.&lt;&#x2F;p&gt;
&lt;p&gt;This is contrast to LDAPS where TLS must be successfully established
before the first LDAP message is exchanged.&lt;&#x2F;p&gt;
&lt;p&gt;It&#x27;s a good time to note that this is inefficent as it takes an extra
round-trip to establish StartTLS like this contrast to LDAPS which
increases latency for all communications. LDAP clients tend to open and
close many connections, so this adds up quickly.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;security-issues&quot;&gt;Security Issues&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;client-misconfiguration&quot;&gt;Client Misconfiguration&lt;&#x2F;h3&gt;
&lt;p&gt;LDAP servers at the start of a connection will only accept two LDAP
messages. Bind (authenticate) and StartTLS. Since StartTLS starts with a
plaintext connection, if a client is misconfigured it is trivial for it
to operate without StartTLS.&lt;&#x2F;p&gt;
&lt;p&gt;For example, consider the following commands.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# ldapwhoami -H ldap:&#x2F;&#x2F;172.17.0.3:389 -x -D &amp;#39;cn=Directory Manager&amp;#39; -W
&lt;&#x2F;span&gt;&lt;span&gt;Enter LDAP Password:
&lt;&#x2F;span&gt;&lt;span&gt;dn: cn=directory manager
&lt;&#x2F;span&gt;&lt;span&gt;# ldapwhoami -H ldap:&#x2F;&#x2F;172.17.0.3:389 -x -Z -D &amp;#39;cn=Directory Manager&amp;#39; -W
&lt;&#x2F;span&gt;&lt;span&gt;Enter LDAP Password:
&lt;&#x2F;span&gt;&lt;span&gt;dn: cn=directory manager
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Notice that in both, the command succeeds and we authenticate. However,
only in the second command are we using StartTLS. This means we
trivially leaked our password. Forcing LDAPS to be the only protocol
prevents this as every byte of the connection is always encrypted.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# ldapwhoami -H ldaps:&#x2F;&#x2F;172.17.0.3:636 -x -D &amp;#39;cn=Directory Manager&amp;#39; -W
&lt;&#x2F;span&gt;&lt;span&gt;Enter LDAP Password:
&lt;&#x2F;span&gt;&lt;span&gt;dn: cn=directory manager
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Simply put this means that if you forget to add the command line flag
for StartTLS, forget the checkbox in an admin console, or any other kind
of possible human error (which happen!), then LDAP will silently
continue without enforcing that StartTLS is present.&lt;&#x2F;p&gt;
&lt;p&gt;For a system to be secure we must prevent human error from being a
factor by removing elements of risk in our systems.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;minssf&quot;&gt;MinSSF&lt;&#x2F;h3&gt;
&lt;p&gt;A response to the above is to enforce MinSSF, or &amp;quot;Minimum Security
Strength Factor&amp;quot;. This is an option on both OpenLDAP and 389-ds and is
related to the integration of SASL. It represents that the bind method
used must have &amp;quot;X number of bits&amp;quot; of security (however X is very
arbitrary and not really representative of true security).&lt;&#x2F;p&gt;
&lt;p&gt;In the context of StartTLS or TLS, the provided SSF becomes the number
of bits in the symmetric encryption used in the connection. Generally
this is 128 due to the use of AES128.&lt;&#x2F;p&gt;
&lt;p&gt;Let us assume we have configured MinSSF=128 and we attempt to bind to
our server.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;┌───────────┐                            ┌───────────┐
&lt;&#x2F;span&gt;&lt;span&gt;│           │                            │           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │─────────open tcp 389──────▶│           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │◀────────────ok─────────────│           │
&lt;&#x2F;span&gt;&lt;span&gt;│  Client   │                            │  Server   │
&lt;&#x2F;span&gt;&lt;span&gt;│           │                            │           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │──────────ldap bind────────▶│           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │◀───────error - minssf──────│           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │                            │           │
&lt;&#x2F;span&gt;&lt;span&gt;└───────────┘                            └───────────┘
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The issue here is the minssf isn&#x27;t enforced until the bind message is
sent. If we look at the LDAP rfc we see:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;BindRequest ::= [APPLICATION 0] SEQUENCE {
&lt;&#x2F;span&gt;&lt;span&gt;     version                 INTEGER (1 ..  127),
&lt;&#x2F;span&gt;&lt;span&gt;     name                    LDAPDN,
&lt;&#x2F;span&gt;&lt;span&gt;     authentication          AuthenticationChoice }
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;AuthenticationChoice ::= CHOICE {
&lt;&#x2F;span&gt;&lt;span&gt;     simple                  [0] OCTET STRING,
&lt;&#x2F;span&gt;&lt;span&gt;                             -- 1 and 2 reserved
&lt;&#x2F;span&gt;&lt;span&gt;     sasl                    [3] SaslCredentials,
&lt;&#x2F;span&gt;&lt;span&gt;     ...  }
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;SaslCredentials ::= SEQUENCE {
&lt;&#x2F;span&gt;&lt;span&gt;     mechanism               LDAPString,
&lt;&#x2F;span&gt;&lt;span&gt;     credentials             OCTET STRING OPTIONAL }
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Which means that in a simple bind (password) in the very first message
we send our plaintext password. MinSSF only tells us &lt;em&gt;after&lt;&#x2F;em&gt; we already
made the mistake, so this is not a suitable defence.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;starttls-can-be-disregarded&quot;&gt;StartTLS can be disregarded&lt;&#x2F;h3&gt;
&lt;p&gt;An interesting aspect of how StartTLS works with LDAP is that it&#x27;s
possible to prevent it from being installed successfully. If we look at
the &lt;a href=&quot;https:&#x2F;&#x2F;datatracker.ietf.org&#x2F;doc&#x2F;html&#x2F;rfc4511#section-4.14.2&quot;&gt;RFC&lt;&#x2F;a&gt;:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;If the server is otherwise unwilling or unable to perform this
&lt;&#x2F;span&gt;&lt;span&gt;operation, the server is to return an appropriate result code
&lt;&#x2F;span&gt;&lt;span&gt;indicating the nature of the problem.  For example, if the TLS
&lt;&#x2F;span&gt;&lt;span&gt;subsystem is not presently available, the server may indicate this by
&lt;&#x2F;span&gt;&lt;span&gt;returning with the resultCode set to unavailable.  In cases where a
&lt;&#x2F;span&gt;&lt;span&gt;non-success result code is returned, the LDAP session is left without
&lt;&#x2F;span&gt;&lt;span&gt;a TLS layer.
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;What this means is it is up to the client and how they respond to this
error to enforce a correct behaviour. An example of a client that
disregards this error may proceed such as:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;┌───────────┐                            ┌───────────┐
&lt;&#x2F;span&gt;&lt;span&gt;│           │                            │           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │─────────open tcp 389──────▶│           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │◀────────────ok─────────────│           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │                            │           │
&lt;&#x2F;span&gt;&lt;span&gt;│  Client   │                            │  Server   │
&lt;&#x2F;span&gt;&lt;span&gt;│           │────────ldap starttls──────▶│           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │◀───────starttls error──────│           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │                            │           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │─────────ldap bind─────────▶│           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │                            │           │
&lt;&#x2F;span&gt;&lt;span&gt;└───────────┘                            └───────────┘
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;In this example, the ldap bind proceeds even though TLS is not active,
again leaking our password in plaintext. A classic example of this is
OpenLDAP&#x27;s own cli tools which in almost all examples of StartTLS
online use the option &#x27;-Z&#x27; to enable this.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# ldapwhoami -Z -H ldap:&#x2F;&#x2F;127.0.0.1:12345 -D &amp;#39;cn=Directory Manager&amp;#39; -w password
&lt;&#x2F;span&gt;&lt;span&gt;ldap_start_tls: Protocol error (2)
&lt;&#x2F;span&gt;&lt;span&gt;dn: cn=Directory Manager
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The quirk is that &#x27;-Z&#x27; here only means to &lt;em&gt;try&lt;&#x2F;em&gt; StartTLS. If you want
to fail when it&#x27;s not available you need &#x27;-ZZ&#x27;. This is a pretty easy
mistake for any administrator to make when typing a command. There is no
way to configure in ldap.conf that you always want StartTLS enforced
either leaving it again to human error. Given the primary users of the
ldap cli are directory admins, this makes it a high value credential
open to potential human input error.&lt;&#x2F;p&gt;
&lt;p&gt;Within client applications a similar risk exists that the developers
need to correctly enforce this behaviour. Thankfully for us, the all
client applications that I tested handle this correctly:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;SSSD&lt;&#x2F;li&gt;
&lt;li&gt;nslcd&lt;&#x2F;li&gt;
&lt;li&gt;ldapvi&lt;&#x2F;li&gt;
&lt;li&gt;python-ldap&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;However, I am sure there are many others that should be tested to ensure
that they correctly handle errors during StartTLS.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;referral-injection&quot;&gt;Referral Injection&lt;&#x2F;h3&gt;
&lt;p&gt;Referral&#x27;s are a feature of LDAP that allow responses to include extra
locations where a client may look for the data they requested, or to
extend the data they requested. Due to the design of LDAP and it&#x27;s
response codes, referrals are valid in all response messages.&lt;&#x2F;p&gt;
&lt;p&gt;LDAP StartTLS does allow a referral as a valid response for the client
to then follow - this may be due to the requested server being
undermaintenance or similar.&lt;&#x2F;p&gt;
&lt;p&gt;Depending on the client implementation, this may allow an mitm to
proceed. There are two possible scenarioes.&lt;&#x2F;p&gt;
&lt;p&gt;Assuming the client &lt;em&gt;does&lt;&#x2F;em&gt; do certificate validation, but is poorly
coded, the following may occur:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;┌───────────┐                            ┌───────────┐
&lt;&#x2F;span&gt;&lt;span&gt;│           │                            │           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │─────────open tcp 389──────▶│           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │◀────────────ok─────────────│           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │                            │  Server   │
&lt;&#x2F;span&gt;&lt;span&gt;│           │                            │           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │────────ldap starttls──────▶│           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │◀──────────referral─────────│           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │                            │           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │                            └───────────┘
&lt;&#x2F;span&gt;&lt;span&gt;│  Client   │
&lt;&#x2F;span&gt;&lt;span&gt;│           │                            ┌───────────┐
&lt;&#x2F;span&gt;&lt;span&gt;│           │─────────ldap bind─────────▶│           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │                            │           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │                            │           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │                            │ Malicious │
&lt;&#x2F;span&gt;&lt;span&gt;│           │                            │  Server   │
&lt;&#x2F;span&gt;&lt;span&gt;│           │                            │           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │                            │           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │                            │           │
&lt;&#x2F;span&gt;&lt;span&gt;└───────────┘                            └───────────┘
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;In this example our server sent a referral as a response to the StartTLS
extended operation, which the client then followed - however the client
did &lt;em&gt;not&lt;&#x2F;em&gt; attempt to install StartTLS again when contacting the
malicious server. This would allow a bypass of certification validation
by simply never letting TLS begin at all. Thankfully the clients I
tested did not exhibt this behaviour, but it is possible.&lt;&#x2F;p&gt;
&lt;p&gt;If the client has configured certificate validation to never
(tls_reqcert = never, which is a surprisingly common setting ...) then
the following is possible.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;┌───────────┐                            ┌───────────┐
&lt;&#x2F;span&gt;&lt;span&gt;│           │                            │           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │─────────open tcp 389──────▶│           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │◀────────────ok─────────────│           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │                            │  Server   │
&lt;&#x2F;span&gt;&lt;span&gt;│           │                            │           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │────────ldap starttls──────▶│           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │◀──────────referral─────────│           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │                            │           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │                            └───────────┘
&lt;&#x2F;span&gt;&lt;span&gt;│  Client   │
&lt;&#x2F;span&gt;&lt;span&gt;│           │                            ┌───────────┐
&lt;&#x2F;span&gt;&lt;span&gt;│           │────────ldap starttls──────▶│           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │◀──────────success──────────│           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │                            │           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │◀──────TLS installed───────▶│ Malicious │
&lt;&#x2F;span&gt;&lt;span&gt;│           │                            │  Server   │
&lt;&#x2F;span&gt;&lt;span&gt;│           │───────TLS(ldap bind)──────▶│           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │                            │           │
&lt;&#x2F;span&gt;&lt;span&gt;│           │                            │           │
&lt;&#x2F;span&gt;&lt;span&gt;└───────────┘                            └───────────┘
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;In this example the client follows the referral and then attempts to
install StartTLS again. The malicious server may present any certificate
it wishes and can then intercept traffic.&lt;&#x2F;p&gt;
&lt;p&gt;In my testing I found that this affected both SSSD and nslcd, however
both of these when redirected to the malicous server would attempt to
install StartTLS over an existing StartTLS channel, which caused the
server to return an error condition. Potentially a modified malicious
server in this case would be able to install two layers of TLS, or a
response that would successfully trick these clients to divulging
further information. I have not yet spent time to research this further.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;&#x2F;h2&gt;
&lt;p&gt;While not as significant as the results found on &amp;quot;No Start TLS&amp;quot;, LDAP
still is potentially exposed to risks related to StartTLS usage. To
mitigate these LDAP server providers should disable plaintext LDAP ports
and exclusively use LDAPS, with tls_reqcert set to &amp;quot;demand&amp;quot;.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Getting started with Yew</title>
          <pubDate>Sun, 20 Jun 2021 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2021-06-20-getting-started-with-yew/</link>
          <guid>https://fy.blackhats.net.au/blog/2021-06-20-getting-started-with-yew/</guid>
          <description>&lt;h1 id=&quot;getting-started-with-yew&quot;&gt;Getting started with Yew&lt;&#x2F;h1&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;&#x2F;strong&gt; This post is really out dated now, there are easier ways to start. See the &lt;a href=&quot;https:&#x2F;&#x2F;yew.rs&#x2F;&quot;&gt;yew official docs&lt;&#x2F;a&gt;
as this process has gotten much easier!&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;Yew is a really nice framework for writing single-page-applications in
Rust, that is then compiled to wasm for running in the browser. For me
it has helped make web development much more accessible to me, but
getting started with it isn&#x27;t always straight forward.&lt;&#x2F;p&gt;
&lt;p&gt;This is the bare-minimum to get a &amp;quot;hello world&amp;quot; in your browser - from
there you can build on that foundation to make many more interesting
applications.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;dependencies&quot;&gt;Dependencies&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;macos&quot;&gt;MacOS&lt;&#x2F;h3&gt;
&lt;ul&gt;
&lt;li&gt;Ensure that you have rust, which you can setup with
&lt;a href=&quot;https:&#x2F;&#x2F;rustup.rs&#x2F;&quot;&gt;RustUp&lt;&#x2F;a&gt;.&lt;&#x2F;li&gt;
&lt;li&gt;Ensure that you have brew, which you can install from the &lt;a href=&quot;https:&#x2F;&#x2F;brew.sh&#x2F;&quot;&gt;Homebrew
Project&lt;&#x2F;a&gt;. This is used to install other tools.&lt;&#x2F;li&gt;
&lt;li&gt;Install wasm-pack. wasm-pack is what drives the rust to wasm build
process.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;cargo&lt;&#x2F;span&gt;&lt;span&gt; install wasm-pack
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;ul&gt;
&lt;li&gt;Install npm and rollup. npm is needed to install rollup, and rollup
is what takes our wasm and javacript and bundles them together for
our browser.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;brew&lt;&#x2F;span&gt;&lt;span&gt; install npm
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;npm&lt;&#x2F;span&gt;&lt;span&gt; install&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt; --global&lt;&#x2F;span&gt;&lt;span&gt; rollup
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;ul&gt;
&lt;li&gt;Install miniserve for hosting our website locally during
development.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;brew&lt;&#x2F;span&gt;&lt;span&gt; install miniserve
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;a-new-project&quot;&gt;A new project&lt;&#x2F;h2&gt;
&lt;p&gt;We can now create a new rust project. Note we use --lib to indicate
that it&#x27;s a library, not an executable.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;cargo&lt;&#x2F;span&gt;&lt;span&gt; new&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt; --lib&lt;&#x2F;span&gt;&lt;span&gt; yewdemo
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;To start with we&#x27;ll need some boilerplate and helpers to get ourselves
started.&lt;&#x2F;p&gt;
&lt;p&gt;[index.html]{.title-ref} - our default page that will load our wasm to
run. This is our &amp;quot;entrypoint&amp;quot; into the site that starts everything
else off. In this case it loads our bundled javascript.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;html&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-html &quot;&gt;&lt;code class=&quot;language-html&quot; data-lang=&quot;html&quot;&gt;&lt;span&gt;    &amp;lt;!&lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;DOCTYPE &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;html&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;html&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;      &amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;head&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;meta &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;charset&lt;&#x2F;span&gt;&lt;span&gt;=&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;utf-8&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;title&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;PROJECTNAME&amp;lt;&#x2F;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;title&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;script &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;src&lt;&#x2F;span&gt;&lt;span&gt;=&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;&#x2F;pkg&#x2F;bundle.js&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;defer&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;&amp;lt;&#x2F;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;script&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;      &amp;lt;&#x2F;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;head&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;      &amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;body&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;      &amp;lt;&#x2F;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;body&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;lt;&#x2F;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;html&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;[main.js]{.title-ref} - this is our javascript entrypoint that we&#x27;ll be
using. Remember to change PROJECTNAME to your crate name (ie yewdemo).
This will be combined with our wasm to create the bundle.js file.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;js&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-js &quot;&gt;&lt;code class=&quot;language-js&quot; data-lang=&quot;js&quot;&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;import &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;init&lt;&#x2F;span&gt;&lt;span&gt;, { &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;run_app &lt;&#x2F;span&gt;&lt;span&gt;} &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;from &lt;&#x2F;span&gt;&lt;span&gt;&amp;#39;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;.&#x2F;pkg&#x2F;PROJECTNAME.js&lt;&#x2F;span&gt;&lt;span&gt;&amp;#39;;
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;async function &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8fa1b3;&quot;&gt;main&lt;&#x2F;span&gt;&lt;span&gt;() {
&lt;&#x2F;span&gt;&lt;span&gt;       &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;await &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8fa1b3;&quot;&gt;init&lt;&#x2F;span&gt;&lt;span&gt;(&amp;#39;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;&#x2F;pkg&#x2F;PROJECTNAME_bg.wasm&lt;&#x2F;span&gt;&lt;span&gt;&amp;#39;);
&lt;&#x2F;span&gt;&lt;span&gt;       &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8fa1b3;&quot;&gt;run_app&lt;&#x2F;span&gt;&lt;span&gt;();
&lt;&#x2F;span&gt;&lt;span&gt;      }
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8fa1b3;&quot;&gt;main&lt;&#x2F;span&gt;&lt;span&gt;()
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;[Cargo.toml]{.title-ref} - we need to extend Cargo.toml with some
dependencies and settings that allows wasm to build and our framework
dependencies.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;toml&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-toml &quot;&gt;&lt;code class=&quot;language-toml&quot; data-lang=&quot;toml&quot;&gt;&lt;span&gt;    [lib]
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;crate-type &lt;&#x2F;span&gt;&lt;span&gt;= [&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;cdylib&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;]
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    [dependencies]
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;wasm-bindgen &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;^0.2&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;yew &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;0.18&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;[build_wasm.sh]{.title-ref} - create this file to help us build our
project. Remember to call [chmod +x build_wasm.sh]{.title-ref} so that
you can execute it later.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;#!&#x2F;bin&#x2F;sh
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;wasm-pack&lt;&#x2F;span&gt;&lt;span&gt; build&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt; --target&lt;&#x2F;span&gt;&lt;span&gt; web &amp;amp;&amp;amp; \
&lt;&#x2F;span&gt;&lt;span&gt;        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;rollup&lt;&#x2F;span&gt;&lt;span&gt; .&#x2F;main.js&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt; --format&lt;&#x2F;span&gt;&lt;span&gt; iife&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt; --file&lt;&#x2F;span&gt;&lt;span&gt; .&#x2F;pkg&#x2F;bundle.js
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;[src&#x2F;lib.rs]{.title-ref} - this is a template of a minimal start point
for yew. This has all the stubs in place for a minimal &amp;quot;hello world&amp;quot;
website.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;use &lt;&#x2F;span&gt;&lt;span&gt;wasm_bindgen::prelude::*;
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;use &lt;&#x2F;span&gt;&lt;span&gt;yew::prelude::*;
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;use &lt;&#x2F;span&gt;&lt;span&gt;yew::services::ConsoleService;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;pub struct &lt;&#x2F;span&gt;&lt;span&gt;App {
&lt;&#x2F;span&gt;&lt;span&gt;        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;link&lt;&#x2F;span&gt;&lt;span&gt;: ComponentLink&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;Self&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;,
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;impl &lt;&#x2F;span&gt;&lt;span&gt;Component &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;for &lt;&#x2F;span&gt;&lt;span&gt;App {
&lt;&#x2F;span&gt;&lt;span&gt;        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;type &lt;&#x2F;span&gt;&lt;span&gt;Message = App;
&lt;&#x2F;span&gt;&lt;span&gt;        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;type &lt;&#x2F;span&gt;&lt;span&gt;Properties = ();
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; This is called when our App is initially created.
&lt;&#x2F;span&gt;&lt;span&gt;        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;fn &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8fa1b3;&quot;&gt;create&lt;&#x2F;span&gt;&lt;span&gt;(_: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;Self::&lt;&#x2F;span&gt;&lt;span&gt;Properties, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;link&lt;&#x2F;span&gt;&lt;span&gt;: ComponentLink&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;Self&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;) -&amp;gt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;Self &lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;            App {
&lt;&#x2F;span&gt;&lt;span&gt;                link,
&lt;&#x2F;span&gt;&lt;span&gt;            }
&lt;&#x2F;span&gt;&lt;span&gt;        }
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;fn &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8fa1b3;&quot;&gt;change&lt;&#x2F;span&gt;&lt;span&gt;(&amp;amp;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;mut &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;self&lt;&#x2F;span&gt;&lt;span&gt;, _: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;Self::&lt;&#x2F;span&gt;&lt;span&gt;Properties) -&amp;gt; ShouldRender {
&lt;&#x2F;span&gt;&lt;span&gt;            &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;false
&lt;&#x2F;span&gt;&lt;span&gt;        }
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; Called during event callbacks initiated by events (user or browser)
&lt;&#x2F;span&gt;&lt;span&gt;        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;fn &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8fa1b3;&quot;&gt;update&lt;&#x2F;span&gt;&lt;span&gt;(&amp;amp;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;mut &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;self&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;msg&lt;&#x2F;span&gt;&lt;span&gt;: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;Self::&lt;&#x2F;span&gt;&lt;span&gt;Message) -&amp;gt; ShouldRender {
&lt;&#x2F;span&gt;&lt;span&gt;            &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;false
&lt;&#x2F;span&gt;&lt;span&gt;        }
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; Render our content to the page, emitting Html that will be loaded into our
&lt;&#x2F;span&gt;&lt;span&gt;        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; index.html&amp;#39;s &amp;lt;body&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;fn &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8fa1b3;&quot;&gt;view&lt;&#x2F;span&gt;&lt;span&gt;(&amp;amp;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;self&lt;&#x2F;span&gt;&lt;span&gt;) -&amp;gt; Html {
&lt;&#x2F;span&gt;&lt;span&gt;            ConsoleService::log(&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Hello World!&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;);
&lt;&#x2F;span&gt;&lt;span&gt;            html! {
&lt;&#x2F;span&gt;&lt;span&gt;                &amp;lt;div&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;                    &amp;lt;h2&amp;gt;{ &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Hello World&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot; }&amp;lt;&#x2F;h2&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;                &amp;lt;&#x2F;div&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;            }
&lt;&#x2F;span&gt;&lt;span&gt;        }
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; This is the entry point that main.js calls into.
&lt;&#x2F;span&gt;&lt;span&gt;    #[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;wasm_bindgen&lt;&#x2F;span&gt;&lt;span&gt;]
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;pub fn &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8fa1b3;&quot;&gt;run_app&lt;&#x2F;span&gt;&lt;span&gt;() -&amp;gt; Result&amp;lt;(), JsValue&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;        yew::start_app::&amp;lt;App&amp;gt;();
&lt;&#x2F;span&gt;&lt;span&gt;        Ok(())
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;building-your-hello-world&quot;&gt;Building your Hello World&lt;&#x2F;h2&gt;
&lt;p&gt;Now you can build your project with:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;.&#x2F;build_wasm.sh
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;And if you want to see it on your machine in your browser:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;miniserve -v --index&lt;&#x2F;span&gt;&lt;span&gt; index.html .
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Navigate to &lt;a href=&quot;http:&#x2F;&#x2F;127.0.0.1:8080&quot;&gt;http:&#x2F;&#x2F;127.0.0.1:8080&lt;&#x2F;a&gt; to see your Hello World!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;further-resources&quot;&gt;Further Resources&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;yew.rs&#x2F;&quot;&gt;yew guide&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;docs.rs&#x2F;yew&#x2F;0.18.0&#x2F;yew&#x2F;&quot;&gt;yew api documentation&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;yewstack&#x2F;yew&#x2F;tree&#x2F;master&#x2F;examples&quot;&gt;yew example
projects&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;rustwasm.github.io&#x2F;wasm-bindgen&#x2F;introduction.html&quot;&gt;wasm-bindgen
book&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;troubleshooting&quot;&gt;Troubleshooting&lt;&#x2F;h2&gt;
&lt;p&gt;I made all the following mistakes while writing this blog 😅&lt;&#x2F;p&gt;
&lt;h3 id=&quot;build-wasm-sh-permission-denied&quot;&gt;build_wasm.sh - permission denied&lt;&#x2F;h3&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;.&#x2F;build_wasm.sh
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;zsh:&lt;&#x2F;span&gt;&lt;span&gt; permission denied: .&#x2F;build_wasm.sh
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You need to run &amp;quot;chmod +x build_wasm.sh&amp;quot; so that you can execute this.
Permission denied means that the executable bits are missing from the
file.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;building-could-not-resolve&quot;&gt;building - &#x27;Could not resolve&#x27;&lt;&#x2F;h3&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;.&#x2F;main.js&lt;&#x2F;span&gt;&lt;span&gt; → .&#x2F;pkg&#x2F;bundle.js...
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;[!]&lt;&#x2F;span&gt;&lt;span&gt; Error: Could not resolve &amp;#39;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;.&#x2F;pkg&#x2F;PROJECTNAME.js&lt;&#x2F;span&gt;&lt;span&gt;&amp;#39; from main.js
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;Error:&lt;&#x2F;span&gt;&lt;span&gt; Could not resolve &amp;#39;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;.&#x2F;pkg&#x2F;PROJECTNAME.js&lt;&#x2F;span&gt;&lt;span&gt;&amp;#39; from main.js
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This error means you need to edit main.js so that PROJECTNAME matches
your crate name.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;blank-page-in-browser&quot;&gt;Blank Page in Browser&lt;&#x2F;h3&gt;
&lt;p&gt;When you first load your page it may be blank. You can check if a file
is missing or incorrectly named by right clicking the page, select
&#x27;inspect&#x27;, and in the inspector go to the &#x27;network&#x27; tab.&lt;&#x2F;p&gt;
&lt;p&gt;From there refresh your page, and see if any files 404. If they do you
may need to rename them or there is an error in yoru main.js. A common
one is:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;    PROJECTNAME.wasm: 404
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This is because in main.js you may have changed the await init line, and
removed the suffix [_bg]{.title-ref}.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;js&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-js &quot;&gt;&lt;code class=&quot;language-js&quot; data-lang=&quot;js&quot;&gt;&lt;span&gt;    # &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;Incorrect
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;await &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8fa1b3;&quot;&gt;init&lt;&#x2F;span&gt;&lt;span&gt;(&amp;#39;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;&#x2F;pkg&#x2F;PROJECTNAME.wasm&lt;&#x2F;span&gt;&lt;span&gt;&amp;#39;);
&lt;&#x2F;span&gt;&lt;span&gt;    # &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;Correct
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;await &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8fa1b3;&quot;&gt;init&lt;&#x2F;span&gt;&lt;span&gt;(&amp;#39;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;&#x2F;pkg&#x2F;PROJECTNAME_bg.wasm&lt;&#x2F;span&gt;&lt;span&gt;&amp;#39;);
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
</description>
      </item>
      <item>
          <title>Compiler Bootstrapping - Can We Trust Rust?</title>
          <pubDate>Wed, 12 May 2021 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2021-05-12-compiler-bootstrapping-can-we-trust-rust/</link>
          <guid>https://fy.blackhats.net.au/blog/2021-05-12-compiler-bootstrapping-can-we-trust-rust/</guid>
          <description>&lt;h1 id=&quot;compiler-bootstrapping-can-we-trust-rust&quot;&gt;Compiler Bootstrapping - Can We Trust Rust?&lt;&#x2F;h1&gt;
&lt;p&gt;Recently I have been doing a lot of work for SUSE with how we package
the Rust compiler. This process has been really interesting and
challenging, but like anything it&#x27;s certainly provided a lot of time
for thought while &lt;a href=&quot;https:&#x2F;&#x2F;xkcd.com&#x2F;303&#x2F;&quot;&gt;waiting&lt;&#x2F;a&gt; for my packages to
build.&lt;&#x2F;p&gt;
&lt;p&gt;The Rust package in OpenSUSE has two methods of building the compiler
internally in it&#x27;s spec file.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;Use our previously packaged version of rustc from packages&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;ol start=&quot;2&quot;&gt;
&lt;li&gt;Bootstrap using the signed and prebuilt binaries provided by the
rust project&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;bootstrapping&quot;&gt;Bootstrapping&lt;&#x2F;h2&gt;
&lt;p&gt;There are many advocates of bootstrapping and then self sustaining a
chain of compilers within a distribution. The roots of this come from
Ken Thompsons Turing Award speech known as &lt;a href=&quot;https:&#x2F;&#x2F;www.ece.cmu.edu&#x2F;~ganger&#x2F;712.fall02&#x2F;papers&#x2F;p761-thompson.pdf&quot;&gt;Reflections on trusting
trust&lt;&#x2F;a&gt;
. This details the process in which a compiler can be backdoored, to
produce future backdoored compilers. This has been replicated by Manish
G. detailed in their &lt;a href=&quot;https:&#x2F;&#x2F;manishearth.github.io&#x2F;blog&#x2F;2016&#x2F;12&#x2F;02&#x2F;reflections-on-rusting-trust&#x2F;&quot;&gt;blog, Reflections on Rusting
Trust&lt;&#x2F;a&gt;
where they successfully create a self-hosting backdoored rust compiler.&lt;&#x2F;p&gt;
&lt;p&gt;The process can be visualised as:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;┌──────────────┐              ┌──────────────┐                             
&lt;&#x2F;span&gt;&lt;span&gt;│  Backdoored  │              │   Trusted    │                             
&lt;&#x2F;span&gt;&lt;span&gt;│   Sources    │──────┐       │   Sources    │──────┐                      
&lt;&#x2F;span&gt;&lt;span&gt;│              │      │       │              │      │                      
&lt;&#x2F;span&gt;&lt;span&gt;└──────────────┘      │       └──────────────┘      │                      
&lt;&#x2F;span&gt;&lt;span&gt;                      │                             │                      
&lt;&#x2F;span&gt;&lt;span&gt;┌──────────────┐      │       ┌──────────────┐      │      ┌──────────────┐
&lt;&#x2F;span&gt;&lt;span&gt;│   Trusted    │      ▼       │  Backdoored  │      ▼      │  Backdoored  │
&lt;&#x2F;span&gt;&lt;span&gt;│ Interpreter  │──Produces───▶│    Binary    ├──Produces──▶│    Binary    │
&lt;&#x2F;span&gt;&lt;span&gt;│              │              │              │             │              │
&lt;&#x2F;span&gt;&lt;span&gt;└──────────────┘              └──────────────┘             └──────────────┘
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;We can see that in this attack, even with a set of trusted compiler
sources, we can continue to produce a chain of backdoored binaries.&lt;&#x2F;p&gt;
&lt;p&gt;This has led to many people, and even groups such as
&lt;a href=&quot;https:&#x2F;&#x2F;www.bootstrappable.org&#x2F;&quot;&gt;Bootstrappable&lt;&#x2F;a&gt; promoting work to be
able to produce trusted chains from trusted sources, so that we can
assert a level of trust in our produced compiler binaries.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;┌──────────────┐              ┌──────────────┐                             
&lt;&#x2F;span&gt;&lt;span&gt;│   Trusted    │              │   Trusted    │                             
&lt;&#x2F;span&gt;&lt;span&gt;│   Sources    │──────┐       │   Sources    │──────┐                      
&lt;&#x2F;span&gt;&lt;span&gt;│              │      │       │              │      │                      
&lt;&#x2F;span&gt;&lt;span&gt;└──────────────┘      │       └──────────────┘      │                      
&lt;&#x2F;span&gt;&lt;span&gt;                      │                             │                      
&lt;&#x2F;span&gt;&lt;span&gt;┌──────────────┐      │       ┌──────────────┐      │      ┌──────────────┐
&lt;&#x2F;span&gt;&lt;span&gt;│   Trusted    │      ▼       │              │      ▼      │              │
&lt;&#x2F;span&gt;&lt;span&gt;│ Interpreter  │──Produces───▶│Trusted Binary├──Produces──▶│Trusted Binary│
&lt;&#x2F;span&gt;&lt;span&gt;│              │              │              │             │              │
&lt;&#x2F;span&gt;&lt;span&gt;└──────────────┘              └──────────────┘             └──────────────┘
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This process would continue forever to the right, where each trusted
binary is the result of trusted sources. This then ties into topics like
&lt;a href=&quot;https:&#x2F;&#x2F;reproducible-builds.org&#x2F;&quot;&gt;reproducible builds&lt;&#x2F;a&gt; which assert
that you can separately rebuild the sources and attain the same binary,
showing the process can not have been tampered with.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;but-does-it-really-work-like-that&quot;&gt;But does it really work like that?&lt;&#x2F;h2&gt;
&lt;p&gt;Outside of thought exercises, there is little evidence of these attacks
being carried out in reality.&lt;&#x2F;p&gt;
&lt;p&gt;Last year in 2020 we saw supply chain attacks such as the &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;SolarWinds#2019%E2%80%932020_supply_chain_attacks&quot;&gt;Solarwinds
supply chain
attacks&lt;&#x2F;a&gt;
which was reported by
&lt;a href=&quot;https:&#x2F;&#x2F;www.fireeye.com&#x2F;blog&#x2F;products-and-services&#x2F;2020&#x2F;12&#x2F;global-intrusion-campaign-leverages-software-supply-chain-compromise.html&quot;&gt;Fireeye&lt;&#x2F;a&gt;
as &lt;em&gt;&amp;quot;Inserting malicious code into legitimate software updates for the
Orion software that allow an attacker remote access into the victim&#x27;s
environment&amp;quot;&lt;&#x2F;em&gt;. What&#x27;s really interesting here was that no compiler was
compromised in the process like our theoretical attack, but code was
simply inserted and then subsequently was released.&lt;&#x2F;p&gt;
&lt;p&gt;Tavis Ormandy in his blog &lt;a href=&quot;https:&#x2F;&#x2F;blog.cmpxchg8b.com&#x2F;2020&#x2F;07&#x2F;you-dont-need-reproducible-builds.html&quot;&gt;You don&#x27;t need reproducible
builds&lt;&#x2F;a&gt;
covers supply chain security, and examines why reproducible builds are
not effective in the promises and claims they present. Importantly,
Tavis discusses how trivial it is to insert &amp;quot;bugdoors&amp;quot;, or pieces of
code that are malicious and will not be found, and can potentially be
waved off as human error.&lt;&#x2F;p&gt;
&lt;p&gt;Today, we don&#x27;t even need bugdoors, with Microsoft Security Response
Centre reporting that &lt;a href=&quot;https:&#x2F;&#x2F;msrc-blog.microsoft.com&#x2F;2019&#x2F;07&#x2F;16&#x2F;a-proactive-approach-to-more-secure-code&#x2F;&quot;&gt;70% of vulnerabilities are memory safety
issues&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;No amount of reproducible builds or compiler bootstrapping chain can
shield us from the reality that attackers today will target the softest
area, and today that is security issues in our languages, and insecure
configuration of supply chain infrastructure.&lt;&#x2F;p&gt;
&lt;p&gt;We don&#x27;t need backdoored compilers when we know that a security
critical piece of software written in C is still exposed to the network.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;but-lets-assume&quot;&gt;But lets assume ...&lt;&#x2F;h2&gt;
&lt;p&gt;Okay, so lets assume that backdoored compilers are a real risk for a
moment. We need to establish a few things first to create our secure
bootstrapping environment, and these requirements generally are
extremely difficult to meet.&lt;&#x2F;p&gt;
&lt;p&gt;We will need:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Trusted Interpreter&lt;&#x2F;li&gt;
&lt;li&gt;Trusted Sources&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;This is the foundation, having these two trusted entities that we can
use to begin the process. But what is &amp;quot;trusted&amp;quot;? How can we define
that these items are truly trusted?&lt;&#x2F;p&gt;
&lt;p&gt;One method could be to check the cryptographic signatures of the
released source code, to validate that it is &amp;quot;what was released&amp;quot;, but
this does not mean that the source code is free from backdoors&#x2F;bugdoors
which are the very thing we are attempting to shield ourselves from.&lt;&#x2F;p&gt;
&lt;p&gt;What would be truly required here is a detailed and complete audit of
all of the source code to these compilers, which would be a monumental
task in and of itself. So today instead, we do not perform source code
audits, and we &lt;em&gt;blindly trust&lt;&#x2F;em&gt; the providers of the source code as
legitimate and having provided us tamper-free source code. We assert
that blind trust through the validation of those cryptographic
signatures. We blindly trust that they have vetted every commit and line
of code, and they have not had their own source code supply chain
compromised in some way to provide us this &amp;quot;trusted source&amp;quot;. This
gives us a relationship with the producers of that source, that they are
trustworthy and have performed vetting of code and their members with
privileges, that they will &amp;quot;do the right thing&amp;quot;™.&lt;&#x2F;p&gt;
&lt;p&gt;The second challenge is asserting trust in the interpreter. Where did
this binary come from? How was it built? Were it&#x27;s sources trusted? As
one can imagine, this becomes a very deep rabbit hole when we want to
chase it, but in reality the approach taken by todays linux
distributions is that &amp;quot;well we haven&#x27;t been compromised to this point,
so I guess this one is okay&amp;quot; and we yolo build with it. We then create
a root of trust in that one point in time, which then creates our
bootstrapping chain of trust for future builds of subsequent trusted
sources.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;so-what-about-rust&quot;&gt;So what about Rust?&lt;&#x2F;h2&gt;
&lt;p&gt;Rust is interesting compared to something like C (clang&#x2F;gcc), as the
rust project not only provides signed sources, they also provide signed
static binaries of their compiler. This is because unlike clang&#x2F;gcc
which have very long release lifecycles, rust is released every six
weeks and to build version N of the compiler, requires version N or
N - 1. This allows people who have missed a version to easily skip ahead
without needing to build every intermediate version of the compiler.&lt;&#x2F;p&gt;
&lt;p&gt;A frequent complaint is the difficulty to package rust because any time
releases are missed, you must compile every intermediate version to
adhere to the bootstrappable guidelines and principles to created a more
&amp;quot;trusted&amp;quot; compiler.&lt;&#x2F;p&gt;
&lt;p&gt;But just like any other humans, in order to save time, when we miss a
version, we can use the rust language&#x27;s provided signed binaries to
reset the chain, allowing us to miss versions of rust, or to re-package
older versions in some cases.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;                        ┌──────────────┐             ┌──────────────┐              
&lt;&#x2F;span&gt;&lt;span&gt;                 │      │   Trusted    │             │   Trusted    │              
&lt;&#x2F;span&gt;&lt;span&gt;             Missed     │   Sources    │──────┐      │   Sources    │──────┐       
&lt;&#x2F;span&gt;&lt;span&gt;             Version!   │              │      │      │              │      │       
&lt;&#x2F;span&gt;&lt;span&gt;                 │      └──────────────┘      │      └──────────────┘      │       
&lt;&#x2F;span&gt;&lt;span&gt;                 │                            │                            │        
&lt;&#x2F;span&gt;&lt;span&gt;┌──────────────┐ │      ┌──────────────┐      │      ┌──────────────┐      │       
&lt;&#x2F;span&gt;&lt;span&gt;│              │ │      │Trusted Binary│      ▼      │              │      ▼       
&lt;&#x2F;span&gt;&lt;span&gt;│Trusted Binary│ │      │ (from rust)  ├──Produces──▶│Trusted Binary│──Produces───▶ ...
&lt;&#x2F;span&gt;&lt;span&gt;│              │ │      │              │             │              │              
&lt;&#x2F;span&gt;&lt;span&gt;└──────────────┘ │      └──────────────┘             └──────────────┘              
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This process here is interesting because:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Using the signed binary from rust-lang is actually &lt;em&gt;faster&lt;&#x2F;em&gt; since we
can skip one compiler rebuild cycle due to being the same version as
the sources&lt;&#x2F;li&gt;
&lt;li&gt;It shows that the &amp;quot;bootstrappable&amp;quot; trust chain, does not actually
matter since we frequently move our trust root to the released
binary from rust, rather than building all intermediates&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Given this process, we must ask, what value do we have from trying to
adhere to the bootstrappable principles with rust? We already root our
trust in the rust project, meaning that because we blindly trust the
sources &lt;em&gt;and&lt;&#x2F;em&gt; the static compiler, why would our resultant compiler be
any more &amp;quot;trustworthy&amp;quot; just because we were the ones who compiled it?&lt;&#x2F;p&gt;
&lt;p&gt;Beyond this the binaries that are issued by the rust project are used by
thousands of people every day through tools like rustup. In reality,
these have been proven time and time again that they are trusted to be
able to run on mass deployments, and that the rust project has the
ability and capability to respond to issues in their source code as well
as the binaries they provide. They certainly have earned the trust of
many people through this!&lt;&#x2F;p&gt;
&lt;p&gt;So why do we keep assuming both that we are somehow more trustworthy
than the rust project, but simultaneously they are fully trusted in the
artefacts they provide to us?&lt;&#x2F;p&gt;
&lt;h2 id=&quot;contradictions&quot;&gt;Contradictions&lt;&#x2F;h2&gt;
&lt;p&gt;It is this contradiction that has made me rethink the process that we
take to packaging rust in SUSE. I think we should bootstrap from
upstream rust every release because the rust project are in a far better
position to perform audits and respond to trust threats than part time
package maintainers that are commonly part of Linux distributions.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;│ ┌──────────────┐                              │ ┌──────────────┐                             
&lt;&#x2F;span&gt;&lt;span&gt;│ │   Trusted    │                              │ │   Trusted    │                             
&lt;&#x2F;span&gt;&lt;span&gt;│ │   Sources    │──────┐                       │ │   Sources    │──────┐                      
&lt;&#x2F;span&gt;&lt;span&gt;│ │              │      │                       │ │              │      │                      
&lt;&#x2F;span&gt;&lt;span&gt;│ └──────────────┘      │                       │ └──────────────┘      │                      
&lt;&#x2F;span&gt;&lt;span&gt;│                       │                       │                       │                      
&lt;&#x2F;span&gt;&lt;span&gt;│ ┌──────────────┐      │      ┌──────────────┐ │ ┌──────────────┐      │      ┌──────────────┐
&lt;&#x2F;span&gt;&lt;span&gt;│ │Trusted Binary│      ▼      │              │ │ │Trusted Binary│      ▼      │              │
&lt;&#x2F;span&gt;&lt;span&gt;│ │ (from rust)  ├──Produces──▶│Trusted Binary│ │ │ (from rust)  ├──Produces──▶│Trusted Binary│
&lt;&#x2F;span&gt;&lt;span&gt;│ │              │             │              │ │ │              │             │              │
&lt;&#x2F;span&gt;&lt;span&gt;│ └──────────────┘             └──────────────┘ │ └──────────────┘             └──────────────┘
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;We already fully trust the sources they release, and we already fully
trust their binary compiler releases. We can simplify our build process
(and speed it up!) by acknowledging this trust relationship exists,
rather than trying to continue to convince ourselves that we are somehow
&amp;quot;more trusted&amp;quot; than the rust project.&lt;&#x2F;p&gt;
&lt;p&gt;Also we must consider the reality of threats in the wild. Does all of
this work and discussions of who is more trusted really pay off and
defend us in reality? Or are we focused on these topics because they are
something that we can control and have opinions over, rather than
acknowledging the true complexity and dirtiness of security threats as
they truly exist today?&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Open Source Enshrines the Wrong Privilege</title>
          <pubDate>Tue, 23 Mar 2021 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2021-03-23-open-source-enshrines-the-wrong-privilege/</link>
          <guid>https://fy.blackhats.net.au/blog/2021-03-23-open-source-enshrines-the-wrong-privilege/</guid>
          <description>&lt;h1 id=&quot;open-source-enshrines-the-wrong-privilege&quot;&gt;Open Source Enshrines the Wrong Privilege&lt;&#x2F;h1&gt;
&lt;p&gt;Within Open Source&#x2F;Free Software, we repeatedly see a set of
behaviours - hostile or toxic project owners, abusive relationships,
aggression towards users, and complete disregard to users of the
software. Some projects have risen above this and advanced the social
behaviours in their communities, but these are still the minority of
projects.&lt;&#x2F;p&gt;
&lt;p&gt;Many advocates for FLOSS have been trying to enhance adoption of these
technologies in communities, but with the exception of limited
non-technical audiences, this really hasn&#x27;t gained much ground.&lt;&#x2F;p&gt;
&lt;p&gt;It is my opinion that these community behaviours, and the low adoption
of FLOSS technologies comes back to what our Open Source licenses
enshrine - the very thing they embody and create.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-origins-of-free-software&quot;&gt;The Origins of Free Software&lt;&#x2F;h2&gt;
&lt;p&gt;The story of Free Software starts with an individual (later revealed as
abusive), who was frustrated at not being able to access software on a
printer so that he could alter it&#x27;s behaviour. This has been extended
to the idea that Free Software &amp;quot;grants people control over their own
lives and software&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;This however, is not correct.&lt;&#x2F;p&gt;
&lt;p&gt;What Free Software licenses protect is that individuals with time,
resources, specialised technical knowledge and social standing have the
possibility to alter that software&#x27;s behaviour.&lt;&#x2F;p&gt;
&lt;p&gt;When we consider that the majority of the world are not developers or
software engineers, what is it that our Free Software is doing to
protect and support these individuals? Should we truly expect
individuals who are linguists, authors, scientists, retail staff, or
social workers to be able to &amp;quot;alter the software to fix their own
problems&amp;quot;?&lt;&#x2F;p&gt;
&lt;p&gt;Even as technical experts, we are frustrated when someone closes an
issue with &amp;quot;PR&#x27;s welcome&amp;quot;. Imagine how these other people feel when
they can&#x27;t even express or report the problem in the first place or get
told they aren&#x27;t good enough, or that &amp;quot;they can fix it themselves if
they want&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;This attitude also discounts the subject matter knowledge required to
alter or contribute to any piece of software however. I may be a Senior
Software Engineer, but I lack the knowledge and time to contribute to
Gnome for example. Even with these &amp;quot;freedoms&amp;quot; I lack the ability to
&amp;quot;control&amp;quot; the software on my own system.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;open-source-is-selfish&quot;&gt;Open Source is Selfish&lt;&#x2F;h2&gt;
&lt;p&gt;These licenses that we have in FLOSS all enshrine selfish and privileged
behaviours.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;I&lt;&#x2F;strong&gt; have the rights to freely access this code so &lt;strong&gt;I&lt;&#x2F;strong&gt; can read it or
alter it.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;I&lt;&#x2F;strong&gt; can change this project to fix issues &lt;strong&gt;I&lt;&#x2F;strong&gt; have.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;I&lt;&#x2F;strong&gt; have freedoms.&lt;&#x2F;p&gt;
&lt;p&gt;None of these statements from FLOSS describe other people - the people
who consume our software (in some cases, without choice). People who are
not subject matter experts and can&#x27;t contribute to &amp;quot;solve their own
problems&amp;quot;. People who may not have the experience and language to
describe the problems they face.&lt;&#x2F;p&gt;
&lt;p&gt;This lack of empathy, the lack of concern for others in FLOSS leads us
to where we are now. Those who have the subject matter knowledge lead
projects, and do what &lt;em&gt;they&lt;&#x2F;em&gt; want because &lt;em&gt;they&lt;&#x2F;em&gt; can fix it. They tell
others &amp;quot;PR&#x27;s welcome&amp;quot; knowing full-well that the other person may
never be able to contribute, that the barriers to contribution are so
high (both in programming experience and domain knowledge). They design
the software to work the way they want, because they understand it and
it &amp;quot;works for me&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;This is reflected in our software. Software that not does not care for
the needs, experiences or rights of others. Software that pretends to be
accessible, all while creating gated communities of control. Software
that is out of reach of people, the same people that we &amp;quot;claim&amp;quot; to be
working for and supporting.&lt;&#x2F;p&gt;
&lt;p&gt;It leads to our communities that are selfish, and do not empathise with
people. Communities that have placed negative behaviours on pedestals
and turned these people into &amp;quot;leaders&amp;quot;. Software that does not account
for the experiences of our users, believing that the &amp;quot;community knows
best&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;One does not need to look far for FLOSS projects that speak one set of
words, but their actions do not align.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-can-we-do&quot;&gt;What Can We Do?&lt;&#x2F;h2&gt;
&lt;p&gt;In our projects we need to go beyond preserving the freedoms of
ourselves, and begin to discuss the freedoms and interactions that
others should have with our systems and projects. Here are some starting
ideas that I have:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Have a code of conduct for all contributors (remember, opening an
issue is a contribution).&lt;&#x2F;li&gt;
&lt;li&gt;Document your target users, and what kind of experience they should
have. Expand this over time.&lt;&#x2F;li&gt;
&lt;li&gt;Promote empathy for those who aren&#x27;t direct contributors - indirect
users without choice exist.&lt;&#x2F;li&gt;
&lt;li&gt;Remove dependencies on as many problematic software projects as
possible.&lt;&#x2F;li&gt;
&lt;li&gt;Push for improvements to open licenses that enshrine the freedoms of
others - not just developers.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;As individual communities we can advance the state of software and how
we act socially so that future projects and users are in a better place.
No software exists in a vacuum, all software exists to support people.
We need to always keep in mind the effects our software has on others.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Time Machine on Samba with ZFS</title>
          <pubDate>Mon, 22 Mar 2021 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2021-03-22-time-machine-on-samba-with-zfs/</link>
          <guid>https://fy.blackhats.net.au/blog/2021-03-22-time-machine-on-samba-with-zfs/</guid>
          <description>&lt;h1 id=&quot;time-machine-on-samba-with-zfs&quot;&gt;Time Machine on Samba with ZFS&lt;&#x2F;h1&gt;
&lt;p&gt;Time Machine is Apple&#x27;s in-built backup system for MacOS. It&#x27;s
probably the best consumer backup option, which really achieves &amp;quot;set
and forget&amp;quot; backups.&lt;&#x2F;p&gt;
&lt;p&gt;It can backup to an external hard disk on a dock, an Apple Time Machine
(wireless access point), or a custom location based on SMB shares.&lt;&#x2F;p&gt;
&lt;p&gt;Since I have a fileserver at home, I use this as my Time Machine backup
target. To make this work really smoothly there are a few setup steps.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;macos-time-machine-performance&quot;&gt;MacOS Time Machine Performance&lt;&#x2F;h2&gt;
&lt;p&gt;By default timemachine operates as a low priority process. You can set a
sysctl to improve the performance of this (especially helpful for a
first backup!)&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;sysctl -w debug.lowpri_throttle_enabled=0
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You will need a launchd script to make this setting survive a reboot.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;zfs&quot;&gt;ZFS&lt;&#x2F;h2&gt;
&lt;p&gt;I&#x27;m using ZFS on my server, which is probably the best filesystem
available. To make Time Machine work well on ZFS there are a number of
tuning options that can help. As these backups write and read many small
files, you should have a large amount of RAM for ARC (best) or a ZIL on
nvme. RAID 10 will likely work better than RAIDZ here as you need better
seek latency than write throughput due to the need to access many small
files. Generally time machine is very &amp;quot;IO demanding&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;For the ZFS properties on the filesystem I created it with the following
options to [zfs create]{.title-ref}. Each once is set with [-o
attribute=value]{.title-ref}&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;atime: off
&lt;&#x2F;span&gt;&lt;span&gt;dnodesize: auto
&lt;&#x2F;span&gt;&lt;span&gt;xattr: sa
&lt;&#x2F;span&gt;&lt;span&gt;logbias: throughput
&lt;&#x2F;span&gt;&lt;span&gt;recordsize: 1M
&lt;&#x2F;span&gt;&lt;span&gt;compression: zstd-10 | zle
&lt;&#x2F;span&gt;&lt;span&gt;refquota: 3T
&lt;&#x2F;span&gt;&lt;span&gt;# optional - greatly improves write performance
&lt;&#x2F;span&gt;&lt;span&gt;sync: disabled
&lt;&#x2F;span&gt;&lt;span&gt;# security
&lt;&#x2F;span&gt;&lt;span&gt;setuid: off
&lt;&#x2F;span&gt;&lt;span&gt;exec: off
&lt;&#x2F;span&gt;&lt;span&gt;devices: off
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The important ones here are the compression setting. If you choose zle,
you gain much faster write performance, but you dont get much in the way
of compression. zstd-10 gives me about 1.3x compression, but at the loss
of performance. Generally the decision is based on your pool and storage
capacity.&lt;&#x2F;p&gt;
&lt;p&gt;Also note the use of refquota instead of quota. This applies the quota
to this filesystem only excluding snapshots - if you use quota, the
space taken by snapshots it also applied to this filesystem, which may
cause you to run out of space.&lt;&#x2F;p&gt;
&lt;p&gt;You may optionally choose to disable sync. This is because Time Machine
issues a sync after every single file write to the server, which can
cause low performance with many small files. To mitigate the data loss
risk here, I snapshot the backups filesystem hourly.&lt;&#x2F;p&gt;
&lt;p&gt;If you want to encrypt at the ZFS level instead of through time machine
you need to enable this as you create the filesystem.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# create a key file to unlock the zfs filesystem
&lt;&#x2F;span&gt;&lt;span&gt;openssl rand -hex -out &#x2F;root&#x2F;key 32
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Add the following settings during zfs create:
&lt;&#x2F;span&gt;&lt;span&gt;-o encryption=aes-128-gcm -o keyformat=hex -o keylocation=file:&#x2F;&#x2F;&#x2F;root&#x2F;key
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If you add any subvolumes, you need to repeat the same encryption steps
during the create of these subvolumes.&lt;&#x2F;p&gt;
&lt;p&gt;For example a create may look like:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;zfs create \
&lt;&#x2F;span&gt;&lt;span&gt;    -o encryption=aes-128-gcm -o keyformat=hex -o keylocation=file:&#x2F;&#x2F;&#x2F;root&#x2F;key \
&lt;&#x2F;span&gt;&lt;span&gt;    -o atime=off -o dnodesize=auto -o xattr=sa -o logbias=throughput \
&lt;&#x2F;span&gt;&lt;span&gt;    -o recordsize=1M -o compression=zle -o refquota=3T -o sync=disabled \
&lt;&#x2F;span&gt;&lt;span&gt;    -o setuid=off -o exec=off -o devices=off tank&#x2F;backups
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;smb-conf&quot;&gt;smb.conf&lt;&#x2F;h2&gt;
&lt;p&gt;In smb.conf you define the share that exposes the timemachine backup
location. You need to set additional metadata on this so that macos will
recognise it correctly.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;[global]
&lt;&#x2F;span&gt;&lt;span&gt;min protocol = SMB2
&lt;&#x2F;span&gt;&lt;span&gt;ea support = yes
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# This needs to be global else time machine ops can fail.
&lt;&#x2F;span&gt;&lt;span&gt;vfs objects = fruit streams_xattr
&lt;&#x2F;span&gt;&lt;span&gt;fruit:aapl = yes
&lt;&#x2F;span&gt;&lt;span&gt;fruit:metadata = stream
&lt;&#x2F;span&gt;&lt;span&gt;fruit:model = MacSamba
&lt;&#x2F;span&gt;&lt;span&gt;fruit:posix_rename = yes
&lt;&#x2F;span&gt;&lt;span&gt;fruit:veto_appledouble = no
&lt;&#x2F;span&gt;&lt;span&gt;fruit:nfs_aces = no
&lt;&#x2F;span&gt;&lt;span&gt;fruit:wipe_intentionally_left_blank_rfork = yes
&lt;&#x2F;span&gt;&lt;span&gt;fruit:delete_empty_adfiles = yes
&lt;&#x2F;span&gt;&lt;span&gt;spotlight = no
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[timemachine_a]
&lt;&#x2F;span&gt;&lt;span&gt;comment = Time Machine
&lt;&#x2F;span&gt;&lt;span&gt;fruit:time machine = yes
&lt;&#x2F;span&gt;&lt;span&gt;fruit:time machine max size = 1050G
&lt;&#x2F;span&gt;&lt;span&gt;path = &#x2F;var&#x2F;data&#x2F;backup&#x2F;timemachine_a
&lt;&#x2F;span&gt;&lt;span&gt;browseable = yes
&lt;&#x2F;span&gt;&lt;span&gt;write list = timemachine
&lt;&#x2F;span&gt;&lt;span&gt;create mask = 0600
&lt;&#x2F;span&gt;&lt;span&gt;directory mask = 0700
&lt;&#x2F;span&gt;&lt;span&gt;# NOTE: Changing these will require a new initial backup cycle if you already have an existing
&lt;&#x2F;span&gt;&lt;span&gt;# timemachine share.
&lt;&#x2F;span&gt;&lt;span&gt;case sensitive = true
&lt;&#x2F;span&gt;&lt;span&gt;default case = lower
&lt;&#x2F;span&gt;&lt;span&gt;preserve case = no
&lt;&#x2F;span&gt;&lt;span&gt;short preserve case = no
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The fruit settings are required to help Time Machine understand that
this share is usable for it. I have also added a custom timemachine user
to smbpasswd, and created a matching posix account who should own these
files.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;macos&quot;&gt;MacOS&lt;&#x2F;h2&gt;
&lt;p&gt;You can now add this to MacOS via system preferences. If your ZFS volume
is NOT encyrpted, you should add the timemachine volume via system
preferences, as it is the only way to enable encryption of the time
machine backup. For system preferences to &amp;quot;see&amp;quot; the samba share you
may need to mount it manually via finder as the time machine user.&lt;&#x2F;p&gt;
&lt;p&gt;If you are using ZFS encryption, you can add the time machine backup
from the command line instead.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;tmutil setdestination smb:&#x2F;&#x2F;timemachine:password@hostname&#x2F;timemachine_a
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If you intend to have multiple time machine targets, MacOS is capable of
mirroring between multilple stripes alternately. You can append the
second stripe with (note the -a). You could do this with other shares
(offsite for example) or with a HDD on your desk.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;tmutil setdestination -a smb:&#x2F;&#x2F;timemachine:password@hostname&#x2F;timemachine_b
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
</description>
      </item>
      <item>
          <title>Against Packaging Rust Crates</title>
          <pubDate>Tue, 16 Feb 2021 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2021-02-16-against-packaging-rust-crates/</link>
          <guid>https://fy.blackhats.net.au/blog/2021-02-16-against-packaging-rust-crates/</guid>
          <description>&lt;h1 id=&quot;against-packaging-rust-crates&quot;&gt;Against Packaging Rust Crates&lt;&#x2F;h1&gt;
&lt;p&gt;Recently the discussion has once again come up around the notion of
packaging Rust crates as libraries in distributions. For example, taking
a library like [serde]{.title-ref} and packaging it to an RPM. While I
use RPM as the examples here it applies equally to other formats.&lt;&#x2F;p&gt;
&lt;p&gt;Proponents of crate packaging want all Rust applications to use the
&amp;quot;distributions&amp;quot; versions of a crate. This is to prevent &amp;quot;vendoring&amp;quot;
or &amp;quot;bundling&amp;quot;. This is where an application (such as 389 Directory
Server) ships all of it&#x27;s sources, as well as the sources of it&#x27;s Rust
dependencies in a single archive. These sources may differ in version
from the bundled sources of other applications.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;packaging-crates-is-not-reinventing-cargo&quot;&gt;&amp;quot;Packaging crates is not reinventing Cargo&amp;quot;&lt;&#x2F;h2&gt;
&lt;p&gt;This is a common claim by advocates of crate packaging. However it is
easily disproved:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;If packaging is not reinventing cargo, I am free to use all of Cargo&#x27;s
features without conflicts to distribution packaging.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The reality is that packaging crates &lt;em&gt;is&lt;&#x2F;em&gt; reinventing Cargo - but
without all it&#x27;s features. Common limitations are that Cargo&#x27;s exact
version&#x2F;less than requirements can not be used safely, or Cargo&#x27;s
ability to apply patches or uses sources from specific git revisions can
not be used at all.&lt;&#x2F;p&gt;
&lt;p&gt;As a result, this hinders upstreams from using all the rich features
within Cargo to comply with distribution packaging limitations, or it
will cause the package to hit exceptions in policy and necesitate
vendoring anyway.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;you-can-vendor-only-in-these-exceptional-cases&quot;&gt;&amp;quot;You can vendor only in these exceptional cases ...&amp;quot;&lt;&#x2F;h2&gt;
&lt;p&gt;As noted, since packaging is reinventing Cargo, if you use features of
Cargo that are unsupported then you may be allowed to vendor depending
on the distributions policy. However, this raises some interesting
issues itself.&lt;&#x2F;p&gt;
&lt;p&gt;Assume I have been using distribution crates for a period of time - then
the upstream adds an exact version or git revision requirement to a
project or a dependency in my project. I now need to change my spec file
and tooling to use vendoring and all of the benefits of distribution
crates no longer exists (because you can not have any dependency in your
tree that has an exact version rule).&lt;&#x2F;p&gt;
&lt;p&gt;If the upstream &#x27;un-does&#x27; that change, then I need to roll back to
distribution crates since the project would no longer be covered by the
exemption.&lt;&#x2F;p&gt;
&lt;p&gt;This will create review delays and large amounts of administrative
overhead. It means pointless effort to swap between vendored and
distribution crates based on small upstream changes. This may cause
packagers to avoid certain versions or updates so that they do not need
to swap between distribution methods.&lt;&#x2F;p&gt;
&lt;p&gt;It&#x27;s very likely that these &amp;quot;exceptional&amp;quot; cases will be very common,
meaning that vendoring will be occuring. This necesitates supporting
vendored applications in distribution packages.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;you-don-t-need-to-package-the-universe&quot;&gt;&amp;quot;You don&#x27;t need to package the universe&amp;quot;&lt;&#x2F;h2&gt;
&lt;p&gt;Many proponents say that they have &amp;quot;already packaged most things&amp;quot;. For
example in 389 Directory Server of our 60 dependencies, only 2 were
missing in Fedora (2021-02). However this overlooks the fact that I do
not want to package those 2 other crates just to move forward. I want to
support 389 Directory Server the &lt;em&gt;application&lt;&#x2F;em&gt; not all of it&#x27;s
dependencies in a distribution.&lt;&#x2F;p&gt;
&lt;p&gt;This is also before we come to larger rust projects, such as Kanidm that
has nearly 400 dependencies. The likelihood that many of them are
missing is high.&lt;&#x2F;p&gt;
&lt;p&gt;So you will need to package the universe. Maybe not all of it. But still
a lot of it. It&#x27;s already hard enough to contribute packages to a
distribution. It becomes even harder when I need to submit 3, 10, or 100
more packages. It could be months before enough approvals were in place.
It&#x27;s a staggering amount of administration and work, which will
discourage many contributors.&lt;&#x2F;p&gt;
&lt;p&gt;People have already contacted me to say that if they had to package
crates to distribution packages to contribute, they would give up and
walk away. We&#x27;ve already lost future contributors.&lt;&#x2F;p&gt;
&lt;p&gt;Further to this Ruby, Python and many other languages today all
recommend language native tools such as rvm or virtualenv to avoid using
distribution packaged libraries.&lt;&#x2F;p&gt;
&lt;p&gt;Packages in distributions should exist as a vehicle to ship bundled
applications that are created from their language native tools.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;we-will-update-your-dependencies-for-you&quot;&gt;&amp;quot;We will update your dependencies for you&amp;quot;&lt;&#x2F;h2&gt;
&lt;p&gt;A supposed benefit is that versions of crates in distributions will be
updated in the background according to semver rules.&lt;&#x2F;p&gt;
&lt;p&gt;If we had an exact version requirement (that was satisfiable), a silent
background update will cause this to no longer work - and will break the
application from building. This would necesitate one of:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;A change to the Cargo.toml to remove the equality requirement - a
requirement that may exist for good reason.&lt;&#x2F;li&gt;
&lt;li&gt;It will force the application to temporarily swap to vendoring
instead.&lt;&#x2F;li&gt;
&lt;li&gt;The application will remain broken and unable to be updated until
upstream resolves the need for the equality requirement.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Background updates also ignore the state of your Cargo.lock file by
removing it. A Cargo.lock file is recommended to be checked in with
binary applications in Rust, as evidence that shows &amp;quot;here is an exact
set of dependencies that upstream has tested and verified as building
and working&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;To remove and ignore this file, means to remove the guarantees of
quality from an upstream.&lt;&#x2F;p&gt;
&lt;p&gt;It is unlikely that packagers will run the entire test suite of an
application to regain this confidence. They will &amp;quot;apply the patch and
pray&amp;quot; method - as they already do with other languages.&lt;&#x2F;p&gt;
&lt;p&gt;We can already see how background updates can have significant negative
consequences on application stability. FreeIPA has hundreds of
dependencies, and it&#x27;s common that if any of them changes in small
ways, it can cause FreeIPA to fall over. This is not the fault of
FreeIPA - it&#x27;s the fault of relying on so many small moving parts that
can change underneath your feet without warning. FreeIPA would strongly
benefit from vendoring to improve it&#x27;s stability and quality.&lt;&#x2F;p&gt;
&lt;p&gt;Inversely, it can cause hesitation to updating libraries - since there
is now a risk of breaking other applications that depend on them. We do
not want people to be afraid of updates.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;we-can-respond-to-security-issues&quot;&gt;&amp;quot;We can respond to security issues&amp;quot;&lt;&#x2F;h2&gt;
&lt;p&gt;On the surface this is a strong argument, but in reality it does not
hold up. The security issues that face Rust are significantly different
to that which affect C. In C it may be viable to patch and update a
dynamic library to fix an issue. It saves time because you only need to
update and change one library to fix everything.&lt;&#x2F;p&gt;
&lt;p&gt;Security issues are much rarer in Rust. When they occur, you will have
to update and re-build all applications depending on the affected
library.&lt;&#x2F;p&gt;
&lt;p&gt;Since this rebuilding work has to occur, where the security fix is
applied is irrelevant. This frees us to apply the fixes in a different
way to how we approach C.&lt;&#x2F;p&gt;
&lt;p&gt;It is better to apply the fixes in a consistent and universal manner.
There &lt;em&gt;will&lt;&#x2F;em&gt; be applications that are vendored due to vendoring
exceptions, there is now duplicated work and different processes to
respond to both distribution crates, and vendored applications.&lt;&#x2F;p&gt;
&lt;p&gt;Instead all applications could be vendored, and tooling exists that
would examine the Cargo.toml to check for insecure versions
(RustSec&#x2F;cargo-audit does this for example). The Cargo.toml&#x27;s can be
patched, and applications tested and re-vendored. Even better is these
changes could easily then be forwarded to upstreams, allowing every
distribution and platform to benefit from the work.&lt;&#x2F;p&gt;
&lt;p&gt;In the cases that the upstream can not fix the issue, then Cargo&#x27;s
native patching tooling can be used to supply fixes directly into
vendored sources for rare situations requiring it.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;patching-20-vulnerable-crates-doesn-t-scale-we-need-to-patch-in-one-place&quot;&gt;&amp;quot;Patching 20 vulnerable crates doesn&#x27;t scale, we need to patch in one place!&amp;quot;&lt;&#x2F;h2&gt;
&lt;p&gt;A common response to the previous section is that the above process
won&#x27;t scale as we need to find and patch 20 locations compared to just
one. It will take &amp;quot;more human effort&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;Today, when a security fix comes out, every distribution&#x27;s security
teams will have to be made aware of this. That means - OpenSUSE, Fedora,
Debian, Ubuntu, Gentoo, Arch, and many more groups all have to become
aware and respond. Then each of these projects security teams will work
with their maintainers to build and update these libraries. In the case
of SUSE and Red Hat this means that multiple developers may be involved,
quality engineering will be engaged to test these changes. Consumers of
that library will re-test their applications in some cases to ensure
there are no faults of the components they rely upon. This is all before
we approach the fact that each of these distributions have many
supported and released versions they likely need to maintain so this
process may be repeated for patching and testing multiple versions in
parallel.&lt;&#x2F;p&gt;
&lt;p&gt;In this process there are a few things to note:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;There is a huge amount of human effort today to keep on top of
security issues in our distributions.&lt;&#x2F;li&gt;
&lt;li&gt;Distributions tend to be isolated and can&#x27;t share the work to
resolve these - the changes to the rpm specs in SUSE won&#x27;t help
Debian for example.&lt;&#x2F;li&gt;
&lt;li&gt;Human error occurs in all of these layers causing security issues to
go un-fixed or breaking a released application.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;To suggest that rust and vendoring somehow makes this harder or more
time consuming is discounting the huge amount of time, skill, and effort
already put in by people to keep our C based distributions functioning
today.&lt;&#x2F;p&gt;
&lt;p&gt;Vendored Rust won&#x27;t make this process easier or harder - it just
changes the nature of the effort we have to apply as maintainers and
distributions. It shifts our focus from &amp;quot;how do we ensure this library
is secure&amp;quot; to &amp;quot;how do we ensure this &lt;em&gt;application&lt;&#x2F;em&gt; made from many
libraries is secure&amp;quot;. It allows further collaboration with upstreams to
be involved in the security update process, which ends up benefiting
&lt;em&gt;all&lt;&#x2F;em&gt; distributions.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;it-doesn-t-duplicate-effort&quot;&gt;&amp;quot;It doesn&#x27;t duplicate effort&amp;quot;&lt;&#x2F;h2&gt;
&lt;p&gt;It does. By the very nature of both distribution libraries and vendored
applications needing to exist in a distribution, there will become
duplicated but seperate processes and policies to manage these, inspect,
and update these. This will create a need for tooling and supporting
both methods, which consumes time for many people.&lt;&#x2F;p&gt;
&lt;p&gt;People have already done the work to package and release libraries to
crates.io. Tools already exist to provide our dependencies and include
them in our applications. Why do we need to duplicate these features and
behaviours in distribution packages when Cargo already does this
correctly, and in a way that is universal and supported.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;don-t-support-distribution-crates&quot;&gt;Don&#x27;t support distribution crates&lt;&#x2F;h2&gt;
&lt;p&gt;I can&#x27;t be any clearer than that. They consume excessive amounts of
contributor time, for little to no benefit, it detracts from simpler
language-native solutions for managing dependencies, distracts from
better language integration tooling being developed, it can introduce
application instability and bugs, and it creates high barriers to entry
for new contributors to distributions.&lt;&#x2F;p&gt;
&lt;p&gt;It doesn&#x27;t have to be like this.&lt;&#x2F;p&gt;
&lt;p&gt;We need to stop thinking that Rust is like C. We have to accept that
language native tools are the interface people will want to use to
manage their libraries and distribute whole applications. We must use
our time more effectively as distributions.&lt;&#x2F;p&gt;
&lt;p&gt;If we focus on supporting vendored Rust applications, and developing our
infrastructure and tooling to support this, we &lt;em&gt;will&lt;&#x2F;em&gt; attract new
contributors by lowering barriers to entry, but we will also have a
stronger ability to contribute back to upstreams, and we will simplify
our building and packaging processes.&lt;&#x2F;p&gt;
&lt;p&gt;Today, tools like docker, podman, flatpak, snapd and others have proven
how bundling&#x2F;vendoring, and a focus an applications can advance the
state of our ecosystems. We need to adopt the same ideas into
distributions. Our package managers should become a method to ship
applications - not libraries.&lt;&#x2F;p&gt;
&lt;p&gt;We need to focus our energy to supporting &lt;em&gt;applications&lt;&#x2F;em&gt; as self
contained units - not supporting the libraries that make them up.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;edits&quot;&gt;Edits&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Released: 2021-02-16&lt;&#x2F;li&gt;
&lt;li&gt;EDIT: 2021-02-22 - improve clarity on some points, thanks to
ftweedal.&lt;&#x2F;li&gt;
&lt;li&gt;EDIT: 2021-02-23 - due to a lot of comments regarding security
updates, added an extra section to address how this scales.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</description>
      </item>
      <item>
          <title>Getting Started Packaging A Rust CLI Tool in SUSE OBS</title>
          <pubDate>Mon, 15 Feb 2021 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2021-02-15-getting-started-packaging-a-rust-cli-tool-in-suse-obs/</link>
          <guid>https://fy.blackhats.net.au/blog/2021-02-15-getting-started-packaging-a-rust-cli-tool-in-suse-obs/</guid>
          <description>&lt;h1 id=&quot;getting-started-packaging-a-rust-cli-tool-in-suse-obs&quot;&gt;Getting Started Packaging A Rust CLI Tool in SUSE OBS&lt;&#x2F;h1&gt;
&lt;p&gt;Distribution packaging always seems like something that is really
difficult or hard to do, but the SUSE &lt;a href=&quot;https:&#x2F;&#x2F;build.opensuse.org&quot;&gt;Open Build
Service&lt;&#x2F;a&gt; makes it really easy to not only
build packages, but to then contribute them to Tumbleweed. Not only
that, OBS can also build for Fedora, CentOS and more.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;getting-started&quot;&gt;Getting Started&lt;&#x2F;h2&gt;
&lt;p&gt;You&#x27;ll need to sign up to service - there is a sign up link on the
front page of &lt;a href=&quot;https:&#x2F;&#x2F;build.opensuse.org&quot;&gt;OBS&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;To do this you&#x27;ll need a SUSE environment. Docker is an easy way to
create this without having to commit to a full virtual machine &#x2F;
install.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;docker&lt;&#x2F;span&gt;&lt;span&gt; run \
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;        --security-opt&lt;&#x2F;span&gt;&lt;span&gt;=seccomp:unconfined&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt; --cap-add&lt;&#x2F;span&gt;&lt;span&gt;=SYS_PTRACE&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt; --cap-add&lt;&#x2F;span&gt;&lt;span&gt;=SYS_CHROOT&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt; --cap-add&lt;&#x2F;span&gt;&lt;span&gt;=SYS_ADMIN \
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;        -i -t&lt;&#x2F;span&gt;&lt;span&gt; opensuse&#x2F;tumbleweed:latest &#x2F;bin&#x2F;sh
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;bash
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;-&lt;&#x2F;span&gt;&lt;span&gt;   NOTE: We need these extra privileges so that the osc build command
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;can&lt;&#x2F;span&gt;&lt;span&gt; work due to how it uses chroots&#x2F;mounts.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;Inside&lt;&#x2F;span&gt;&lt;span&gt; of this we&lt;&#x2F;span&gt;&lt;span style=&quot;color:#96b5b4;&quot;&gt;\&amp;#39;&lt;&#x2F;span&gt;&lt;span&gt;ll need some packages to help make the process
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;easier.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;```&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;bash
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;zypper&lt;&#x2F;span&gt;&lt;span&gt; install obs-service-cargo_vendor osc obs-service-tar obs-service-obs_scm \
&lt;&#x2F;span&gt;&lt;span&gt;        obs-service-recompress obs-service-set_version obs-service-format_spec_file \
&lt;&#x2F;span&gt;&lt;span&gt;        obs-service-cargo_audit cargo sudo
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You should also install your editor of choice in this command (docker
images tend not to come with any editors!)&lt;&#x2F;p&gt;
&lt;p&gt;You&#x27;ll need to configure osc, which is the CLI interface to OBS. This
is done in the file [~&#x2F;.config&#x2F;osc&#x2F;oscrc]{.title-ref}. A minimal
starting configuration is:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;ini&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-ini &quot;&gt;&lt;code class=&quot;language-ini&quot; data-lang=&quot;ini&quot;&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;    [general]
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# URL to access API server, e.g. https:&#x2F;&#x2F;api.opensuse.org
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# you also need a section [https:&#x2F;&#x2F;api.opensuse.org] with the credentials
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;apiurl &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;https:&#x2F;&#x2F;api.opensuse.org
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;    [https:&#x2F;&#x2F;api.opensuse.org]
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;user &lt;&#x2F;span&gt;&lt;span&gt;= &amp;lt;username&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;pass &lt;&#x2F;span&gt;&lt;span&gt;= &amp;lt;password&amp;gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You can check this works by using the &amp;quot;whois&amp;quot; command.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# osc whois
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;firstyear: &lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;William Brown&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot; &amp;lt;email here&amp;gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Optionally, you may install &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;Firstyear&#x2F;cargo-lock2rpmprovides&quot;&gt;cargo
lock2rpmprovides&lt;&#x2F;a&gt;
to assist with creation of the license string for your package:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;cargo&lt;&#x2F;span&gt;&lt;span&gt; install cargo-lock2rpmprovides
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;packaging-a-rust-project&quot;&gt;Packaging A Rust Project&lt;&#x2F;h2&gt;
&lt;p&gt;In this example we&#x27;ll use a toy Rust application I created called
&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;Firstyear&#x2F;hellorust&quot;&gt;hellorust&lt;&#x2F;a&gt;. Of course, feel
free to choose your own project or Rust project you want to package!&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;HINT: It&#x27;s best to choose binaries, not libraries to package. This
is because Rust can self-manage it&#x27;s dependencies, so we don&#x27;t
need to package every library. Neat!&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;First we&#x27;ll create a package in our OBS home project.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;osc&lt;&#x2F;span&gt;&lt;span&gt; co home:&amp;lt;username&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#96b5b4;&quot;&gt;cd&lt;&#x2F;span&gt;&lt;span&gt; home:&amp;lt;username&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;osc&lt;&#x2F;span&gt;&lt;span&gt; mkpac hellorust
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#96b5b4;&quot;&gt;cd&lt;&#x2F;span&gt;&lt;span&gt; hellorust
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;OBS comes with a lot of useful utilities to help create and manage
sources for our project. First we&#x27;ll create a skeleton RPM spec file.
This should be in a file named [hellorust.spec]{.title-ref}&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;    %global rustflags -Clink-arg=-Wl,-z,relro,-z,now -C debuginfo=2
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    Name:           hellorust
&lt;&#x2F;span&gt;&lt;span&gt;    #               This will be set by osc services, that will run after this.
&lt;&#x2F;span&gt;&lt;span&gt;    Version:        0.0.0
&lt;&#x2F;span&gt;&lt;span&gt;    Release:        0
&lt;&#x2F;span&gt;&lt;span&gt;    Summary:        A hello world with a number of the day printer.
&lt;&#x2F;span&gt;&lt;span&gt;    #               If you know the license, put it&amp;#39;s SPDX string here.
&lt;&#x2F;span&gt;&lt;span&gt;    #               Alternately, you can use cargo lock2rpmprovides to help generate this.
&lt;&#x2F;span&gt;&lt;span&gt;    License:        Unknown
&lt;&#x2F;span&gt;&lt;span&gt;    #               Select a group from this link:
&lt;&#x2F;span&gt;&lt;span&gt;    #               https:&#x2F;&#x2F;en.opensuse.org&#x2F;openSUSE:Package_group_guidelines
&lt;&#x2F;span&gt;&lt;span&gt;    Group:          Amusements&#x2F;Games&#x2F;Other
&lt;&#x2F;span&gt;&lt;span&gt;    Url:            https:&#x2F;&#x2F;github.com&#x2F;Firstyear&#x2F;hellorust
&lt;&#x2F;span&gt;&lt;span&gt;    Source0:        %{name}-%{version}.tar.xz
&lt;&#x2F;span&gt;&lt;span&gt;    Source1:        vendor.tar.xz
&lt;&#x2F;span&gt;&lt;span&gt;    Source2:        cargo_config
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    BuildRequires:  rust-packaging
&lt;&#x2F;span&gt;&lt;span&gt;    ExcludeArch:    s390 s390x ppc ppc64 ppc64le %ix86
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    %description
&lt;&#x2F;span&gt;&lt;span&gt;    A hello world with a number of the day printer.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    %prep
&lt;&#x2F;span&gt;&lt;span&gt;    %setup -q
&lt;&#x2F;span&gt;&lt;span&gt;    %setup -qa1
&lt;&#x2F;span&gt;&lt;span&gt;    mkdir .cargo
&lt;&#x2F;span&gt;&lt;span&gt;    cp %{SOURCE2} .cargo&#x2F;config
&lt;&#x2F;span&gt;&lt;span&gt;    # Remove exec bits to prevent an issue in fedora shebang checking
&lt;&#x2F;span&gt;&lt;span&gt;    find vendor -type f -name \*.rs -exec chmod -x &amp;#39;{}&amp;#39; \;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    %build
&lt;&#x2F;span&gt;&lt;span&gt;    export RUSTFLAGS=&amp;quot;%{rustflags}&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    cargo build --offline --release
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    %install
&lt;&#x2F;span&gt;&lt;span&gt;    install -D -d -m 0755 %{buildroot}%{_bindir}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    install -m 0755 %{_builddir}&#x2F;%{name}-%{version}&#x2F;target&#x2F;release&#x2F;hellorust %{buildroot}%{_bindir}&#x2F;hellorust
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    %files
&lt;&#x2F;span&gt;&lt;span&gt;    %{_bindir}&#x2F;hellorust
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    %changelog
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;There are a few commented areas you&#x27;ll need to fill in and check. But
next we will create a service file that allows OBS to help get our
sources and bundle them for us. This should go in a file called
&lt;code&gt;_service&lt;&#x2F;code&gt;&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;    &amp;lt;services&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;      &amp;lt;service mode=&amp;quot;disabled&amp;quot; name=&amp;quot;obs_scm&amp;quot;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;lt;!-- ✨ URL of the git repo ✨ --&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;lt;param name=&amp;quot;url&amp;quot;&amp;gt;https:&#x2F;&#x2F;github.com&#x2F;Firstyear&#x2F;hellorust.git&amp;lt;&#x2F;param&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;lt;param name=&amp;quot;versionformat&amp;quot;&amp;gt;@PARENT_TAG@~git@TAG_OFFSET@.%h&amp;lt;&#x2F;param&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;lt;param name=&amp;quot;scm&amp;quot;&amp;gt;git&amp;lt;&#x2F;param&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;lt;!-- ✨ The version tag or branch name from git ✨ --&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;lt;param name=&amp;quot;revision&amp;quot;&amp;gt;v0.1.1&amp;lt;&#x2F;param&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;lt;param name=&amp;quot;match-tag&amp;quot;&amp;gt;*&amp;lt;&#x2F;param&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;lt;param name=&amp;quot;versionrewrite-pattern&amp;quot;&amp;gt;v(\d+\.\d+\.\d+)&amp;lt;&#x2F;param&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;lt;param name=&amp;quot;versionrewrite-replacement&amp;quot;&amp;gt;\1&amp;lt;&#x2F;param&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;lt;param name=&amp;quot;changesgenerate&amp;quot;&amp;gt;enable&amp;lt;&#x2F;param&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;lt;!-- ✨ Your email here ✨ --&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;lt;param name=&amp;quot;changesauthor&amp;quot;&amp;gt; YOUR EMAIL HERE &amp;lt;&#x2F;param&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;      &amp;lt;&#x2F;service&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;      &amp;lt;service mode=&amp;quot;disabled&amp;quot; name=&amp;quot;tar&amp;quot; &#x2F;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;      &amp;lt;service mode=&amp;quot;disabled&amp;quot; name=&amp;quot;recompress&amp;quot;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;lt;param name=&amp;quot;file&amp;quot;&amp;gt;*.tar&amp;lt;&#x2F;param&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;lt;param name=&amp;quot;compression&amp;quot;&amp;gt;xz&amp;lt;&#x2F;param&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;      &amp;lt;&#x2F;service&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;      &amp;lt;service mode=&amp;quot;disabled&amp;quot; name=&amp;quot;set_version&amp;quot;&#x2F;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;      &amp;lt;service name=&amp;quot;cargo_audit&amp;quot; mode=&amp;quot;disabled&amp;quot;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;          &amp;lt;!-- ✨ The name of the project here ✨ --&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;         &amp;lt;param name=&amp;quot;srcdir&amp;quot;&amp;gt;hellorust&amp;lt;&#x2F;param&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;      &amp;lt;&#x2F;service&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;      &amp;lt;service name=&amp;quot;cargo_vendor&amp;quot; mode=&amp;quot;disabled&amp;quot;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;          &amp;lt;!-- ✨ The name of the project here ✨ --&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;         &amp;lt;param name=&amp;quot;srcdir&amp;quot;&amp;gt;hellorust&amp;lt;&#x2F;param&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;         &amp;lt;param name=&amp;quot;compression&amp;quot;&amp;gt;xz&amp;lt;&#x2F;param&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;      &amp;lt;&#x2F;service&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;lt;&#x2F;services&amp;gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now this service file does a lot of the heavy lifting for us:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;It will fetch the sources from git, based on the version we set.&lt;&#x2F;li&gt;
&lt;li&gt;It will turn them into a tar.xz for us.&lt;&#x2F;li&gt;
&lt;li&gt;It will update the changelog for the rpm, and set the correct
version in the spec file.&lt;&#x2F;li&gt;
&lt;li&gt;It scans our project for any known vulnerabilities&lt;&#x2F;li&gt;
&lt;li&gt;It will download our rust dependencies, and then bundle them to
vendor.tar.xz.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;So our current work dir should look like:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# ls -1 .
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;.osc
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;_service
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;hellorust.spec
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now we can run [osc service ra]{.title-ref}. This will run the services
in our [_service]{.title-ref} file as we mentioned. Once it&#x27;s complete
we&#x27;ll have quite a few more files in our directory:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# ls -1 .
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;_service
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;_servicedata
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;cargo_config
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;hellorust
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;hellorust-0.1.1~git0.db340ad.obscpio
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;hellorust-0.1.1~git0.db340ad.tar.xz
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;hellorust.obsinfo
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;hellorust.spec
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;vendor.tar.xz
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Inside the [hellorust]{.title-ref} folder
([home:username&#x2F;hellorust&#x2F;hellorust]{.title-ref}), is a checkout of our
source. If you cd to that directory, you can run [cargo
lock2rpmprovides]{.title-ref} which will display your license string you
need:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;    License: ( Apache-2.0 OR MIT ) AND ( Apache-2.0 WITH LLVM-exception OR Apache-2.0 OR MIT ) AND
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Just add the license from the project, and then we can update our
[hellorust.spec]{.title-ref} with the correct license.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;    License: ( Apache-2.0 OR MIT ) AND ( Apache-2.0 WITH LLVM-exception OR Apache-2.0 OR MIT ) AND MPL-2.0
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;ul&gt;
&lt;li&gt;HINT: You don&#x27;t need to use the emitted &amp;quot;provides&amp;quot; lines here.
They are just for fedora rpms to adhere to some of their policy
requirements.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Now we can build our package on our local system to test it. This may
take a while to get all its build dependencies and other parts, so be
patient :)&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;osc&lt;&#x2F;span&gt;&lt;span&gt; build
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If that completes successfully, you can now test these rpms:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# zypper in &#x2F;var&#x2F;tmp&#x2F;build-root&#x2F;openSUSE_Tumbleweed-x86_64&#x2F;home&#x2F;abuild&#x2F;rpmbuild&#x2F;RPMS&#x2F;x86_64&#x2F;hellorust-0.1.1~git0.db340ad-0.x86_64.rpm
&lt;&#x2F;span&gt;&lt;span&gt;    (&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;1&#x2F;1&lt;&#x2F;span&gt;&lt;span&gt;) Installing: hellorust-0.1.1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;~&lt;&#x2F;span&gt;&lt;span&gt;git0.db340ad-0.x86_64  ... &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;[&lt;&#x2F;span&gt;&lt;span&gt;done&lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;]
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# rpm -ql hellorust
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;&#x2F;usr&#x2F;bin&#x2F;hellorust
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# hellorust
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;Hello,&lt;&#x2F;span&gt;&lt;span&gt; Rust! The number of the day is: 68
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Next you can commit to your project. Add the files that we created:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# osc add _service cargo_config hellorust-0.1.1~git0.db340ad.tar.xz hellorust.spec vendor.tar.xz
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# osc status
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;A&lt;&#x2F;span&gt;&lt;span&gt;    _service
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;?&lt;&#x2F;span&gt;&lt;span&gt;    _servicedata
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;A&lt;&#x2F;span&gt;&lt;span&gt;    cargo_config
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;?&lt;&#x2F;span&gt;&lt;span&gt;    hellorust-0.1.1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;~&lt;&#x2F;span&gt;&lt;span&gt;git0.db340ad.obscpio
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;A&lt;&#x2F;span&gt;&lt;span&gt;    hellorust-0.1.1&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;~&lt;&#x2F;span&gt;&lt;span&gt;git0.db340ad.tar.xz
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;?&lt;&#x2F;span&gt;&lt;span&gt;    hellorust.obsinfo
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;A&lt;&#x2F;span&gt;&lt;span&gt;    hellorust.spec
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;A&lt;&#x2F;span&gt;&lt;span&gt;    vendor.tar.xz
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;ul&gt;
&lt;li&gt;HINT: You DO NOT need to commit _servicedata OR
hellorust-0.1.1~git0.db340ad.obscpio OR hellorust.obsinfo&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;osc&lt;&#x2F;span&gt;&lt;span&gt; ci
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;From here, you can use your packages from your own respository, or you
can forward them to OpenSUSE Tumbleweed (via Factory). You likely need
to polish and add extra parts to your package for it to be accepted into
Factory, but this should at least make it easier for you to start!&lt;&#x2F;p&gt;
&lt;p&gt;For more, see the &lt;a href=&quot;https:&#x2F;&#x2F;en.opensuse.org&#x2F;openSUSE:How_to_contribute_to_Factory&quot;&gt;how to contribute to
Factory&lt;&#x2F;a&gt;
document. To submit to Leap, the package must be in Factory, then you
can request it to be &lt;a href=&quot;https:&#x2F;&#x2F;en.opensuse.org&#x2F;openSUSE:Packaging_for_Leap&quot;&gt;submitted to
Leap&lt;&#x2F;a&gt; as well.&lt;&#x2F;p&gt;
&lt;p&gt;Happy Contributing! 🦎🦀&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Webauthn UserVerificationPolicy Curiosities</title>
          <pubDate>Sat, 21 Nov 2020 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2020-11-21-webauthn-userverificationpolicy-curiosities/</link>
          <guid>https://fy.blackhats.net.au/blog/2020-11-21-webauthn-userverificationpolicy-curiosities/</guid>
          <description>&lt;h1 id=&quot;webauthn-userverificationpolicy-curiosities&quot;&gt;Webauthn UserVerificationPolicy Curiosities&lt;&#x2F;h1&gt;
&lt;p&gt;Recently I received a
&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;webauthn-rs&#x2F;issues&#x2F;32&quot;&gt;pair&lt;&#x2F;a&gt;
&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;webauthn-rs&#x2F;issues&#x2F;34&quot;&gt;of&lt;&#x2F;a&gt; interesting bugs
in &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;webauthn-rs&#x2F;&quot;&gt;Webauthn RS&lt;&#x2F;a&gt; where certain
types of authenticators would not work in Firefox, but did work in
Chromium. This confused me, and I couldn&#x27;t reproduce the behaviour. So
like any obsessed person I ordered myself one of the affected devices
and waited for Australia Post to lose it, find it, lose it again, and
then finally deliver the device 2 months later.&lt;&#x2F;p&gt;
&lt;p&gt;In the meantime I swapped browsers from Firefox to Edge and started to
notice some odd behaviour when logging into my corporate account - my
yubikey began to ask me for my pin on every authentication, even though
the key was registered to the corp servers &lt;em&gt;without&lt;&#x2F;em&gt; a pin. Yet the key
kept working on Edge with a pin - and confusingly &lt;em&gt;without&lt;&#x2F;em&gt; a pin on
Firefox.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;some-background-on-webauthn&quot;&gt;Some background on Webauthn&lt;&#x2F;h2&gt;
&lt;p&gt;Before we dive into the issue, we need to understand some details about
Webauthn. &lt;a href=&quot;https:&#x2F;&#x2F;www.w3.org&#x2F;TR&#x2F;webauthn&#x2F;&quot;&gt;Webauthn&lt;&#x2F;a&gt; is a standard that
allows a client (commonly a web browser) to cryptographically
authenticate to a server (commonly a web site). Webauthn defines how
different types of hardware cryptographic authenticators may communicate
between the client and the server.&lt;&#x2F;p&gt;
&lt;p&gt;An example of some types of authenticator devices are U2F tokens
(yubikeys), TouchID (Apple Mac, iPhone, iPad), Trusted Platform Modules
(Windows Hello) and many more. Webauthn has to account for differences
in these hardware classes and how they communicate, but in the end each
device performs a set of &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Public-key_cryptography&quot;&gt;asymmetric
cryptographic&lt;&#x2F;a&gt;
(public&#x2F;private key) operations.&lt;&#x2F;p&gt;
&lt;p&gt;Webauthn defines the structures of how a client and server communicate
to both register new authenticators and subsequently authenticate with
those authenticators.&lt;&#x2F;p&gt;
&lt;p&gt;For the first step of registration, the server provides a registration
challenge to the client. The structure of this (which is important for
later) looks like:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;dictionary PublicKeyCredentialCreationOptions {
&lt;&#x2F;span&gt;&lt;span&gt;    required PublicKeyCredentialRpEntity         rp;
&lt;&#x2F;span&gt;&lt;span&gt;    required PublicKeyCredentialUserEntity       user;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    required BufferSource                             challenge;
&lt;&#x2F;span&gt;&lt;span&gt;    required sequence&amp;lt;PublicKeyCredentialParameters&amp;gt;  pubKeyCredParams;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    unsigned long                                timeout;
&lt;&#x2F;span&gt;&lt;span&gt;    sequence&amp;lt;PublicKeyCredentialDescriptor&amp;gt;      excludeCredentials = [];
&lt;&#x2F;span&gt;&lt;span&gt;    AuthenticatorSelectionCriteria               authenticatorSelection = {
&lt;&#x2F;span&gt;&lt;span&gt;        AuthenticatorAttachment      authenticatorAttachment;
&lt;&#x2F;span&gt;&lt;span&gt;        boolean                      requireResidentKey = false;
&lt;&#x2F;span&gt;&lt;span&gt;        UserVerificationRequirement  userVerification = &amp;quot;preferred&amp;quot;;
&lt;&#x2F;span&gt;&lt;span&gt;    };
&lt;&#x2F;span&gt;&lt;span&gt;    AttestationConveyancePreference              attestation = &amp;quot;none&amp;quot;;
&lt;&#x2F;span&gt;&lt;span&gt;    AuthenticationExtensionsClientInputs         extensions;
&lt;&#x2F;span&gt;&lt;span&gt;};
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The client then takes this structure, and creates a number of hashes
from it which the authenticator then signs. This signed data and options
are returned to the server as a
&lt;a href=&quot;https:&#x2F;&#x2F;w3c.github.io&#x2F;webauthn&#x2F;#iface-pkcredential&quot;&gt;PublicKeyCredential&lt;&#x2F;a&gt;
containing an &lt;a href=&quot;https:&#x2F;&#x2F;www.w3.org&#x2F;TR&#x2F;webauthn&#x2F;#iface-authenticatorattestationresponse&quot;&gt;Authenticator Attestation
Response&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;Next is authentication. The server sends a challenge to the client which
has the structure:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;dictionary PublicKeyCredentialRequestOptions {
&lt;&#x2F;span&gt;&lt;span&gt;    required BufferSource                challenge;
&lt;&#x2F;span&gt;&lt;span&gt;    unsigned long                        timeout;
&lt;&#x2F;span&gt;&lt;span&gt;    USVString                            rpId;
&lt;&#x2F;span&gt;&lt;span&gt;    sequence&amp;lt;PublicKeyCredentialDescriptor&amp;gt; allowCredentials = [];
&lt;&#x2F;span&gt;&lt;span&gt;    UserVerificationRequirement          userVerification = &amp;quot;preferred&amp;quot;;
&lt;&#x2F;span&gt;&lt;span&gt;    AuthenticationExtensionsClientInputs extensions;
&lt;&#x2F;span&gt;&lt;span&gt;};
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Again, the client takes this structure, takes a number of hashes and the
authenticator signs this to prove it is the holder of the private key.
The signed response is sent to the server as a PublicKeyCredential
containing an &lt;a href=&quot;https:&#x2F;&#x2F;www.w3.org&#x2F;TR&#x2F;webauthn&#x2F;#iface-authenticatorassertionresponse&quot;&gt;Authenticator Assertion
Response&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;Key to this discussion is the following field:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;UserVerificationRequirement          userVerification = &amp;quot;preferred&amp;quot;;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This is present in both PublicKeyCredentialRequestOptions and
PublicKeyCredentialCreationOptions. This informs what level of
interaction assurance should be provided during the signing process.
These are discussed in &lt;a href=&quot;https:&#x2F;&#x2F;pages.nist.gov&#x2F;800-63-3&#x2F;sp800-63b.html&quot;&gt;NIST SP800-64b (5.1.7,
5.1.9)&lt;&#x2F;a&gt; (which is just
an excellent document anyway, so read it).&lt;&#x2F;p&gt;
&lt;p&gt;One aspect of these authenticators is that they must provide tamper
proof evidence that a person is physically present and interacting with
the device for the signature to proceed. This is important as it means
that if someone is able to gain remote code execution on your system,
they are unable to use your authenticator devices (even if it&#x27;s part of
the device, like touch id) as they are not physically present at the
machine.&lt;&#x2F;p&gt;
&lt;p&gt;Some authenticators are able to go beyond to strengthen this assurance,
by verifying the identity of the person interacting with the
authenticator. This means that the interaction &lt;em&gt;also&lt;&#x2F;em&gt; requires say a PIN
(something you know), or a biometric (something you are). This allows
the authenticator to assert not just that &lt;em&gt;someone&lt;&#x2F;em&gt; is present but that
it is a specific person who is present.&lt;&#x2F;p&gt;
&lt;p&gt;All authenticators are capable of asserting user presence but only some
are capable of asserting user verification. This creates two classes of
authenticators as defined by NIST SP800-64b.&lt;&#x2F;p&gt;
&lt;p&gt;Single-Factor Cryptographic Devices (5.1.7) which only assert presence
(the device becomes something you have) and Multi-Factor Cryptographic
Devices (5.1.9) which assert the identity of the holder (something you
have + something you know&#x2F;are).&lt;&#x2F;p&gt;
&lt;p&gt;Webauthn is able to request the use of a Single-Factor Device or
Multi-Factor Device through it&#x27;s UserVerificationRequirement option.
The levels are:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Discouraged - Only use Single-Factor Devices&lt;&#x2F;li&gt;
&lt;li&gt;Required - Only use Multi-Factor Devices&lt;&#x2F;li&gt;
&lt;li&gt;Preferred - Request Multi-Factor if possible, but allow
Single-Factor devices.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;back-to-the-mystery&quot;&gt;Back to the mystery ...&lt;&#x2F;h2&gt;
&lt;p&gt;When I initially saw these reports - of devices that did not work in
Firefox but did in Chromium, and of devices asking for PINs on some
browsers but not others -I was really confused. The breakthrough came as
I was developing &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;webauthn-authenticator-rs&quot;&gt;Webauthn Authenticator
RS&lt;&#x2F;a&gt;. This is the
client half of Webauthn, so that I could have the
&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&quot;&gt;Kanidm&lt;&#x2F;a&gt; CLI tools use Webauthn for
multi-factor authentication (MFA). In the process, I have been using the
&lt;a href=&quot;https:&#x2F;&#x2F;crates.io&#x2F;crates&#x2F;authenticator&quot;&gt;authenticator&lt;&#x2F;a&gt; crate made by
Mozilla and used by Firefox.&lt;&#x2F;p&gt;
&lt;p&gt;The authenticator crate is what communicates to authenticators by NFC,
Bluetooth, or USB. Due to the different types of devices, there are
multiple different protocols involved. For U2F devices, the protocol is
CTAP over USB. There are two versions of the CTAP protocol - CTAP1, and
CTAP2.&lt;&#x2F;p&gt;
&lt;p&gt;In the authenticator crate, only CTAP1 is supported. CTAP1 devices are
unable to accept a PIN, so user verification must be performed
internally to the device (such as a fingerprint reader built into the
U2F device).&lt;&#x2F;p&gt;
&lt;p&gt;Chromium, however, is able to use CTAP2 - CTAP2 &lt;em&gt;does&lt;&#x2F;em&gt; allow a PIN to be
provided from the host machine to the device as a user verification
method.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;why-would-devices-fail-in-firefox&quot;&gt;Why would devices fail in Firefox?&lt;&#x2F;h2&gt;
&lt;p&gt;Once I had learnt this about CTAP1&#x2F;CTAP2, I realised that my example
code in Webauthn RS was hardcoding Required as the user verification
level. Since Firefox can only use CTAP1, it was unable to use PINs to
U2F devices, so they would not respond to the challenge. But on Chromium
with CTAP2 they &lt;em&gt;are&lt;&#x2F;em&gt; able to have PINs so Required can be satisfied and
the devices work.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;okay-but-the-corp-account&quot;&gt;Okay but the corp account?&lt;&#x2F;h2&gt;
&lt;p&gt;This one is subtle. The corp identity system uses user verification of
&#x27;Preferred&#x27;. That meant that on Firefox, no PIN was requested since
CTAP1 can&#x27;t provide them, but on Edge&#x2F;Chromium a PIN &lt;em&gt;can&lt;&#x2F;em&gt; be provided
as they use CTAP2.&lt;&#x2F;p&gt;
&lt;p&gt;What&#x27;s more curious is that the same authenticator device is flipping
between Single Factor and Multi Factor, with the same Private&#x2F;Public Key
pair just based on what protocol is used! So even though the
&#x27;Preferred&#x27; request can be satisfied on Chromium&#x2F;Edge, it&#x27;s not on
Firefox. To further extend my confusion, the device was originally
registered to the corp identity system in Firefox so it would have &lt;em&gt;not&lt;&#x2F;em&gt;
had user verification available, but now that I use Edge it has &lt;em&gt;gained&lt;&#x2F;em&gt;
this requirement during authentication.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;that-seems-wrong&quot;&gt;That seems ... wrong.&lt;&#x2F;h2&gt;
&lt;p&gt;I agree. But Webauthn fully allows this. This is because user
verification is a property of the &lt;em&gt;request&#x2F;response&lt;&#x2F;em&gt; flow, not a
property of the &lt;em&gt;device&lt;&#x2F;em&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;This creates some interesting side effects that become an opportunity
for user confusion. (&lt;em&gt;I&lt;&#x2F;em&gt; was confused about what the behaviour was and I
write a webauthn server and client library - imagine how other people
feel ...).&lt;&#x2F;p&gt;
&lt;h2 id=&quot;devices-change-behaviour&quot;&gt;Devices change behaviour&lt;&#x2F;h2&gt;
&lt;p&gt;This means that during registration one policy can be requested (i.e.
Required) but subsequently it may not be used (Preferred + Firefox +
U2F, or Discouraged). Another example of a change in behaviour occurs
when a device is used on Chromium with Preferred user verification is
required, but when used on Firefox the device may &lt;em&gt;not&lt;&#x2F;em&gt; require
verification. It also means that a site that implements Required can
have devices that simply don&#x27;t work in other browsers.&lt;&#x2F;p&gt;
&lt;p&gt;Because this is changing behaviour it can confuse users. For examples:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Why do I need a PIN now but not before?&lt;&#x2F;li&gt;
&lt;li&gt;Why did I need a PIN before but not now?&lt;&#x2F;li&gt;
&lt;li&gt;Why does my authenticator work on this computer but not on another?&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;preferred-becomes-discouraged&quot;&gt;Preferred becomes Discouraged&lt;&#x2F;h2&gt;
&lt;p&gt;This opens up a security risk where since Preferred &amp;quot;attempts&amp;quot;
verification but allows it to not be present, a U2F device can be
&amp;quot;downgraded&amp;quot; from Multi-Factor to Single-Factor by using it with CTAP1
instead of CTAP2. Since it&#x27;s also per &lt;em&gt;request&#x2F;response&lt;&#x2F;em&gt;, a compromised
client could also tamper with the communication to the authenticator
removing the requested userverification parameter silently and the
server would allow it.&lt;&#x2F;p&gt;
&lt;p&gt;This means that in reality, Preferred is policy and security wise
equivalent to Discouraged, but with a more annoying UI&#x2F;UX for users who
have to conduct a verification that doesn&#x27;t actually help identify
them.&lt;&#x2F;p&gt;
&lt;p&gt;Remember - if unspecified, &#x27;Preferred&#x27; is the default user
verification policy in Webauthn!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;lock-out-abuse-vectors&quot;&gt;Lock Out &#x2F; Abuse Vectors&lt;&#x2F;h2&gt;
&lt;p&gt;There is also a potential abuse vector here. Many devices such as U2F
tokens perform a &amp;quot;trust on first use&amp;quot; for their PIN setup. This means
that the first time a user verification is requested you configure the
pin at that point in time.&lt;&#x2F;p&gt;
&lt;p&gt;A potential abuse vector here is a token that is always used on Firefox,
a malicious person could connect the device to Chromium, and setup the
PIN without the knowledge of the owner. The owner could continue to use
the device, and when Firefox eventually supports CTAP2, or they swap
computer or browser, they would &lt;em&gt;not&lt;&#x2F;em&gt; know the PIN, and their token
would effectively be unusable at that point. They would need to reset
it, potentially causing them to be locked out from accounts, but more
likely causing them to need to conduct a &lt;em&gt;lot&lt;&#x2F;em&gt; of password&#x2F;credential
resets.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;unable-to-implement-authenticator-policy&quot;&gt;Unable to implement Authenticator Policy&lt;&#x2F;h2&gt;
&lt;p&gt;One of the greatest issues here though is that because user verification
is part of the &lt;em&gt;request&#x2F;response&lt;&#x2F;em&gt; flow and not &lt;em&gt;per device&lt;&#x2F;em&gt; attributes,
authenticator policy, and mixed credentials are unable to exist in the
current implementation of Webauthn.&lt;&#x2F;p&gt;
&lt;p&gt;Consider a user who has enrolled say their laptop&#x27;s U2F device +
password, and their iPhone&#x27;s touchID to a server. Both of these are
Multi Factor credentials. The U2F is a Single Factor Device and becomes
Multi-Factor in combination with the password. The iPhone touchID is a
Multi-Factor Device on it&#x27;s due to the biometric verification it is
capable of.&lt;&#x2F;p&gt;
&lt;p&gt;We &lt;em&gt;should&lt;&#x2F;em&gt; be able to have a website request webauthn and based on the
device used we can flow to the next required step. If the device was the
iPhone, we would be authenticated as we have authenticated a Multi
Factor credentials. If we saw the U2F device we would then move to
request the password since we have only received a Single Factor.
However Webauthn is unable to express this authentication flow.&lt;&#x2F;p&gt;
&lt;p&gt;If we requested Required, we would exclude the U2F device.&lt;&#x2F;p&gt;
&lt;p&gt;If we requested Discouraged, we would exclude the iPhone.&lt;&#x2F;p&gt;
&lt;p&gt;If we request Preferred, the U2F device could be used on a different
browser with CTAP2, either:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;bypassing the password, since the device is now a self contained
Multi-Factor; or&lt;&#x2F;li&gt;
&lt;li&gt;the U2F device could prompt for the PIN needlessly and we progress
to setting a password&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;The request to an iPhone could be tampered with, preventing the
verification occurring and turning it into a single factor device
(presence only).&lt;&#x2F;p&gt;
&lt;p&gt;Today, these mixed device scenarios can not exist in Webauthn. We are
unable to create the policy around Single-Factor and Multi-Factor
devices as defined by NIST because these require us to assert the
verification requirements per credential, but Webauthn can not satisfy
this.&lt;&#x2F;p&gt;
&lt;p&gt;We would need to pre-ask the user &lt;em&gt;how&lt;&#x2F;em&gt; they want to authenticate on
that device and then only send a Webauthn challenge that can satisfy the
authentication policy we have decided on for those credentials.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;how-to-fix-this&quot;&gt;How to fix this&lt;&#x2F;h2&gt;
&lt;p&gt;The solution here is to change PublicKeyCredentialDescriptor in the
Webauthn standard to contain an optional UserVerificationRequirement
field. This would allow a &amp;quot;global&amp;quot; default set by the server and then
per-credential requirements to be defined. This would allow the user
verification properties during registration to be associated to that
credential, which can then be enforced by the server to guarantee the
behaviour of a webauthn device. It would also allow the &#x27;Preferred&#x27;
option to have a valid and useful meaning during registration, where
devices capable of verification can provide that or not, and then that
verification boolean can be then transformed to a Discouraged or
Required setting for that credential for future authentications.&lt;&#x2F;p&gt;
&lt;p&gt;The second change would be to disallow &#x27;Preferred&#x27; as a valid value in
the &amp;quot;global&amp;quot; default during authentications. The new &amp;quot;default&amp;quot;
global value should be &#x27;Discouraged&#x27; and then only credentials that
registered with verification would indicate that in their
PublicKeyCredentialDescriptor.&lt;&#x2F;p&gt;
&lt;p&gt;This would resolve the issues above by:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Making the use of an authenticator consistent after registration.
For example, authenticators registered with CTAP1 would stay
&#x27;Discouraged&#x27; even when used with CTAP2&lt;&#x2F;li&gt;
&lt;li&gt;If PIN&#x2F;Verification abuse occurred, the credentials registered on
CTAP1 without verification would continue to be &#x27;presence only&#x27;
preventing the lockout&lt;&#x2F;li&gt;
&lt;li&gt;Allowing the server to proceed with the authentication flow based on
which credential authenticated and provide logic about further
factors if needed.&lt;&#x2F;li&gt;
&lt;li&gt;Allowing true Single Factor and Multi Factor device policies to be
expressed in line with NIST SP800-63b, so users can have a mix of
Single and Multi Factor devices associated with a single account.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;I have since opened &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;w3c&#x2F;webauthn&#x2F;issues&#x2F;1510&quot;&gt;this
issue&lt;&#x2F;a&gt; with the webauthn
specification about this, but early comments seem to be highly focused
on the current expression of the standard rather than the issues around
the user experience and ability for identity systems to accurately
express credential policy.&lt;&#x2F;p&gt;
&lt;p&gt;In the meantime, I am going to make changes to Webauthn RS to help avoid
some of these issues:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Preferred will be renamed to Preferred_Is_Equivalent_To_Discouraged
(it will still emit &#x27;Preferred&#x27; in the JSON, this only changes the
Rust API enum)&lt;&#x2F;li&gt;
&lt;li&gt;Credential structures persisted by applications will contain the
boolean of user-verification if it occurred during registration&lt;&#x2F;li&gt;
&lt;li&gt;During an authentication, if the set of credentials contains
inconsistent user-verification booleans, an error will be raised&lt;&#x2F;li&gt;
&lt;li&gt;Authentication User Verification Policy is derived from the set of
credentials having a consistent user-verification boolean&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;While not perfect, it will mean that it&#x27;s &amp;quot;hard to hold it wrong&amp;quot;
with Webauthn RS.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;acknowledgements&quot;&gt;Acknowledgements&lt;&#x2F;h2&gt;
&lt;p&gt;Thanks to both @Charcol0x89 and @JuxhinDB for reviewing this post.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Rust, SIMD and target-feature flags</title>
          <pubDate>Fri, 20 Nov 2020 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2020-11-20-rust-and-target-feature-flags/</link>
          <guid>https://fy.blackhats.net.au/blog/2020-11-20-rust-and-target-feature-flags/</guid>
          <description>&lt;h1 id=&quot;rust-simd-and-target-feature-flags&quot;&gt;Rust, SIMD and target-feature flags&lt;&#x2F;h1&gt;
&lt;p&gt;This year I&#x27;ve been working on
&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;concread&quot;&gt;concread&lt;&#x2F;a&gt; and one of the ways that
I have improved it is through the use of
&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;rust-lang&#x2F;packed_simd&quot;&gt;packed_simd&lt;&#x2F;a&gt; for parallel key
lookups in hashmaps. During testing I saw a ~10% speed up in Kanidm
which heavily relies on concread, so great, pack it up, go home.&lt;&#x2F;p&gt;
&lt;h1 id=&quot;&quot;&gt;...?&lt;&#x2F;h1&gt;
&lt;p&gt;Or so I thought. Recently I was learning to use Ghidra with a friend,
and as a thought exercise I wanted to see how Rust decompiled. I put the
concread test suite into Ghidra and took a look. Looking at the version
of concread with [simd_support]{.title-ref} enabled, I saw this in the
disassembly (truncated for readability).&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;**************************************************************
&lt;&#x2F;span&gt;&lt;span&gt;*                          FUNCTION                          *
&lt;&#x2F;span&gt;&lt;span&gt;**************************************************************
&lt;&#x2F;span&gt;&lt;span&gt;Simd&amp;lt;[packed_simd_2--masks--m64;8]&amp;gt; __stdcall eq(Simd&amp;lt;[p
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;span&gt;100114510 55              PUSH       RBP
&lt;&#x2F;span&gt;&lt;span&gt;100114511 48 89 e5        MOV        RBP,RSP
&lt;&#x2F;span&gt;&lt;span&gt;100114514 48 83 e4 c0     AND        RSP,-0x40
&lt;&#x2F;span&gt;&lt;span&gt;100114518 48 81 ec        SUB        RSP,0x100
&lt;&#x2F;span&gt;&lt;span&gt;        00 01 00 00
&lt;&#x2F;span&gt;&lt;span&gt;10011451f 48 89 f8        MOV        RAX,__return_storage_ptr__
&lt;&#x2F;span&gt;&lt;span&gt;100114522 0f 28 06        MOVAPS     XMM0,xmmword ptr [self-&amp;gt;__0.__0]
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;span&gt;100114540 66 0f 76 c4     PCMPEQD    XMM0,XMM4
&lt;&#x2F;span&gt;&lt;span&gt;100114544 66 0f 70        PSHUFD     XMM4,XMM0,0xb1
&lt;&#x2F;span&gt;&lt;span&gt;        e0 b1
&lt;&#x2F;span&gt;&lt;span&gt;100114549 66 0f db c4     PAND       XMM0,XMM4
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;span&gt;100114574 0f 29 9c        MOVAPS     xmmword ptr [RSP + local_90],XMM3
&lt;&#x2F;span&gt;&lt;span&gt;        24 b0 00 
&lt;&#x2F;span&gt;&lt;span&gt;        00 00
&lt;&#x2F;span&gt;&lt;span&gt;1001145b4 48 89 7c        MOV        qword ptr [RSP + local_c8],__return_storage_pt
&lt;&#x2F;span&gt;&lt;span&gt;        24 78
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;span&gt;1001145be 0f 29 44        MOVAPS     xmmword ptr [RSP + local_e0],XMM0
&lt;&#x2F;span&gt;&lt;span&gt;        24 60
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;span&gt;1001145d2 48 8b 44        MOV        RAX,qword ptr [RSP + local_c8]
&lt;&#x2F;span&gt;&lt;span&gt;        24 78
&lt;&#x2F;span&gt;&lt;span&gt;1001145d7 0f 28 44        MOVAPS     XMM0,xmmword ptr [RSP + local_e0]
&lt;&#x2F;span&gt;&lt;span&gt;        24 60
&lt;&#x2F;span&gt;&lt;span&gt;1001145dc 0f 29 00        MOVAPS     xmmword ptr [RAX],XMM0
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;span&gt;1001145ff 48 89 ec        MOV        RSP,RBP
&lt;&#x2F;span&gt;&lt;span&gt;100114602 5d              POP        RBP
&lt;&#x2F;span&gt;&lt;span&gt;100114603 c3              RET
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now, it&#x27;s been a long time since I&#x27;ve had to look at x86_64 asm, so I
saw this and went &amp;quot;great, it&#x27;s not using a loop, those aren&#x27;t simple
[TEST&#x2F;JNZ]{.title-ref} instructions, they have a lot of letters, awesome
it&#x27;s using HW accel.&lt;&#x2F;p&gt;
&lt;h1 id=&quot;time-passes&quot;&gt;Time passes ...&lt;&#x2F;h1&gt;
&lt;p&gt;Coming back to this, I have been wondering how we could enable SIMD in
concread at SUSE, since 389 Directory Server has just merged a change
for 2.0.0 that uses concread as a cache. For this I needed to know what
minimum CPU is supported at SUSE. After some chasing internally, knowing
what we need I asked in the Rust Brisbane group about how you can define
in [packed_simd]{.title-ref} to only emit instructions that work on a
minimum CPU level rather than &lt;em&gt;my&lt;&#x2F;em&gt; cpu or the builder cpu.&lt;&#x2F;p&gt;
&lt;p&gt;The response was &amp;quot;but that&#x27;s already how it works&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;I was helpfully directed to the &lt;a href=&quot;https:&#x2F;&#x2F;rust-lang.github.io&#x2F;packed_simd&#x2F;perf-guide&#x2F;target-feature&#x2F;rustflags.html&quot;&gt;packed_simd perf
guide&lt;&#x2F;a&gt;
which discusses the use of target features and target cpu. At that point
I realised that for this whole time I&#x27;ve only been using the default:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# rustc --print cfg | grep -i target_feature
&lt;&#x2F;span&gt;&lt;span&gt;target_feature=&amp;quot;fxsr&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;target_feature=&amp;quot;sse&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;target_feature=&amp;quot;sse2&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The [PCMPEQD]{.title-ref} is from sse2, but my cpu is much newer and
should support AVX and AVX2. Retesting this, I can see my CPU has much
more:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# rustc --print cfg -C target-cpu=native | grep -i target_feature
&lt;&#x2F;span&gt;&lt;span&gt;target_feature=&amp;quot;aes&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;target_feature=&amp;quot;avx&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;target_feature=&amp;quot;avx2&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;target_feature=&amp;quot;bmi1&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;target_feature=&amp;quot;bmi2&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;target_feature=&amp;quot;fma&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;target_feature=&amp;quot;fxsr&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;target_feature=&amp;quot;lzcnt&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;target_feature=&amp;quot;pclmulqdq&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;target_feature=&amp;quot;popcnt&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;target_feature=&amp;quot;rdrand&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;target_feature=&amp;quot;rdseed&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;target_feature=&amp;quot;sse&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;target_feature=&amp;quot;sse2&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;target_feature=&amp;quot;sse3&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;target_feature=&amp;quot;sse4.1&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;target_feature=&amp;quot;sse4.2&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;target_feature=&amp;quot;ssse3&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;target_feature=&amp;quot;xsave&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;target_feature=&amp;quot;xsavec&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;target_feature=&amp;quot;xsaveopt&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;target_feature=&amp;quot;xsaves&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;All this time, I haven&#x27;t been using my native features!&lt;&#x2F;p&gt;
&lt;p&gt;For local builds now, I have .cargo&#x2F;config set with:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;[build]
&lt;&#x2F;span&gt;&lt;span&gt;rustflags = &amp;quot;-C target-cpu=native&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;I recompiled concread and I now see in Ghidra:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;00198960 55              PUSH       RBP
&lt;&#x2F;span&gt;&lt;span&gt;00198961 48 89 e5        MOV        RBP,RSP
&lt;&#x2F;span&gt;&lt;span&gt;00198964 48 83 e4 c0     AND        RSP,-0x40
&lt;&#x2F;span&gt;&lt;span&gt;00198968 48 81 ec        SUB        RSP,0x100
&lt;&#x2F;span&gt;&lt;span&gt;         00 01 00 00
&lt;&#x2F;span&gt;&lt;span&gt;0019896f 48 89 f8        MOV        RAX,__return_storage_ptr__
&lt;&#x2F;span&gt;&lt;span&gt;00198972 c5 fc 28 06     VMOVAPS    YMM0,ymmword ptr [self-&amp;gt;__0.__0]
&lt;&#x2F;span&gt;&lt;span&gt;00198976 c5 fc 28        VMOVAPS    YMM1,ymmword ptr [RSI + self-&amp;gt;__0.__4]
&lt;&#x2F;span&gt;&lt;span&gt;         4e 20
&lt;&#x2F;span&gt;&lt;span&gt;0019897b c5 fc 28 12     VMOVAPS    YMM2,ymmword ptr [other-&amp;gt;__0.__0]
&lt;&#x2F;span&gt;&lt;span&gt;0019897f c5 fc 28        VMOVAPS    YMM3,ymmword ptr [RDX + other-&amp;gt;__0.__4]
&lt;&#x2F;span&gt;&lt;span&gt;         5a 20
&lt;&#x2F;span&gt;&lt;span&gt;00198984 c4 e2 7d        VPCMPEQQ   YMM0,YMM0,YMM2
&lt;&#x2F;span&gt;&lt;span&gt;         29 c2
&lt;&#x2F;span&gt;&lt;span&gt;00198989 c4 e2 75        VPCMPEQQ   YMM1,YMM1,YMM3
&lt;&#x2F;span&gt;&lt;span&gt;         29 cb
&lt;&#x2F;span&gt;&lt;span&gt;0019898e c5 fc 29        VMOVAPS    ymmword ptr [RSP + local_a0[0]],YMM1
&lt;&#x2F;span&gt;&lt;span&gt;         8c 24 a0 
&lt;&#x2F;span&gt;&lt;span&gt;         00 00 00
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;span&gt;001989e7 48 89 ec        MOV        RSP,RBP
&lt;&#x2F;span&gt;&lt;span&gt;001989ea 5d              POP        RBP
&lt;&#x2F;span&gt;&lt;span&gt;001989eb c5 f8 77        VZEROUPPER
&lt;&#x2F;span&gt;&lt;span&gt;001989ee c3              RET
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;[VPCMPEQQ]{.title-ref} is the AVX2 compare instruction (You can tell
it&#x27;s AVX2 due to the register YMM, AVX uses XMM). Which means now I&#x27;m
getting the SIMD comparisons I wanted!&lt;&#x2F;p&gt;
&lt;p&gt;These can be enabled with [RUSTFLAGS=&#x27;-C
target-feature=+avx2,+avx&#x27;]{.title-ref} for selected builds, or in your
.cargo&#x2F;config. It may be a good idea for just local development to do
[target-cpu=native]{.title-ref}.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Deploying sccache on SUSE</title>
          <pubDate>Thu, 19 Nov 2020 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2020-11-19-deploying-sccache-on-suse/</link>
          <guid>https://fy.blackhats.net.au/blog/2020-11-19-deploying-sccache-on-suse/</guid>
          <description>&lt;h1 id=&quot;deploying-sccache-on-suse&quot;&gt;Deploying sccache on SUSE&lt;&#x2F;h1&gt;
&lt;p&gt;sccache is a ccache&#x2F;icecc-like tool from Mozilla, which in addition to
working with C and C++, is also able to help with Rust builds.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;adding-the-repo&quot;&gt;Adding the Repo&lt;&#x2F;h2&gt;
&lt;p&gt;A submission to Factory (tumbleweed) has been made, so check if you can
install from zypper:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;zypper install sccache
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If not, sccache is still part of
&lt;a href=&quot;https:&#x2F;&#x2F;build.opensuse.org&#x2F;package&#x2F;show&#x2F;devel:tools:building&#x2F;sccache&quot;&gt;devel:tools:building&lt;&#x2F;a&gt;
so you will need to add the repo to use sccache.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;zypper ar -f obs:&#x2F;&#x2F;devel:tools:building devel:tools:building
&lt;&#x2F;span&gt;&lt;span&gt;zypper install sccache
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;It&#x27;s also important you &lt;em&gt;do not&lt;&#x2F;em&gt; have ccache installed. ccache
intercepts the gcc command so you end up &amp;quot;double caching&amp;quot; potentially.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;zypper rm ccache
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;single-host&quot;&gt;Single Host&lt;&#x2F;h2&gt;
&lt;p&gt;To use sccache on your host, you need to set the following environment
variables:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;export RUSTC_WRAPPER=sccache
&lt;&#x2F;span&gt;&lt;span&gt;export CC=&amp;quot;sccache &#x2F;usr&#x2F;bin&#x2F;gcc&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;export CXX=&amp;quot;sccache &#x2F;usr&#x2F;bin&#x2F;g++&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;# Optional: This can improve rust caching
&lt;&#x2F;span&gt;&lt;span&gt;# export CARGO_INCREMENTAL=false
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This will allow sccache to wrap your compiler commands. You can show
your current sccache status with:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;sccache -s
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;There is more information about using cloud&#x2F;remote storage for the cache
on the sccache &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;mozilla&#x2F;sccache&#x2F;blob&#x2F;master&#x2F;README.md&quot;&gt;project
site&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;distributed-compiliation&quot;&gt;Distributed Compiliation&lt;&#x2F;h2&gt;
&lt;p&gt;sccache is also capable of distributed compilation, where a number of
builder servers can compile items and return the artificats to your
machine. This can save you time by allowing compilation over a cluster,
using a faster remote builder, or just to keep your laptop cool.&lt;&#x2F;p&gt;
&lt;p&gt;Three components are needed to make this work. A scheduler that
coordinates the activities, one or more builders that provide their CPU,
and a client that submits compilation jobs.&lt;&#x2F;p&gt;
&lt;p&gt;The sccache package contains the required elements for all three parts.&lt;&#x2F;p&gt;
&lt;p&gt;Note that the client does &lt;em&gt;not&lt;&#x2F;em&gt; need to be the same version of SUSE or
even the same distro as the scheduler or builder. This is because the
client is able to bundle and submit it&#x27;s toolchains to the workers on
the fly. Neat! sccache is capacble of also compiling for macos and
windows, but in these cases the toolchains can-not be submitted on the
fly and requires extra &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;mozilla&#x2F;sccache&#x2F;blob&#x2F;master&#x2F;docs&#x2F;DistributedQuickstart.md&quot;&gt;work to
configure.&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;scheduler&quot;&gt;Scheduler&lt;&#x2F;h2&gt;
&lt;p&gt;The scheduler is configured with
[&#x2F;etc&#x2F;sccache&#x2F;scheduler.conf]{.title-ref}. You need to define the
listening ip, client auth, and server (builder) auth methods. The
example configuration is well commented to help with this:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# The socket address the scheduler will listen on. It&amp;#39;s strongly recommended
&lt;&#x2F;span&gt;&lt;span&gt;# to listen on localhost and put a HTTPS server in front of it.
&lt;&#x2F;span&gt;&lt;span&gt;public_addr = &amp;quot;127.0.0.1:10600&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;# public_addr = &amp;quot;[::1]:10600&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[client_auth]
&lt;&#x2F;span&gt;&lt;span&gt;# This is how a client will authenticate to the scheduler.
&lt;&#x2F;span&gt;&lt;span&gt;# # sccache-dist auth generate-shared-token --help
&lt;&#x2F;span&gt;&lt;span&gt;type = &amp;quot;token&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;token = &amp;quot;token here&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;#
&lt;&#x2F;span&gt;&lt;span&gt;# type = &amp;quot;jwt_hs256&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;# secret_key = &amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[server_auth]
&lt;&#x2F;span&gt;&lt;span&gt;# sccache-dist auth --help
&lt;&#x2F;span&gt;&lt;span&gt;# To generate the secret_key:
&lt;&#x2F;span&gt;&lt;span&gt;# # sccache-dist auth generate-jwt-hs256-key
&lt;&#x2F;span&gt;&lt;span&gt;# To generate a key for a builder, use the command:
&lt;&#x2F;span&gt;&lt;span&gt;# # sccache-dist auth generate-jwt-hs256-server-token --config &#x2F;etc&#x2F;sccache&#x2F;scheduler.conf --secret-key &amp;quot;...&amp;quot; --server &amp;quot;builderip:builderport&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;type = &amp;quot;jwt_hs256&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;secret_key = &amp;quot;my secret key&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You can start the scheduler with:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;systemctl start sccache-dist-scheduler.service
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If you have issues you can increase logging verbosity with:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# systemctl edit sccache-dist-scheduler.service
&lt;&#x2F;span&gt;&lt;span&gt;[Service]
&lt;&#x2F;span&gt;&lt;span&gt;Environment=&amp;quot;RUST_LOG=sccache=trace&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;builder&quot;&gt;Builder&lt;&#x2F;h2&gt;
&lt;p&gt;Similar to the scheduler, the builder is configured with
[&#x2F;etc&#x2F;sccache&#x2F;builder.conf]{.title-ref}. Most of the defaults should be
left &amp;quot;as is&amp;quot; but you will need to add the token generated from the
comments in [scheduler.conf - server_auth]{.title-ref}.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# This is where client toolchains will be stored.
&lt;&#x2F;span&gt;&lt;span&gt;# You should not need to change this as it is configured to work with systemd.
&lt;&#x2F;span&gt;&lt;span&gt;cache_dir = &amp;quot;&#x2F;var&#x2F;cache&#x2F;sccache-builder&#x2F;toolchains&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;# The maximum size of the toolchain cache, in bytes.
&lt;&#x2F;span&gt;&lt;span&gt;# If unspecified the default is 10GB.
&lt;&#x2F;span&gt;&lt;span&gt;# toolchain_cache_size = 10737418240
&lt;&#x2F;span&gt;&lt;span&gt;# A public IP address and port that clients will use to connect to this builder.
&lt;&#x2F;span&gt;&lt;span&gt;public_addr = &amp;quot;127.0.0.1:10501&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;# public_addr = &amp;quot;[::1]:10501&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# The URL used to connect to the scheduler (should use https, given an ideal
&lt;&#x2F;span&gt;&lt;span&gt;# setup of a HTTPS server in front of the scheduler)
&lt;&#x2F;span&gt;&lt;span&gt;scheduler_url = &amp;quot;https:&#x2F;&#x2F;127.0.0.1:10600&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[builder]
&lt;&#x2F;span&gt;&lt;span&gt;type = &amp;quot;overlay&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;# The directory under which a sandboxed filesystem will be created for builds.
&lt;&#x2F;span&gt;&lt;span&gt;# You should not need to change this as it is configured to work with systemd.
&lt;&#x2F;span&gt;&lt;span&gt;build_dir = &amp;quot;&#x2F;var&#x2F;cache&#x2F;sccache-builder&#x2F;tmp&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;# The path to the bubblewrap version 0.3.0+ `bwrap` binary.
&lt;&#x2F;span&gt;&lt;span&gt;# You should not need to change this as it is configured for a default SUSE install.
&lt;&#x2F;span&gt;&lt;span&gt;bwrap_path = &amp;quot;&#x2F;usr&#x2F;bin&#x2F;bwrap&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[scheduler_auth]
&lt;&#x2F;span&gt;&lt;span&gt;type = &amp;quot;jwt_token&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;# This will be generated by the `generate-jwt-hs256-server-token` command or
&lt;&#x2F;span&gt;&lt;span&gt;# provided by an administrator of the sccache cluster. See &#x2F;etc&#x2F;sccache&#x2F;scheduler.conf
&lt;&#x2F;span&gt;&lt;span&gt;token = &amp;quot;token goes here&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Again, you can start the builder with:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;systemctl start sccache-dist-builder.service
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If you have issues you can increase logging verbosity with:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# systemctl edit sccache-dist-builder.service
&lt;&#x2F;span&gt;&lt;span&gt;[Service]
&lt;&#x2F;span&gt;&lt;span&gt;Environment=&amp;quot;RUST_LOG=sccache=trace&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You can configure many hosts as builders, and compilation jobs will be
distributed amongst them.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;client&quot;&gt;Client&lt;&#x2F;h2&gt;
&lt;p&gt;The client is the part that submits compilation work. You need to
configure your machine the same as single host with regard to the
environment variables.&lt;&#x2F;p&gt;
&lt;p&gt;Additionally you need to configure the file
[~&#x2F;.config&#x2F;sccache&#x2F;config]{.title-ref}. An example of this can be found
in [&#x2F;etc&#x2F;sccache&#x2F;client.example]{.title-ref}.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;[dist]
&lt;&#x2F;span&gt;&lt;span&gt;# The URL used to connect to the scheduler (should use https, given an ideal
&lt;&#x2F;span&gt;&lt;span&gt;# setup of a HTTPS server in front of the scheduler)
&lt;&#x2F;span&gt;&lt;span&gt;scheduler_url = &amp;quot;http:&#x2F;&#x2F;x.x.x.x:10600&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;# Used for mapping local toolchains to remote cross-compile toolchains. Empty in
&lt;&#x2F;span&gt;&lt;span&gt;# this example where the client and build server are both Linux.
&lt;&#x2F;span&gt;&lt;span&gt;toolchains = []
&lt;&#x2F;span&gt;&lt;span&gt;# Size of the local toolchain cache, in bytes (5GB here, 10GB if unspecified).
&lt;&#x2F;span&gt;&lt;span&gt;# toolchain_cache_size = 5368709120
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;cache_dir = &amp;quot;&#x2F;tmp&#x2F;toolchains&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[dist.auth]
&lt;&#x2F;span&gt;&lt;span&gt;type = &amp;quot;token&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;# This should match the `client_auth` section of the scheduler config.
&lt;&#x2F;span&gt;&lt;span&gt;token = &amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You can check the status with:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;sccache --stop-server
&lt;&#x2F;span&gt;&lt;span&gt;sccache --dist-status
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If you have issues, you can increase the logging with:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;sccache --stop-server
&lt;&#x2F;span&gt;&lt;span&gt;SCCACHE_NO_DAEMON=1 RUST_LOG=sccache=trace sccache --dist-status
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Then begin a compilation job and you will get the extra logging. To undo
this, run:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;sccache --stop-server
&lt;&#x2F;span&gt;&lt;span&gt;sccache --dist-status
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;In addition, sccache even in distributed mode can still use cloud or
remote storage for items, using it&#x27;s cache first, and the distributed
complitation second. Anything that can&#x27;t be remotely complied will be
run locally.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;verifying&quot;&gt;Verifying&lt;&#x2F;h2&gt;
&lt;p&gt;If you compile something from your client, you should see messages like
this appear in journald in the builder&#x2F;scheduler machine:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;INFO 2020-11-19T22:23:46Z: sccache_dist: Job 140 created and will be assigned to server ServerId(V4(x.x.x.x:10501))
&lt;&#x2F;span&gt;&lt;span&gt;INFO 2020-11-19T22:23:46Z: sccache_dist: Job 140 successfully assigned and saved with state Ready
&lt;&#x2F;span&gt;&lt;span&gt;INFO 2020-11-19T22:23:46Z: sccache_dist: Job 140 updated state to Started
&lt;&#x2F;span&gt;&lt;span&gt;INFO 2020-11-19T22:23:46Z: sccache_dist: Job 140 updated state to Complete
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
</description>
      </item>
      <item>
          <title>How a Search Query is Processed in Kanidm</title>
          <pubDate>Tue, 01 Sep 2020 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2020-09-01-how-a-search-query-is-processed-in-kanidm/</link>
          <guid>https://fy.blackhats.net.au/blog/2020-09-01-how-a-search-query-is-processed-in-kanidm/</guid>
          <description>&lt;h1 id=&quot;how-a-search-query-is-processed-in-kanidm&quot;&gt;How a Search Query is Processed in Kanidm&lt;&#x2F;h1&gt;
&lt;p&gt;Databases from postgres to sqlite, mongodb, and even LDAP all need to
take a query and turn that into a meaningful result set. This process
can often seem like magic, especially when you consider an LDAP server
is able to process thousands of parallel queries, with a database
spanning millions of entries and still can return results in less than a
millisecond. Even more impressive is that every one of these databases
can be expected to return the correct result, every time. This level of
performance, correctness and precision is an astounding feat of
engineering, but is rooted in a simple set of design patterns.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;disclaimer&quot;&gt;Disclaimer&lt;&#x2F;h2&gt;
&lt;p&gt;This will be a very long post. You may want to set aside some time for
it :)&lt;&#x2F;p&gt;
&lt;p&gt;This post will discuss how &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&quot;&gt;Kanidm&lt;&#x2F;a&gt;
processes queries. This means that some implementation specifics are
specific to the Kanidm project. However conceptually this is very close
to the operation of LDAP servers (389-ds, samba 4, openldap) and
MongoDB, and certainly there are still many overlaps and similarities to
SQLite and Postgres. At the least, I hope it gives you some foundation
to research the specifics behaviours you chosen database.&lt;&#x2F;p&gt;
&lt;p&gt;This post does NOT discuss how creation or modification paths operate.
That is likely worthy of a post of it&#x27;s own. Saying this, search relies
heavily on correct function of the write paths, and they are always
intertwined.&lt;&#x2F;p&gt;
&lt;p&gt;The referenced code and links relate to commit
&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&#x2F;tree&#x2F;dbfe87e675beac7fd931a445fd80cf439c2c6e61&quot;&gt;dbfe87e&lt;&#x2F;a&gt;
from 2020-08-24. The project may have changed since this point, so it&#x27;s
best if you can look at the latest commits in the tree if possible.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;&#x2F;h2&gt;
&lt;p&gt;Kanidm uses a structured document store model, similar to LDAP or
MongoDB. You can consider entries to be like a JSON document. For
example,&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;class&amp;quot;: [
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;quot;object&amp;quot;,
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;quot;memberof&amp;quot;,
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;quot;account&amp;quot;,
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;quot;posixaccount&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    ],
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;displayname&amp;quot;: [
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;quot;William&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    ],
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;gidnumber&amp;quot;: [
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;quot;1000&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    ],
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;loginshell&amp;quot;: [
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;quot;&#x2F;bin&#x2F;zsh&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    ],
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;name&amp;quot;: [
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;quot;william&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    ],
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;uuid&amp;quot;: [
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;quot;5e01622e-740a-4bea-b694-e952653252b4&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    ],
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;memberof&amp;quot;: [
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;quot;admins&amp;quot;,
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;quot;users&amp;quot;,
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;quot;radius&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    ],
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;ssh_publickey&amp;quot;: [
&lt;&#x2F;span&gt;&lt;span&gt;        {
&lt;&#x2F;span&gt;&lt;span&gt;            &amp;quot;tag&amp;quot;: &amp;quot;laptop&amp;quot;,
&lt;&#x2F;span&gt;&lt;span&gt;            &amp;quot;key&amp;quot;: &amp;quot;....&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;        }
&lt;&#x2F;span&gt;&lt;span&gt;    ]
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Something of note here is that an entry has many attributes, and those
attributes can consist of one or more values. values themself can be
structured such as the ssh_publickey value which has a tag and the
public key, or the uuid which enforces uuid syntax.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;filters-queries&quot;&gt;Filters &#x2F; Queries&lt;&#x2F;h2&gt;
&lt;p&gt;During a search we want to find entries that match specific attribute
value assertions or attribute assertions. We also want to be able to use
logic to provide complex conditions or logic in how we perform the
search. We could consider the search in terms of SQL such as:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;select from entries where name = william and class = account;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Or in LDAP syntax&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;(&amp;amp;(objectClass=account)(name=william))
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;In Kanidm JSON (which admitedly, is a bit rough, we don&#x27;t expect people
to use this much!)&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;{ &amp;quot;and&amp;quot;: [{&amp;quot;eq&amp;quot;: [&amp;quot;class&amp;quot;, &amp;quot;account&amp;quot;]}, {&amp;quot;eq&amp;quot;: [&amp;quot;name&amp;quot;: &amp;quot;william&amp;quot;]} ]}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Regardless of how we structure these, they are the same query. We want
to find entries where the property of class=account and name=william
hold true. There are many other types of logic we could apply
(especially true for sql), but in Kanidm we support the following
&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&#x2F;blob&#x2F;dbfe87e675beac7fd931a445fd80cf439c2c6e61&#x2F;kanidm_proto&#x2F;src&#x2F;v1.rs#L305&quot;&gt;proto(col)
filters&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;pub enum Filter {
&lt;&#x2F;span&gt;&lt;span&gt;    Eq(String, String),
&lt;&#x2F;span&gt;&lt;span&gt;    Sub(String, String),
&lt;&#x2F;span&gt;&lt;span&gt;    Pres(String),
&lt;&#x2F;span&gt;&lt;span&gt;    Or(Vec&amp;lt;Filter&amp;gt;),
&lt;&#x2F;span&gt;&lt;span&gt;    And(Vec&amp;lt;Filter&amp;gt;),
&lt;&#x2F;span&gt;&lt;span&gt;    AndNot(Box&amp;lt;Filter&amp;gt;),
&lt;&#x2F;span&gt;&lt;span&gt;    SelfUUID,
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;These represent:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Eq(uality) - an attribute of name, has at least one value matching
the term&lt;&#x2F;li&gt;
&lt;li&gt;Sub(string) - an attribute of name, has at least one value matching
the substring term&lt;&#x2F;li&gt;
&lt;li&gt;Pres(ence) - an attribute of name, regardless of value exists on the
entry&lt;&#x2F;li&gt;
&lt;li&gt;Or - One or more of the nested conditions must evaluate to true&lt;&#x2F;li&gt;
&lt;li&gt;And - All nested conditions must be true, or the and returns false&lt;&#x2F;li&gt;
&lt;li&gt;AndNot - Within an And query, the inner term must not be true
relative to the related and term&lt;&#x2F;li&gt;
&lt;li&gt;SelfUUID - A dynamic Eq(uality) where the authenticated user&#x27;s UUID
is added. Essentially, this substitutes to &amp;quot;eq (uuid, selfuuid)&amp;quot;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Comparing to the previous example entry, we can see that [{ &amp;quot;and&amp;quot;:
[{&amp;quot;eq&amp;quot;: [&amp;quot;class&amp;quot;, &amp;quot;account&amp;quot;]}, {&amp;quot;eq&amp;quot;: [&amp;quot;name&amp;quot;:
&amp;quot;william&amp;quot;]} ]}]{.title-ref} would be true, where [{ &amp;quot;eq&amp;quot;:
[&amp;quot;name&amp;quot;: &amp;quot;claire&amp;quot;]}]{.title-ref} would be false as no matching
name attribute-value exists on the entry.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;recieving-the-query&quot;&gt;Recieving the Query&lt;&#x2F;h2&gt;
&lt;p&gt;There are multiple ways that a query could find it&#x27;s way into Kanidm.
It may be submitted from the raw search api, it could be generated from
a REST endpoint request, it may be translated via the LDAP
compatability. The most important part is that it is then recieved by a
worker thread in the query server. For this discussion we&#x27;ll assume we
recieved a raw search via the front end.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&#x2F;blob&#x2F;dbfe87e675beac7fd931a445fd80cf439c2c6e61&#x2F;kanidmd&#x2F;src&#x2F;lib&#x2F;actors&#x2F;v1_read.rs#L245&quot;&gt;handle_search&lt;&#x2F;a&gt;
is the entry point of a worker thread to process a search operation. The
first thing we do is begin a read transaction over the various elements
of the database we need.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;fn handle(&amp;amp;mut self, msg: SearchMessage, _: &amp;amp;mut Self::Context) -&amp;gt; Self::Result {
&lt;&#x2F;span&gt;&lt;span&gt;let mut audit = AuditScope::new(&amp;quot;search&amp;quot;, msg.eventid, self.log_level);
&lt;&#x2F;span&gt;&lt;span&gt;let res = lperf_op_segment!(&amp;amp;mut audit, &amp;quot;actors::v1_read::handle&amp;lt;SearchMessage&amp;gt;&amp;quot;, || {
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; Begin a read
&lt;&#x2F;span&gt;&lt;span&gt;    let qs_read = self.qs.read();
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The call to
&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&#x2F;blob&#x2F;dbfe87e675beac7fd931a445fd80cf439c2c6e61&#x2F;kanidmd&#x2F;src&#x2F;lib&#x2F;server.rs#L732&quot;&gt;qs.read&lt;&#x2F;a&gt;
takes three transactions - the backend, the schema cache and the access
control cache.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;pub fn read(&amp;amp;self) -&amp;gt; QueryServerReadTransaction {
&lt;&#x2F;span&gt;&lt;span&gt;    QueryServerReadTransaction {
&lt;&#x2F;span&gt;&lt;span&gt;        be_txn: self.be.read(),
&lt;&#x2F;span&gt;&lt;span&gt;        schema: self.schema.read(),
&lt;&#x2F;span&gt;&lt;span&gt;        accesscontrols: self.accesscontrols.read(),
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&#x2F;blob&#x2F;dbfe87e675beac7fd931a445fd80cf439c2c6e61&#x2F;kanidmd&#x2F;src&#x2F;lib&#x2F;be&#x2F;mod.rs#L1348&quot;&gt;backend
read&lt;&#x2F;a&gt;
takes two transactions internally - the database layers, and the
indexing metadata cache.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;pub fn read(&amp;amp;self) -&amp;gt; BackendReadTransaction {
&lt;&#x2F;span&gt;&lt;span&gt;    BackendReadTransaction {
&lt;&#x2F;span&gt;&lt;span&gt;        idlayer: UnsafeCell::new(self.idlayer.read()),
&lt;&#x2F;span&gt;&lt;span&gt;        idxmeta: self.idxmeta.read(),
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Once complete, we can now transform the submitted request, into an
internal event. By structuring all requests as event, we standarise all
operations to a subset of operations, and we ensure that that all
resources required are available in the event. The &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&#x2F;blob&#x2F;dbfe87e675beac7fd931a445fd80cf439c2c6e61&#x2F;kanidmd&#x2F;src&#x2F;lib&#x2F;event.rs#L255&quot;&gt;search
event&lt;&#x2F;a&gt;
as processed stores an event origin aka the identiy of the event origin.
The search query is stored in the [filter]{.title-ref} attribute, and
the original query is stored in the [filter_orig]{.title-ref}. There is
a reason for this duplication.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;pub fn from_message(
&lt;&#x2F;span&gt;&lt;span&gt;    audit: &amp;amp;mut AuditScope,
&lt;&#x2F;span&gt;&lt;span&gt;    msg: SearchMessage,
&lt;&#x2F;span&gt;&lt;span&gt;    qs: &amp;amp;QueryServerReadTransaction,
&lt;&#x2F;span&gt;&lt;span&gt;) -&amp;gt; Result&amp;lt;Self, OperationError&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;    let event = Event::from_ro_uat(audit, qs, msg.uat.as_ref())?;
&lt;&#x2F;span&gt;&lt;span&gt;    let f = Filter::from_ro(audit, &amp;amp;event, &amp;amp;msg.req.filter, qs)?;
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; We do need to do this twice to account for the ignore_hidden
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; changes.
&lt;&#x2F;span&gt;&lt;span&gt;    let filter = f
&lt;&#x2F;span&gt;&lt;span&gt;        .clone()
&lt;&#x2F;span&gt;&lt;span&gt;        .into_ignore_hidden()
&lt;&#x2F;span&gt;&lt;span&gt;        .validate(qs.get_schema())
&lt;&#x2F;span&gt;&lt;span&gt;        .map_err(OperationError::SchemaViolation)?;
&lt;&#x2F;span&gt;&lt;span&gt;    let filter_orig = f
&lt;&#x2F;span&gt;&lt;span&gt;        .validate(qs.get_schema())
&lt;&#x2F;span&gt;&lt;span&gt;        .map_err(OperationError::SchemaViolation)?;
&lt;&#x2F;span&gt;&lt;span&gt;    Ok(SearchEvent {
&lt;&#x2F;span&gt;&lt;span&gt;        event,
&lt;&#x2F;span&gt;&lt;span&gt;        filter,
&lt;&#x2F;span&gt;&lt;span&gt;        filter_orig,
&lt;&#x2F;span&gt;&lt;span&gt;        &#x2F;&#x2F; We can&amp;#39;t get this from the SearchMessage because it&amp;#39;s annoying with the
&lt;&#x2F;span&gt;&lt;span&gt;        &#x2F;&#x2F; current macro design.
&lt;&#x2F;span&gt;&lt;span&gt;        attrs: None,
&lt;&#x2F;span&gt;&lt;span&gt;    })
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;As [filter]{.title-ref} is processed it is transformed by the server to
change it&#x27;s semantics. This is due to the call to
&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&#x2F;blob&#x2F;dbfe87e675beac7fd931a445fd80cf439c2c6e61&#x2F;kanidmd&#x2F;src&#x2F;lib&#x2F;filter.rs#L504&quot;&gt;into_ignore_hidden&lt;&#x2F;a&gt;.
This function adds a wrapping layer to the outside of the query that
hides certain classes of entries from view unless explicitly requested.
In the case of kanidm this transformation is to add:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;{ &amp;quot;and&amp;quot;: [
&lt;&#x2F;span&gt;&lt;span&gt;    { &amp;quot;andnot&amp;quot; : { &amp;quot;or&amp;quot; [
&lt;&#x2F;span&gt;&lt;span&gt;        {&amp;quot;eq&amp;quot;: [&amp;quot;class&amp;quot;, &amp;quot;tombstone&amp;quot;]},
&lt;&#x2F;span&gt;&lt;span&gt;        {&amp;quot;eq&amp;quot;: [&amp;quot;class&amp;quot;, &amp;quot;recycled&amp;quot;]}
&lt;&#x2F;span&gt;&lt;span&gt;    }]},
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;lt;original query&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;]}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This prevents the display of deleted (recycle bin) entries, and the
display of tombstones - marker entries representing that an entry with
this UUID once existed in this location. These tombstones are part of
the (future) eventually consistent replication machinery to allow
deletes to be processed.&lt;&#x2F;p&gt;
&lt;p&gt;This is why [filter_orig]{.title-ref} is stored. We require a copy of
the &amp;quot;query as intended by the caller&amp;quot; for the purpose of checking
access controls later. A user may not have access to the attribute
&amp;quot;class&amp;quot; which would mean that the addition of the
[into_ignore_hidden]{.title-ref} could cause them to not have any
results at all. We should not penalise the user for something they
didn&#x27;t ask for!&lt;&#x2F;p&gt;
&lt;p&gt;After the query is transformed, we now
&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&#x2F;blob&#x2F;dbfe87e675beac7fd931a445fd80cf439c2c6e61&#x2F;kanidmd&#x2F;src&#x2F;lib&#x2F;event.rs#L277&quot;&gt;validate&lt;&#x2F;a&gt;
it&#x27;s content. This validation ensures that queries contain only
attributes that truly exist in schema, and that their representation in
the query is sound. This prevents a number of security issues related to
denial of service or possible information disclosures. The query has
every attribute-value
&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&#x2F;blob&#x2F;dbfe87e675beac7fd931a445fd80cf439c2c6e61&#x2F;kanidmd&#x2F;src&#x2F;lib&#x2F;filter.rs#L545&quot;&gt;compared&lt;&#x2F;a&gt;
to the schema to ensure that they exist and are correct syntax types.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;start-processing-the-query&quot;&gt;Start Processing the Query&lt;&#x2F;h2&gt;
&lt;p&gt;Now that the search event has been created and we know that is is valid
within a set of rules, we can submit it to the
&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&#x2F;blob&#x2F;dbfe87e675beac7fd931a445fd80cf439c2c6e61&#x2F;kanidmd&#x2F;src&#x2F;lib&#x2F;actors&#x2F;v1_read.rs#L265&quot;&gt;search_ext(ernal)&lt;&#x2F;a&gt;
interface of the query server. Because everything we need is contained
in the search event we are able to process the query from this point.
Search external is a wrapper to the internal search, where
&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&#x2F;blob&#x2F;dbfe87e675beac7fd931a445fd80cf439c2c6e61&#x2F;kanidmd&#x2F;src&#x2F;lib&#x2F;server.rs#L90&quot;&gt;search_ext&lt;&#x2F;a&gt;
is able to wrap and apply access controls to the results from the
operation.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;fn search_ext(
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;amp;self,
&lt;&#x2F;span&gt;&lt;span&gt;    au: &amp;amp;mut AuditScope,
&lt;&#x2F;span&gt;&lt;span&gt;    se: &amp;amp;SearchEvent,
&lt;&#x2F;span&gt;&lt;span&gt;) -&amp;gt; Result&amp;lt;Vec&amp;lt;Entry&amp;lt;EntryReduced, EntryCommitted&amp;gt;&amp;gt;, OperationError&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;    lperf_segment!(au, &amp;quot;server::search_ext&amp;quot;, || {
&lt;&#x2F;span&gt;&lt;span&gt;        &#x2F;*
&lt;&#x2F;span&gt;&lt;span&gt;         * This just wraps search, but it&amp;#39;s for the external interface
&lt;&#x2F;span&gt;&lt;span&gt;         * so as a result it also reduces the entry set&amp;#39;s attributes at
&lt;&#x2F;span&gt;&lt;span&gt;         * the end.
&lt;&#x2F;span&gt;&lt;span&gt;         *&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;        let entries = self.search(au, se)?;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;        let access = self.get_accesscontrols();
&lt;&#x2F;span&gt;&lt;span&gt;        access
&lt;&#x2F;span&gt;&lt;span&gt;            .search_filter_entry_attributes(au, se, entries)
&lt;&#x2F;span&gt;&lt;span&gt;            .map_err(|e| {
&lt;&#x2F;span&gt;&lt;span&gt;                &#x2F;&#x2F; Log and fail if something went wrong.
&lt;&#x2F;span&gt;&lt;span&gt;                ladmin_error!(au, &amp;quot;Failed to filter entry attributes {:?}&amp;quot;, e);
&lt;&#x2F;span&gt;&lt;span&gt;                e
&lt;&#x2F;span&gt;&lt;span&gt;            })
&lt;&#x2F;span&gt;&lt;span&gt;        &#x2F;&#x2F; This now returns the reduced vec.
&lt;&#x2F;span&gt;&lt;span&gt;    })
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&#x2F;blob&#x2F;dbfe87e675beac7fd931a445fd80cf439c2c6e61&#x2F;kanidmd&#x2F;src&#x2F;lib&#x2F;server.rs#L90&quot;&gt;internal
search&lt;&#x2F;a&gt;
function is now called, and we begin to prepare for the backend to
handle the query.&lt;&#x2F;p&gt;
&lt;p&gt;We have a final transformation we must apply to the query that we intend
to pass to the backend. We must attach metadata to the query elements so
that we can perform informed optimisation of the query.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;let be_txn = self.get_be_txn();
&lt;&#x2F;span&gt;&lt;span&gt;let idxmeta = be_txn.get_idxmeta_ref();
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;&#x2F; Now resolve all references and indexes.
&lt;&#x2F;span&gt;&lt;span&gt;let vfr = lperf_trace_segment!(au, &amp;quot;server::search&amp;lt;filter_resolve&amp;gt;&amp;quot;, || {
&lt;&#x2F;span&gt;&lt;span&gt;    se.filter.resolve(&amp;amp;se.event, Some(idxmeta))
&lt;&#x2F;span&gt;&lt;span&gt;})
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This is done by retreiving indexing metadata from the backend, which
defines which attributes and types of indexes exist. This indexing
metadata is passed to the filter to &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&#x2F;blob&#x2F;dbfe87e675beac7fd931a445fd80cf439c2c6e61&#x2F;kanidmd&#x2F;src&#x2F;lib&#x2F;filter.rs#L504&quot;&gt;be
resolved&lt;&#x2F;a&gt;.
In the case of tests we may not pass index metadata, which is why filter
resolve accounts for the possibility of idxmeta being None. The filter
elements are transformed, for example we change &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&#x2F;blob&#x2F;dbfe87e675beac7fd931a445fd80cf439c2c6e61&#x2F;kanidmd&#x2F;src&#x2F;lib&#x2F;filter.rs#L973&quot;&gt;eq to have a
boolean&lt;&#x2F;a&gt;
associated if the attribute is indexed. In our example this would change
the query:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;{ &amp;quot;and&amp;quot;: [
&lt;&#x2F;span&gt;&lt;span&gt;    { &amp;quot;andnot&amp;quot; : { &amp;quot;or&amp;quot; [
&lt;&#x2F;span&gt;&lt;span&gt;        {&amp;quot;eq&amp;quot;: [&amp;quot;class&amp;quot;, &amp;quot;tombstone&amp;quot;]},
&lt;&#x2F;span&gt;&lt;span&gt;        {&amp;quot;eq&amp;quot;: [&amp;quot;class&amp;quot;, &amp;quot;recycled&amp;quot;]}
&lt;&#x2F;span&gt;&lt;span&gt;    }]},
&lt;&#x2F;span&gt;&lt;span&gt;    { &amp;quot;and&amp;quot;: [
&lt;&#x2F;span&gt;&lt;span&gt;        {&amp;quot;eq&amp;quot;: [&amp;quot;class&amp;quot;, &amp;quot;account&amp;quot;]},
&lt;&#x2F;span&gt;&lt;span&gt;        {&amp;quot;eq&amp;quot;: [&amp;quot;name&amp;quot;: &amp;quot;william&amp;quot;]}
&lt;&#x2F;span&gt;&lt;span&gt;    ]}
&lt;&#x2F;span&gt;&lt;span&gt;]}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;To&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;{ &amp;quot;and&amp;quot;: [
&lt;&#x2F;span&gt;&lt;span&gt;    { &amp;quot;andnot&amp;quot; : { &amp;quot;or&amp;quot; [
&lt;&#x2F;span&gt;&lt;span&gt;        {&amp;quot;eq&amp;quot;: [&amp;quot;class&amp;quot;, &amp;quot;tombstone&amp;quot;, true]},
&lt;&#x2F;span&gt;&lt;span&gt;        {&amp;quot;eq&amp;quot;: [&amp;quot;class&amp;quot;, &amp;quot;recycled&amp;quot;, true]}
&lt;&#x2F;span&gt;&lt;span&gt;    }]},
&lt;&#x2F;span&gt;&lt;span&gt;    { &amp;quot;and&amp;quot;: [
&lt;&#x2F;span&gt;&lt;span&gt;        {&amp;quot;eq&amp;quot;: [&amp;quot;class&amp;quot;, &amp;quot;account&amp;quot;, true]},
&lt;&#x2F;span&gt;&lt;span&gt;        {&amp;quot;eq&amp;quot;: [&amp;quot;name&amp;quot;: &amp;quot;william&amp;quot;, true]}
&lt;&#x2F;span&gt;&lt;span&gt;    ]}
&lt;&#x2F;span&gt;&lt;span&gt;]}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;With this metadata associated to the query, we can now submit it to the
backend for processing.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;backend-processing&quot;&gt;Backend Processing&lt;&#x2F;h2&gt;
&lt;p&gt;We are now in a position where the backend can begin to do work to
actually process the query. The first step of the &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&#x2F;blob&#x2F;dbfe87e675beac7fd931a445fd80cf439c2c6e61&#x2F;kanidmd&#x2F;src&#x2F;lib&#x2F;be&#x2F;mod.rs#L474&quot;&gt;backend
search&lt;&#x2F;a&gt;
function is to perform the final optimisation of the filter.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;fn search(
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;amp;self,
&lt;&#x2F;span&gt;&lt;span&gt;    au: &amp;amp;mut AuditScope,
&lt;&#x2F;span&gt;&lt;span&gt;    erl: &amp;amp;EventLimits,
&lt;&#x2F;span&gt;&lt;span&gt;    filt: &amp;amp;Filter&amp;lt;FilterValidResolved&amp;gt;,
&lt;&#x2F;span&gt;&lt;span&gt;) -&amp;gt; Result&amp;lt;Vec&amp;lt;Entry&amp;lt;EntrySealed, EntryCommitted&amp;gt;&amp;gt;, OperationError&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;    lperf_trace_segment!(au, &amp;quot;be::search&amp;quot;, || {
&lt;&#x2F;span&gt;&lt;span&gt;        &#x2F;&#x2F; Do a final optimise of the filter
&lt;&#x2F;span&gt;&lt;span&gt;        let filt =
&lt;&#x2F;span&gt;&lt;span&gt;            lperf_trace_segment!(au, &amp;quot;be::search&amp;lt;filt::optimise&amp;gt;&amp;quot;, || { filt.optimise() });
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Query optimisation is critical to make searches fast. In Kanidm it
relies on a specific behaviour of the indexing application process. I
will highlight that step shortly.&lt;&#x2F;p&gt;
&lt;p&gt;For now, the way query optimisation works is by sorting and folding
terms in the query. This is because there are a number of logical
equivalences, but also that due to the associated metadata and
experience we know that some terms may be better in different areas.
Optimisation relies on a &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&#x2F;blob&#x2F;dbfe87e675beac7fd931a445fd80cf439c2c6e61&#x2F;kanidmd&#x2F;src&#x2F;lib&#x2F;filter.rs#L1088&quot;&gt;sorting
function&lt;&#x2F;a&gt;
that will rearrange terms as needed.&lt;&#x2F;p&gt;
&lt;p&gt;An example is that a nested [and]{.title-ref} term, can be folded to the
parent because logically an [and]{.title-ref} inside and
[and]{.title-ref} is the same. Similar for [or]{.title-ref} inside
[or]{.title-ref}.&lt;&#x2F;p&gt;
&lt;p&gt;Within the [and]{.title-ref} term, we can then rearrange the terms,
because the order of the terms does not matter in an [and]{.title-ref}
or [or]{.title-ref}, only that the other logical elements hold true. We
sort indexed equality terms first because we know that they are always
going to resolve &amp;quot;faster&amp;quot; than the nested [andnot]{.title-ref} term.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;{ &amp;quot;and&amp;quot;: [
&lt;&#x2F;span&gt;&lt;span&gt;    {&amp;quot;eq&amp;quot;: [&amp;quot;class&amp;quot;, &amp;quot;account&amp;quot;, true]},
&lt;&#x2F;span&gt;&lt;span&gt;    {&amp;quot;eq&amp;quot;: [&amp;quot;name&amp;quot;: &amp;quot;william&amp;quot;, true]},
&lt;&#x2F;span&gt;&lt;span&gt;    { &amp;quot;andnot&amp;quot; : { &amp;quot;or&amp;quot; [
&lt;&#x2F;span&gt;&lt;span&gt;        {&amp;quot;eq&amp;quot;: [&amp;quot;class&amp;quot;, &amp;quot;tombstone&amp;quot;, true]},
&lt;&#x2F;span&gt;&lt;span&gt;        {&amp;quot;eq&amp;quot;: [&amp;quot;class&amp;quot;, &amp;quot;recycled&amp;quot;, true]}
&lt;&#x2F;span&gt;&lt;span&gt;    }]}
&lt;&#x2F;span&gt;&lt;span&gt;]}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;In the future, an improvement here is to put name before class, which
will happen as part of the issue
&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&#x2F;issues&#x2F;238&quot;&gt;#238&lt;&#x2F;a&gt; which allows us to
work out which indexes are going to yield the best information content.
So we can sort them first in the query.&lt;&#x2F;p&gt;
&lt;p&gt;Finally, we are at the point where we can begin to actually load some
data! 🎉&lt;&#x2F;p&gt;
&lt;p&gt;The filter is submitted to
&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&#x2F;blob&#x2F;dbfe87e675beac7fd931a445fd80cf439c2c6e61&#x2F;kanidmd&#x2F;src&#x2F;lib&#x2F;be&#x2F;mod.rs#L109&quot;&gt;filter2idl&lt;&#x2F;a&gt;.
To understand this function, we need to understand how indexes and
entries are stored.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;let (idl, fplan) = lperf_trace_segment!(au, &amp;quot;be::search -&amp;gt; filter2idl&amp;quot;, || {
&lt;&#x2F;span&gt;&lt;span&gt;    self.filter2idl(au, filt.to_inner(), FILTER_SEARCH_TEST_THRESHOLD)
&lt;&#x2F;span&gt;&lt;span&gt;})?;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;All databases at the lowest levels are built on collections of key-value
stores. That keyvalue store may be a in memory tree or hashmap, or an on
disk tree. Some common stores are BDB, LMDB, SLED. In Kanidm we use
SQLite as a key-value store, through tables that only contain two
columns. The intent is to swap to SLED in the future once it gains
transactions over a collection of trees, and that trees can be
created&#x2F;removed in transactions.&lt;&#x2F;p&gt;
&lt;p&gt;The primary storage of all entries is in the table
&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&#x2F;blob&#x2F;master&#x2F;kanidmd&#x2F;src&#x2F;lib&#x2F;be&#x2F;idl_sqlite.rs#L1134&quot;&gt;id2entry&lt;&#x2F;a&gt;
which has an id column (the key) and stores serialised entries in the
data column.&lt;&#x2F;p&gt;
&lt;p&gt;Indexes are stored in a collection of their own tables, named in the
scheme &amp;quot;idx_&amp;lt;type&amp;gt;_&amp;lt;attr&amp;gt;&amp;quot;. For example, &amp;quot;idx_eq_name&amp;quot; or
&amp;quot;idx_pres_class&amp;quot;. These are stored as two columns, where the &amp;quot;key&amp;quot;
column is a precomputed result of a value in the entry, and the
&amp;quot;value&amp;quot; is a set of integer ID&#x27;s related to the entries that contain
the relevant match.&lt;&#x2F;p&gt;
&lt;p&gt;As a bit more of a graphic example, you can imagine these as:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;id2entry
&lt;&#x2F;span&gt;&lt;span&gt;| id | data                                    |
&lt;&#x2F;span&gt;&lt;span&gt;| 1  | { &amp;quot;name&amp;quot;: &amp;quot;william&amp;quot;, ... }
&lt;&#x2F;span&gt;&lt;span&gt;| 2  | { &amp;quot;name&amp;quot;: &amp;quot;claire&amp;quot;, ... }
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;idx_eq_name
&lt;&#x2F;span&gt;&lt;span&gt;| key     |
&lt;&#x2F;span&gt;&lt;span&gt;| william | [1, ]
&lt;&#x2F;span&gt;&lt;span&gt;| claire  | [2, ]
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;idm_eq_class
&lt;&#x2F;span&gt;&lt;span&gt;| account | [1, 2, ... ]
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;As these are key-value stores, they are able to be cached through an
in-memory key value store to speed up the process. Initially, we&#x27;ll
assume these are not cache.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;filter2idl&quot;&gt;filter2idl&lt;&#x2F;h2&gt;
&lt;p&gt;Back to [filter2idl]{.title-ref}. The query begins by processing the
outer [and]{.title-ref} term. As the [and]{.title-ref} progresses inner
elements are &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&#x2F;blob&#x2F;dbfe87e675beac7fd931a445fd80cf439c2c6e61&#x2F;kanidmd&#x2F;src&#x2F;lib&#x2F;be&#x2F;mod.rs#L229&quot;&gt;iterated
over&lt;&#x2F;a&gt;
and then recursively sent to [filter2idl]{.title-ref}.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;FilterResolved::And(l) =&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; First, setup the two filter lists. We always apply AndNot after positive
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; and terms.
&lt;&#x2F;span&gt;&lt;span&gt;    let (f_andnot, f_rem): (Vec&amp;lt;_&amp;gt;, Vec&amp;lt;_&amp;gt;) = l.iter().partition(|f| f.is_andnot());
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; We make this an iter, so everything comes off in order. if we used pop it means we
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; pull from the tail, which is the WORST item to start with!
&lt;&#x2F;span&gt;&lt;span&gt;    let mut f_rem_iter = f_rem.iter();
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; Setup the initial result.
&lt;&#x2F;span&gt;&lt;span&gt;    let (mut cand_idl, fp) = match f_rem_iter.next() {
&lt;&#x2F;span&gt;&lt;span&gt;        Some(f) =&amp;gt; self.filter2idl(au, f, thres)?,
&lt;&#x2F;span&gt;&lt;span&gt;        None =&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;            lfilter_error!(au, &amp;quot;WARNING: And filter was empty, or contains only AndNot, can not evaluate.&amp;quot;);
&lt;&#x2F;span&gt;&lt;span&gt;            return Ok((IDL::Indexed(IDLBitRange::new()), FilterPlan::Invalid));
&lt;&#x2F;span&gt;&lt;span&gt;        }
&lt;&#x2F;span&gt;&lt;span&gt;    };
&lt;&#x2F;span&gt;&lt;span&gt;    ...
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The first term we encounter is [{&amp;quot;eq&amp;quot;: [&amp;quot;class&amp;quot;, &amp;quot;account&amp;quot;,
true]}]{.title-ref}. At this point [filter2idl]{.title-ref} is able to
&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&#x2F;blob&#x2F;dbfe87e675beac7fd931a445fd80cf439c2c6e61&#x2F;kanidmd&#x2F;src&#x2F;lib&#x2F;be&#x2F;mod.rs#L123&quot;&gt;request the id
list&lt;&#x2F;a&gt;
from the lower levels.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;FilterResolved::Eq(attr, value, idx) =&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;    if *idx {
&lt;&#x2F;span&gt;&lt;span&gt;        &#x2F;&#x2F; Get the idx_key
&lt;&#x2F;span&gt;&lt;span&gt;        let idx_key = value.get_idx_eq_key();
&lt;&#x2F;span&gt;&lt;span&gt;        &#x2F;&#x2F; Get the idl for this
&lt;&#x2F;span&gt;&lt;span&gt;        match self
&lt;&#x2F;span&gt;&lt;span&gt;            .get_idlayer()
&lt;&#x2F;span&gt;&lt;span&gt;            .get_idl(au, attr, &amp;amp;IndexType::EQUALITY, &amp;amp;idx_key)?
&lt;&#x2F;span&gt;&lt;span&gt;        {
&lt;&#x2F;span&gt;&lt;span&gt;            Some(idl) =&amp;gt; (
&lt;&#x2F;span&gt;&lt;span&gt;                IDL::Indexed(idl),
&lt;&#x2F;span&gt;&lt;span&gt;                FilterPlan::EqIndexed(attr.to_string(), idx_key),
&lt;&#x2F;span&gt;&lt;span&gt;            ),
&lt;&#x2F;span&gt;&lt;span&gt;            None =&amp;gt; (IDL::ALLIDS, FilterPlan::EqCorrupt(attr.to_string())),
&lt;&#x2F;span&gt;&lt;span&gt;        }
&lt;&#x2F;span&gt;&lt;span&gt;    } else {
&lt;&#x2F;span&gt;&lt;span&gt;        &#x2F;&#x2F; Schema believes this is not indexed
&lt;&#x2F;span&gt;&lt;span&gt;        (IDL::ALLIDS, FilterPlan::EqUnindexed(attr.to_string()))
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The first level that is able to serve the request for the key to be
resolved is the &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&#x2F;blob&#x2F;dbfe87e675beac7fd931a445fd80cf439c2c6e61&#x2F;kanidmd&#x2F;src&#x2F;lib&#x2F;be&#x2F;idl_arc_sqlite.rs#L178&quot;&gt;ARCache
layer&lt;&#x2F;a&gt;.
This tries to lookup the combination of (&amp;quot;class&amp;quot;, &amp;quot;account&amp;quot;, eq) in
the cache. If found it is returned to the caller. If not, it is
requested from the &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&#x2F;blob&#x2F;master&#x2F;kanidmd&#x2F;src&#x2F;lib&#x2F;be&#x2F;idl_sqlite.rs#L220&quot;&gt;sqlite
layer&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;let cache_key = IdlCacheKey {
&lt;&#x2F;span&gt;&lt;span&gt;    a: $attr.to_string(),
&lt;&#x2F;span&gt;&lt;span&gt;    i: $itype.clone(),
&lt;&#x2F;span&gt;&lt;span&gt;    k: $idx_key.to_string(),
&lt;&#x2F;span&gt;&lt;span&gt;};
&lt;&#x2F;span&gt;&lt;span&gt;let cache_r = $self.idl_cache.get(&amp;amp;cache_key);
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;&#x2F; If hit, continue.
&lt;&#x2F;span&gt;&lt;span&gt;if let Some(ref data) = cache_r {
&lt;&#x2F;span&gt;&lt;span&gt;    ltrace!(
&lt;&#x2F;span&gt;&lt;span&gt;        $audit,
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;quot;Got cached idl for index {:?} {:?} -&amp;gt; {}&amp;quot;,
&lt;&#x2F;span&gt;&lt;span&gt;        $itype,
&lt;&#x2F;span&gt;&lt;span&gt;        $attr,
&lt;&#x2F;span&gt;&lt;span&gt;        data
&lt;&#x2F;span&gt;&lt;span&gt;    );
&lt;&#x2F;span&gt;&lt;span&gt;    return Ok(Some(data.as_ref().clone()));
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;&#x2F; If miss, get from db *and* insert to the cache.
&lt;&#x2F;span&gt;&lt;span&gt;let db_r = $self.db.get_idl($audit, $attr, $itype, $idx_key)?;
&lt;&#x2F;span&gt;&lt;span&gt;if let Some(ref idl) = db_r {
&lt;&#x2F;span&gt;&lt;span&gt;    $self.idl_cache.insert(cache_key, Box::new(idl.clone()))
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This sqlite layer performs the select from the
&amp;quot;idx_&amp;lt;type&amp;gt;_&amp;lt;attr&amp;gt;&amp;quot; table, and then deserialises the stored id
list (IDL).&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;let mut stmt = self.get_conn().prepare(query.as_str()).map_err(|e| {
&lt;&#x2F;span&gt;&lt;span&gt;    ladmin_error!(audit, &amp;quot;SQLite Error {:?}&amp;quot;, e);
&lt;&#x2F;span&gt;&lt;span&gt;    OperationError::SQLiteError
&lt;&#x2F;span&gt;&lt;span&gt;})?;
&lt;&#x2F;span&gt;&lt;span&gt;let idl_raw: Option&amp;lt;Vec&amp;lt;u8&amp;gt;&amp;gt; = stmt
&lt;&#x2F;span&gt;&lt;span&gt;    .query_row_named(&amp;amp;[(&amp;quot;:idx_key&amp;quot;, &amp;amp;idx_key)], |row| row.get(0))
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; We don&amp;#39;t mind if it doesn&amp;#39;t exist
&lt;&#x2F;span&gt;&lt;span&gt;    .optional()
&lt;&#x2F;span&gt;&lt;span&gt;    .map_err(|e| {
&lt;&#x2F;span&gt;&lt;span&gt;        ladmin_error!(audit, &amp;quot;SQLite Error {:?}&amp;quot;, e);
&lt;&#x2F;span&gt;&lt;span&gt;        OperationError::SQLiteError
&lt;&#x2F;span&gt;&lt;span&gt;    })?;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;let idl = match idl_raw {
&lt;&#x2F;span&gt;&lt;span&gt;    Some(d) =&amp;gt; serde_cbor::from_slice(d.as_slice())
&lt;&#x2F;span&gt;&lt;span&gt;        .map_err(|_| OperationError::SerdeCborError)?,
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; We don&amp;#39;t have this value, it must be empty (or we
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; have a corrupted index .....
&lt;&#x2F;span&gt;&lt;span&gt;    None =&amp;gt; IDLBitRange::new(),
&lt;&#x2F;span&gt;&lt;span&gt;};
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The IDL is returned and cached, then returned to the
[filter2idl]{.title-ref} caller. At this point the IDL is the &amp;quot;partial
candidate set&amp;quot;. It contains the ID numbers of entries that we know
partially match this query at this point. Since the first term is
[{&amp;quot;eq&amp;quot;: [&amp;quot;class&amp;quot;, &amp;quot;account&amp;quot;, true]}]{.title-ref} the current
candidate set is [[1, 2, ...]]{.title-ref}.&lt;&#x2F;p&gt;
&lt;p&gt;The
&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&#x2F;blob&#x2F;dbfe87e675beac7fd931a445fd80cf439c2c6e61&#x2F;kanidmd&#x2F;src&#x2F;lib&#x2F;be&#x2F;mod.rs#L284&quot;&gt;and&lt;&#x2F;a&gt;
path in [filter2idl]{.title-ref} continues, and the next term
encountered is [{&amp;quot;eq&amp;quot;: [&amp;quot;name&amp;quot;: &amp;quot;william&amp;quot;, true]}]{.title-ref}.
This resolves into another IDL. The two IDL&#x27;s are merged through an
[and]{.title-ref} operation leaving only the ID numbers that were
present in both.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;(IDL::Indexed(ia), IDL::Indexed(ib)) =&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;    let r = ia &amp;amp; ib;
&lt;&#x2F;span&gt;&lt;span&gt;    ...
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;For this example this means in our example that the state of r(esult
set) is the below;&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;res = ia &amp;amp; ib;
&lt;&#x2F;span&gt;&lt;span&gt;res = [1, 2, ....] &amp;amp; [1, ];
&lt;&#x2F;span&gt;&lt;span&gt;res == [1, ]
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;We know that only the entry with [ID == 1]{.title-ref} matches both
[name = william]{.title-ref} and [class = account]{.title-ref}.&lt;&#x2F;p&gt;
&lt;p&gt;We now perform a check called the &amp;quot;filter threshold check&amp;quot;. If the
number of ID&#x27;s in the IDL is less than a certain number, we can
&lt;em&gt;shortcut&lt;&#x2F;em&gt; and return early even though we are not finished processing.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;if r.len() &amp;lt; thres &amp;amp;&amp;amp; f_rem_count &amp;gt; 0 {
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; When below thres, we have to return partials to trigger the entry_no_match_filter check.
&lt;&#x2F;span&gt;&lt;span&gt;    let setplan = FilterPlan::AndPartialThreshold(plan);
&lt;&#x2F;span&gt;&lt;span&gt;    return Ok((IDL::PartialThreshold(r), setplan));
&lt;&#x2F;span&gt;&lt;span&gt;} else if r.is_empty() {
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; Regardless of the input state, if it&amp;#39;s empty, this can never
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; be satisfied, so return we are indexed and complete.
&lt;&#x2F;span&gt;&lt;span&gt;    let setplan = FilterPlan::AndEmptyCand(plan);
&lt;&#x2F;span&gt;&lt;span&gt;    return Ok((IDL::Indexed(IDLBitRange::new()), setplan));
&lt;&#x2F;span&gt;&lt;span&gt;} else {
&lt;&#x2F;span&gt;&lt;span&gt;    IDL::Indexed(r)
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This is because the IDL is now small, and continuing to load more
indexes may cost more time and resources. The IDL can only ever shrink
or stay the same from this point, never expand, so we know it must stay
small.&lt;&#x2F;p&gt;
&lt;p&gt;However, you may correctly have deduced that there are still two terms
we must check. That is the terms contained within the
[andnot]{.title-ref} of the query. I promise you, we will check them :)&lt;&#x2F;p&gt;
&lt;p&gt;So at this point we now step out of [filter2idl]{.title-ref} and begin
the process of post-processing the results we have.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;resolving-the-partial-set&quot;&gt;Resolving the Partial Set&lt;&#x2F;h2&gt;
&lt;p&gt;We check the way that the &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&#x2F;blob&#x2F;dbfe87e675beac7fd931a445fd80cf439c2c6e61&#x2F;kanidmd&#x2F;src&#x2F;lib&#x2F;be&#x2F;mod.rs#L498&quot;&gt;IDL is
tagged&lt;&#x2F;a&gt;
so that we understand what post processing is required, and check some
security controls. If the search was unindexed aka [ALLIDS]{.title-ref},
and if the account is not allowed to access fully unindexed searches,
then we return a failure at this point. We also now check if the query
was [Partial(ly)]{.title-ref} unindexed, and if it is, we assert limits
over the number of entries we may load and test.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;match &amp;amp;idl {
&lt;&#x2F;span&gt;&lt;span&gt;    IDL::ALLIDS =&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;        if !erl.unindexed_allow {
&lt;&#x2F;span&gt;&lt;span&gt;            ladmin_error!(au, &amp;quot;filter (search) is fully unindexed, and not allowed by resource limits&amp;quot;);
&lt;&#x2F;span&gt;&lt;span&gt;            return Err(OperationError::ResourceLimit);
&lt;&#x2F;span&gt;&lt;span&gt;        }
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;    IDL::Partial(idl_br) =&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;        if idl_br.len() &amp;gt; erl.search_max_filter_test {
&lt;&#x2F;span&gt;&lt;span&gt;            ladmin_error!(au, &amp;quot;filter (search) is partial indexed and greater than search_max_filter_test allowed by resource limits&amp;quot;);
&lt;&#x2F;span&gt;&lt;span&gt;            return Err(OperationError::ResourceLimit);
&lt;&#x2F;span&gt;&lt;span&gt;        }
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;    IDL::PartialThreshold(_) =&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;        &#x2F;&#x2F; Since we opted for this, this is not the fault
&lt;&#x2F;span&gt;&lt;span&gt;        &#x2F;&#x2F; of the user and we should not penalise them by limiting on partial.
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;    IDL::Indexed(idl_br) =&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;        &#x2F;&#x2F; We know this is resolved here, so we can attempt the limit
&lt;&#x2F;span&gt;&lt;span&gt;        &#x2F;&#x2F; check. This has to fold the whole index, but you know, class=pres is
&lt;&#x2F;span&gt;&lt;span&gt;        &#x2F;&#x2F; indexed ...
&lt;&#x2F;span&gt;&lt;span&gt;        if idl_br.len() &amp;gt; erl.search_max_results {
&lt;&#x2F;span&gt;&lt;span&gt;            ladmin_error!(au, &amp;quot;filter (search) is indexed and greater than search_max_results allowed by resource limits&amp;quot;);
&lt;&#x2F;span&gt;&lt;span&gt;            return Err(OperationError::ResourceLimit);
&lt;&#x2F;span&gt;&lt;span&gt;        }
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;};
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;We then load the related entries from the IDL we have. Initially, this
is called through the entry cache of the ARCache.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;let entries = self.get_idlayer().get_identry(au, &amp;amp;idl).map_err(|e| {
&lt;&#x2F;span&gt;&lt;span&gt;    ladmin_error!(au, &amp;quot;get_identry failed {:?}&amp;quot;, e);
&lt;&#x2F;span&gt;&lt;span&gt;    e
&lt;&#x2F;span&gt;&lt;span&gt;})?;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;As many entries as possible are &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&#x2F;blob&#x2F;dbfe87e675beac7fd931a445fd80cf439c2c6e61&#x2F;kanidmd&#x2F;src&#x2F;lib&#x2F;be&#x2F;idl_arc_sqlite.rs#L93&quot;&gt;loaded from the
ARCache&lt;&#x2F;a&gt;.
The remaining ID&#x27;s that were missed are stored in a secondary IDL set.
The missed entry set is then submitted to &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&#x2F;blob&#x2F;master&#x2F;kanidmd&#x2F;src&#x2F;lib&#x2F;be&#x2F;idl_sqlite.rs#L99&quot;&gt;the sqlite
layer&lt;&#x2F;a&gt;
where the entries are loaded and deserialised. An important part of the
ARCache is to keep fully inflated entries in memory, to speed up the
process of retrieving these. Real world use shows this can have orders
of magnitude of impact on performance by just avoiding this
deserialisation step, but also that we avoid IO to disk.&lt;&#x2F;p&gt;
&lt;p&gt;The entry set is now able to be checked. If the IDL was
[Indexed]{.title-ref} no extra work is required, and we can just return
the values. But in all other cases we must apply the filter test. The
filter test is where the terms of the filter are checked against each
entry to determine if they match and are part of the set.&lt;&#x2F;p&gt;
&lt;p&gt;This is where the partial threshold is important - that the act of
processing the remaining indexes may be more expensive than applying the
filter assertions to the subset of entries in memory. It&#x27;s also why
filter optimisation matters. If a query can be below the threshold
sooner, than we can apply the filter test earlier and we reduce the
number of indexes we must load and keep cached. This helps performance
and cache behaviour.&lt;&#x2F;p&gt;
&lt;p&gt;The &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&#x2F;blob&#x2F;dbfe87e675beac7fd931a445fd80cf439c2c6e61&#x2F;kanidmd&#x2F;src&#x2F;lib&#x2F;entry.rs#L1663&quot;&gt;filter
test&lt;&#x2F;a&gt;
applies the terms of the filter to the entry, using the same rules as
the indexing process to ensure consistent results. This gives us a
true&#x2F;false result, which lets us know if the entry really does match and
should become part of the final candidate set.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;fn search(...) {
&lt;&#x2F;span&gt;&lt;span&gt;    ...
&lt;&#x2F;span&gt;&lt;span&gt;    IDL::Partial(_) =&amp;gt; lperf_segment!(au, &amp;quot;be::search&amp;lt;entry::ftest::partial&amp;gt;&amp;quot;, || {
&lt;&#x2F;span&gt;&lt;span&gt;        entries
&lt;&#x2F;span&gt;&lt;span&gt;            .into_iter()
&lt;&#x2F;span&gt;&lt;span&gt;            .filter(|e| e.entry_match_no_index(&amp;amp;filt))
&lt;&#x2F;span&gt;&lt;span&gt;            .collect()
&lt;&#x2F;span&gt;&lt;span&gt;    }),
&lt;&#x2F;span&gt;&lt;span&gt;    ...
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;fn entry_match_no_index_inner(&amp;amp;self, filter: &amp;amp;FilterResolved) -&amp;gt; bool {
&lt;&#x2F;span&gt;&lt;span&gt;    match filter {
&lt;&#x2F;span&gt;&lt;span&gt;        FilterResolved::Eq(attr, value, _) =&amp;gt; self.attribute_equality(attr.as_str(), value),
&lt;&#x2F;span&gt;&lt;span&gt;        FilterResolved::Sub(attr, subvalue, _) =&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;            self.attribute_substring(attr.as_str(), subvalue)
&lt;&#x2F;span&gt;&lt;span&gt;        }
&lt;&#x2F;span&gt;&lt;span&gt;        ...
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;It is now at this point that we finally have the fully resolved set of
entries, in memory as a result set from the backend. These are returned
to the query server&#x27;s [search]{.title-ref} function.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;access-controls&quot;&gt;Access Controls&lt;&#x2F;h2&gt;
&lt;p&gt;Now the process of
&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&#x2F;blob&#x2F;dbfe87e675beac7fd931a445fd80cf439c2c6e61&#x2F;kanidmd&#x2F;src&#x2F;lib&#x2F;server.rs#L168&quot;&gt;applying&lt;&#x2F;a&gt;
access controls begins. There are two layers of access controls as
applied in kanidm. The first is &lt;em&gt;which entries are you allowed to see&lt;&#x2F;em&gt;.
The second is &lt;em&gt;within an entry, what attributes may you see&lt;&#x2F;em&gt;. There is a
reason for this seperation. The seperation exists so that when an
internal search is performed on behalf of the user, we retrieve the set
of entries you can see, but the server internally then performs the
operation on your behalf and itself has access to see all attributes. If
you wish to see this in action, it&#x27;s a critical part of how
&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&#x2F;blob&#x2F;dbfe87e675beac7fd931a445fd80cf439c2c6e61&#x2F;kanidmd&#x2F;src&#x2F;lib&#x2F;server.rs#L1290&quot;&gt;modify&lt;&#x2F;a&gt;
and
&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&#x2F;blob&#x2F;dbfe87e675beac7fd931a445fd80cf439c2c6e61&#x2F;kanidmd&#x2F;src&#x2F;lib&#x2F;server.rs#L988&quot;&gt;delete&lt;&#x2F;a&gt;
both function, where you can only change or delete within your visible
entry scope.&lt;&#x2F;p&gt;
&lt;p&gt;The first stage is
&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&#x2F;blob&#x2F;master&#x2F;kanidmd&#x2F;src&#x2F;lib&#x2F;access.rs#L376&quot;&gt;search_filter_entries&lt;&#x2F;a&gt;.
This is the function that checks what entries you &lt;em&gt;may&lt;&#x2F;em&gt; see. This checks
that you have the rights to see specific attributes (ie can you see
name?), which then affects, &amp;quot;could you possibly have queried for
this?&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;Imagine for example, that we search for &amp;quot;password = X&amp;quot; (which kanidm
disallows but anyway ...). Even if you could not read password, the act
of testing the equality, if an entry was returned you would know now
about the value or association to a user since the equality condition
held true. This is a security risk for information disclosure.&lt;&#x2F;p&gt;
&lt;p&gt;The first stage of access controls is &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&#x2F;blob&#x2F;master&#x2F;kanidmd&#x2F;src&#x2F;lib&#x2F;access.rs#L397&quot;&gt;what rules apply to your
authenticated
user&lt;&#x2F;a&gt;.
There may be thousands of access controls in the system, but only some
may related to your account.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;let related_acp: Vec&amp;lt;&amp;amp;AccessControlSearch&amp;gt; =
&lt;&#x2F;span&gt;&lt;span&gt;    lperf_segment!(audit, &amp;quot;access::search_filter_entries&amp;lt;related_acp&amp;gt;&amp;quot;, || {
&lt;&#x2F;span&gt;&lt;span&gt;        search_state
&lt;&#x2F;span&gt;&lt;span&gt;            .iter()
&lt;&#x2F;span&gt;&lt;span&gt;            .filter(|acs| {
&lt;&#x2F;span&gt;&lt;span&gt;                let f_val = acs.acp.receiver.clone();
&lt;&#x2F;span&gt;&lt;span&gt;                match f_val.resolve(&amp;amp;se.event, None) {
&lt;&#x2F;span&gt;&lt;span&gt;                    Ok(f_res) =&amp;gt; rec_entry.entry_match_no_index(&amp;amp;f_res),
&lt;&#x2F;span&gt;&lt;span&gt;                    Err(e) =&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;                        ...
&lt;&#x2F;span&gt;&lt;span&gt;                    }
&lt;&#x2F;span&gt;&lt;span&gt;                }
&lt;&#x2F;span&gt;&lt;span&gt;            })
&lt;&#x2F;span&gt;&lt;span&gt;            .collect()
&lt;&#x2F;span&gt;&lt;span&gt;    });
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The next stage is to determine &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&#x2F;blob&#x2F;master&#x2F;kanidmd&#x2F;src&#x2F;lib&#x2F;access.rs#L440&quot;&gt;what attributes did you request to
filter
on&lt;&#x2F;a&gt;.
This is why [filter_orig]{.title-ref} is stored in the event. We must
test against the filter as intended by the caller, not the filter as
executed. This is because the filter as executed may have been
transformed by the server, using terms the user does not have access to.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;let requested_attrs: BTreeSet&amp;lt;&amp;amp;str&amp;gt; = se.filter_orig.get_attr_set();
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Then for each entry, the set of allowed attributes is determined. If the
user related access control also holds rights oven the entry in the
result set, the set of attributes it grants read access over is appended
to the &amp;quot;allowed&amp;quot; set. This repeats until the set of related access
controls is exhausted.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;let allowed_entries: Vec&amp;lt;Entry&amp;lt;EntrySealed, EntryCommitted&amp;gt;&amp;gt; =
&lt;&#x2F;span&gt;&lt;span&gt;    entries
&lt;&#x2F;span&gt;&lt;span&gt;        .into_iter()
&lt;&#x2F;span&gt;&lt;span&gt;        .filter(|e| {
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;            let allowed_attrs: BTreeSet&amp;lt;&amp;amp;str&amp;gt; = related_acp.iter()
&lt;&#x2F;span&gt;&lt;span&gt;                .filter_map(|acs| {
&lt;&#x2F;span&gt;&lt;span&gt;                    ...
&lt;&#x2F;span&gt;&lt;span&gt;                    if e.entry_match_no_index(&amp;amp;f_res) {
&lt;&#x2F;span&gt;&lt;span&gt;                        &#x2F;&#x2F; add search_attrs to allowed.
&lt;&#x2F;span&gt;&lt;span&gt;                        Some(acs.attrs.iter().map(|s| s.as_str()))
&lt;&#x2F;span&gt;&lt;span&gt;                    } else {
&lt;&#x2F;span&gt;&lt;span&gt;                        None
&lt;&#x2F;span&gt;&lt;span&gt;                    }
&lt;&#x2F;span&gt;&lt;span&gt;                    ...
&lt;&#x2F;span&gt;&lt;span&gt;                })
&lt;&#x2F;span&gt;&lt;span&gt;                .collect();
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;            let decision = requested_attrs.is_subset(&amp;amp;allowed_attrs);
&lt;&#x2F;span&gt;&lt;span&gt;            lsecurity_access!(audit, &amp;quot;search attr decision --&amp;gt; {:?}&amp;quot;, decision);
&lt;&#x2F;span&gt;&lt;span&gt;            decision
&lt;&#x2F;span&gt;&lt;span&gt;        })
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This now has created a set of &amp;quot;attributes this person can see&amp;quot; on this
entry based on all related rules. The requested attributes are compared
to the attributes you may see, and if requested is a subset or equal,
then the entry is allowed to be returned to the user.&lt;&#x2F;p&gt;
&lt;p&gt;If there is even a single attribute in the query you do not have the
rights to see, then the entry is disallowed from the result set. This is
because if you can not see that attribute, you must not be able to apply
a filter test to it.&lt;&#x2F;p&gt;
&lt;p&gt;To give a worked example, consider the entry from before. We also have
three access controls:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;applies to: all users
&lt;&#x2F;span&gt;&lt;span&gt;over: pres class
&lt;&#x2F;span&gt;&lt;span&gt;read attr: class
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;applies to: memberof admins
&lt;&#x2F;span&gt;&lt;span&gt;over: entries where class = account
&lt;&#x2F;span&gt;&lt;span&gt;read attr: name, displayname
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;applies to: memberof radius_servers
&lt;&#x2F;span&gt;&lt;span&gt;over: entries where class = account
&lt;&#x2F;span&gt;&lt;span&gt;read attr: radius secret
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Our current authenticated user (let&#x27;s assume it&#x27;s also
&amp;quot;name=william&amp;quot;), would only have the first two rules apply. As we
search through the candidate entries, the &amp;quot;all users&amp;quot; rule would match
our entry, which means class is added to the allowed set. Then since
william is memberof admins, they also have read to name, and
displayname. Since the target entry is class=account then name and
displayname are also added to the allowed set. But since william is
&lt;em&gt;not&lt;&#x2F;em&gt; a member of radius_servers, we don&#x27;t get to read radius secrets.&lt;&#x2F;p&gt;
&lt;p&gt;At this point the entry set is reduced to the set of entries the user
was &lt;em&gt;able&lt;&#x2F;em&gt; to have applied filter tests too, and is returned.&lt;&#x2F;p&gt;
&lt;p&gt;The query server then unwinds to [search_ext]{.title-ref} where the
second stage of access controls is now checked. This calls
&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&#x2F;blob&#x2F;master&#x2F;kanidmd&#x2F;src&#x2F;lib&#x2F;access.rs#L524&quot;&gt;search_filter_entry_attributes&lt;&#x2F;a&gt;
which is responsible for changing an entry in memory to remove content
that the user may not see. A key difference is this line:&lt;&#x2F;p&gt;
&lt;p&gt;Again, the set of related access controls is generated, and then applied
to each entry to determine if they are in scope. This builds a set of
&amp;quot;attributes the user can see, per entry&amp;quot;. This is then applied to the
entry to reduction function, which removes any attribute &lt;em&gt;not&lt;&#x2F;em&gt; in the
allowed set.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;e.reduce_attributes(&amp;amp;allowed_attrs)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;A clear example is when you attempt to view yourself vs when you view
another persons account as there are permissions over self that exist,
which do not apply to others. You may view your own legalname field, but
not the legalname of another person.&lt;&#x2F;p&gt;
&lt;p&gt;The entry set is finally returned and turned into a JSON entry for
transmission to the client. Hooray!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;&#x2F;h2&gt;
&lt;p&gt;There is a lot that goes into a query being processed in a database. But
like all things in computing since it was created by a person, any other
person must be able to understand it. It&#x27;s always amazing that this
whole process can be achieved in fractions of a second, in parallel, and
so reliably.&lt;&#x2F;p&gt;
&lt;p&gt;There is so much more involved in this process too. The way that a write
operation is performed to extract correct index values, the way that the
database reloads the access control cache based on changes, and even how
the schema is loaded and constructed. Ontop of all this, a complete
identity management stack is built that can allow authentication through
wireless, machines, ssh keys and more.&lt;&#x2F;p&gt;
&lt;p&gt;If you are interested more in databases and
&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&quot;&gt;Kanidm&lt;&#x2F;a&gt; please get in contact!&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Using SUSE Leap Enterprise with Docker</title>
          <pubDate>Wed, 26 Aug 2020 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2020-08-26-using-suse-leap-enterprise-with-docker/</link>
          <guid>https://fy.blackhats.net.au/blog/2020-08-26-using-suse-leap-enterprise-with-docker/</guid>
          <description>&lt;h1 id=&quot;using-suse-leap-enterprise-with-docker&quot;&gt;Using SUSE Leap Enterprise with Docker&lt;&#x2F;h1&gt;
&lt;p&gt;It&#x27;s a little bit annoying to connect up all the parts for this. If you
have a SLE15 system then credentials for SCC are automatically passed
into containers via secrets.&lt;&#x2F;p&gt;
&lt;p&gt;But if you are on a non-SLE base, like myself with MacOS or OpenSUSE
you&#x27;ll need to provide these to the container in another way. The
documentation is a bit tricky to search and connect up what you need but
in summary:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Get [&#x2F;etc&#x2F;SUSEConnect]{.title-ref} and
[&#x2F;etc&#x2F;zypp&#x2F;credentials.d&#x2F;SCCcredentials]{.title-ref} from an SLE
install that has been registered. The SLE version does not matter.&lt;&#x2F;li&gt;
&lt;li&gt;Mount them into the image:&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;docker&lt;&#x2F;span&gt;&lt;span&gt; ...&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt; -v&lt;&#x2F;span&gt;&lt;span&gt; &#x2F;scc&#x2F;SUSEConnect:&#x2F;etc&#x2F;SUSEConnect \
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;        -v&lt;&#x2F;span&gt;&lt;span&gt; &#x2F;scc&#x2F;SCCcredentials:&#x2F;etc&#x2F;zypp&#x2F;credentials.d&#x2F;SCCcredentials \
&lt;&#x2F;span&gt;&lt;span&gt;        ...
&lt;&#x2F;span&gt;&lt;span&gt;        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;registry.suse.com&#x2F;suse&#x2F;sle15:15.2
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now you can use the images from &lt;a href=&quot;https:&#x2F;&#x2F;registry.suse.com&#x2F;&quot;&gt;the SUSE
registry&lt;&#x2F;a&gt;. For example [docker pull
registry.suse.com&#x2F;suse&#x2F;sle15:15.2]{.title-ref} and have working zypper
within them.&lt;&#x2F;p&gt;
&lt;p&gt;If you want to add extra modules to your container (you can list what&#x27;s
available with container-suseconnect from an existing SLE container of
the same version), you can do this by adding environment variables at
startup. For example, to add dev tools like gdb:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;docker&lt;&#x2F;span&gt;&lt;span&gt; ...&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt; -e&lt;&#x2F;span&gt;&lt;span&gt; ADDITIONAL_MODULES=sle-module-development-tools \
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;        -v&lt;&#x2F;span&gt;&lt;span&gt; &#x2F;scc&#x2F;SUSEConnect:&#x2F;etc&#x2F;SUSEConnect \
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;        -v&lt;&#x2F;span&gt;&lt;span&gt; &#x2F;scc&#x2F;SCCcredentials:&#x2F;etc&#x2F;zypp&#x2F;credentials.d&#x2F;SCCcredentials \
&lt;&#x2F;span&gt;&lt;span&gt;        ...
&lt;&#x2F;span&gt;&lt;span&gt;        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;registry.suse.com&#x2F;suse&#x2F;sle15:15.2
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This also works during builds to add extra modules.&lt;&#x2F;p&gt;
&lt;p&gt;HINT: SUSEConnect and SCCcredentials and not version dependent so will
work in any image version.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Windows Hello in Webauthn-rs</title>
          <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2020-08-24-windows-hello-in-webauthn-rs/</link>
          <guid>https://fy.blackhats.net.au/blog/2020-08-24-windows-hello-in-webauthn-rs/</guid>
          <description>&lt;h1 id=&quot;windows-hello-in-webauthn-rs&quot;&gt;Windows Hello in Webauthn-rs&lt;&#x2F;h1&gt;
&lt;p&gt;Recently I&#x27;ve been working again on
&lt;a href=&quot;https:&#x2F;&#x2F;crates.io&#x2F;crates&#x2F;webauthn-rs&quot;&gt;webauthn-rs&lt;&#x2F;a&gt;, as a member of the
community wants to start using it in production for a service. So far
the development of the library has been limited to the test devices that
I own, but now this pushes me toward implementing true fido compliance.&lt;&#x2F;p&gt;
&lt;p&gt;A really major part of this though was that a lot of their consumers use
windows, which means support windows hello.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;a-background-on-webauthn&quot;&gt;A background on webauthn&lt;&#x2F;h2&gt;
&lt;p&gt;Webauthn itself is not a specification for the cryptographic operations
required for authentication using an authenticator device, but a
specification that wraps other techniques to allow a variety of
authenticators to be used exposing their &amp;quot;native&amp;quot; features.&lt;&#x2F;p&gt;
&lt;p&gt;The authentication side of webauthn is reasonably simple in this way.
The server stores a public key credential associated to a user. During
authentication the server provides a challenge which the authenticator
signs using it&#x27;s private key. The server can then verify using it&#x27;s
copy of the challenge, and the public key that the authentication must
have come from that credentials. Of course like anything there is a
little bit of magic in here around how the authenticators store
credentials that allows other properties to be asserted, but that&#x27;s
beyond the scope of this post.&lt;&#x2F;p&gt;
&lt;p&gt;The majority of the webauthn specification is around the process of
registering credentials and requesting specific properties to exist in
the credentials. Some of these properties are optional hints (resident
keys, authenticator attachment) and some of these properties are
enforced (user verification so that the credential is a true MFA).
Beyond these there is also a process for the authenticator to provide
information about it&#x27;s source and trust. This process is attestation
and has multiple different formats and details associated.&lt;&#x2F;p&gt;
&lt;p&gt;It&#x27;s interesting to note that for most deployments of webauthn,
attestation is not required by the attestation conveyance preference,
and generally provides little value to these deployments. For many sites
you only need to know that a webauthn authenticator is in use. However
attestation allows environments with strict security requirements to
verify and attest the legitimacy of, and make and model of
authenticators in use. (An interesting part of webauthn is how much of
it seems to be Google and Microsoft internal requirements leaking into a
specification, just saying).&lt;&#x2F;p&gt;
&lt;p&gt;This leads to what is effectively, most of the code in webauthn-rs -
attestation.rs.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;windows-hello&quot;&gt;Windows Hello&lt;&#x2F;h2&gt;
&lt;p&gt;Windows Hello is Microsoft&#x27;s equivalent to TouchID on iOS. Using a
Trusted Platform Module (TPM) as a tamper-resistant secure element, it
allows devices such as a Windows Surface to perform cryptographic
operations. As Microsoft is attempting to move to a passwordless future
(which honestly, I&#x27;m on board for and want to support in Kanidm), this
means they want to support Webauthn on as many of their devices as
possible. Microsoft even defines in their hardware requirements for
Windows 10 Home, Pro, Education and Enterprise that &lt;a href=&quot;https:&#x2F;&#x2F;docs.microsoft.com&#x2F;en-us&#x2F;windows-hardware&#x2F;design&#x2F;minimum&#x2F;minimum-hardware-requirements-overview&quot;&gt;as of July 28,
2016, all new device models, lines or series ... a component which
implements the TPM 2.0 must be present and enabled by default from this
effective
date.&lt;&#x2F;a&gt;.
This is pretty major as this means that slowly MS have been ensuring
that &lt;em&gt;all&lt;&#x2F;em&gt; consumer and enterprise devices are steadily moving to a
point where passwordless is a viable future. Microsoft state that they
use TPMv2 for many reasons, but a defining one is: &lt;a href=&quot;https:&#x2F;&#x2F;docs.microsoft.com&#x2F;en-us&#x2F;windows&#x2F;security&#x2F;information-protection&#x2F;tpm&#x2F;tpm-recommendations&quot;&gt;The TPM 1.2 spec
only allows for the use of RSA and the SHA-1 hashing
algorithm&lt;&#x2F;a&gt;
which is now considered broken.&lt;&#x2F;p&gt;
&lt;p&gt;Of course, if you have noticed this means that TPM&#x27;s are involved.
Webauthn supports a TPM attestation path, and that means I have to
implement it.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;once-more-into-the-abyss&quot;&gt;Once more into the abyss&lt;&#x2F;h2&gt;
&lt;p&gt;Reading the &lt;a href=&quot;https:&#x2F;&#x2F;www.w3.org&#x2F;TR&#x2F;webauthn&#x2F;#tpm-attestation&quot;&gt;Webauthn spec for TPM
attestation&lt;&#x2F;a&gt; it pointed
me to the TPMv2.0 specification part1, part2 and part3. I will spare you
from this as there is a sum total of 861 pages between these documents,
and the Webauthn spec while it only references a few parts, manages to
then create a set of expanding references within these documents. To
make it even more enjoyable, text search is mostly broken in these
documents, meaning that trying to determine the field contents and types
involves a lot of manual-eyeball work.&lt;&#x2F;p&gt;
&lt;p&gt;TPM&#x27;s structures are packed C structs which means that they can be very
tricky to parse. They use u16 identifiers to switch on unions, and other
fun tricks that we love to see from C programs. These u16&#x27;s often have
some defined constants which are valid choices, such as TPM_ALG_ID,
which allows switching on which cryptographic algorithms are in use.
Some stand out parts of this section were as follows.&lt;&#x2F;p&gt;
&lt;p&gt;Unabashed optimism:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;code&gt;TPM_ALG_ERROR 0x0000 &#x2F;&#x2F; Should not occur&lt;&#x2F;code&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Broken Crypto&lt;&#x2F;p&gt;
&lt;p&gt;&lt;code&gt;TPM_ALG_SHA1 0x0004 &#x2F;&#x2F; The SHA1 Algorithm&lt;&#x2F;code&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Being the boomer equivalent of
&lt;a href=&quot;https:&#x2F;&#x2F;auth0.com&#x2F;blog&#x2F;critical-vulnerabilities-in-json-web-token-libraries&#x2F;&quot;&gt;JWT&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;code&gt;TPM_ALG_NULL 0x0010 &#x2F;&#x2F; The NULL Algorithm&lt;&#x2F;code&gt;&lt;&#x2F;p&gt;
&lt;p&gt;And supporting the latest in modern cipher suites&lt;&#x2F;p&gt;
&lt;p&gt;&lt;code&gt;TPM_ALG_XOR 0x000A &#x2F;&#x2F; TCG TPM 2.0 library specification - the XOR encryption algorithm.&lt;&#x2F;code&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;code&gt;ThE XOR eNcRyPtIoN aLgoRitHm.&lt;&#x2F;code&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Some of the structures are even quite fun to implement, such as
TPMT_SIGNATURE, where a matrix of how to switch on it is present where
the first two bytes when interpreted as a u16, define a TPM_ALG_ID
where, if it the two bytes are not in a set of the TPM_ALG_ID then the
whole blob including leading two bytes is actually just a blob of hash.
It would certainly be unfortunate if in the interest of saving two bytes
that my hash accidentally emited data where the first two bytes were
accidentally a TPM_ALG_ID causing a parser to overflow.&lt;&#x2F;p&gt;
&lt;p&gt;I think the cherry on all of this though, is that despite Microsoft
requiring TPMv2.0 to move away from RSA and SHA-1, that when I checked
the attestation signatures for a Windows Hello device I had to implement
the following:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;COSEContentType::INSECURE_RS1 =&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;    hash::hash(hash::MessageDigest::sha1(), input)
&lt;&#x2F;span&gt;&lt;span&gt;        .map(|dbytes| Vec::from(dbytes.as_ref()))
&lt;&#x2F;span&gt;&lt;span&gt;        .map_err(|e| WebauthnError::OpenSSLError(e))
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;&#x2F;h2&gt;
&lt;p&gt;Saying this, I&#x27;m happy that Windows Hello is now in Webauthn-rs. The
actual Webauthn authentication flows DO use secure algorithms (RSA2048 +
SHA256 and better), it is only in the attestation path that some
components are signed by SHA1. So please use
&lt;a href=&quot;https:&#x2F;&#x2F;crates.io&#x2F;crates&#x2F;webauthn-rs&quot;&gt;webauthn-rs&lt;&#x2F;a&gt;, and do use Windows
Hello with it!&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>User gesture is not detected - using iOS TouchID with webauthn-rs</title>
          <pubDate>Wed, 12 Aug 2020 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2020-08-12-user-gesture-is-not-detected-using-ios-touchid-with-webauthn-rs/</link>
          <guid>https://fy.blackhats.net.au/blog/2020-08-12-user-gesture-is-not-detected-using-ios-touchid-with-webauthn-rs/</guid>
          <description>&lt;h1 id=&quot;user-gesture-is-not-detected-using-ios-touchid-with-webauthn-rs&quot;&gt;User gesture is not detected - using iOS TouchID with webauthn-rs&lt;&#x2F;h1&gt;
&lt;p&gt;I was recently contacted by a future user of
&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;webauthn-rs&quot;&gt;webauthn-rs&lt;&#x2F;a&gt; who indicated that
the library may not currently support Windows Hello as an authenticator.
This is due to the nature of the device being a platform attached
authenticator and that webauthn-rs at the time did not support
attachment preferences.&lt;&#x2F;p&gt;
&lt;p&gt;As I have an ipad, and it&#x27;s not a primary computing device I decided to
upgrade to iPadOS 14 beta to try out webauthn via touch (and handwriting
support).&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-issue&quot;&gt;The Issue&lt;&#x2F;h2&gt;
&lt;p&gt;After watching &lt;a href=&quot;https:&#x2F;&#x2F;developer.apple.com&#x2F;videos&#x2F;play&#x2F;wwdc2020&#x2F;10670&#x2F;&quot;&gt;Jiewen&#x27;s WWDC
presentation&lt;&#x2F;a&gt;
about using TouchID with webauthn, I had a better idea about some of the
server side requirements to work with this.&lt;&#x2F;p&gt;
&lt;p&gt;Once I started to test though, I would recieve the following error in
the safari debug console.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;User gesture is not detected. To use the platform authenticator,
&lt;&#x2F;span&gt;&lt;span&gt;call &amp;#39;navigator.credentials.create&amp;#39; within user activated events.
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;I was quite confused by this error - a user activated event seems to be
a bit of an unknown term, and asking other people they also didn&#x27;t
quite know what it meant. My demo site was using a button input with
onclick event handlers to call javascript similar to the following:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;function register() {
&lt;&#x2F;span&gt;&lt;span&gt;fetch(REG_CHALLENGE_URL + username, {method: &amp;quot;POST&amp;quot;})
&lt;&#x2F;span&gt;&lt;span&gt;   .then(res =&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;      ... &#x2F;&#x2F; error handling
&lt;&#x2F;span&gt;&lt;span&gt;   })
&lt;&#x2F;span&gt;&lt;span&gt;   .then(res =&amp;gt; res.json())
&lt;&#x2F;span&gt;&lt;span&gt;   .then(challenge =&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;     challenge.publicKey.challenge = fromBase64(challenge.publicKey.challenge);
&lt;&#x2F;span&gt;&lt;span&gt;     challenge.publicKey.user.id = fromBase64(challenge.publicKey.user.id);
&lt;&#x2F;span&gt;&lt;span&gt;     return navigator.credentials.create(challenge)
&lt;&#x2F;span&gt;&lt;span&gt;       .then(newCredential =&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;         console.log(&amp;quot;PublicKeyCredential Created&amp;quot;);
&lt;&#x2F;span&gt;&lt;span&gt;              .... 
&lt;&#x2F;span&gt;&lt;span&gt;         return fetch(REGISTER_URL + username, {
&lt;&#x2F;span&gt;&lt;span&gt;           method: &amp;quot;POST&amp;quot;,
&lt;&#x2F;span&gt;&lt;span&gt;           body: JSON.stringify(cc),
&lt;&#x2F;span&gt;&lt;span&gt;           headers: {
&lt;&#x2F;span&gt;&lt;span&gt;             &amp;quot;Content-Type&amp;quot;: &amp;quot;application&#x2F;json&amp;quot;,
&lt;&#x2F;span&gt;&lt;span&gt;           },
&lt;&#x2F;span&gt;&lt;span&gt;         })
&lt;&#x2F;span&gt;&lt;span&gt;       })
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This works happily in Firefox and Chrome, and for iPadOS it event works
with my yubikey 5ci.&lt;&#x2F;p&gt;
&lt;p&gt;I investigated further to determine if the issue was in the way I was
presenting the registration to the
[navigator.credentials.create]{.title-ref} function. Comparing to
webauthn.io (which does work with TouchID on iPadOS 14 beta), I noticed
some subtle differences but nothing that should cause an issue like
this.&lt;&#x2F;p&gt;
&lt;p&gt;After much pacing, thinking and asking for help I eventually gave in and
went to the source of webkit&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-solution&quot;&gt;The Solution&lt;&#x2F;h2&gt;
&lt;p&gt;Reading through the webkit source I noted that the check within the code
was looking for association of how the event was initiated. This comes
from a context that is available within the browser. This got me to
think about the fact that the fetch api is &lt;em&gt;async&lt;&#x2F;em&gt;, and I realised at
this point that webauthn.io was using the [jQuery.ajax]{.title-ref}
apis. I altered my demo to use the same, and it began to work with
TouchID. That meant that the user activation was being lost over the
async boundary to the fetch API. (note: it&#x27;s quite reasonable to expect
user interaction to use [navigator.credentials]{.title-ref} to prevent
tricking or manipulating users into activating their webauthn devices).&lt;&#x2F;p&gt;
&lt;p&gt;I emailed Jiewen, who responded overnight and informed me that this is
an issue, and it&#x27;s being tracked in the &lt;a href=&quot;https:&#x2F;&#x2F;bugs.webkit.org&#x2F;show_bug.cgi?id=214722&quot;&gt;webkit
bugzilla&lt;&#x2F;a&gt; . He assures
me that it will be resolved in a future release. Many thanks to him for
helping me with this issue!&lt;&#x2F;p&gt;
&lt;p&gt;At this point I now know that TouchID will work with webauthn-rs, and I
can submit some updates to the library to help support this.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;notes-on-webauthn-with-touchid&quot;&gt;Notes on Webauthn with TouchID&lt;&#x2F;h2&gt;
&lt;p&gt;It&#x27;s worth pointing out a few notes from the WWDC talk, and the
differences I have observed with webauthn on real devices.&lt;&#x2F;p&gt;
&lt;p&gt;In the presentation it is recommended that in your Credential Creation
Options, that you (must?) define the options listed to work with TouchID&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;authenticatorSelection: { authenticatorAttachment: &amp;quot;platform&amp;quot; },
&lt;&#x2F;span&gt;&lt;span&gt;attestation: &amp;quot;direct&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;It&#x27;s worth pointing out that authenticatorAttachment is only a &lt;em&gt;hint&lt;&#x2F;em&gt;
to the client to which credentials it should use. This allows your web
page to streamline the UI flow (such as detection of platform key and
then using that to toggle the authenticatorAttachment), but it&#x27;s not an
enforced security policy. &lt;em&gt;There is no part of the attestation response
that indicates the attachement method&lt;&#x2F;em&gt;. The only way to determine that
the authenticator is a platform authenticator would be in attestation
&amp;quot;direct&amp;quot; to validate the issuing CA or the device&#x27;s AAGUID match the
expectations you hold for what authenticators can be used within your
organisation or site.&lt;&#x2F;p&gt;
&lt;p&gt;Additionally, TouchID does work with &lt;em&gt;no&lt;&#x2F;em&gt; authenticatorAttachment hint
(safari prompts if you want to use an external key or TouchID), and that
[attestation: &amp;quot;none&amp;quot;]{.title-ref} also works. This means that a
minimised and default set of Credential Creation Options will allow you
to work with the majority of webauthn devices.&lt;&#x2F;p&gt;
&lt;p&gt;Finally, the WWDC video glosses over the server side process. Be sure to
follow the w3c standard for verifying attestations, or use a library
that implementes this standard (such as
&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;webauthn-rs&quot;&gt;webauthn-rs&lt;&#x2F;a&gt; or &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;duo-labs&#x2F;webauthn&#x2F;&quot;&gt;duo-labs go
webauthn&lt;&#x2F;a&gt;). I&#x27;m sure that other
libraries exist, but it&#x27;s critical that they follow the w3c process as
webauthn is quite complex and fiddly to implement in a correct and
secure manner.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>docker buildx for multiarch builds</title>
          <pubDate>Thu, 06 Aug 2020 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2020-08-06-docker-buildx-for-multiarch-builds/</link>
          <guid>https://fy.blackhats.net.au/blog/2020-08-06-docker-buildx-for-multiarch-builds/</guid>
          <description>&lt;h1 id=&quot;docker-buildx-for-multiarch-builds&quot;&gt;docker buildx for multiarch builds&lt;&#x2F;h1&gt;
&lt;p&gt;I have been previously building Kanidm with plain docker build, but
recently a community member wanted to be able to run kanidm on arm64.
That meant that I needed to go down the rabbit hole of how to make this
work ...&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-not-to-do&quot;&gt;What not to do ...&lt;&#x2F;h2&gt;
&lt;p&gt;There is a previous method of using manifest files to allow multiarch
uploads. It&#x27;s pretty messy but it works, so this is an option if you
want to investigate but I didn&#x27;t want to pursue it.&lt;&#x2F;p&gt;
&lt;p&gt;Bulidx exists and I got it working on my linux machine with the steps
from
&lt;a href=&quot;https:&#x2F;&#x2F;www.docker.com&#x2F;blog&#x2F;getting-started-with-docker-for-arm-on-linux&#x2F;&quot;&gt;here&lt;&#x2F;a&gt;
but the build took more than 3 hours, so I don&#x27;t recommend it if you
plan to do anything intense or frequently.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;buildx-cluster&quot;&gt;Buildx cluster&lt;&#x2F;h2&gt;
&lt;p&gt;Docker has a cross-platform building toolkit called buildx which is
currently tucked into the experimental features. It can be enabled on
docker for mac in the settings (note: you only need experimental support
on the coordinating machine aka your workstation).&lt;&#x2F;p&gt;
&lt;p&gt;Rather than follow the &lt;a href=&quot;https:&#x2F;&#x2F;docs.docker.com&#x2F;buildx&#x2F;working-with-buildx&#x2F;&quot;&gt;official
docs&lt;&#x2F;a&gt; this will
branch out. The reason is that buildx in the official docs uses
qemu-aarch64 translation which is very slow and energy hungry, taking a
long time to produce builds. As mentioned already I was seeing in excess
of 3 hours for aarch64 on my builder VM or my mac.&lt;&#x2F;p&gt;
&lt;p&gt;Instead, in this configuration I will use my mac as a coordinator, and
an x86_64 VM and a rock64pro as builder nodes, so that the builds are
performed on native architecture machines.&lt;&#x2F;p&gt;
&lt;p&gt;First we need to configure our nodes. In
[&#x2F;etc&#x2F;docker&#x2F;daemon.json]{.title-ref} we need to expose our docker
socket to our mac. I have done this with the following:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;  &amp;quot;hosts&amp;quot;: [&amp;quot;unix:&#x2F;&#x2F;&#x2F;var&#x2F;run&#x2F;docker.sock&amp;quot;, &amp;quot;tcp:&#x2F;&#x2F;0.0.0.0:2376&amp;quot;]
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&lt;em&gt;WARNING&lt;&#x2F;em&gt;: This configuration is HIGHLY INSECURE. This exposes your
docker socket to the network with no authentication, which is equivalent
to un-authenticated root access. I have done this because my builder
nodes are on an isolated and authenticated VLAN of my home network. You
should either do similar or use TLS authentication.&lt;&#x2F;p&gt;
&lt;p&gt;NOTE: The [ssh:&#x2F;&#x2F;]{.title-ref} transport does not work for docker
buildx. No idea why but it don&#x27;t.&lt;&#x2F;p&gt;
&lt;p&gt;Once this is done restart docker on the two builder nodes.&lt;&#x2F;p&gt;
&lt;p&gt;Now we can configure our coordinator machine. We need to check buildx is
present:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;docker buildx --help
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;We then want to create a new builder instance and join our nodes to it.
We can use the DOCKER_HOST environment variable for this:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;DOCKER_HOST=tcp:&#x2F;&#x2F;x.x.x.x:2376 docker buildx create --name cluster
&lt;&#x2F;span&gt;&lt;span&gt;DOCKER_HOST=tcp:&#x2F;&#x2F;x.x.x.x:2376 docker buildx create --name cluster --append
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;We can then startup and bootstrap the required components with:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;docker buildx use cluster
&lt;&#x2F;span&gt;&lt;span&gt;docker buildx inspect --bootstrap
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;We should see output like:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;Name:   cluster
&lt;&#x2F;span&gt;&lt;span&gt;Driver: docker-container
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Nodes:
&lt;&#x2F;span&gt;&lt;span&gt;Name:      cluster0
&lt;&#x2F;span&gt;&lt;span&gt;Endpoint:  tcp:&#x2F;&#x2F;...
&lt;&#x2F;span&gt;&lt;span&gt;Status:    running
&lt;&#x2F;span&gt;&lt;span&gt;Platforms: linux&#x2F;amd64, linux&#x2F;386
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Name:      cluster1
&lt;&#x2F;span&gt;&lt;span&gt;Endpoint:  tcp:&#x2F;&#x2F;...
&lt;&#x2F;span&gt;&lt;span&gt;Status:    running
&lt;&#x2F;span&gt;&lt;span&gt;Platforms: linux&#x2F;arm64, linux&#x2F;arm&#x2F;v7, linux&#x2F;arm&#x2F;v6
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If we are happy with this we can make this the default builder.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;docker buildx use cluster --default
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;And you can now use it to build your images such as:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;docker buildx build --push --platform linux&#x2F;amd64,linux&#x2F;arm64 -f Dockerfile -t &amp;lt;tag&amp;gt; .
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now I can build my multiarch images much quicker and efficently!&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Developer Perspective on Docker</title>
          <pubDate>Mon, 13 Jul 2020 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2020-07-13-developer-perspective-on-docker/</link>
          <guid>https://fy.blackhats.net.au/blog/2020-07-13-developer-perspective-on-docker/</guid>
          <description>&lt;h1 id=&quot;developer-perspective-on-docker&quot;&gt;Developer Perspective on Docker&lt;&#x2F;h1&gt;
&lt;p&gt;A good mate of mine &lt;a href=&quot;https:&#x2F;&#x2F;ronamosa.io&#x2F;&quot;&gt;Ron Amosa&lt;&#x2F;a&gt; put a question up
on twitter about what do developers think Docker brings to the table.
I&#x27;m really keen to see what he has to say (his knowledge of CI&#x2F;CD and
Kubernetes is amazing by the way!), but I thought I&#x27;d answer his
question from my view as a software engineer.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;Docker provides resource isolation and management to applications&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Lets break that down.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-is-a-resource-what-is-an-application&quot;&gt;What is a resource? What is an application?&lt;&#x2F;h2&gt;
&lt;p&gt;It doesn&#x27;t matter what kind of application we write: A Rust command
line tool, an embedded database in C, or a webserver or website with
Javascript. Every language and that program requires resources to run.
Let&#x27;s focus on a Python webserver for this thought process.&lt;&#x2F;p&gt;
&lt;p&gt;Our webserver (which is an application) requires a lot of things to be
functional! It needs to access a network to open listening sockets, it
needs access to a filesystem to read pages or write to a database (like
sqlite). It needs CPU time to process requests, and memory to create a
stack&#x2F;heap to work through those requests. But as well our application
also needs to be seperated and isolated from other programs too, so that
they can not disclose our data - but so that faults in our application
do not affect other services. It probably needs a seperate user and
group, which is a key idea in unix process isolation and security. Maybe
also there are things like SELinux or AppArmor that also provide extra
enhancements.&lt;&#x2F;p&gt;
&lt;p&gt;But why stop here there are many more. We might need system controls
(sysctls) that define networking stack behaviour like how TCP performs.
We may need specific versions of python libraries for our application.
Perhaps we also want to limit the system calls that our python
application can perform to our OS.&lt;&#x2F;p&gt;
&lt;p&gt;I hope we can see that the resources we have, really is more than simply
CPU and Memory here! Every application is really quite involved.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;a-short-view-back-to-the-past&quot;&gt;A short view back to the past ...&lt;&#x2F;h2&gt;
&lt;p&gt;In the olden days, as developers we had to be responsible for these
isolations. For example on a system, we&#x27;d have to select a bind address
so that we could be configured to only use a single network device for
listening on. This not only meant that our applications had to support
this behaviour, but that a person had to read our documentation, and
find out how to configure that behaviour to isolate the networking
resource.&lt;&#x2F;p&gt;
&lt;p&gt;And of course many others. To limit the amount of CPU or RAM that was
available required you to configure ulimits for the user, and to select
which user was going to run our application.&lt;&#x2F;p&gt;
&lt;p&gt;Many problems have been seen too with a language like python where
libraries are not isolated and there are conflicts between which
&lt;a href=&quot;&#x2F;blog&#x2F;html&#x2F;2019&#x2F;12&#x2F;18&#x2F;packaging_vendoring_and_how_it_s_changing.html&quot;&gt;version different
applications&lt;&#x2F;a&gt;
require. Is it the fault of python? The application developer? It&#x27;s
hard to say ...&lt;&#x2F;p&gt;
&lt;p&gt;What about system calls? With an interpretted language like python, you
can&#x27;t just set the capabilities flags or other hardening options
because they have to be set on the interpretter (python) which is used
in many places. An example where the resource (python) is shared between
many applications preventing us from creating isolated python runtimes.&lt;&#x2F;p&gt;
&lt;p&gt;Even things like SELinux and AppArmor required complex, hand created
profiles, that were cryptic at best, or led to being disabled in the
common case (It can&#x27;t be secure if it&#x27;s not usable! People will always
take the easy option ...).&lt;&#x2F;p&gt;
&lt;p&gt;And that&#x27;s even before we look at init scripts - bash scripts that had
to be invoked in careful ways, and were all hand rolled, each adding
different mistakes or issues. It was a time where to &amp;quot;package&amp;quot; and
application and deploy it, required huge amounts of knowledge of a broad
range of topics.&lt;&#x2F;p&gt;
&lt;p&gt;In many cases, I have seen another way this manifested. Rather than
isolated applications (which was too hard), every application was
installed on a dedicated virtual machine. The resource management then
came as an artifact of every machine being seperate and managed by a
hypervisor.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;systemd&quot;&gt;Systemd&lt;&#x2F;h2&gt;
&lt;p&gt;Along came systemd though, and it got us much further. It provided
consistent application launch tools, and has done a lot of work to
manage and provide resource management such as cgroups (cpu, mem),
dynamic users, some types of filesystem isolation and some more. Systemd
as an init system has done some really good stuff.&lt;&#x2F;p&gt;
&lt;p&gt;But still problems exist. Applications still require custom SELinux or
AppArmor profiles, and systemd can&#x27;t help managing network interfaces
(that still falls on the application).&lt;&#x2F;p&gt;
&lt;p&gt;It also still relies on you to put the files in place, or a distribution
package to get the file content into the system.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;docker&quot;&gt;Docker&lt;&#x2F;h2&gt;
&lt;p&gt;Docker takes this even further. Docker manages and arbitrates every
resource your application requires, even the filesystem and install
process. For example, a very complex topic like CPU or memory limit&#x27;s
on Linux, becomes quite simple in docker which exposes CPU and memory
tunables. Docker allows sysctls per container. You assign and manage
storage.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;docker run -v db:&#x2F;data&#x2F;db -v config:&#x2F;data&#x2F;config --network private_net \
&lt;&#x2F;span&gt;&lt;span&gt;    --memory 1024M --shm-size 128M -P 80:8080 --user isolated \
&lt;&#x2F;span&gt;&lt;span&gt;    my&#x2F;application:version
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;From this command we can see what resources are involved. We know that
we mount two storage locations. We can see that we confine the network
to a private network, and that we want to limit memory to 1024M. We also
can see we&#x27;ll be listening on port 80 which remaps to the container
internally. We even know what user we&#x27;ll run as so we can assign
permissions to the volumes. Our application is also defined as is it&#x27;s
version.&lt;&#x2F;p&gt;
&lt;p&gt;Not only can we see what resources we are using there are a lot of other
benefits. Docker can dynamically generate selinux&#x2F;apparmor isolation
profiles, so we get stronger process isolation between containers and
host processes. We know that the filesystem of this container is
isolated from others, so they can have and bundle the correct versions
of dependencies. We know how to start, stop, and even monitor the
application. It can even have health checks. Logs will (should?) go to
stdout&#x2F;err which docker will forward to a log collector we can define.
In the future each application may even be in it&#x27;s own virtual memory
space (IE seperate vm&#x27;s).&lt;&#x2F;p&gt;
&lt;p&gt;Docker provides a level of isolation to resources that is still hard to
achieve in systemd, and not only that it makes very advanced or complex
configurations easy to access and use. Accesibility of these features is
vitally important to allow all people to create robust applications in
their environments. But it also allows me as a developer to know what
resources &lt;em&gt;can&lt;&#x2F;em&gt; exist in the container and how to interact with these in
a way that will respect the wishes of the deploying administrator.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;docker-isn-t-security-isolation&quot;&gt;Docker Isn&#x27;t Security Isolation&lt;&#x2F;h2&gt;
&lt;p&gt;It&#x27;s worth noting that while Docker can provide SELinux and AppArmor
profiles, Docker is not an effective form of security isolation. It
certainly makes the bar much much higher than before yes! And that&#x27;s
great! And I hope that bar continues to rise. However today we do live
in an age where there are many attacks still locally on linux kernels
and the fix delay in these is still long. We also still see CPU
sidechannels, and these will never be resolved &lt;a href=&quot;&#x2F;blog&#x2F;html&#x2F;2020&#x2F;01&#x2F;20&#x2F;there_are_no_root_causes.html&quot;&gt;while we rely on
asynchronous CPU
behaviour&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;If you have high value data, it is always best to have seperated
physical machines for these applications, and to always patch
frequently, have a proper CI&#x2F;CD pipeline, and centralised logging, and
much much more. Ask your security team! I&#x27;m sure they&#x27;d love to help
:)&lt;&#x2F;p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;&#x2F;h2&gt;
&lt;p&gt;For me personally, docker is about resource management and isolation. It
helps me to define an interface that an admin can consume and interact
with, making very advanced concepts easy to use. It gives me trust that
applications will run in a way that is isolated and known all the way
from development and testing through to production under high load. By
making this accessible, it means that anyone - from a single docker
container to a giant kubernetes cluster, can have really clear knowledge
of how their applications are operating.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>virt-manager missing pci.ids usb.ids macos</title>
          <pubDate>Mon, 15 Jun 2020 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2020-06-15-virt-manager-missing-pci-ids-usb-ids-macos/</link>
          <guid>https://fy.blackhats.net.au/blog/2020-06-15-virt-manager-missing-pci-ids-usb-ids-macos/</guid>
          <description>&lt;h1 id=&quot;virt-manager-missing-pci-ids-usb-ids-macos&quot;&gt;virt-manager missing pci.ids usb.ids macos&lt;&#x2F;h1&gt;
&lt;p&gt;I got the following error:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;usr&#x2F;local&#x2F;Cellar&#x2F;libosinfo&#x2F;1.8.0&#x2F;share&#x2F;libosinfo&#x2F;pci.ids No such file or directory
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This appears to be an issue in libosinfo from homebrew. Looking at the
libosinfo source, there are some aux download files. You can fix this
with:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;mkdir -p &#x2F;usr&#x2F;local&#x2F;Cellar&#x2F;libosinfo&#x2F;1.8.0&#x2F;share&#x2F;libosinfo&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;cd &#x2F;usr&#x2F;local&#x2F;Cellar&#x2F;libosinfo&#x2F;1.8.0&#x2F;share&#x2F;libosinfo&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;wget -q -O pci.ids http:&#x2F;&#x2F;pciids.sourceforge.net&#x2F;v2.2&#x2F;pci.ids
&lt;&#x2F;span&gt;&lt;span&gt;wget -q -O usb.ids http:&#x2F;&#x2F;www.linux-usb.org&#x2F;usb.ids
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;All is happy again with virt-manager&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Resolving AirPlayXPCHelper Perr NULL kCanceledErr with Apple TV and MacOS</title>
          <pubDate>Sun, 03 May 2020 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2020-05-03-resolving-airplayxpchelper-perr-null-kcancelederr-with-apple-tv-and-macos/</link>
          <guid>https://fy.blackhats.net.au/blog/2020-05-03-resolving-airplayxpchelper-perr-null-kcancelederr-with-apple-tv-and-macos/</guid>
          <description>&lt;h1 id=&quot;resolving-airplayxpchelper-perr-null-kcancelederr-with-apple-tv-and-macos&quot;&gt;Resolving AirPlayXPCHelper Perr NULL kCanceledErr with Apple TV and MacOS&lt;&#x2F;h1&gt;
&lt;p&gt;I decided to finally get an Apple TV so that I could use my iPad and
MacBook Pro to airplay to my projector. So far I&#x27;ve been really
impressed by it and how well it works with modern amplifiers and my
iPad.&lt;&#x2F;p&gt;
&lt;p&gt;Sadly though, when I tried to use my MacBook pro to airplay to the Apple
TV I recieved an &amp;quot;Unable to connect&amp;quot; error, with no further
description.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;initial-research&quot;&gt;Initial Research&lt;&#x2F;h2&gt;
&lt;p&gt;The first step was to look in console.app at the local system logs. The
following item stood out:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;error 09:24:41.459722+1000 AirPlayXPCHelper ### Error: CID 0xACF10006, Peer NULL, -6723&#x2F;0xFFFFE5BD kCanceledErr
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;I only found a single result on a search for this, and they resolved the
problem by disabling their MacOS firewall - attempting this myself did
not fix the issue. There are also reports of apple service staff
disabling the firewall to resolve airplay problems too.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;time-to-dig-further&quot;&gt;Time to Dig Further ...&lt;&#x2F;h2&gt;
&lt;p&gt;Now it was time to look more. To debug an Apple TV you need to connect a
USB-C cable to it&#x27;s service port on the rear of the device, while you
connect this to a Mac on the other side. Console.app will then show you
the streamed logs from the device.&lt;&#x2F;p&gt;
&lt;p&gt;While looking on the Apple TV I noticed the following log item:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;[AirPlay] ### [0x8F37] Set up session 16845584210140482044 with [&amp;lt;ipv6 address&amp;gt;:3378]:52762 failed: 61&#x2F;0x3D ECONNREFUSED {
&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;timingProtocol&amp;quot; : &amp;quot;NTP&amp;quot;,
&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;osName&amp;quot; : &amp;quot;Mac OS X&amp;quot;,
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;isScreenMirroringSession&amp;quot; : true,
&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;osVersion&amp;quot; : &amp;quot;10.15.4&amp;quot;,
&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;timingPort&amp;quot; : 64880,
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;I have trimmed this log, as most details don&#x27;t matter. What is
important is that it looks like the Apple TV is attempting to
back-connect to the MacBook Pro, which has a connection refused. From
iOS it appears that the video&#x2F;timing channel is initiated from the iOS
device, so no back-connection is required, but for AirPlay to work from
the MacBook Pro to the Apple TV, the Apple TV must be able to connect
back on high ports with new UDP&#x2F;TCP sessions for NTP to synchronise
clocks.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;my-network&quot;&gt;My Network&lt;&#x2F;h2&gt;
&lt;p&gt;My MacBook pro is on a seperate VLAN to my Apple TV for security
reasons, mainly because I don&#x27;t want most devices to access management
consoles of various software that I have installed. I have used the
Avahi reflector on my USG to enable cross VLAN discovery. This would
appear to be issue, is that my firewall is not allowing the NTP traffic
back to my MacBook pro.&lt;&#x2F;p&gt;
&lt;p&gt;To resolve this I allowed some high ports from the Apple TV to connect
back to the VLAN my MacBook Pro is on, and I allowed built-in software
to recieve connections.&lt;&#x2F;p&gt;
&lt;p&gt;Once this was done, I was able to AirPlay across VLANs to my Apple TV!&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Building containers on OBS</title>
          <pubDate>Mon, 20 Apr 2020 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2020-04-20-building-containers-on-obs/</link>
          <guid>https://fy.blackhats.net.au/blog/2020-04-20-building-containers-on-obs/</guid>
          <description>&lt;h1 id=&quot;building-containers-on-obs&quot;&gt;Building containers on OBS&lt;&#x2F;h1&gt;
&lt;p&gt;My friend showed me how to build containers in OBS, the opensuse build
service. It makes it really quite nice, as the service can parse your
dockerfile, and automatically trigger rebuilds when any package
dependency in the chain requires a rebuild.&lt;&#x2F;p&gt;
&lt;p&gt;The simplest way is to have a seperate project for your containers to
make the repository setup a little easier.&lt;&#x2F;p&gt;
&lt;p&gt;When you edit the project metadata, if the project doesn&#x27;t already
exist, a new one is created. So we can start by filling out the template
from the command:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;osc meta prj -e home:firstyear:containers
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This will give you a template: We need to add some repository lines:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&amp;lt;project name=&amp;quot;home:firstyear:apps&amp;quot;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;  &amp;lt;title&amp;gt;Containers Demo&amp;lt;&#x2F;title&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;  &amp;lt;description&amp;gt;Containers Demo&amp;lt;&#x2F;description&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;  &amp;lt;person userid=&amp;quot;firstyear&amp;quot; role=&amp;quot;bugowner&amp;quot;&#x2F;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;  &amp;lt;person userid=&amp;quot;firstyear&amp;quot; role=&amp;quot;maintainer&amp;quot;&#x2F;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;  &amp;lt;build&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;lt;enable&#x2F;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;  &amp;lt;&#x2F;build&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;  &amp;lt;publish&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;lt;enable&#x2F;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;  &amp;lt;&#x2F;publish&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;  &amp;lt;debuginfo&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;lt;enable&#x2F;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;  &amp;lt;&#x2F;debuginfo&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;  &amp;lt;!-- this repository --&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;  &amp;lt;repository name=&amp;quot;containers&amp;quot;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;lt;path project=&amp;quot;openSUSE:Templates:Images:Tumbleweed&amp;quot; repository=&amp;quot;containers&amp;quot;&#x2F;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;lt;arch&amp;gt;x86_64&amp;lt;&#x2F;arch&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;  &amp;lt;&#x2F;repository&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&#x2F;project&amp;gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Remember, to set the publist to &amp;quot;enable&amp;quot; if you want the docker images
you build to be pushed to the registry!&lt;&#x2F;p&gt;
&lt;p&gt;Now that that&#x27;s done, we can check out the project, and create a new
container package within.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;osc co home:firstyear:containers
&lt;&#x2F;span&gt;&lt;span&gt;cd home:firstyear:containers
&lt;&#x2F;span&gt;&lt;span&gt;osc mkpac mycontainer
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now in the mycontainer folder you can start to build a container. Add
your dockerfile:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;#!BuildTag: mycontainer
&lt;&#x2F;span&gt;&lt;span&gt;#
&lt;&#x2F;span&gt;&lt;span&gt;# docker pull registry.opensuse.org&#x2F;home&#x2F;firstyear&#x2F;apps&#x2F;containers&#x2F;mycontainer:latest
&lt;&#x2F;span&gt;&lt;span&gt;#                                   ^projectname        ^repos     ^ build tag
&lt;&#x2F;span&gt;&lt;span&gt;FROM opensuse&#x2F;tumbleweed:latest
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;#
&lt;&#x2F;span&gt;&lt;span&gt;# only one zypper ar command per line. only repositories inside the OBS are allowed
&lt;&#x2F;span&gt;&lt;span&gt;#
&lt;&#x2F;span&gt;&lt;span&gt;RUN zypper ar http:&#x2F;&#x2F;download.opensuse.org&#x2F;repositories&#x2F;home:firstyear:apps&#x2F;openSUSE_Tumbleweed&#x2F; &amp;quot;home:firstyear:apps&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;RUN zypper mr -p 97 &amp;quot;home:firstyear:apps&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;RUN zypper --gpg-auto-import-keys ref
&lt;&#x2F;span&gt;&lt;span&gt;RUN zypper install -y vim-data vim python3-ipython shadow python3-praw
&lt;&#x2F;span&gt;&lt;span&gt;# Then the rest of your container as per usual ...
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Then to finish up, you can commit this:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;osc add Dockerfile
&lt;&#x2F;span&gt;&lt;span&gt;osc ci
&lt;&#x2F;span&gt;&lt;span&gt;osc results
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
</description>
      </item>
      <item>
          <title>389ds in containers</title>
          <pubDate>Sat, 28 Mar 2020 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2020-03-28-389ds-in-containers/</link>
          <guid>https://fy.blackhats.net.au/blog/2020-03-28-389ds-in-containers/</guid>
          <description>&lt;h1 id=&quot;389ds-in-containers&quot;&gt;389ds in containers&lt;&#x2F;h1&gt;
&lt;p&gt;I&#x27;ve spent a number of years working in the background to get 389-ds
working in containers. I think it&#x27;s very close to production ready
(&lt;a href=&quot;https:&#x2F;&#x2F;pagure.io&#x2F;389-ds-base&#x2F;issue&#x2F;50989&quot;&gt;one issue outstanding!&lt;&#x2F;a&gt;)
and I&#x27;m now using it at home for my production LDAP needs.&lt;&#x2F;p&gt;
&lt;p&gt;So here&#x27;s a run down on using 389ds in a container!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;getting-it-started&quot;&gt;Getting it Started&lt;&#x2F;h2&gt;
&lt;p&gt;The team provides an image for pre-release testing which you can get
with docker pull:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;docker pull 389ds&#x2F;dirsrv:latest
&lt;&#x2F;span&gt;&lt;span&gt;# OR, if you want to be pinned to the 1.4 release series.
&lt;&#x2F;span&gt;&lt;span&gt;docker pull 389ds&#x2F;dirsrv:1.4
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The image can be run in an ephemeral mode (data will be lost on stop of
the container) so you can test it:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;docker run 389ds&#x2F;dirsrv:1.4
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;making-it-persistent&quot;&gt;Making it Persistent&lt;&#x2F;h2&gt;
&lt;p&gt;To make your data persistent, you&#x27;ll need to add a volume, and bind it
to the container.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;docker volume create 389ds
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You can run 389ds where the container instance is removed each time the
container stops, but the data persists (I promise this is safe!) with:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;docker run --rm -v 389ds:&#x2F;data -p 3636:3636 389ds&#x2F;dirsrv:latest
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Check your instance is working with an ldapsearch:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;LDAPTLS_REQCERT=never ldapsearch -H ldaps:&#x2F;&#x2F;127.0.0.1:3636 -x -b &amp;#39;&amp;#39; -s base vendorVersion
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&lt;em&gt;NOTE: Setting the environment variable `LDAPTLS_REQCERT` to `never`
disables CA verification of the LDAPS connection. Only use this in
testing environments!&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;If you want to make the container instance permanent (uses docker
start&#x2F;stop&#x2F;restart etc) then you&#x27;ll need to do a docker create with
similar arguments:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;docker create  -v 389ds:&#x2F;data -p 3636:3636 389ds&#x2F;dirsrv:latest
&lt;&#x2F;span&gt;&lt;span&gt;docker ps -a
&lt;&#x2F;span&gt;&lt;span&gt;CONTAINER ID        IMAGE                 ...  NAMES
&lt;&#x2F;span&gt;&lt;span&gt;89b342c2e058        389ds&#x2F;dirsrv:latest   ...  adoring_bartik
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Remember, even if you rm the container instance, the volume stores all
the data so you can re-pull the image and recreate the container and
continue.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;administering-the-instance&quot;&gt;Administering the Instance&lt;&#x2F;h2&gt;
&lt;p&gt;The best way is to the use the local LDAPI socket - by default the
cn=Directory Manager password is randomised so that it can&#x27;t be
accessed remotely.&lt;&#x2F;p&gt;
&lt;p&gt;To use the local LDAPI socket, you&#x27;ll use docker exec into the running
instance.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;docker start &amp;lt;container name&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;docker exec -i -t &amp;lt;container name&amp;gt; &#x2F;usr&#x2F;sbin&#x2F;dsconf localhost &amp;lt;cmd&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;docker exec -i -t &amp;lt;container name&amp;gt; &#x2F;usr&#x2F;sbin&#x2F;dsconf localhost backend suffix list
&lt;&#x2F;span&gt;&lt;span&gt;No backends
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;In a container, the instance is always named &amp;quot;localhost&amp;quot;. So lets add
a database backend now to our instance:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;docker exec -i -t &amp;lt;cn&amp;gt; &#x2F;usr&#x2F;sbin&#x2F;dsconf localhost backend create --suffix dc=example,dc=com --be-name userRoot
&lt;&#x2F;span&gt;&lt;span&gt;The database was sucessfully created
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You can even go ahead and populate your backend now. To make it easier,
specify your basedn into the volume&#x27;s &#x2F;data&#x2F;config&#x2F;container.inf. Once
that&#x27;s done we can setup sample data (including access controls), and
create some users and groups.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;docker exec -i -t &amp;lt;cn&amp;gt; &#x2F;bin&#x2F;sh -c &amp;quot;echo -e &amp;#39;\nbasedn = dc=example,dc=com&amp;#39; &amp;gt;&amp;gt; &#x2F;data&#x2F;config&#x2F;container.inf&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;docker exec -i -t &amp;lt;cn&amp;gt; &#x2F;usr&#x2F;sbin&#x2F;dsidm localhost initialise
&lt;&#x2F;span&gt;&lt;span&gt;docker exec -i -t &amp;lt;cn&amp;gt; &#x2F;usr&#x2F;sbin&#x2F;dsidm localhost user create --uid william --cn william \
&lt;&#x2F;span&gt;&lt;span&gt;    --displayName William --uidNumber 1000 --gidNumber 1000 --homeDirectory &#x2F;home&#x2F;william
&lt;&#x2F;span&gt;&lt;span&gt;docker exec -i -t &amp;lt;cn&amp;gt; &#x2F;usr&#x2F;sbin&#x2F;dsidm localhost group create --cn test_group
&lt;&#x2F;span&gt;&lt;span&gt;docker exec -i -t &amp;lt;cn&amp;gt; &#x2F;usr&#x2F;sbin&#x2F;dsidm localhost group add_member test_group uid=william,ou=people,dc=example,dc=com
&lt;&#x2F;span&gt;&lt;span&gt;docker exec -i -t &amp;lt;cn&amp;gt; &#x2F;usr&#x2F;sbin&#x2F;dsidm localhost account reset_password uid=william,ou=people,dc=example,dc=com
&lt;&#x2F;span&gt;&lt;span&gt;LDAPTLS_REQCERT=never ldapwhoami -H ldaps:&#x2F;&#x2F;127.0.0.1:3636 -x -D uid=william,ou=people,dc=example,dc=com -W
&lt;&#x2F;span&gt;&lt;span&gt;    Enter LDAP Password:
&lt;&#x2F;span&gt;&lt;span&gt;    dn: uid=william,ou=people,dc=example,dc=com
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;There is much more you can do with these tools of course, but it&#x27;s very
easy to get started and working with an ldap server like this.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;further-configuration&quot;&gt;Further Configuration&lt;&#x2F;h2&gt;
&lt;p&gt;Because this runs in a container, the approach to some configuration is
a bit different. Some settings can be configured through either the
content of the volume, or through environment variables.&lt;&#x2F;p&gt;
&lt;p&gt;You can reset the directory manager password on startup but use the
environment variable DS_DM_PASSWORD. Of course, please use a better
password than &amp;quot;password&amp;quot;. pwgen is a good tool for this! This password
persists across restarts, so you should make sure it&#x27;s good.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;docker run --rm -e DS_DM_PASSWORD=password -v 389ds:&#x2F;data -p 3636:3636 389ds&#x2F;dirsrv:latest
&lt;&#x2F;span&gt;&lt;span&gt;LDAPTLS_REQCERT=never ldapwhoami -H ldaps:&#x2F;&#x2F;127.0.0.1:3636 -x -D &amp;#39;cn=Directory Manager&amp;#39; -w password
&lt;&#x2F;span&gt;&lt;span&gt;    dn: cn=directory manager
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You can also configure certificates through pem files.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;data&#x2F;tls&#x2F;server.key
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;data&#x2F;tls&#x2F;server.crt
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;data&#x2F;tls&#x2F;ca&#x2F;*.crt
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;All the certs in &#x2F;data&#x2F;tls&#x2F;ca&#x2F; will be imported as CA&#x27;s and the server
key and crt will be used for the TLS server.&lt;&#x2F;p&gt;
&lt;p&gt;If for some reason you need to reindex your db at startup, you can use:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;docker run --rm -e DS_REINDEX=true -v 389ds:&#x2F;data -p 3636:3636 389ds&#x2F;dirsrv:latest
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;After the reindex is complete the instance will start like normal.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;&#x2F;h2&gt;
&lt;p&gt;389ds in a container is one of the easiest and quickest ways to get a
working LDAP environment today. Please test it and let us know what you
think!&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>APFS (why is df showing me funny numbers?!)</title>
          <pubDate>Sat, 28 Mar 2020 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2020-03-28-apfs-why-is-df-showing-me-funny-numbers/</link>
          <guid>https://fy.blackhats.net.au/blog/2020-03-28-apfs-why-is-df-showing-me-funny-numbers/</guid>
          <description>&lt;h1 id=&quot;apfs-why-is-df-showing-me-funny-numbers&quot;&gt;APFS (why is df showing me funny numbers?!)&lt;&#x2F;h1&gt;
&lt;p&gt;Apple&#x27;s APFS has been the default for MacOS since High Sierra, where
SSD (flash) automatically would convert from HFS+. This is a god send,
especially with HFS+&#x27;s history of destroying any folder that has a
large number of inodes within it.&lt;&#x2F;p&gt;
&lt;p&gt;However, APFS behaves differently to previous filesystem technology.
Let&#x27;s see if we can explain why df reports multiple 932Gi disks like
this:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&amp;gt; df -h
&lt;&#x2F;span&gt;&lt;span&gt;Filesystem                             Size   Used  Avail Capacity    iused      ifree %iused  Mounted on
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;dev&#x2F;disk1s5                          932Gi   10Gi  380Gi     3%     484322 9767493838    0%   &#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;dev&#x2F;disk1s1                          932Gi  530Gi  380Gi    59%    2072480 9765905680    0%   &#x2F;System&#x2F;Volumes&#x2F;Data
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;And if we can explain why when you delete large files, you don&#x27;t get
any space back from df either.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;how-it-looked-with-hfs&quot;&gt;How it looked with HFS+&lt;&#x2F;h2&gt;
&lt;p&gt;With HFS+ it was pretty simple. You had a disk (a block device), which
had partitions (slices of the space in the block device) and those
partitions were formatted with a filesystem that knew how to store data
in them. An example:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&amp;gt; diskutil list
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;dev&#x2F;disk2 (external, physical):
&lt;&#x2F;span&gt;&lt;span&gt;   #:                       TYPE NAME                    SIZE       IDENTIFIER
&lt;&#x2F;span&gt;&lt;span&gt;   0:      GUID_partition_scheme                         *1.0 TB     disk2
&lt;&#x2F;span&gt;&lt;span&gt;   1:                        EFI EFI                     209.7 MB   disk2s1
&lt;&#x2F;span&gt;&lt;span&gt;   2:                  Apple_HFS tmachine                999.9 GB   disk2s2
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;We can see that disk2 is 1.0TB in size, and it contains two partitions,
the first is 209.7MB for EFI (disk2s1) and the second has data and
formatted as HFS+ (disk2s2).&lt;&#x2F;p&gt;
&lt;p&gt;Of course, this has some drawbacks - partitions don&#x27;t like being moved,
and filesystem resizing is a costly process of time and IO cycles. It&#x27;s
quite inflexible. If you wanted another partition here for read only
data, well, you&#x27;d have to change a lot. Properties can only be applied
to a filesystem as a whole, and they can&#x27;t share space. If you had a
1TB drive partitioned to 500GB each, and were running low on space on
one of them, well ... good luck! You have to move data manually, or
change where applications store data.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;apfs&quot;&gt;APFS&lt;&#x2F;h2&gt;
&lt;p&gt;APFS doesn&#x27;t quite follow this model though. APFS is what&#x27;s called a
volume based filesystem. That means there is an intermediate layer in
here. The layout looks like this in diskutil&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&amp;gt; diskutil list
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;dev&#x2F;disk0 (internal, physical):
&lt;&#x2F;span&gt;&lt;span&gt;   #:                       TYPE NAME                    SIZE       IDENTIFIER
&lt;&#x2F;span&gt;&lt;span&gt;   0:      GUID_partition_scheme                        *1.0 TB     disk0
&lt;&#x2F;span&gt;&lt;span&gt;   1:                        EFI EFI                     314.6 MB   disk0s1
&lt;&#x2F;span&gt;&lt;span&gt;   2:                 Apple_APFS Container disk1         1.0 TB     disk0s2
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;So our disk0 looks like before - an EFI partition, and a very large APFS
container. However the container itself is NOT the filesystem. The
contain is a pool of storage that APFS volumes are created into. We can
see the volumes too.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&amp;gt; diskutil list
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;dev&#x2F;disk1 (synthesized):
&lt;&#x2F;span&gt;&lt;span&gt;   #:                       TYPE NAME                    SIZE       IDENTIFIER
&lt;&#x2F;span&gt;&lt;span&gt;   0:      APFS Container Scheme -                      +1.0 TB     disk1
&lt;&#x2F;span&gt;&lt;span&gt;                                 Physical Store disk0s2
&lt;&#x2F;span&gt;&lt;span&gt;   1:                APFS Volume Macintosh HD — Data     569.4 GB   disk1s1
&lt;&#x2F;span&gt;&lt;span&gt;   2:                APFS Volume Preboot                 81.8 MB    disk1s2
&lt;&#x2F;span&gt;&lt;span&gt;   3:                APFS Volume Recovery                526.6 MB   disk1s3
&lt;&#x2F;span&gt;&lt;span&gt;   4:                APFS Volume VM                      10.8 GB    disk1s4
&lt;&#x2F;span&gt;&lt;span&gt;   5:                APFS Volume Macintosh HD            11.0 GB    disk1s5
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Notice how &#x2F;dev&#x2F;disk1 is &amp;quot;synthesized&amp;quot;? It&#x27;s not real - it&#x27;s there
to &amp;quot;trick&amp;quot; legacy tools into thinking that the container is a
&amp;quot;block&amp;quot; device and the volumes are &amp;quot;partitions&amp;quot;.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;benefits-of-volumes&quot;&gt;Benefits of Volumes&lt;&#x2F;h2&gt;
&lt;p&gt;One of the immediate benefits is that unlike partitions, in a volume
filesystem, &lt;em&gt;all&lt;&#x2F;em&gt; the space of the underlying container (also known as:
pool, volume group) is available to &lt;em&gt;all&lt;&#x2F;em&gt; volumes at anytime. Because
the volumes are a flexible concept, they can have non-contiguous
geometry on the disk (unlike a partition). That&#x27;s why in your df output
you can see:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&amp;gt; df -h
&lt;&#x2F;span&gt;&lt;span&gt;Filesystem                             Size   Used  Avail Capacity    iused      ifree %iused  Mounted on
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;dev&#x2F;disk1s5                          932Gi   10Gi  380Gi     3%     484322 9767493838    0%   &#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;dev&#x2F;disk1s1                          932Gi  530Gi  380Gi    59%    2072480 9765905680    0%   &#x2F;System&#x2F;Volumes&#x2F;Data
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Both disk1s5 (Macintosh HD) and disk1s1 (Macintosh HD --- Data) are APFS
volumes. The container has 932Gi total space, and 380Gi available in the
container which either volume could allocate. But you can also see the
exact space reservation of each volume too: disk1s5 only has 10Gi in
use, and disk1s1 has 530Gi in use.&lt;&#x2F;p&gt;
&lt;p&gt;It would be very possible for disk1s1 to grow to fill all the space, and
then to contract, and then have disk1s5 grow to take all the space and
contract - this is because the space is flexibly allocated from the
container. Neat!&lt;&#x2F;p&gt;
&lt;p&gt;Each volume also can have different properties applied. For example,
&#x2F;dev&#x2F;disk1s5 (Macintosh HD) in MacOS catalina is read-only:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;dev&#x2F;disk1s5 on &#x2F; (apfs, local, read-only, journaled)
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;dev&#x2F;disk1s1 on &#x2F;System&#x2F;Volumes&#x2F;Data (apfs, local, journaled, nobrowse)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This is to prevent system tampering, and strengthen integrity of the
system. There are a number of tricks to achieve this such as overlaying
multiple volumes together. &#x2F;Applications for example is actually a
folder consitituted from the content of &#x2F;System&#x2F;Applications and
&#x2F;System&#x2F;Volumes&#x2F;Data&#x2F;Applications. Anytime you &amp;quot;drag&amp;quot; and application
to &#x2F;Applications, you are actually putting it into
&#x2F;System&#x2F;Volumes&#x2F;Data&#x2F;Applications. A very similar property holds for
&#x2F;Users (&#x2F;System&#x2F;Volumes&#x2F;Data&#x2F;Users), and even &#x2F;Volumes.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;copy-on-write-snapshots&quot;&gt;Copy-on-Write, Snapshots&lt;&#x2F;h2&gt;
&lt;p&gt;APFS is also a copy-on-write filesystem. This means whenever you write
data, it&#x27;s actually written to newly allocated disk regions, and the
pointers are atomicly flipped to it. The full write occurs or it does
not. This is part of the reason why APFS is so much better than HFS+ -
in a crash your data is either in a previous state, or the new state -
never a half written or corrupted state.&lt;&#x2F;p&gt;
&lt;p&gt;This is the reason why APFS is only used on SSD (flash) devices - COW is
very random IO write intensive, and on a rotational disk this would
cause the head to &amp;quot;seek&amp;quot; randomly which would make both writes and
reads very slow. SSD of course isn&#x27;t affected by this, so having a
highly fragmented file does not impose a penalty in the same way.&lt;&#x2F;p&gt;
&lt;p&gt;Copy-on-Write however opens up some interesting behaviours. If you COW a
file, but never remove the old version, you have a &lt;em&gt;snapshot&lt;&#x2F;em&gt;. This
means you can have point-in-time views to how a filesystem was. This is
actually used now by time machine during backups to ensure the content
of a backup is stable before being written to the external backup media.
It also allow time machine to perform &amp;quot;backups&amp;quot; while you are
out-and-about, by snapshotting as you work. Because snapshots are just
&amp;quot;not removing old data&amp;quot; they are low overhead to maintain and take
snapshots.&lt;&#x2F;p&gt;
&lt;p&gt;You can see snapshots on your system with:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&amp;gt; tmutil listlocalsnapshots &#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;Snapshots for volume group containing disk &#x2F;:
&lt;&#x2F;span&gt;&lt;span&gt;com.apple.TimeMachine.2020-03-27-084939.local
&lt;&#x2F;span&gt;&lt;span&gt;com.apple.TimeMachine.2020-03-27-100157.local
&lt;&#x2F;span&gt;&lt;span&gt;com.apple.TimeMachine.2020-03-27-105937.local
&lt;&#x2F;span&gt;&lt;span&gt;com.apple.TimeMachine.2020-03-27-121414.local
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You can even take your own snapshots if you want!&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&amp;gt; time tmutil localsnapshot
&lt;&#x2F;span&gt;&lt;span&gt;Created local snapshot with date: 2020-03-28-091943
&lt;&#x2F;span&gt;&lt;span&gt;tmutil localsnapshot  0.01s user 0.01s system 4% cpu 0.439 total
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;See how fast that is! Remember also because this is based on
copy-on-write, the snapshots only take as much data as the
&lt;em&gt;differences&lt;&#x2F;em&gt;, or what you are changing as you work.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;space-reclaim&quot;&gt;Space Reclaim&lt;&#x2F;h2&gt;
&lt;p&gt;This leads to the final point of confusion - when people delete files to
clear space, but df reports no change. For example:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&amp;gt; df -h
&lt;&#x2F;span&gt;&lt;span&gt;Filesystem                             Size   Used  Avail Capacity    iused      ifree %iused  Mounted on
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;dev&#x2F;disk1s1                          932Gi  530Gi  380Gi    59%    2072480 9765905680    0%   &#x2F;System&#x2F;Volumes&#x2F;Data
&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt; ls -alh Downloads&#x2F;Windows_Server_2016_Datacenter_EVAL_en-us_14393_refresh.ISO
&lt;&#x2F;span&gt;&lt;span&gt;-rwx------@ 1 william  staff   6.5G 10 Oct  2018 Downloads&#x2F;Windows_Server_2016_Datacenter_EVAL_en-us_14393_refresh.ISO
&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt; rm Downloads&#x2F;Windows_Server_2016_Datacenter_EVAL_en-us_14393_refresh.ISO
&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt; df -h
&lt;&#x2F;span&gt;&lt;span&gt;Filesystem                             Size   Used  Avail Capacity    iused      ifree %iused  Mounted on
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;dev&#x2F;disk1s1                          932Gi  530Gi  380Gi    59%    2072479 9765905681    0%   &#x2F;System&#x2F;Volumes&#x2F;Data
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now I promise, I really did delete the file - check the &amp;quot;iused&amp;quot; and
&amp;quot;ifree&amp;quot; columns. But also note that the &amp;quot;Used&amp;quot; space didn&#x27;t change?
Surely we should expect to see this value drop to 523Gi since I removed
a 6.5G file.&lt;&#x2F;p&gt;
&lt;p&gt;Remember that APFS is a voluming filesystem, with copy-on-write. Due to
snapshots, the space used in a volume is the sum of active data &lt;em&gt;and&lt;&#x2F;em&gt;
snapshotted data. This means that when you are removing a file you are
removing it from the volume at this point in time, but it may still
exist in snapshots that exist in the volume! That&#x27;s why there is a
reduction in the iused&#x2F;ifree (an inode pointer was removed) but no
change in the space (the file still exists in a snapshot).&lt;&#x2F;p&gt;
&lt;p&gt;During normal operation, provided there is sufficent freespace, you
won&#x27;t actually notice this behaviour. But when you say ... have not a
lot of space left (maybe 10G), and you delete some files to import
something (say a 40G import), you try the copy again ... and it fails!
Drat! But you wait a bit and suddenly it works? What in heck happened?&lt;&#x2F;p&gt;
&lt;p&gt;In the background, MacOS has registered &amp;quot;okay, the user demands at
least 30G more space to complete this task. Let&#x27;s clean snapshots until
we have that much space available&amp;quot;. The snapshots are pruned so when
you come back later, suddenly you have the space.&lt;&#x2F;p&gt;
&lt;p&gt;Again, you can actually do this yourself. tmutil has a command
&amp;quot;thinlocalsnapshots&amp;quot; for this. An example usage would be:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&amp;gt; tmutil thinlocalsnapshots &#x2F;System&#x2F;Volumes&#x2F;Data [bytes required]
&lt;&#x2F;span&gt;&lt;span&gt;Thinned local snapshots:
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;In my case I have a lot of space available, so no snapshots are pruned.
But you may find that multiple snapshots are removed in this process!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;&#x2F;h2&gt;
&lt;p&gt;APFS is actually a really cool piece of filesystem technology, and I
think has made MacOS one of the most viable platforms for reliable daily
use. It embraces many great ideas, and despite it&#x27;s youth, has done
really well. But those new ideas conflict with legacy, and have some
behaviours that are not always clearly exposed on shown to you, the
user. Understanding those behaviours means we can see &lt;em&gt;why&lt;&#x2F;em&gt; our
computers are behaving in certain - sometimes unexpected - ways.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>USG fixing avahi</title>
          <pubDate>Sun, 15 Mar 2020 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2020-03-15-usg-fixing-some-basic-issues/</link>
          <guid>https://fy.blackhats.net.au/blog/2020-03-15-usg-fixing-some-basic-issues/</guid>
          <description>&lt;h1 id=&quot;usg-fixing-avahi&quot;&gt;USG fixing avahi&lt;&#x2F;h1&gt;
&lt;p&gt;Sadly on the USG pro 4 avahi will regularly spiral out of control taking
up 100% cpu. To fix this, we set an hourly restart:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;sudo -s
&lt;&#x2F;span&gt;&lt;span&gt;crontab -e
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Then add:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;15 * * * * &#x2F;usr&#x2F;sbin&#x2F;service avahi-daemon restart
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
</description>
      </item>
      <item>
          <title>Fedora 32 Wallpaper Submission - Story</title>
          <pubDate>Sat, 14 Mar 2020 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2020-03-14-fedora-32-wallpaper-submission-story/</link>
          <guid>https://fy.blackhats.net.au/blog/2020-03-14-fedora-32-wallpaper-submission-story/</guid>
          <description>&lt;h1 id=&quot;fedora-32-wallpaper-submission-story&quot;&gt;Fedora 32 Wallpaper Submission - Story&lt;&#x2F;h1&gt;
&lt;p&gt;Fedora opens submissions for
&lt;a href=&quot;https:&#x2F;&#x2F;apps.fedoraproject.org&#x2F;nuancier&#x2F;contribute&#x2F;&quot;&gt;wallpapers&lt;&#x2F;a&gt; to be
submitted for the next version of the release. I used fedora for a long
time, so I decided to submit this photo, and write this post to talk
about it:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;20191119_184819_DSCF0043_5.jpg&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;This was takeing on 2019-11-19 in my home city of Adelaide, South
Australia. I had traveled to see some friends over Christmas. We went to
&lt;a href=&quot;https:&#x2F;&#x2F;www.google.com&#x2F;maps&#x2F;@-34.9656653,138.6670176,14.51z&quot;&gt;Mount
Osmond&lt;&#x2F;a&gt; to
take some photos, and I took this as we walked up to the lookout.&lt;&#x2F;p&gt;
&lt;p&gt;The next day, this area was a high risk location for a possible
bushfire - and many bushfires have since devastated many regions of
Australia, affecting many people that I know.&lt;&#x2F;p&gt;
&lt;p&gt;I really find that the Australian landscape is so different to Europe or
Asia - many tones of subtle reds, browns, and more. A dry and dusty
look. The palette is such a contrast to the lush greens of Europe.
Australia is a really beautiful country, in a very distinct and striking
manner.&lt;&#x2F;p&gt;
&lt;p&gt;Anyway, I hope you like the photo :)&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Fixing a MacBook Pro 8,2 with dead AMD GPU</title>
          <pubDate>Tue, 04 Feb 2020 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2020-02-04-fixing-a-macbook-pro-8-2-with-dead-amd-gpu/</link>
          <guid>https://fy.blackhats.net.au/blog/2020-02-04-fixing-a-macbook-pro-8-2-with-dead-amd-gpu/</guid>
          <description>&lt;h1 id=&quot;fixing-a-macbook-pro-8-2-with-dead-amd-gpu&quot;&gt;Fixing a MacBook Pro 8,2 with dead AMD GPU&lt;&#x2F;h1&gt;
&lt;p&gt;I&#x27;ve owned a MacBook Pro 8,2 late 2011 edition, which I used from 2011
to about 2018. It was a great piece of hardware, and honestly I&#x27;m
surprised it lasted so long given how many MacOS and Fedora installs
it&#x27;s seen.&lt;&#x2F;p&gt;
&lt;p&gt;I upgraded to a MacBook Pro 15,1, and I gave the 8,2 to a friend who was
in need of a new computer so she could do her work. It worked really
well for her until today when she&#x27;s messaged me that the machine is
having a problem.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-problem&quot;&gt;The Problem&lt;&#x2F;h2&gt;
&lt;p&gt;The machine appeared to be in a bootloop, where just before swapping
from the EFI GPU to the main display server, it would go black and then
lock up&#x2F;reboot. Booting to single user mode (boot holding cmd + s)
showed the machine&#x27;s disk was intact with a clean apfs. The system.log
showed corruption at the time of the fault, which didn&#x27;t instill
confidence in me.&lt;&#x2F;p&gt;
&lt;p&gt;Attempting a recovery boot (boot holding cmd + r), this also yielded the
bootloop. So we have potentially eliminated the installed copy of MacOS
as the source of the issue.&lt;&#x2F;p&gt;
&lt;p&gt;I&#x27;ve then used the apple hardware test (boot while holding d), and it
has passed the machine as a clear bill of health.&lt;&#x2F;p&gt;
&lt;p&gt;I have seen one of these machines give up in the past - my friends
mother had one from the same generation and that died in almost the same
way - could it be the same?&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-8-2-s-cursed-gpu-stack&quot;&gt;The 8,2&#x27;s cursed gpu stack&lt;&#x2F;h2&gt;
&lt;p&gt;The 8,2 15&amp;quot; mbp has dual gpu&#x27;s - it has the on cpu Intel 3000, and an
AMD radeon 6750M. The two pass through an LVDS graphics multiplexer to
the main panel. The external display port however is not so clear - the
DDC lines are passed through the GMUX, but the datalines directly attach
to the the display port.&lt;&#x2F;p&gt;
&lt;p&gt;The machine is also able to boot with EFI rendering to either card. By
default this is the AMD radeon. Which ever card is used at boot is also
the first card MacOS attempts to use, but it will try to swap to the
radeon later on.&lt;&#x2F;p&gt;
&lt;p&gt;This generation had a large number of the radeons develop faults in
their 3d rendering capability so it would render the EFI buffer
correctly, but on the initiation of 3d rendering it would fail. Sounds
like what we have here!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;to-fix-this&quot;&gt;To fix this ...&lt;&#x2F;h2&gt;
&lt;p&gt;Okay, so this is fixable. First, we need to tell EFI to boot primarily
from the intel card. Boot to single user mode and then run.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;nvram fa4ce28d-b62f-4c99-9cc3-6815686e30f9:gpu-power-prefs=%01%00%00%00
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now we need to prevent loading of the AMD drivers so that during the
boot MacOS doesn&#x27;t attempt to swap from Intel to the Radeon. We can do
this by hiding the drivers. System integrity protection will stop you,
so you need to do this as part of recovery. Boot with cmd + r, which now
works thanks to the EFI changes, then open terminal&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;cd &#x2F;Volumes&#x2F;Macintosh HD
&lt;&#x2F;span&gt;&lt;span&gt;sudo mkdir amdkext
&lt;&#x2F;span&gt;&lt;span&gt;sudo mv System&#x2F;Library&#x2F;Extensions&#x2F;AMDRadeonX3000.kext amdkext&#x2F;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Then reboot. You&#x27;ll notice the fans go crazy because the Radeon card
can&#x27;t be disabled without the driver. We can post-boot load the driver
to stop the fans to fix this up.&lt;&#x2F;p&gt;
&lt;p&gt;To achieve this we make a helper script:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# cat &#x2F;usr&#x2F;local&#x2F;libexec&#x2F;amd_kext_load.sh
&lt;&#x2F;span&gt;&lt;span&gt;#!&#x2F;bin&#x2F;sh
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;sbin&#x2F;kextload &#x2F;amdkext&#x2F;AMDRadeonX3000.kext
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;And a launchctl daemon&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# cat &#x2F;Library&#x2F;LaunchDaemons&#x2F;au.net.blackhats.fy.amdkext.plist
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;!DOCTYPE plist PUBLIC &amp;quot;-&#x2F;&#x2F;Apple&#x2F;&#x2F;DTD PLIST 1.0&#x2F;&#x2F;EN&amp;quot; &amp;quot;http:&#x2F;&#x2F;www.apple.com&#x2F;DTDs&#x2F;PropertyList-1.0.dtd&amp;quot;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;plist version=&amp;quot;1.0&amp;quot;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;lt;dict&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;                &amp;lt;key&amp;gt;Label&amp;lt;&#x2F;key&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;                &amp;lt;string&amp;gt;au.net.blackhats.fy.amdkext&amp;lt;&#x2F;string&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;                &amp;lt;key&amp;gt;Program&amp;lt;&#x2F;key&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;                &amp;lt;string&amp;gt;&#x2F;usr&#x2F;local&#x2F;libexec&#x2F;amd_kext_load.sh&amp;lt;&#x2F;string&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;                &amp;lt;key&amp;gt;RunAtLoad&amp;lt;&#x2F;key&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;                &amp;lt;true&#x2F;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;                &amp;lt;key&amp;gt;StandardOutPath&amp;lt;&#x2F;key&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;                &amp;lt;string&amp;gt;&#x2F;var&#x2F;log&#x2F;amd_kext_load.log&amp;lt;&#x2F;string&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;lt;&#x2F;dict&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&#x2F;plist&amp;gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now if you reboot, you&#x27;ll have a working mac, and the fans will stop
properly. I&#x27;ve tested this with suspend and resume too and it works!
The old beast continues to live :)&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>There are no root causes</title>
          <pubDate>Mon, 20 Jan 2020 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2020-01-20-there-are-no-root-causes/</link>
          <guid>https://fy.blackhats.net.au/blog/2020-01-20-there-are-no-root-causes/</guid>
          <description>&lt;h1 id=&quot;there-are-no-root-causes&quot;&gt;There are no root causes&lt;&#x2F;h1&gt;
&lt;p&gt;At Gold Coast LCA2020 I gave a &lt;a href=&quot;https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=eqQUepwTHjA&amp;amp;t=25m47s&quot;&gt;lightning talk on swiss
cheese&lt;&#x2F;a&gt;. Well,
maybe not really swiss cheese. But it was about the &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Swiss_cheese_model&quot;&gt;swiss cheese
failure model&lt;&#x2F;a&gt; which
was proposed at the university of manchester.&lt;&#x2F;p&gt;
&lt;p&gt;Please note this will cover some of the same topics as the talk, but in
more detail, and with less jokes.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;an-example-problem&quot;&gt;An example problem&lt;&#x2F;h2&gt;
&lt;p&gt;So we&#x27;ll discuss the current issues behind modern CPU isolation attacks
IE spectre. Spectre is an attack that uses timing of a CPU&#x27;s
speculative execution unit to retrieve information from another running
process on the same physical system.&lt;&#x2F;p&gt;
&lt;p&gt;Modern computers rely on hardware features in their CPU to isolate
programs from each other. This could be isolating your web-browser from
your slack client, or your sibling&#x27;s login from yours.&lt;&#x2F;p&gt;
&lt;p&gt;This isolation however has been compromised by attacks like Spectre, and
it looks unlikely that it can be resolved.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-is-speculative-execution&quot;&gt;What is speculative execution?&lt;&#x2F;h2&gt;
&lt;p&gt;In order to be &amp;quot;fast&amp;quot; modern CPU&#x27;s are far more complex than most of
us have been taught. Often we believe that a CPU thread&#x2F;core is
executing &amp;quot;one instruction&#x2F;operation&amp;quot; at a time. However this isn&#x27;t
how most CPU&#x27;s work. Most work by having a pipeline of instructions
that are in various stages of execution. You could imagine it like this:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;let mut x = 0
&lt;&#x2F;span&gt;&lt;span&gt;let mut y = 0
&lt;&#x2F;span&gt;&lt;span&gt;x = 15 * some_input;
&lt;&#x2F;span&gt;&lt;span&gt;y = 10 * other_input;
&lt;&#x2F;span&gt;&lt;span&gt;if x &amp;gt; y {
&lt;&#x2F;span&gt;&lt;span&gt;    return true;
&lt;&#x2F;span&gt;&lt;span&gt;} else {
&lt;&#x2F;span&gt;&lt;span&gt;    return false;
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This is some made up code, but in a CPU, every part of this could be in
the &amp;quot;pipeline&amp;quot; at once.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;let mut x = 0                   &amp;lt;&amp;lt;-- at the head of the queue and &amp;quot;further&amp;quot; along completion
&lt;&#x2F;span&gt;&lt;span&gt;let mut y = 0                   &amp;lt;&amp;lt;-- it&amp;#39;s executed part way, but not to completion
&lt;&#x2F;span&gt;&lt;span&gt;x = 15 * some_input;
&lt;&#x2F;span&gt;&lt;span&gt;y = 10 * other_input;           &amp;lt;&amp;lt;-- all of these are in pipeline, and partially complete
&lt;&#x2F;span&gt;&lt;span&gt;if x &amp;gt; y {                      &amp;lt;&amp;lt;-- what happens here?
&lt;&#x2F;span&gt;&lt;span&gt;    return true;
&lt;&#x2F;span&gt;&lt;span&gt;} else {
&lt;&#x2F;span&gt;&lt;span&gt;    return false;
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;So how does this &amp;quot;pipeline&amp;quot; handle the if statement? If the pipeline
is looking ahead, how can we handle a choice like an if? Can we really
predict the future?&lt;&#x2F;p&gt;
&lt;h2 id=&quot;speculative-execution&quot;&gt;Speculative execution&lt;&#x2F;h2&gt;
&lt;p&gt;At the if statement, the CPU uses past measurements to make a
&lt;em&gt;prediction&lt;&#x2F;em&gt; about which branch &lt;em&gt;might&lt;&#x2F;em&gt; be taken, and it then begins to
execute that path, even though &#x27;x &amp;gt; y&#x27; has not been executed or
completed yet! At this point x or y may not have even finished &lt;em&gt;being
computed&lt;&#x2F;em&gt; yet!&lt;&#x2F;p&gt;
&lt;p&gt;Let&#x27;s assume for now our branch predictor thinks that &#x27;x &amp;gt; y&#x27; is
false, so we&#x27;ll start to execute the &amp;quot;return false&amp;quot; or any other
content in that branch.&lt;&#x2F;p&gt;
&lt;p&gt;Now the instructions ahead catch up, and we resolve &amp;quot;did we really
predict correctly?&amp;quot;. If we did, great! We have been able to advance the
program state &lt;em&gt;asynchronously&lt;&#x2F;em&gt; even without knowing the answer until we
get there.&lt;&#x2F;p&gt;
&lt;p&gt;If not, ohh nooo. We have to unwind what we were doing, clear some of
the pipeline and try to do the correct branch.&lt;&#x2F;p&gt;
&lt;p&gt;Of course this has an impact on &lt;em&gt;timing&lt;&#x2F;em&gt; of the program. Some people
found you could write a program to manipulate this predictor and using
specific addresses and content, they could use these timing variations
to &amp;quot;access memory&amp;quot; they are not allowed to by letting the specualative
executor contribute to code they are not allowed to access before the
unroll occurs. They could time this, and retrieve the memory contents
from areas they are not allowed to access, breaking isolation.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;owwww-my-brain&quot;&gt;Owwww my brain&lt;&#x2F;h2&gt;
&lt;p&gt;Yes. Mine too.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;community-reactions&quot;&gt;Community Reactions&lt;&#x2F;h2&gt;
&lt;p&gt;Since this has been found, a large amount of the community reaction has
been about the &amp;quot;root cause&amp;quot;. &#x27;Clearly&#x27; the root cause is &amp;quot;Intel are
bad at making CPU&#x27;s&amp;quot; and so everyone should buy AMD instead because
they &amp;quot;weren&#x27;t affected quite as badly&amp;quot; (Narrators voice: &lt;a href=&quot;https:&#x2F;&#x2F;www.zdnet.com&#x2F;article&#x2F;amd-processors-from-2011-to-2019-vulnerable-to-two-new-attacks&#x2F;&quot;&gt;They were
absolutely just as
bad&lt;&#x2F;a&gt;).
We&#x27;ve had some intel CPU updates and kernel&#x2F;program fixes so all good
right? We addressed the root cause.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;or-did-we&quot;&gt;Or ... did we?&lt;&#x2F;h2&gt;
&lt;p&gt;Our computers are still asynchronous, and contain many out-of-order
parts. It&#x27;s hard to believe we have &amp;quot;found&amp;quot; every method of
exploiting this. Indeed in the last year many more ways to bypass
hardware isolation due to our systems async nature have been found.&lt;&#x2F;p&gt;
&lt;p&gt;Maybe the &amp;quot;root cause&amp;quot; wasn&#x27;t addressed. Maybe ... there are no
....&lt;&#x2F;p&gt;
&lt;h2 id=&quot;history&quot;&gt;History&lt;&#x2F;h2&gt;
&lt;p&gt;To understand how we got to this situation we need to look at how CPU&#x27;s
have evolved. This is not a complete history.&lt;&#x2F;p&gt;
&lt;p&gt;The PDP11 was a system owned at bell labs, where the C programing
language was developed. Back then CPU&#x27;s were very simple - A CPU and
memory, executing one instruction at a time.&lt;&#x2F;p&gt;
&lt;p&gt;The C programming language gained a lot of popularity as it was able to
be &amp;quot;quickly&amp;quot; ported to other CPU models to allow software to be
compiled on other platforms. This led to many systems being developed in
C.&lt;&#x2F;p&gt;
&lt;p&gt;Intel introduced the 8086, and many C programs were ported to run on it.
Intel then released the 80486 in 1989, which had the first pipeline and
cache to improve performance. In order to continue to support C, this
meant the memory model could not change from the PDP11 - the cache had
to be transparent, and the pipeline could not expose state.&lt;&#x2F;p&gt;
&lt;p&gt;This has of course led to computers being more important in our lives
and businesses, so we expected further performance, leading to increased
frequencies and async behaviours.&lt;&#x2F;p&gt;
&lt;p&gt;The limits of frequencies were really hit in the Pentium 4 era, when
about 4GHz was shown to be a barrier of stability for those systems.
They had very deep pipelines to improve performance, but that also had
issues when branch prediction failed causing pipeline stalls. Systems
had to improve their async behaviours &lt;em&gt;futher&lt;&#x2F;em&gt; to squeeze every single
piece of performance possible out.&lt;&#x2F;p&gt;
&lt;p&gt;Compiler developers also wanted more performance so they started to
develop ways to transform C in ways that &amp;quot;took advantage&amp;quot; of x86_64
tricks, by manipulating the environment so the CPU is &amp;quot;hinted&amp;quot; into
states we &amp;quot;hope&amp;quot; it gets into.&lt;&#x2F;p&gt;
&lt;p&gt;Many businesses also started to run servers to provide to consumers, and
in order to keep costs low they would put many users onto single pieces
of hardware so they could share or overcommit resources.&lt;&#x2F;p&gt;
&lt;p&gt;This has created a series of positive reinforcement loops - C is &#x27;abi
stable&#x27; so we keep developing it due to it&#x27;s universal nature. C code
can&#x27;t be changed without breaking every existing system. We can&#x27;t
change the CPU memory model without breaking C, which is hugely
prevalent. We improve the CPU to make C faster, transparently so that
users&#x2F;businesses can run more C programs and users. And then we improve
compilers to make C faster given quirks of the current CPU models that
exist ...&lt;&#x2F;p&gt;
&lt;h2 id=&quot;swiss-cheese-model&quot;&gt;Swiss cheese model&lt;&#x2F;h2&gt;
&lt;p&gt;It&#x27;s hard to look at the current state of systems security and simply
say &amp;quot;it&#x27;s the cpu vendors fault&amp;quot;. There are many layers that have
come together to cause this situation.&lt;&#x2F;p&gt;
&lt;p&gt;This is called the &amp;quot;swiss cheese model&amp;quot;. Imagine you take a stack of
swiss cheese and rotate and rearrange the slices. You will not be able
to see through it. but as you continue to rotate and rearrange,
eventually you may see a tunnel through the cheese where all the holes
line up.&lt;&#x2F;p&gt;
&lt;p&gt;This is what has happened here - we developed many layers socially and
technically that all seemed reasonable over time, and only after enough
time and re-arrangements of the layers, have we now arrived at a
situation where a failure has occured that permeates all of computer
hardware.&lt;&#x2F;p&gt;
&lt;p&gt;To address it, we need to look beyond just &amp;quot;blaming hardware makers&amp;quot;
or &amp;quot;software patches&amp;quot;. We need to help developers move away from C to
other languages that can be brought onto new memory models that have
manual or other cache strategies. We need hardware vendors to implement
different async models. We need to educate businesses on risk analysis
and how hardware works to provide proper decision making capability. We
need developers to alter there behaviour to work in environments with
higher performance constraints. And probably much much more.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;there-are-no-root-causes-1&quot;&gt;There are no root causes&lt;&#x2F;h2&gt;
&lt;p&gt;It is a very pervasive attitude in IT that every issue has a root cause.
However, looking above we can see it&#x27;s never quite so simple.&lt;&#x2F;p&gt;
&lt;p&gt;Saying an issue has a root cause, prevents us from examining the social,
political, economic and human factors that all become contributing
factors to failure. Because we are unable to examine them, we are unable
to address the various layers that have contributed to our failures.&lt;&#x2F;p&gt;
&lt;p&gt;There are no root causes. Only contributing factors.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Concurrency 1: Types of Concurrency</title>
          <pubDate>Sun, 29 Dec 2019 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2019-12-29-concurrency-1-types-of-concurrency/</link>
          <guid>https://fy.blackhats.net.au/blog/2019-12-29-concurrency-1-types-of-concurrency/</guid>
          <description>&lt;h1 id=&quot;concurrency-1-types-of-concurrency&quot;&gt;Concurrency 1: Types of Concurrency&lt;&#x2F;h1&gt;
&lt;p&gt;I want to explain different types of concurrent datastructures, so that
we can explore their properties and when or why they might be useful.&lt;&#x2F;p&gt;
&lt;p&gt;As our computer systems become increasingly parallel and asynchronous,
it&#x27;s important that our applications are able to work in these
environments effectively. Languages like Rust help us to ensure our
concurrent structures are safe.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;cpu-memory-model-crash-course&quot;&gt;CPU Memory Model Crash Course&lt;&#x2F;h2&gt;
&lt;p&gt;In no way is this a thorough, complete, or 100% accurate representation
of CPU memory. My goal is to give you a quick brief on how it works. I
highly recommend you read &lt;a href=&quot;https:&#x2F;&#x2F;people.freebsd.org&#x2F;~lstewart&#x2F;articles&#x2F;cpumemory.pdf&quot;&gt;&amp;quot;what every programmer should know about
memory&amp;quot;&lt;&#x2F;a&gt;
if you want to learn more.&lt;&#x2F;p&gt;
&lt;p&gt;In a CPU we have a view of a memory space. That could be in the order of
KB to TB. But it&#x27;s a single coherent view of that space.&lt;&#x2F;p&gt;
&lt;p&gt;Of course, over time systems and people have demanded more and more
performance. But we also have languages like C, that won&#x27;t change from
their view of a system as a single memory space, or change how they
work. Of course, it turns out &lt;a href=&quot;https:&#x2F;&#x2F;queue.acm.org&#x2F;detail.cfm?id=3212479&quot;&gt;C is not a low level
language&lt;&#x2F;a&gt; but we like to
convince ourselves it is.&lt;&#x2F;p&gt;
&lt;p&gt;To keep working with C and others, CPU&#x27;s have acquired cache&#x27;s that
are transparent to the operation of the memory. You have no control of
what is - or is not - in the cache. It &amp;quot;just happens&amp;quot; asynchronously.
This is exactly why spectre and meltdown happened (and will continue to
happen) because these async behaviours will always have the observable
effect of making your CPU faster. Who knew!&lt;&#x2F;p&gt;
&lt;p&gt;Anyway, for this to work, each CPU has multiple layers of cache. At L3
the cache is shared with all the cores on the die. At L1 it is &amp;quot;per
cpu&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;Of course it&#x27;s a single view into memory. So if address 0xff is in the
CPU cache of core 1, and also in cache of core 2, what happens? Well
it&#x27;s supported! Caches between cores are kept in sync via a state
machine called MESI. These states are:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Exclusive - The cache is the only owner of this value, and it is
unchanged.&lt;&#x2F;li&gt;
&lt;li&gt;Modified - The cache is the only owner of this value, and it has
been changed.&lt;&#x2F;li&gt;
&lt;li&gt;Invalid - The cache holds this value but another cache has changed
it.&lt;&#x2F;li&gt;
&lt;li&gt;Shared - This cache and maybe others are viewing this valid value.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;To gloss very heavily over this topic, we want to avoid invaild. Why?
That means two cpus are &lt;em&gt;contending&lt;&#x2F;em&gt; for the value, causing many
attempts to keep each other in check. These contentions cause CPU&#x27;s to
slow down.&lt;&#x2F;p&gt;
&lt;p&gt;We want values to either be in E&#x2F;M or S. In shared, many cpu&#x27;s are able
to read the value at maximum speed, all the time. In E&#x2F;M, we know only
this cpu is changing the value.&lt;&#x2F;p&gt;
&lt;p&gt;This cache coherency is also why mutexes and locks exist - they issue
the needed CPU commands to keep the caches in the correct states for the
memory we are accessing.&lt;&#x2F;p&gt;
&lt;p&gt;Keep in mind Rust&#x27;s variables are immutable, and able to share between
threads, or mutable and single thread only. Sound familar? Rust is
helping with concurrency by keeping our variables in the fastest
possible cache states.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;data-structures&quot;&gt;Data Structures&lt;&#x2F;h2&gt;
&lt;p&gt;We use data structures in programming to help improve behaviours of
certain tasks. Maybe we need to find values quicker, sort contents, or
search for things. Data Structures are a key element of modern computer
performance.&lt;&#x2F;p&gt;
&lt;p&gt;However most data structures are not thread safe. This means only a
single CPU can access or change them at a time. Why? Because if a second
read them, due to cache-differences in content the second CPU may see an
invalid datastructure, leading to undefined behaviour.&lt;&#x2F;p&gt;
&lt;p&gt;Mutexes can be used, but this causes other CPU&#x27;s to stall and wait for
the mutex to be released -not really what we want on our system. We want
every CPU to be able to process data without stopping!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;thread-safe-datastructures&quot;&gt;Thread Safe Datastructures&lt;&#x2F;h2&gt;
&lt;p&gt;There exist many types of thread safe datastructures that can work on
parallel systems. They often avoid mutexes to try and keep CPU&#x27;s moving
as fast as possible, relying on special atomic cpu operations to keep
all the threads in sync.&lt;&#x2F;p&gt;
&lt;p&gt;Multiple classes of these structures exist, which have different
properties.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;mutex&quot;&gt;Mutex&lt;&#x2F;h2&gt;
&lt;p&gt;I have mentioned these already, but it&#x27;s worth specifying the
properties of a mutex. A mutex is a system where a single CPU exists in
the mutex. It becomes one &amp;quot;reader&#x2F;writer&amp;quot; and all other CPU&#x27;s must
wait until the mutex is released by the current CPU holder.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;read-write-lock&quot;&gt;Read Write Lock&lt;&#x2F;h2&gt;
&lt;p&gt;Often called RWlock, these allow one writer OR multiple parallel
readers. If a reader is reading then a writer request is delayed until
the readers complete. If a writer is changing data, all new reads are
blocked. All readers will always be reading the same data.&lt;&#x2F;p&gt;
&lt;p&gt;These are great for highly concurrent systems provided your data changes
infrequently. If you have a writer changing data a lot, this causes your
readers to be continually blocking. The delay on the writer is also high
due to a potentially high amount of parallel readers that need to exit.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;lock-free&quot;&gt;Lock Free&lt;&#x2F;h2&gt;
&lt;p&gt;Lock free is a common (and popular) datastructue type. These are
structures that don&#x27;t use a mutex at all, and can have multiple readers
&lt;em&gt;and&lt;&#x2F;em&gt; multiple writers at the same time.&lt;&#x2F;p&gt;
&lt;p&gt;The most common and popular structure for lock free is queues, where
many CPUs can append items and many can dequeue at the same time. There
are also a number of lock free sets which can be updated in the same
way.&lt;&#x2F;p&gt;
&lt;p&gt;An interesting part of lock free is that all CPU&#x27;s are working on the
same set - if CPU 1 reads a value, then CPU 2 writes the same value, the
next read from CPU 1 will show the new value. This is because these
structures aren&#x27;t transactional - lock free, but not transactional.
There are some times where this is really useful as a property when you
need a single view of the world between all threads, and your program
can tolerate data changing between reads.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;wait-free&quot;&gt;Wait Free&lt;&#x2F;h2&gt;
&lt;p&gt;This is a specialisation of lock free, where the reader&#x2F;writer has
guaranteed characteristics about the time they will wait to read or
write data. This is very detailed and subtle, only affecting real time
systems that have strict deadline and performance requirements.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;concurrently-readable&quot;&gt;Concurrently Readable&lt;&#x2F;h2&gt;
&lt;p&gt;In between all of these is a type of structure called concurrently
readable. A concurrently readable structure allows one writer &lt;em&gt;and&lt;&#x2F;em&gt;
multiple parallel readers. An interesting property is that when the
reader &amp;quot;begins&amp;quot; to read, the view for that reader is guaranteed not to
change until the reader completes. This means that the structure is
transactional.&lt;&#x2F;p&gt;
&lt;p&gt;An example being if CPU 1 reads a value, and CPU 2 writes to it, CPU 1
would NOT see the change from CPU 2 - it&#x27;s outside of the read
transaction!&lt;&#x2F;p&gt;
&lt;p&gt;In this way there are a lot of read-only immutable data, and one writer
mutating and changing things ... sounds familar? It&#x27;s very close to
how our CPU&#x27;s cache work!&lt;&#x2F;p&gt;
&lt;p&gt;These structures also naturally lend themself well to long processing or
database systems where you need transactional (ACID) properties. In fact
some databases use concurrent readable structures to achieve ACID
semantics.&lt;&#x2F;p&gt;
&lt;p&gt;If it&#x27;s not obvious - concurrent readability is where my interest lies,
and in the next post I&#x27;ll discuss some specific concurrently readable
structures that exist today, and ideas for future structures.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Concurrency 2: Concurrently Readable Structures</title>
          <pubDate>Sun, 29 Dec 2019 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2019-12-29-concurrency-2-concurrently-readable-structures/</link>
          <guid>https://fy.blackhats.net.au/blog/2019-12-29-concurrency-2-concurrently-readable-structures/</guid>
          <description>&lt;h1 id=&quot;concurrency-2-concurrently-readable-structures&quot;&gt;Concurrency 2: Concurrently Readable Structures&lt;&#x2F;h1&gt;
&lt;p&gt;In this post, I&#x27;ll discuss concurrently readable datastructures that
exist, and ideas for future structures. Please note, this post is an
inprogress design, and may be altered in the future.&lt;&#x2F;p&gt;
&lt;p&gt;Before you start, make sure you have &lt;a href=&quot;..&#x2F;concurrency_1_types_of_concurrency.html&quot;&gt;read part
1&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;concurrent-cell&quot;&gt;Concurrent Cell&lt;&#x2F;h2&gt;
&lt;p&gt;The simplest form of concurrently readable structure is a concurrent
cell. This is equivalent to a read-write lock, but has concurrently
readable properties instead. The key mechanism to enable this is that
when the writer begins, it clones the data before writing it. We trade
more memory usage for a gain in concurrency.&lt;&#x2F;p&gt;
&lt;p&gt;To see an implementation, see my &lt;a href=&quot;https:&#x2F;&#x2F;crates.io&#x2F;crates&#x2F;concread&quot;&gt;rust crate,
concread&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;concurrent-tree&quot;&gt;Concurrent Tree&lt;&#x2F;h2&gt;
&lt;p&gt;The concurrent cell is good for small data, but a larger structure -
like a tree - may take too long to clone on each write. A good estimate
is that if your data in the cell is larger than about 512 bytes, you
likely want a concurrent tree instead.&lt;&#x2F;p&gt;
&lt;p&gt;In a concurrent tree, only the &lt;em&gt;branches&lt;&#x2F;em&gt; involved in the operation are
cloned. Imagine the following tree:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;cow_1.png&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;When we attempt to change a value in the 4th leaf we copy it before we
begin, and all it&#x27;s parents to update their pointers.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;cow_2.png&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;In the process the pointers from the new root b to branch 1 are
maintained. The new second branch also maintains a pointer to the
original 3rd leaf.&lt;&#x2F;p&gt;
&lt;p&gt;This means that in this example only 3&#x2F;7 nodes are copied, saving a lot
of cloning. As your tree grows this saves a lot of work. Consider a tree
with node-widths of 7 pointers and at height level 5. Assuming perfect
layout, you only need to clone 5&#x2F;~16000 nodes. A huge saving in memory
copy!&lt;&#x2F;p&gt;
&lt;p&gt;The interesting part is a reader of root a, also is unaffected by the
changes to root b - the tree from root a hasn&#x27;t been changed, as all
it&#x27;s pointers and nodes are still valid.&lt;&#x2F;p&gt;
&lt;p&gt;When all readers of root a end, we clean up all the nodes it pointed to
that no longer are needed by root b (this can be done with atomic
reference counting, or garbage lists in transactions).&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;cow_3.png&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;It is through this copy-on-write (also called multi view concurrency
control) that we achieve concurrent readability in the tree.&lt;&#x2F;p&gt;
&lt;p&gt;This is really excellent for databases where you have in memory
structures that work in parallel to the database transactions. In kanidm
an example is the in-memory schema that is used at run time but loaded
from the database. They require transactional behaviours to match the
database, and ACID properties so that readers of a past transaction have
the &amp;quot;matched&amp;quot; schema in memory.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;concurrent-cache-updated-2020-05-13&quot;&gt;Concurrent Cache (Updated 2020-05-13)&lt;&#x2F;h2&gt;
&lt;p&gt;A design that I have thought about for a long time has finally come to
reality. This is a concurrently readable transactional cache. One
writer, multiple readers with consistent views of the data. Additionally
due to the transactioal nature, rollbacks and commits are fulled
supported.&lt;&#x2F;p&gt;
&lt;p&gt;For a more formal version of this design, please see &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;Firstyear&#x2F;concread&#x2F;blob&#x2F;master&#x2F;CACHE.md&quot;&gt;my concurrent ARC
draft
paper&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;This scheme should work with any cache type - LRU, LRU2Q, LFU. I have
used
&lt;a href=&quot;https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20100329071954&#x2F;http:&#x2F;&#x2F;www.almaden.ibm.com&#x2F;StorageSystems&#x2F;projects&#x2F;arc&#x2F;&quot;&gt;ARC&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;ARC was popularised by ZFS - ARC is not specific to ZFS, it&#x27;s a
strategy for cache replacement, despite the comment association between
the two.&lt;&#x2F;p&gt;
&lt;p&gt;ARC is a pair of LRU&#x27;s with a set of ghost lists and a weighting
factor. When an entry is &amp;quot;missed&amp;quot; it&#x27;s inserted to the &amp;quot;recent&amp;quot;
LRU. When it&#x27;s accessed from the LRU a second time, it moves to the
&amp;quot;frequent&amp;quot; LRU.&lt;&#x2F;p&gt;
&lt;p&gt;When entries are evicted from their sets they are added to the ghost
list. When a cache miss occurs, the ghost list is consulted. If the
entry &amp;quot;would have been&amp;quot; in the &amp;quot;recent&amp;quot; LRU, but was not, the
&amp;quot;recent&amp;quot; LRU grows and the &amp;quot;frequent&amp;quot; LRU shrinks. If the item
&amp;quot;would have been&amp;quot; in the &amp;quot;frequent&amp;quot; LRU but was not, the
&amp;quot;frequent&amp;quot; LRU is expanded, and the &amp;quot;recent&amp;quot; LRU shrunk.&lt;&#x2F;p&gt;
&lt;p&gt;This causes ARC to be self tuning to your workload, as well as balancing
&amp;quot;high frequency&amp;quot; and &amp;quot;high locality&amp;quot; operations. It&#x27;s also
resistant to many cache invalidation or busting patterns that can occur
in other algorithms.&lt;&#x2F;p&gt;
&lt;p&gt;A major problem though is ARC is not designed for concurrency - LRU&#x27;s
rely on double linked lists which is &lt;em&gt;very&lt;&#x2F;em&gt; much something that only a
single thread can modify safely due to the number of pointers that are
not aligned in a single cache line, prevent atomic changes.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;how-to-make-arc-concurrent&quot;&gt;How to make ARC concurrent&lt;&#x2F;h2&gt;
&lt;p&gt;To make this concurrent, I think it&#x27;s important to specify the goals.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Readers must always have a correct &amp;quot;point in time&amp;quot; view of the
cache and its data&lt;&#x2F;li&gt;
&lt;li&gt;Readers must be able to trigger cache inclusions&lt;&#x2F;li&gt;
&lt;li&gt;Readers must be able to track cache hits accurately&lt;&#x2F;li&gt;
&lt;li&gt;Readers are isolated from all other readers and writer actions&lt;&#x2F;li&gt;
&lt;li&gt;Writers must always have a correct &amp;quot;point in time&amp;quot; view&lt;&#x2F;li&gt;
&lt;li&gt;Writers must be able to rollback changes without penalty&lt;&#x2F;li&gt;
&lt;li&gt;Writers must be able to trigger cache inclusions&lt;&#x2F;li&gt;
&lt;li&gt;Writers must be able to track cache hits accurately&lt;&#x2F;li&gt;
&lt;li&gt;Writers are isolated from all readers&lt;&#x2F;li&gt;
&lt;li&gt;The cache must maintain correct temporal ordering of items in the
cache&lt;&#x2F;li&gt;
&lt;li&gt;The cache must properly update hit and inclusions based on readers
and writers&lt;&#x2F;li&gt;
&lt;li&gt;The cache must provide ARC semantics for management of items&lt;&#x2F;li&gt;
&lt;li&gt;The cache must be concurrently readable and transactional&lt;&#x2F;li&gt;
&lt;li&gt;The overhead compared to single thread ARC is minimal&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;There are a lot of places to draw inspiration from, and I don&#x27;t think I
can list - or remember them all.&lt;&#x2F;p&gt;
&lt;p&gt;My current design uses a per-thread reader cache to allow inclusions,
with a channel to asynchronously include and track hits to the write
thread. The writer also maintains a local cache of items including
markers of removed items. When the writer commits, the channel is
drained to a time point T, and actions on the ARC taken.&lt;&#x2F;p&gt;
&lt;p&gt;This means the LRU&#x27;s are maintained only in a single write thread, but
the readers changes are able to influence the caching decisions.&lt;&#x2F;p&gt;
&lt;p&gt;To maintain consistency, and extra set is added which is the haunted
set, so that a key that has existed at some point can be tracked to
identify it&#x27;s point in time of eviction and last update so that stale
data can never be included by accident.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;limitations-and-concerns&quot;&gt;Limitations and Concerns&lt;&#x2F;h2&gt;
&lt;p&gt;Cache missing is very expensive - multiple threads may load the value,
the readers must queue the value, and the writer must then act on the
queue. Sizing the cache to be large enough is critically important as
eviction&#x2F;missing will have a higher penalty than normal. Optimally the
cache will be &amp;quot;as large or larger&amp;quot; than the working set.&lt;&#x2F;p&gt;
&lt;p&gt;But with a concurrent ARC we now have a cache where each reader thread
has a thread local cache and the writer is communicated to by channels.
This may make the cache&#x27;s memory limit baloon to a high amount over a
normal cache. To help, an algorithm was developed based on expect cache
behaviour for misses and communication to help size the caches of
readers and writers.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;&#x2F;h2&gt;
&lt;p&gt;This is a snapshot of some concurrently readable datastructures, and how
they are implemented and useful in your projects. Using them in
&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kanidm&#x2F;kanidm&#x2F;blob&#x2F;master&#x2F;README.md&quot;&gt;Kanidm&lt;&#x2F;a&gt; we have
already seen excellent performance and scaling of the server, with very
little effort for tuning. We plan to adapt these for use in 389
Directory Server too. Stay tuned!&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Packaging and the Security Proposition</title>
          <pubDate>Thu, 19 Dec 2019 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2019-12-19-packaging-and-the-security-proposition/</link>
          <guid>https://fy.blackhats.net.au/blog/2019-12-19-packaging-and-the-security-proposition/</guid>
          <description>&lt;h1 id=&quot;packaging-and-the-security-proposition&quot;&gt;Packaging and the Security Proposition&lt;&#x2F;h1&gt;
&lt;p&gt;As a follow up to my post on distribution packaging, it was commented by
Fraser Tweedale (@hackuador) that traditionally the &amp;quot;security&amp;quot; aspects
of distribution packaging was a compelling reason to use distribution
packages over &amp;quot;upstreams&amp;quot;. I want to dig into this further.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;why-does-c-need-securing&quot;&gt;Why does C need &amp;quot;securing&amp;quot;&lt;&#x2F;h2&gt;
&lt;p&gt;C as a language is &lt;em&gt;unsafe&lt;&#x2F;em&gt; in every meaning of the word. The best C
programmers on the planet are incapable of writing a secure program.
This is because to code in C you have to express a concurrent problem,
into a language that is linearised, which is compiled relying on
undefined behaviour, to be executed on an asynchronous concurrent out of
order CPU. What could possibly go wrong?!&lt;&#x2F;p&gt;
&lt;p&gt;There is a lot you need to hold in mind to make C work. I can tell you
now that I spend a majority of my development time thinking about the
code to change rather than writing C because of this!&lt;&#x2F;p&gt;
&lt;p&gt;This has led to C based applications having just about every security
issue known to man.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;how-is-c-secured&quot;&gt;How is C &amp;quot;secured&amp;quot;&lt;&#x2F;h2&gt;
&lt;p&gt;So as C is security swiss cheese, this means we have developed processes
around the language to soften this issue - for example advice like patch
and update continually as new changes are continually released to
resolve issues.&lt;&#x2F;p&gt;
&lt;p&gt;Distribution packages have always been the &amp;quot;source&amp;quot; of updates for
these libraries and applications. These packages are maintained by
humans who need to update these packages. This means when a C project
releases a fix, these maintainers would apply the patch to various
versions, and then release the updates. These library updates due to
C&#x27;s dynamic nature means when the machine is next rebooted (yes
rebooted, not application restarted) that these fixes apply to all
consumers who have linked to that library - change one, fix everything.
Great!&lt;&#x2F;p&gt;
&lt;p&gt;But there are some (glaring) weaknesses to this model. C historically
has little to poor application testing so many of these patches and
their effects can&#x27;t be reproduced. Which also subsequently means that
consuming applications also aren&#x27;t re-tested adequately. It can also
have impacts where a change to a shared library can impact a consuming
application in a way that was unforseen as the library changed.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-dirty-secret&quot;&gt;The Dirty Secret&lt;&#x2F;h2&gt;
&lt;p&gt;The dirty secret of many of these things is that &amp;quot;thoughts and
prayers&amp;quot; is often the testing strategy of choice when patches are
applied. It&#x27;s only because humans carefully think about and write tiny
amounts of C that we have any reliability in our applications. And we
already established that it&#x27;s nearly impossible for humans to write
correct C ...&lt;&#x2F;p&gt;
&lt;h2 id=&quot;why-are-we-doing-this&quot;&gt;Why Are We Doing This?&lt;&#x2F;h2&gt;
&lt;p&gt;Because C linking and interfaces are so fragile, and due to the huge
scope in which C can go wrong due to being a memory unsafe language,
distributions and consumers have learnt to fear &lt;em&gt;version changes&lt;&#x2F;em&gt;. So
instead we patch ancient C code stacks, barely test them, and hope that
our castles of sand don&#x27;t fall over, all so we can keep &amp;quot;the same
version&amp;quot; of a program to avoid changing it as much as possible.
Ironically this makes those stacks even worse because we&#x27;ve developed
infinite numbers of bespoke barely tested packages that people rely on
daily.&lt;&#x2F;p&gt;
&lt;p&gt;To add more insult to this, most of this process is manual - humans
monitor mailing lists, and have to know what code needs what patch, and
when in what release streams. It&#x27;s a monumental amount of human time
and labour involved to keep the sand castles standing. This manual
involvement is what leads to information overload, and maintainers
potentially missing security updates or releases that causes many
distribution packages to be outdated, missing patches, or vulnerable
more often than not. In other cases packages continue to be shipped that
are unmaintained or have no upstream, so any issues that may exist are
unknown or unresolved.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;distribution-security&quot;&gt;Distribution Security&lt;&#x2F;h2&gt;
&lt;p&gt;This means all of platform and distribution security comes to one
factor.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;A lot of manual human labour.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;It&#x27;s is only because distributions have so many volunteers or paid
staff, that this entire system continues to progress to give the
illusion of security and reliability. When it fails, it fails silently.&lt;&#x2F;p&gt;
&lt;p&gt;Heartbleed really &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Heartbleed#Root_causes,_possible_lessons,_and_reactions&quot;&gt;dragged the poor state of C security into the
open&lt;&#x2F;a&gt;
, and it&#x27;s still not been addressed.&lt;&#x2F;p&gt;
&lt;p&gt;When people say &amp;quot;how can we secure docker&#x2F;flatpak&#x2F;Rust&amp;quot; like we do
with distributions, I say: &amp;quot;Do we really secure distributions at
all?&amp;quot;. We only have a veneer of best effort masquerading as a secure
supply chain.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;a-different-model&quot;&gt;A Different Model ...&lt;&#x2F;h2&gt;
&lt;p&gt;So let&#x27;s look briefly at Rust and how you package it today (against
distribution maintainer advice).&lt;&#x2F;p&gt;
&lt;p&gt;Because it&#x27;s staticly linked, each application must be rebuilt if a
library changes. Because the code comes from a central upstream, there
are automated tools to find security issues (like cargo audit). The
updates are pulled from the library as a whole working tested unit, and
then built into our application to to recieve further testing and
verification of the application as a whole singular functional unit.&lt;&#x2F;p&gt;
&lt;p&gt;These dependencies once can then be vendored to a tar (allowing offline
builds and some aspects of reproducability). This vendor.tar.gz is
placed into the source rpm along with the application source, and then
built.&lt;&#x2F;p&gt;
&lt;p&gt;There is a much stronger pipeline of assurances here! And to further aid
Rust&#x27;s cause, because it is a memory &lt;em&gt;safe&lt;&#x2F;em&gt; language, it eliminates
most of the security issues that C is afflicted by, causing security
updates to be far fewer, and to often affect higher level or esoteric
situations. If you don&#x27;t believe me, look at the low frequency, and low
severity &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;RustSec&#x2F;advisory-db&#x2F;commits&#x2F;master&quot;&gt;commits for the rust
advisory-db&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;People have worried that because Rust is staticly linked we&#x27;ll have to
rebuild it and update it continually to keep it secure - I&#x27;d say
because it&#x27;s Rust we&#x27;ll have stronger guarantees at build that
security issues are less likely to exist and we won&#x27;t have to ship
updates nearly as often as a C stack.&lt;&#x2F;p&gt;
&lt;p&gt;Another point to make is Rust libraries don&#x27;t release patches - because
of Rust&#x27;s stronger guarantees at compile time and through integrated
testing, people are less afraid of updates to versions. We are very
unlikely to see Rust releasing patches, rather than just shipping
&amp;quot;updates&amp;quot; to libraries and expecting you to update. Because these are
staticly linked, we don&#x27;t have to worry about versions for other
libraries on the platform, we only need to assure the &lt;em&gt;application&lt;&#x2F;em&gt; is
currently working as intended. Because of the strong typing those
interfaces of those libraries has stronger compile time guarantees at
build time, meaning the issues around shared object versioning and
symbol&#x2F;version mismatching simply don&#x27;t exist - one of the key reasons
people became version change averse in the first place.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;so-why-not-package-all-the-things&quot;&gt;So Why Not Package All The Things?&lt;&#x2F;h2&gt;
&lt;p&gt;Many distribution packagers have been demanding a C-like model for Rust
and others (&lt;a href=&quot;..&#x2F;18&#x2F;packaging_vendoring_and_how_it_s_changing.html&quot;&gt;remember, square peg, round
hole&lt;&#x2F;a&gt;). This means
every single crate (library) is packaged, and then added to a set of
buildrequires for the application. When a crate updates, it triggers the
application to rebuild. When a security update for a library comes out,
it rebuilds etc.&lt;&#x2F;p&gt;
&lt;p&gt;This should sound familiar ... because it is. It&#x27;s reinventing Cargo
in a clean-room.&lt;&#x2F;p&gt;
&lt;p&gt;RPM provides a way to manage dependencies. Cargo provides a way to
manage dependencies.&lt;&#x2F;p&gt;
&lt;p&gt;RPM provides a way to offline build sources. Cargo provides a way to
offline build sources.&lt;&#x2F;p&gt;
&lt;p&gt;RPM provides a way to patch sources. Cargo provides a way to update them
inplace - and patch if needed.&lt;&#x2F;p&gt;
&lt;p&gt;RPM provides a way to ... okay you get the point.&lt;&#x2F;p&gt;
&lt;p&gt;There is also a list of what we won&#x27;t get from distribution packages -
remember distribution packages are the &lt;a href=&quot;..&#x2F;18&#x2F;packaging_vendoring_and_how_it_s_changing.html&quot;&gt;C language packaging
system&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;We won&#x27;t get the same level of attention to detail, innovation and
support as the upstream language tooling has. Simply put, users of the
language just won&#x27;t use distribution packages (or toolchains, libraries
...) in their workflows.&lt;&#x2F;p&gt;
&lt;p&gt;Distribution packages can&#x27;t offer is the integration into tools like
cargo-audit for scanning for security issues - that needs still needs
Cargo, not RPM, meaning the RPM will need to emulate what Cargo does
exactly.&lt;&#x2F;p&gt;
&lt;p&gt;Using distribution packages means you have an untested pipeline that may
add more risks now. Developers won&#x27;t use distribution packages -
they&#x27;ll use cargo. Remember applications work best as they are tested
and developed - outside of that environment they are an unknown.&lt;&#x2F;p&gt;
&lt;p&gt;Finally, the distribution maintainers security proposition is to secure
our &lt;em&gt;libraries&lt;&#x2F;em&gt; - for distributions only. That&#x27;s acting in self
interest. Cargo is offering a way to secure upstream so that everyone
benefits. That means less effort and less manual labour all around. And
secure libraries are not the full picture. Secure &lt;em&gt;applications&lt;&#x2F;em&gt; is what
matters.&lt;&#x2F;p&gt;
&lt;p&gt;The large concerning factor is the sheer amount of &lt;em&gt;human effort&lt;&#x2F;em&gt;. We
would spend hundreds if not thousands of hours to reinvent a functional
tool in a disengaged manner, just so that we can do things as they have
always been done in C - for the benefit of distributions individually
rather than languages upstream.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-is-the-point&quot;&gt;What is the Point&lt;&#x2F;h2&gt;
&lt;p&gt;Again - as a platform our role is to provide &lt;em&gt;applications&lt;&#x2F;em&gt; that people
can trust. The way we provide these applications is never going to be
one size fits all. Our objective isn&#x27;t to secure &amp;quot;this library&amp;quot; or
&amp;quot;that library&amp;quot;, it&#x27;s to secure &lt;em&gt;applications&lt;&#x2F;em&gt; as a functional whole.
That means that companies shipping those applications, should hire
maintainers to work on those applications to secure their stacks.&lt;&#x2F;p&gt;
&lt;p&gt;Today I honestly think Rust has a better security and updating story
than C packages ever has, powered by automation and upstream
integration. Let&#x27;s lean on that, contribute to it, and focus on
shipping applications instead of reinventing tools. We need to accept
our current model is focused on C, that developers have moved around
distribution packaging, and that we need to change our approach to
eliminate the large human risk factor that currently exists.&lt;&#x2F;p&gt;
&lt;p&gt;We can&#x27;t keep looking to the models of the past, we need to start to
invest in new methods for the future.&lt;&#x2F;p&gt;
&lt;p&gt;Today, distributions should focus on supporting and distributing
&lt;em&gt;applications&lt;&#x2F;em&gt; and work with native language supply chains to enable
this.&lt;&#x2F;p&gt;
&lt;p&gt;Which is why I&#x27;ll keep using cargo&#x27;s tooling and auditing, and use
distribution packages as a delievery mechanism for those applications.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-could-it-look-like&quot;&gt;What Could it Look Like?&lt;&#x2F;h2&gt;
&lt;p&gt;We have a platform that updates as a whole (Fedora Atomic comes to mind
...) with known snapshots that are tested and well known. This platform
has methods to run applications, and those applications are isolated
from each other, have their own libraries, and security audits.&lt;&#x2F;p&gt;
&lt;p&gt;And because there are now far fewer moving parts, quality is easier to
assert, understand, and security updates are far easier and faster, less
risky.&lt;&#x2F;p&gt;
&lt;p&gt;It certainly sounds a lot like what macOS and iOS have been doing with a
read-only base, and self-contained applications within that system.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Packaging, Vendoring, and How It&#x27;s Changing</title>
          <pubDate>Wed, 18 Dec 2019 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2019-12-18-packaging-vendoring-and-how-it-s-changing/</link>
          <guid>https://fy.blackhats.net.au/blog/2019-12-18-packaging-vendoring-and-how-it-s-changing/</guid>
          <description>&lt;h1 id=&quot;packaging-vendoring-and-how-it-s-changing&quot;&gt;Packaging, Vendoring, and How It&#x27;s Changing&lt;&#x2F;h1&gt;
&lt;p&gt;In today&#x27;s thoughts, I was considering packaging for platforms like
opensuse or other distributions and how that interacts with language
based packaging tools. This is a complex and ... difficult topic, so
I&#x27;ll start with my summary:&lt;&#x2F;p&gt;
&lt;p&gt;Today, distributions should focus on supporting and distributing
&lt;em&gt;applications&lt;&#x2F;em&gt; and work with native language supply chains to enable
this.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;distribution-packaging&quot;&gt;Distribution Packaging&lt;&#x2F;h2&gt;
&lt;p&gt;Let&#x27;s start by clarifying what distribution packaging is. This is your
linux or platforms method of distributing it&#x27;s programs libraries. For
our discussion we really only care about linux so say suse or fedora
here. How macOS or FreeBSD deal with this is quite different.&lt;&#x2F;p&gt;
&lt;p&gt;Now these distribution packages are built to support certain workflows
and end goals. Many open source C projects release their source code in
varying states, perhaps also patches to improve or fix issues. These
code are then put into packages, dependencies between them established
due to dynamic linking, they are signed for verification purposes and
then shipped.&lt;&#x2F;p&gt;
&lt;p&gt;This process is really optimised for C applications. C has been the
&amp;quot;system language&amp;quot; for many decades now, and so we can really see these
features designed to promote - and fill in gaps - for these
applications.&lt;&#x2F;p&gt;
&lt;p&gt;For example, C applications are dynamically linked. Because of this it
encourages package maintainers to &amp;quot;split&amp;quot; applications into smaller
units that can have shared elements. An example that I know is openldap
which may be a single source tree, but often is packaged to multiple
parts such as the libldap.so, lmdb, openldap-client applications, it&#x27;s
server binary, and probably others. The package maintainer is used to
taking their scalpels and carefully slicing sources into elegant
packages that can minimise how many things are installed to what is
&amp;quot;just needed&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;We also see other behaviours where C shared objects have &amp;quot;versions&amp;quot;,
which means you can install multiple versions of them at once and
programs declare in their headers which library versions they want to
consume. This means a distribution package can have many versions of the
same thing installed!&lt;&#x2F;p&gt;
&lt;p&gt;This in mind, the linking is simplistic and naive. If a shared object
symbol doesn&#x27;t exist, or you don&#x27;t give it the &amp;quot;right arguments&amp;quot; via
a weak-compile time contract, it&#x27;s likely bad things (tm) will happen.
So for this, distribution packaging provides the stronger assertions
about &amp;quot;this program requires that library version&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;As well, in the past the internet was a more ... wild place, where TLS
wasn&#x27;t really widely used. This meant that to gain strong assertions
about the source of a package &lt;em&gt;and&lt;&#x2F;em&gt; that it had not been tampered, tools
like GPG were used.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-about-ruby-or-python&quot;&gt;What about Ruby or Python?&lt;&#x2F;h2&gt;
&lt;p&gt;Ruby and Python are very different languages compared to C though. They
don&#x27;t have information in their programs about what versions of
software they require, and how they mesh together. Both languages are
interpreted, and simply &amp;quot;import library&amp;quot; by name, searching a
filesystem path for a library matching &lt;em&gt;regardless of it&#x27;s version&lt;&#x2F;em&gt;.
Python then just loads in that library as source straight to the running
vm.&lt;&#x2F;p&gt;
&lt;p&gt;It&#x27;s already apparent how we&#x27;ll run into issues here. What if we have
a library &amp;quot;foo&amp;quot; that has a different function interface between
version 1 and version 2? Python applications only request access to
&amp;quot;foo&amp;quot;, not the version, so what happens if the wrong version is found?
What if it&#x27;s not found?&lt;&#x2F;p&gt;
&lt;p&gt;Some features here are pretty useful from the &amp;quot;distribution package&amp;quot;
though. Allowing these dynamic tools to have their dependencies
requested from the &amp;quot;package&amp;quot;, and having the package integrity checked
for them.&lt;&#x2F;p&gt;
&lt;p&gt;But overtime, conflicts started, and issues arose. A real turning point
was ruby in debian&#x2F;ubuntu where debian package maintainers (who are used
to C) brought out the scalpel and attempted to slice ruby down to
&amp;quot;parts&amp;quot; that could be reused form a C mindset. This led to a
combinations of packages that didn&#x27;t make sense (rubygems minus TLS,
but rubygems requires https), which really disrupted the communities.&lt;&#x2F;p&gt;
&lt;p&gt;Another issue was these languages as they grew in popularity had
different projects requiring &lt;em&gt;different&lt;&#x2F;em&gt; versions of libraries - which
as before we mentioned isn&#x27;t possible beside library search path
manipulations which is frankly user hostile.&lt;&#x2F;p&gt;
&lt;p&gt;These issues (and more) eventually caused these communities as a whole
to &lt;em&gt;stop recommending&lt;&#x2F;em&gt; distribution packages.&lt;&#x2F;p&gt;
&lt;p&gt;So put this history in context. We have Ruby (1995) and Python (1990),
which both decided to avoid distribution packages with their own tools
aka rubygems (2004) and pip (2011), as well as tools to manage multiple
parallel environments (rvm, virtualenv) that were per-application.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;new-kids-on-the-block&quot;&gt;New kids on the block&lt;&#x2F;h2&gt;
&lt;p&gt;Since then I would say three languages have risen to importance and
learnt from the experiences of Ruby - This is Javascript (npm&#x2F;node), Go
and Rust.&lt;&#x2F;p&gt;
&lt;p&gt;Rust went further than Ruby and Python and embedded distribution of
libraries into it&#x27;s build tools from an early date with Cargo. As Rust
is staticly linked (libraries are build into the final binary, rather
than being dynamicly loaded), this moves all dependency management to
build time - which prevents runtime library conflict. And because Cargo
is involved and controls all the paths, it can do things such as having
multiple versions available in a single build for different components
and coordinating all these elements.&lt;&#x2F;p&gt;
&lt;p&gt;Now to hop back to npm&#x2F;js. This ecosystem introduced a new concept -
micro-dependencies. This happened because javascript doesn&#x27;t have dead
code elimination. So if given a large utility library, and you call one
function out of 100, you still have to ship all 99 unused ones. This
means they needed a way to manage and distribute hundreds, if not
thousands of tiny libraries, each that did &amp;quot;one thing&amp;quot; so that you
pulled in &amp;quot;exactly&amp;quot; the minimum required (that&#x27;s not how it turned
out ... but it was the intent).&lt;&#x2F;p&gt;
&lt;p&gt;Rust also has inherited a similar culture - not to the same extreme as
npm because Rust DOES have dead code elimination, but still enough that
my concread library with 3 dependencies pulls in 32 dependencies, and
kanidm from it&#x27;s 30 dependencies, pulls in 365 into it&#x27;s graph.&lt;&#x2F;p&gt;
&lt;p&gt;But in a way this also doesn&#x27;t matter - Rust enforces strong typing at
compile time, so changes in libraries are detected before a release (not
after like in C, or dynamic languages), and those versions at build are
used in production due to the static linking.&lt;&#x2F;p&gt;
&lt;p&gt;This has led to a great challenge is distribution packaging for Rust -
there are so many &amp;quot;libraries&amp;quot; that to package them all would be a
monumental piece of human effort, time, and work.&lt;&#x2F;p&gt;
&lt;p&gt;But once again, we see the distribution maintainers, scalpel in hand, a
shine in their eyes looking and thinking &amp;quot;excellent, time to package
365 libraries ...&amp;quot;. In the name of a &amp;quot;supply chain&amp;quot; and adding
&amp;quot;security&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;We have to ask though, is there really &lt;em&gt;value&lt;&#x2F;em&gt; of spending all this time
to package 365 libraries when Rust functions so differently?&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-are-you-getting-at-here&quot;&gt;What are you getting at here?&lt;&#x2F;h2&gt;
&lt;p&gt;To put it clearly - distribution packaging isn&#x27;t a &amp;quot;higher&amp;quot; form of
distributing software. Distribution packages are not the one-true
solution to distribute software. It doesn&#x27;t magically enable
&amp;quot;security&amp;quot;. Distribution Packaging &lt;em&gt;is&lt;&#x2F;em&gt; the C language source and
binary distribution mechanism - and for that it works great!&lt;&#x2F;p&gt;
&lt;p&gt;Now that we can frame it like this we can see &lt;em&gt;why&lt;&#x2F;em&gt; there are so many
challenges when we attempt to package Rust, Python or friends in rpms.&lt;&#x2F;p&gt;
&lt;p&gt;Rust isn&#x27;t C. We can&#x27;t think about Rust like C. We can&#x27;t secure Rust
like C.&lt;&#x2F;p&gt;
&lt;p&gt;Python isn&#x27;t C. We can&#x27;t think about Python like C. We can&#x27;t secure
Python like C.&lt;&#x2F;p&gt;
&lt;p&gt;These languages all have their own quirks, behaviours, flaws, benefits,
and goals. They need to be distributed in unique ways appropriate to
those languages.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;an-example-of-the-mismatch&quot;&gt;An example of the mismatch&lt;&#x2F;h2&gt;
&lt;p&gt;To help drive this home, I want to bring up FreeIPA. FreeIPA has a lot
of challenges in packaging due to it&#x27;s &lt;em&gt;huge&lt;&#x2F;em&gt; number of C, Python and
Java dependencies. Recently on twitter it was annouced that &amp;quot;FreeIPA
has been packaged for debian&amp;quot; as the last barrier (being dogtag&#x2F;java)
was overcome to package the hundreds of required dependencies.&lt;&#x2F;p&gt;
&lt;p&gt;The inevitable outcome of debian now packaging FreeIPA will be:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;FreeIPA will break in some future event as one of the python or java
libraries was changed in a way that was not expected by the
developers or package maintainers.&lt;&#x2F;li&gt;
&lt;li&gt;Other applications may be &amp;quot;held back&amp;quot; from updating at risk&#x2F;fear
of breaking FreeIPA which stifles innovation in the java&#x2F;python
ecosystems surrounding.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;It won&#x27;t be the fault of FreeIPA. It won&#x27;t be the fault of the debian
maintainers. It will be that we are shoving square applications through
round C shaped holes and hoping it works.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;so-what-does-matter&quot;&gt;So what does matter?&lt;&#x2F;h2&gt;
&lt;p&gt;It doesn&#x27;t matter if it&#x27;s Kanidm, FreeIPA, or 389-ds. End users want
to consume &lt;em&gt;applications&lt;&#x2F;em&gt;. How that application is developed, built and
distributed is a secondary concern, and many people will go their whole
lives never knowing how this process works.&lt;&#x2F;p&gt;
&lt;p&gt;We need to stop focusing on packaging &lt;em&gt;libraries&lt;&#x2F;em&gt; and start to focus on
how we distribute &lt;em&gt;applications&lt;&#x2F;em&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;This is why projects like docker and flatpak have surprised traditional
packaging advocates. These tools are about how we ship &lt;em&gt;applications&lt;&#x2F;em&gt;,
and their build and supply chains are separated from these.&lt;&#x2F;p&gt;
&lt;p&gt;This is why I have really started to advocate and say:&lt;&#x2F;p&gt;
&lt;p&gt;Today, distributions should focus on supporting and distributing
&lt;em&gt;applications&lt;&#x2F;em&gt; and work with native language supply chains to enable
this.&lt;&#x2F;p&gt;
&lt;p&gt;Only we accept this shift, we can start to find value in distributions
again as sources of trusted applications, and how we see the
distribution as an application platform rather than a collection of tiny
libraries.&lt;&#x2F;p&gt;
&lt;p&gt;The risk of not doing this is alienating communities (again) from being
involved in our platforms.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;follow-up&quot;&gt;Follow Up&lt;&#x2F;h2&gt;
&lt;p&gt;There have been some major comments since:&lt;&#x2F;p&gt;
&lt;p&gt;First, there is now a C package manager named &lt;a href=&quot;https:&#x2F;&#x2F;conan.io&#x2F;&quot;&gt;conan&lt;&#x2F;a&gt;
. I have no experience with this tool, so at a distance I can only
assume it works well for what it does. However it was noted it&#x27;s not
gained much popularity, likely due to the fact that distro packages are
the current C language distribution channels.&lt;&#x2F;p&gt;
&lt;p&gt;The second was about the security components of distribution packaging
and this - that topic is so long I&#x27;ve written &lt;a href=&quot;..&#x2F;19&#x2F;packaging_and_the_security_proposition.html&quot;&gt;another
post&lt;&#x2F;a&gt; about the topic
instead, to try and keep this post focused on the topic.&lt;&#x2F;p&gt;
&lt;p&gt;Finally, The Fedora Modularity effort is trying to deal with some of
these issues - that modules, aka applications have different cadences
and requirements, and those modules can move more freely from the base
OS.&lt;&#x2F;p&gt;
&lt;p&gt;Some of the challenges have been &lt;a href=&quot;https:&#x2F;&#x2F;lwn.net&#x2F;Articles&#x2F;805180&#x2F;&quot;&gt;explored by
LWN&lt;&#x2F;a&gt; and it&#x27;s worth reading. But I
think the underlying issue is that again we are approaching things in a
way that may not align with reality - people are looking at modules as
libraries, not applications which is causing things to go sideways. And
when those modules are installed, they aren&#x27;t &lt;a href=&quot;https:&#x2F;&#x2F;lwn.net&#x2F;ml&#x2F;fedora-devel&#x2F;4040208.GuUW4P68lE@marvin.jharris.pw&#x2F;&quot;&gt;isolated from each
other&lt;&#x2F;a&gt;
, meaning we are back to square one, with a system designed only for C.
People are &lt;a href=&quot;https:&#x2F;&#x2F;lwn.net&#x2F;ml&#x2F;fedora-devel&#x2F;CAB-QmhSdQ+Gwuf6gnLaiziMY+nxNgTSFaUyzRuJqO6sN7_6wzw@mail.gmail.com&#x2F;&quot;&gt;starting to see
that&lt;&#x2F;a&gt;
but the key point is continually missed - that modularity should be
about &lt;em&gt;applications&lt;&#x2F;em&gt; and their isolation not about &lt;em&gt;multiple library
versions&lt;&#x2F;em&gt;.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Fixing opensuse virtual machines with resume</title>
          <pubDate>Sun, 15 Dec 2019 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2019-12-15-fixing-opensuse-virtual-machines-with-resume/</link>
          <guid>https://fy.blackhats.net.au/blog/2019-12-15-fixing-opensuse-virtual-machines-with-resume/</guid>
          <description>&lt;h1 id=&quot;fixing-opensuse-virtual-machines-with-resume&quot;&gt;Fixing opensuse virtual machines with resume&lt;&#x2F;h1&gt;
&lt;p&gt;Today I hit an unexpected issue - after changing a virtual machines root
disk to scsi, I was unable to boot the machine.&lt;&#x2F;p&gt;
&lt;p&gt;The host is opensuse leap 15.1, and the vm is the same. What&#x27;s
happening!&lt;&#x2F;p&gt;
&lt;p&gt;The first issue appears to be that opensuse 15.1 doesn&#x27;t support scsi
disks from libvirt. I&#x27;m honestly not sure what&#x27;s wrong here.&lt;&#x2F;p&gt;
&lt;p&gt;The second is that by default opensuse leap configures suspend and
resume to disk - by it uses the pci path instead of a swap volume UUID.
So when you change the bus type, it renames the path making the volume
inaccessible. This causes boot to fail.&lt;&#x2F;p&gt;
&lt;p&gt;To work around you can remove &amp;quot;resume=&#x2F;disk&#x2F;path&amp;quot; from the cli. Then
to fix it permanently you need:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;transactional-update shell
&lt;&#x2F;span&gt;&lt;span&gt;vim &#x2F;etc&#x2F;default&#x2F;grub
&lt;&#x2F;span&gt;&lt;span&gt;# Edit this line to remove &amp;quot;resume&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;GRUB_CMDLINE_LINUX_DEFAULT=&amp;quot;console=ttyS0,115200 resume=&#x2F;dev&#x2F;disk&#x2F;by-path&#x2F;pci-0000:00:07.0-part3 splash=silent quiet showopts&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;vim &#x2F;etc&#x2F;default&#x2F;grub_installdevice
&lt;&#x2F;span&gt;&lt;span&gt;# Edit the path to the correct swap location as by ls -al &#x2F;dev&#x2F;disk&#x2F;by-path
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;dev&#x2F;disk&#x2F;by-path&#x2F;pci-0000:00:07.0-part3
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;I have reported these issues, and I hope they are resolved.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Password Quality and Badlisting in Kanidm</title>
          <pubDate>Sat, 07 Dec 2019 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2019-12-07-password-quality-and-badlisting-in-kanidm/</link>
          <guid>https://fy.blackhats.net.au/blog/2019-12-07-password-quality-and-badlisting-in-kanidm/</guid>
          <description>&lt;h1 id=&quot;password-quality-and-badlisting-in-kanidm&quot;&gt;Password Quality and Badlisting in Kanidm&lt;&#x2F;h1&gt;
&lt;p&gt;Passwords are still a required part of any IDM system. As much as I wish
for Kanidm to only support webauthn and stronger authentication types,
at the end of the day devices can be lost, destroyed, some people may
not be able to afford them, some clients aren&#x27;t compatible with them
and more.&lt;&#x2F;p&gt;
&lt;p&gt;This means the current state of the art is still multi-factor auth.
Something you have and something you know.&lt;&#x2F;p&gt;
&lt;p&gt;Despite the presence of the multiple factors, it&#x27;s still important to
quality check passwords. Microsoft&#x27;s Azure security team &lt;a href=&quot;https:&#x2F;&#x2F;techcommunity.microsoft.com&#x2F;t5&#x2F;Azure-Active-Directory-Identity&#x2F;Your-Pa-word-doesn-t-matter&#x2F;ba-p&#x2F;731984&quot;&gt;have written
about
passwords&lt;&#x2F;a&gt;,
and it really drives home the current situation. I would certainly trust
these people at Microsoft to know what they are talking about given the
scale of what they have to defend daily.&lt;&#x2F;p&gt;
&lt;p&gt;The most important take away is that trying to obscure the password from
a bruteforce is a pointless exercise because passwords end up in
password dumps, they get phished, keylogged, and more. MFA matters!&lt;&#x2F;p&gt;
&lt;p&gt;It&#x27;s important here to look at the &amp;quot;easily guessed&amp;quot; and &amp;quot;credential
stuffing&amp;quot; category. That&#x27;s what we really want to defend against with
password quality, and MFA protects us against keylogging, phising (only
webauthn), and reuse.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;can-we-avoid-this&quot;&gt;Can we Avoid This?&lt;&#x2F;h2&gt;
&lt;p&gt;Yes! Kanidm supports a &amp;quot;generated&amp;quot; password that is a long, high
entropy password that should be stored in a password manager or similar
tool to prevent human knowledge. This fits to our &amp;quot;device as
authentication&amp;quot; philosophy. You authenticate to your device (phone,
laptop etc), and then the devices stored passwords authenticate you from
that point on. This has the benefit that devices and password managers
generally perform better checking of the target where we enter the
password, making phising less likely.&lt;&#x2F;p&gt;
&lt;p&gt;But sometimes we can&#x27;t rely on this, so we still need human-known
passwords, so we still take steps to handle these.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;quality&quot;&gt;Quality&lt;&#x2F;h2&gt;
&lt;p&gt;In the darkages, we would decree that human known passwords had to have
a number, symbol, roman numeral, no double letters, one capital letter,
two kanji and no symbols that could be part of an sql injection because
of that one legacy system we can&#x27;t patch.&lt;&#x2F;p&gt;
&lt;p&gt;This lead to people making horrid, un-rememberable passwords in
leetspeak, or giving up altogether and making the excellent
&amp;quot;Password1&amp;quot; (which passes AD minimum password requirements on server
2003).&lt;&#x2F;p&gt;
&lt;p&gt;What we really want is entropy, length, and memorability. Dropbox made a
great library for this called zxcvbn, which has since &lt;a href=&quot;https:&#x2F;&#x2F;docs.rs&#x2F;zxcvbn&#x2F;2.0.0&#x2F;zxcvbn&#x2F;index.html&quot;&gt;been ported to
rust&lt;&#x2F;a&gt; . I highly
recommend it.&lt;&#x2F;p&gt;
&lt;p&gt;This library is great because it focuses on entropy, and then if the
password doesn&#x27;t meet these requirements, the library recommends ways
to improve. This is excellent for human interaction and experience,
guiding people to create better passwords that they can remember, rather
than our outdated advice of the complex passwords as described above.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;badlisting&quot;&gt;Badlisting&lt;&#x2F;h2&gt;
&lt;p&gt;Badlisting is another great technique for improving password quality.
It&#x27;s essentially a blocklist of passwords that people are not allowed
to set. This way you can have corporate-specific breach lists, or the
top 10k most used passwords badlisted to prevent users using them. For
example, &amp;quot;correct horse battery staple&amp;quot; may be a strong password, but
it&#x27;s well known thanks to xkcd.&lt;&#x2F;p&gt;
&lt;p&gt;It&#x27;s also good for preventing password reuse in your company if you are
phished and the credentials privately notified to you as some of the
regional CERT&#x27;s do, allowing you to block these without them being in a
public breach list.&lt;&#x2F;p&gt;
&lt;p&gt;This is important as many bots will attempt to spam these passwords
against accounts (rate limiting auth and soft-locking accounts also
helps to delay these attack styles).&lt;&#x2F;p&gt;
&lt;h2 id=&quot;in-kanidm&quot;&gt;In Kanidm&lt;&#x2F;h2&gt;
&lt;p&gt;In Kanidm, we chose to use both approaches. First we check the password
with zxcvbn, then we ensure it&#x27;s not in a badlist.&lt;&#x2F;p&gt;
&lt;p&gt;In order to minimise the size of the badlist, the badlist uses case
insensitive storage so that multiple variants of &amp;quot;password&amp;quot; and
&amp;quot;PasSWOrD&amp;quot; are only listed once. We also preprocessed the badlist with
zxcvbn to remove any passwords that it would have denied from being
entered. The preprocessor tool will be shipped with kanidm so that
administrators can preprocess their own lists before adding them to the
badlist configuration.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;creating-a-badlist&quot;&gt;Creating a Badlist&lt;&#x2F;h2&gt;
&lt;p&gt;I decided to do some analysis on a well known set of passwords
maintained on the &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;danielmiessler&#x2F;SecLists&#x2F;tree&#x2F;master&#x2F;Passwords&quot;&gt;seclists
repository&lt;&#x2F;a&gt;
. Apparently this is what pentesters reach for when they want to
bruteforce or credential stuff on a domain.&lt;&#x2F;p&gt;
&lt;p&gt;I analysed this in three ways. The first was as a full set of passwords
(about 25 million) and a smaller but &amp;quot;popular&amp;quot; set in the &amp;quot;rockyou&amp;quot;
files which is about 60,000 passwords. Finally I did an analysis of the
rockyou + top 10 million most common (which combined was 1011327 unique
passwords, so about 50k of the rockyou set is from top 10 million).&lt;&#x2F;p&gt;
&lt;p&gt;From the 25 million set I ran this through a preprocessor tool that I
developed for kanidm. It eliminated anything less than a score of 3 and
no length rule. This showed that zxcvbn was able to prevent 80% of these
inputs from being allowed. If I was to ship this full list, this would
contain 4.8 million badlisted passwords. It&#x27;s pretty amazing already
that zxcvbn stops 80% of bad passwords that end up in breaches from
being able to be used, with the remaining 20% likely to be complex
passwords that just got dumped by other means.&lt;&#x2F;p&gt;
&lt;p&gt;However, for the badlist in Kanidm, I decided to start with &amp;quot;what&#x27;s
popular&amp;quot; for now, and to allow sites to add extra content if they
desire. This meant that I focused instead on the &amp;quot;rockyou&amp;quot; password
set instead.&lt;&#x2F;p&gt;
&lt;p&gt;From the rockyou set I did more tests. zxcvbn has a concept of scores,
and we can have policy to request a minimum score is present to allow
the password. I did a score 3 test, a score 3 with min pw len 10 and a
score 4 test. This showed the following results which has the % blocked
by zxcvbn and the no. that passed which will required badlisting as
zxcvbn can&#x27;t detect them (today).&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;TEST     | % blocked | no. passed
&lt;&#x2F;span&gt;&lt;span&gt;---------------------------------
&lt;&#x2F;span&gt;&lt;span&gt; s3      |  98.3%    |  1004
&lt;&#x2F;span&gt;&lt;span&gt; s3 + 10 |  98.9%    |  637
&lt;&#x2F;span&gt;&lt;span&gt; s4      |  99.7%    |  133
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Personally, it&#x27;s quite hilarious that &amp;quot;2fast2furious&amp;quot; passed the
score 3 check, and &amp;quot;30secondstomars&amp;quot; and &amp;quot;dracomalfoy&amp;quot; passed the
score 4 check, but who am I to judge - that&#x27;s what bad lists are for.&lt;&#x2F;p&gt;
&lt;p&gt;More seriously, I found it interesting to see the effect of the check on
length - not only was the preprocessor step faster, but alone that
eliminated ~400 passwords that would have &amp;quot;passed&amp;quot; on score 3.&lt;&#x2F;p&gt;
&lt;p&gt;Finally, from the rockyou + 10m set, the results show the following in
the same conditions.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;TEST     | % blocked | no. passed
&lt;&#x2F;span&gt;&lt;span&gt;---------------------------------
&lt;&#x2F;span&gt;&lt;span&gt; s3      |  89.9%    |  101349
&lt;&#x2F;span&gt;&lt;span&gt; s3 + 10 |  92.4%    |  76425
&lt;&#x2F;span&gt;&lt;span&gt; s4      |  96.5%    |  34696
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This shows that a very &amp;quot;easy&amp;quot; win is to enforce password length, in
addition to entropy checkers like zxcvbn, which are effective to block
92% of the most common passwords in use on a broad set and 98% of what a
pentester will look for (assuming rockyou lists). If you have a high
security environment you should consider setting zxcvbn to request
passwords of score 4 (the maximum), given that on the 10m set it had a
96.5% block rate.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;conclusions&quot;&gt;Conclusions&lt;&#x2F;h2&gt;
&lt;p&gt;You should use zxcvbn, it&#x27;s a great library, which quickly reduces a
huge amount of risk from low quality passwords.&lt;&#x2F;p&gt;
&lt;p&gt;After that your next two strongest controls are password length, and
being able to support badlisting.&lt;&#x2F;p&gt;
&lt;p&gt;Better yet, use MFA like Webauthn as well, and support server-side
generated high-entropy passwords!&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Rust 2020 - helping to get rust deployed</title>
          <pubDate>Thu, 28 Nov 2019 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2019-11-28-rust-2020-helping-to-get-rust-deployed/</link>
          <guid>https://fy.blackhats.net.au/blog/2019-11-28-rust-2020-helping-to-get-rust-deployed/</guid>
          <description>&lt;h1 id=&quot;rust-2020-helping-to-get-rust-deployed&quot;&gt;Rust 2020 - helping to get rust deployed&lt;&#x2F;h1&gt;
&lt;p&gt;This is my contribution to Rust 2020, where community members put
forward ideas on what they thing Rust should aim to achieve in 2020.&lt;&#x2F;p&gt;
&lt;p&gt;In my view, Rust has had an amazing adoption by developers, and is great
if you are in a position to deploy it in your own infrastructure, but we
have yet to really see Rust make it to broad low-level components (IE in
a linux distro or other infrastructure).&lt;&#x2F;p&gt;
&lt;p&gt;As someone who works on &amp;quot;enterprise&amp;quot; software (389-ds) and my own IDM
project (kanidm), there is a need to have software packaged and
distributed. We can not ask our consumers to build and compile these
tools. One could view it as a chain, where I develop software in a
language, it&#x27;s packaged for a company (like SUSE), and then consumed by
a customer (could be anyone!) who provides a service to others (indirect
users).&lt;&#x2F;p&gt;
&lt;p&gt;Rust however has always been modeled that there is no &amp;quot;middle&amp;quot;
section. You have either a developer who&#x27;s intent is to develop for
other developers. This is where Rust ideas like crates.io becomes
involved. Alternately, you have a larger example in firefox, where
developers build a project and can &amp;quot;bundle&amp;quot; everything into a whole
unit that is then distributed directly to customers.&lt;&#x2F;p&gt;
&lt;p&gt;The major difference is that in the intermediate distribution case, we
have to take on different responsibilities such as security auditing,
building, ensuring dependencies exist etc.&lt;&#x2F;p&gt;
&lt;p&gt;So this leads me to:&lt;&#x2F;p&gt;
&lt;h2 id=&quot;1-cargo-vendor-needs-some-love&quot;&gt;1: Cargo Vendor Needs Some Love&lt;&#x2F;h2&gt;
&lt;p&gt;Cargo vendor today is quite confusing in some scenarios, and it&#x27;s not
clear how to have it work for projects that require offline builds. I
have raised issues about this, but largely they have been un-acted upon.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;2-cargo-is-difficult-to-use-in-mixed-language-projects&quot;&gt;2: Cargo is Difficult to Use in Mixed Language Projects&lt;&#x2F;h2&gt;
&lt;p&gt;A large value proposition of Rust is the ability to use it with FFI and
C. This is great if you say have cargo compile your C code for you.&lt;&#x2F;p&gt;
&lt;p&gt;But most major existing projects don&#x27;t. They use autotools, cmake, or
maybe even meson or more esoteric, waf (looking at you samba). Cargo&#x27;s
extreme opinionation in this area makes it extremely difficult to
integrate Rust into an existing build system reliably. It&#x27;s hard to
point to one fault, as much as a broader &amp;quot;lack of concern&amp;quot; in the
space, and I think cargo needs to evolve improvements to help allow Rust
to be used from other build tools.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;3-rust-moves-too-fast&quot;&gt;3: Rust Moves Too Fast&lt;&#x2F;h2&gt;
&lt;p&gt;A lot of &amp;quot;slower&amp;quot; enterprise companies want to move slowly, including
compiler versions. Admittedly, this conservative behaviour is because of
the historical instability of gcc versions and how it can change or
affect your code between releases. Rust doesn&#x27;t suffer this, but people
are still wary of fast version changes. This means Rustc + Cargo will
get pinned to some version that may be 6 months old.&lt;&#x2F;p&gt;
&lt;p&gt;However crate authors don&#x27;t consider this - they will use the latest
and greatest features from stable (and sometimes still nightly ...
grrr) in releases. Multiple times I have found that on my development
environment even with a 3 month old compiler, dependencies won&#x27;t build.&lt;&#x2F;p&gt;
&lt;p&gt;Compounding this, crates.io doesn&#x27;t distinguish a security release from
a feature one. Crates also encourages continuall version bumping, rather
than maintenence of versioned branches. IE version 0.4.3 of a crate with
a security fix will become 0.4.4, but then a feature update to include
try_from may go to 0.4.5 as it &amp;quot;adds&amp;quot; to the api, or they use it
internally as a cleanup.&lt;&#x2F;p&gt;
&lt;p&gt;Part of this issue is that Rust applications need to be treated closer
to docker, as static whole units where only the resulting binary is
supported rather than the toolchain that built it. But that only works
on pure Rust applications - any mixed C + Rust application will hit this
issue due to the difference between a system Rust version and what crate
dependencies publish.&lt;&#x2F;p&gt;
&lt;p&gt;So I think that from this it leads to:&lt;&#x2F;p&gt;
&lt;h2 id=&quot;3-1-crates-need-to-indicate-a-minimum-supported-compiler-version&quot;&gt;3.1: Crates need to indicate a minimum supported compiler version&lt;&#x2F;h2&gt;
&lt;p&gt;Rust has &amp;quot;toyed&amp;quot; with the idea of editions, but within 2018 we&#x27;ve
seen new features like maybeuninit and try_from land, which within an
&amp;quot;edition&amp;quot; caused crates to stop worked on older compilers.&lt;&#x2F;p&gt;
&lt;p&gt;As a result, editions I think is &amp;quot;too broad&amp;quot; and people will fear
incrementing it, and Rust will add features without changing edition
anyway. Instead Rust needs to consider following up on the minimum
supported rust version flag RFC. Rust has made it pretty clear the only
&amp;quot;edition&amp;quot; flag that matters is the rust compiler version based on
crate developers and what they are releasing.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;3-2-rust-needs-to-think-what-s-our-end-goal&quot;&gt;3.2: Rust Needs to Think &amp;quot;What&#x27;s Our End Goal&amp;quot;&lt;&#x2F;h2&gt;
&lt;p&gt;Rust is still moving incredibly fast, and I think in a way we need to
ask ... when will Rust be finished? When will it as a language go from
continually rapid growth to stable and known feature sets? The idea of
Rust editions acts as though this has happened (saying we change only
every few years) when this is clearly not the case. Rust is evolving
release-on-release, every 6 weeks.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;4-zero-cost-needs-to-factor-in-human-cost&quot;&gt;4: Zero Cost Needs to Factor in Human Cost&lt;&#x2F;h2&gt;
&lt;p&gt;My final wish for Rust is that sometimes we are so obsessed with the
technical desire for zero cost abstraction, that we forget the high
human cost and barriers that can exist as a result making feature
adoption challenging. Rust has had a great community that treats people
very well, and I think sometimes we need to extend that into feature
development, to really consider the human cognitive cost of a feature.&lt;&#x2F;p&gt;
&lt;p&gt;Summarised - what&#x27;s the benefit of a zero cost abstraction if people
can not work out how to use it?&lt;&#x2F;p&gt;
&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;&#x2F;h2&gt;
&lt;p&gt;I want to see Rust become a major part of operating systems and how we
build computer systems, but I think that we need to pace ourselves,
improve our tooling, and have some better ideas around what Rust should
look like.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Recovering LVM when a device is missing with a cache pool lv</title>
          <pubDate>Tue, 26 Nov 2019 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2019-11-26-recovering-lvm-when-a-device-is-missing-with-a-cache-pool-lv/</link>
          <guid>https://fy.blackhats.net.au/blog/2019-11-26-recovering-lvm-when-a-device-is-missing-with-a-cache-pool-lv/</guid>
          <description>&lt;h1 id=&quot;recovering-lvm-when-a-device-is-missing-with-a-cache-pool-lv&quot;&gt;Recovering LVM when a device is missing with a cache pool lv&lt;&#x2F;h1&gt;
&lt;p&gt;I had a heartstopping moment today: my after running a command lvm
proudly annouced it had removed an 8TB volume containing all of my
virtual machine backing stores.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;everyone-a-short-view-back-to-the-past&quot;&gt;Everyone, A short view back to the past ...&lt;&#x2F;h2&gt;
&lt;p&gt;I have a home server, with the configured storage array of:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;2x 8TB SMR (Shingled Magnetic Recording) archive disks (backup
target)&lt;&#x2F;li&gt;
&lt;li&gt;2x 8TB disks (vm backing store)&lt;&#x2F;li&gt;
&lt;li&gt;2x 1TB nvme SSD (os + cache)&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;The vm backing store also had a lvm cache segment via the nvme ssds in a
raid 1 configuration. This means that the 2x8TB drives are in raid 1,
and a partition on each of the nvme devices are in raid 1, then they are
composed to allow the nvme to cache blocks from&#x2F;to the 8TB array.&lt;&#x2F;p&gt;
&lt;p&gt;Two weeks ago I noticed one of the nvme drives was producing IO errors
indicating a fault of the device. Not wanting to risk corruption or
other issues from growing out of hand, I immediately shutdown the
machine and identified the nvme disk with the error.&lt;&#x2F;p&gt;
&lt;p&gt;At this stage I took the precaution of imaging (dd) both the good and
bad nvme devices to the archive array. Subsequently I completed a secure
erase of the faulty nvme drive before returning it to the vendor for
RMA.&lt;&#x2F;p&gt;
&lt;p&gt;I then left the server offline as I was away from my home for more than
a week and would not need, and was unable to monitor if the other drives
would produce further errors.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;returning-home&quot;&gt;Returning home ...&lt;&#x2F;h2&gt;
&lt;p&gt;I decided to ignore William of the past (always a bad idea) and to
&amp;quot;break&amp;quot; the raid on the remaining nvme device so that my server could
operate allowing me some options for work related tasks.&lt;&#x2F;p&gt;
&lt;p&gt;This is an annoying process in lvm - you need to remove the missing
device from the volume group as well as indicating to the array that it
should no longer be in a raid state. This vgreduce is only for removing
missing PV&#x27;s, it shouldn&#x27;t be doing anything else.&lt;&#x2F;p&gt;
&lt;p&gt;I initiated the raid break process on the home, root and swap devices.
The steps are:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;vgreduce --removemissing &amp;lt;vgname&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;lvconvert -m0 &amp;lt;vgname&amp;gt;&#x2F;&amp;lt;lvname&amp;gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This occured without fault due to being present on an isolated
&amp;quot;system&amp;quot; volume group, so the partial lvs were untouched and left on
the remaining pv in the vg.&lt;&#x2F;p&gt;
&lt;p&gt;When I then initiated this process on the &amp;quot;data&amp;quot; vg which contained
the libvirt backing store, vgreduce gave me the terrifying message:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;Removing logical volume &amp;quot;libvirt_t2&amp;quot;.
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Oh no ~&lt;&#x2F;p&gt;
&lt;h2 id=&quot;recovery-attempts&quot;&gt;Recovery Attempts&lt;&#x2F;h2&gt;
&lt;p&gt;When a logical volume is removed, it can be recovered as lvm stores
backups of the LVM metadata state in &#x2F;etc&#x2F;lvm&#x2F;archive.&lt;&#x2F;p&gt;
&lt;p&gt;My initial first reaction was that I was on a live disk, so I needed to
backup this content else it would be lost on reboot. I chose to put this
on the unaffected, and healthy SMR archive array.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;mount &#x2F;dev&#x2F;mapper&#x2F;archive-backup &#x2F;archive
&lt;&#x2F;span&gt;&lt;span&gt;cp -a &#x2F;etc&#x2F;lvm &#x2F;archive&#x2F;lvm-backup
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;At this point I knew that randomly attempting commands would cause
&lt;em&gt;further damage&lt;&#x2F;em&gt; and likely &lt;em&gt;prevent any ability to recover&lt;&#x2F;em&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;The first step was to activate ssh so that I could work from my laptop -
rather than the tty with keyboard and monitor on my floor. It also means
you can copy paste, which reduces errors. Remember, I&#x27;m booted on a
live usb, which is why I reset the password.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# Only needed in a live usb.
&lt;&#x2F;span&gt;&lt;span&gt;passwd
&lt;&#x2F;span&gt;&lt;span&gt;systemctl start sshd
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;I then formulated a plan and wrote it out. This helps to ensure that
I&#x27;ve thought through the recovery process and the risks, it helps be to
be fully aware of the situation.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;vim recovery-plan.txt
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Into this I laid out the commands I would follow. Here is the plan:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;bytes 808934440960
&lt;&#x2F;span&gt;&lt;span&gt;data_00001-2096569583
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;dd if=&#x2F;dev&#x2F;zero of=&#x2F;mnt&#x2F;lv_temp bs=4096 count=197493760
&lt;&#x2F;span&gt;&lt;span&gt;losetup &#x2F;dev&#x2F;loop10 &#x2F;mnt&#x2F;lv_temp
&lt;&#x2F;span&gt;&lt;span&gt;pvcreate --restorefile &#x2F;etc&#x2F;lvm&#x2F;archive&#x2F;data_00001-2096569583.vg --uuid iC4G41-PSFt-6vqp-GC0y-oN6T-NHnk-ivssmg &#x2F;dev&#x2F;loop10
&lt;&#x2F;span&gt;&lt;span&gt;vgcfgrestore data --test --file &#x2F;etc&#x2F;lvm&#x2F;archive&#x2F;data_00001-2096569583.vg
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now to explain this: The situation we are in is:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;We have a removed data&#x2F;libvirt_t2 logical volume&lt;&#x2F;li&gt;
&lt;li&gt;The VG data is missing a single PV (nvme0). It still has three PVs
(nvme1, sda1, sdb1).&lt;&#x2F;li&gt;
&lt;li&gt;We can not restore metadata unless all devices are present as per
the vgcfgrestore man page.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;This means, we need to make a replacement device to replace into the
array, and then to restore the metadata with that.&lt;&#x2F;p&gt;
&lt;p&gt;The &amp;quot;bytes&amp;quot; section you see, is the &lt;em&gt;size&lt;&#x2F;em&gt; of the missing nvme0
partition that was a member of this array - we need to create a loopback
device of the same or greater size to allow us to restore the metadata.
(dd, losetup)&lt;&#x2F;p&gt;
&lt;p&gt;Once the loopback is created, we can then recreate the pv on the
loopback device with the same UUID as the missing device.&lt;&#x2F;p&gt;
&lt;p&gt;Once this is present, we can now restore the metadata as documented
which should contain the logical volume.&lt;&#x2F;p&gt;
&lt;p&gt;I ran these steps and it was all great until vgcfgrestore. I can not
remember the exact error but it was along the lines of:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;Unable to restore metadata as PV was missing for VG when last modification was performed.
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Yep, the vgreduce command has changed the VG state, triggering a
metadata backup, but because a device was missing at the time, we can
not restore this metadata.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;options&quot;&gt;Options ...&lt;&#x2F;h2&gt;
&lt;p&gt;At this point I had to consider alternate options. I conducted research
into this topic as well to see if others had encountered this case (no
one has ever not been able to restore their metadata apparently in this
case ...). The options that I arrived at:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;Restore the metadata from the nvme &#x2F;root as it has older (but
known) states - however I had recently expanded the libvirt_t2
volume from a live disk, meaning it may not have the correct
part sizes.&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;ol start=&quot;2&quot;&gt;
&lt;li&gt;Attempt to extract the xfs filesystem with DD from the disk to
begin a data recovery.&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;ol start=&quot;3&quot;&gt;
&lt;li&gt;Cry in a corner&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;ol start=&quot;4&quot;&gt;
&lt;li&gt;Use lvcreate with the &amp;quot;same paramaters&amp;quot; and hope that it
aligns the start at the same location as the former
data&#x2F;libvirt_t2 allowing the xfs filesystem to be accessed.&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;All of these weren&#x27;t good - especially not 3.&lt;&#x2F;p&gt;
&lt;p&gt;I opted to attempt solution 1, and then if that failed, I would
disconnect one of the 8TB disks, attempt solution 4, then if that ALSO
failed, I would then attempt 2, finally all else lost I would begin
solution 3. The major risk of relying on 4 and 2 is that LVM has dynamic
geometry on disk, it does not always allocate contiguously. This means
that attempting 4 with lvcreate may not create with the same geometry,
and it may write to incorrect locations causing dataloss. The risk of 2
was again, due to the dynamic geometry what we recover may be
re-arranged and corrupt.&lt;&#x2F;p&gt;
&lt;p&gt;This mean option 1 was the best way to proceed.&lt;&#x2F;p&gt;
&lt;p&gt;I mounted the &#x2F;root volume of the host and using the lvm archive I was
able to now restore the metadata.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;vgcfgrestore data --test --file &#x2F;system&#x2F;etc&#x2F;lvm&#x2F;archive&#x2F;data_00004-xxxx.vg
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Once completed I performed an lvscan to refresh what block devices were
available. I was then shown that every member of the VG data had
conflicting seqno, and that the metadata was corrupt and unable to
proceed.&lt;&#x2F;p&gt;
&lt;p&gt;Somehow we&#x27;d made it worse :(&lt;&#x2F;p&gt;
&lt;h2 id=&quot;successful-procedure&quot;&gt;Successful Procedure&lt;&#x2F;h2&gt;
&lt;p&gt;At this point, faced with 3 options that were all terrible, I started to
do more research. I finally discovered a post describing that the lvm
metadata is stored on disk in the same format as the .vg files in the
archive, and it&#x27;s a ring buffer. We may be able to restore from these.&lt;&#x2F;p&gt;
&lt;p&gt;To do so, you must &lt;em&gt;dd&lt;&#x2F;em&gt; out of the disk into a file, and then manipulate
the file to only contain a single metadata entry.&lt;&#x2F;p&gt;
&lt;p&gt;Remember how I made images of my disks before I sent them back? This was
their time to shine.&lt;&#x2F;p&gt;
&lt;p&gt;I did do a recovery plan with these commands too, but it was more
evolving due to the paramaters involved so it changed frequently with
the offsets. The plan was very similar to above - use a loop device as a
stand in for the missing block device, restore the metadata, and then go
from there.&lt;&#x2F;p&gt;
&lt;p&gt;We know that LVM metadata occurs in the first section of the disk, just
after the partition start. So to work out where this is we use gdisk to
show the partitions in the backup image.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# gdisk &#x2F;mnt&#x2F;mion.nvme0n1.img
&lt;&#x2F;span&gt;&lt;span&gt;GPT fdisk (gdisk) version 1.0.4
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Command (? for help): p
&lt;&#x2F;span&gt;&lt;span&gt;Disk &#x2F;mnt&#x2F;mion.nvme0n1.img: 2000409264 sectors, 953.9 GiB
&lt;&#x2F;span&gt;&lt;span&gt;Sector size (logical): 512 bytes
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Number  Start (sector)    End (sector)  Size       Code  Name
&lt;&#x2F;span&gt;&lt;span&gt;   1            2048         1026047   500.0 MiB   EF00
&lt;&#x2F;span&gt;&lt;span&gt;   2         1026048       420456447   200.0 GiB   8E00
&lt;&#x2F;span&gt;&lt;span&gt;   3       420456448      2000409230   753.4 GiB   8E00
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;It&#x27;s important to note the sector size flag, as well as the fact the
output is in sectors.&lt;&#x2F;p&gt;
&lt;p&gt;The LVM header occupies 255 sectors after the start of the partition. So
this in mind we can now create a dd command to extract the needed
information.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;dd if=&#x2F;mnt&#x2F;mion.nvme0n1.img of=&#x2F;tmp&#x2F;lvmmeta bs=512 count=255 skip=420456448
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;bs sets the sector size to 512, count will read from the start up to 255
sectors of size &#x27;bs&#x27;, and skip says to start reading after &#x27;skip&#x27; *
&#x27;sector&#x27;.&lt;&#x2F;p&gt;
&lt;p&gt;At this point, we can now copy this and edit the file:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;cp &#x2F;tmp&#x2F;lvmmeta &#x2F;archive&#x2F;lvm.meta.edit
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Within this file you can see the ring buffer of lvm metadata. You need
to find the highest seqno that is a &lt;em&gt;complete record&lt;&#x2F;em&gt;. For example, my
seqno = 20 was partial (is the lvm meta longer than 255, please contact
me if you know!), but seqno=19 was complete.&lt;&#x2F;p&gt;
&lt;p&gt;Here is the region:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# ^ more data above.
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;# Generated by LVM2 version 2.02.180(2) (2018-07-19): Mon Nov 11 18:05:45 2019
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;contents = &amp;quot;Text Format Volume Group&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;version = 1
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;description = &amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;creation_host = &amp;quot;linux-p21s&amp;quot;    # Linux linux-p21s 4.12.14-lp151.28.25-default #1 SMP Wed Oct 30 08:39:59 UTC 2019 (54d7657) x86_64
&lt;&#x2F;span&gt;&lt;span&gt;creation_time = 1573459545      # Mon Nov 11 18:05:45 2019
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@data {
&lt;&#x2F;span&gt;&lt;span&gt;id = &amp;quot;4t86tq-3DEW-VATS-1Q5x-nLLy-41pR-zEWwnr&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;seqno = 19
&lt;&#x2F;span&gt;&lt;span&gt;format = &amp;quot;lvm2&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;So from there you remove everything above &amp;quot;contents = ...&amp;quot;, and clean
up the vgname header. It should look something like this.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;contents = &amp;quot;Text Format Volume Group&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;version = 1
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;description = &amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;creation_host = &amp;quot;linux-p21s&amp;quot;    # Linux linux-p21s 4.12.14-lp151.28.25-default #1 SMP Wed Oct 30 08:39:59 UTC 2019 (54d7657) x86_64
&lt;&#x2F;span&gt;&lt;span&gt;creation_time = 1573459545      # Mon Nov 11 18:05:45 2019
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;data {
&lt;&#x2F;span&gt;&lt;span&gt;id = &amp;quot;4t86tq-3DEW-VATS-1Q5x-nLLy-41pR-zEWwnr&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;seqno = 19
&lt;&#x2F;span&gt;&lt;span&gt;format = &amp;quot;lvm2&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Similar, you need to then find the bottom of the segment (look for the
next highest seqno) and remove everything &lt;em&gt;below&lt;&#x2F;em&gt; the line: &amp;quot;#
Generated by LVM2 ...&amp;quot;&lt;&#x2F;p&gt;
&lt;p&gt;Now, you can import this metadata to the loop device for the missing
device. Note I had to wipe the former lvm meta segment due to the
previous corruption, which caused pvcreate to refuse to touch the
device.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;dd if=&#x2F;dev&#x2F;zero of=&#x2F;dev&#x2F;loop10 bs=512 count=255
&lt;&#x2F;span&gt;&lt;span&gt;pvcreate --restorefile lvmmeta.orig.nvme1.edited --uuid iC4G41-PSFt-6vqp-GC0y-oN6T-NHnk-ivssmg &#x2F;dev&#x2F;loop10
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now you can do a dry run:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;vgcfgrestore --test -f lvmmeta.orig.nvme1.edited data
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;And the real thing:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;vgcfgrestore -f lvmmeta.orig.nvme1.edited data
&lt;&#x2F;span&gt;&lt;span&gt;lvscan
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Hooray! We have volumes! Let&#x27;s check them, and ensure their filesystems
are sane:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;lvs
&lt;&#x2F;span&gt;&lt;span&gt;lvchange -ay data&#x2F;libvirt_t2
&lt;&#x2F;span&gt;&lt;span&gt;xfs_repair -n &#x2F;dev&#x2F;mapper&#x2F;data-libvirt_t2
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If xfs_repair says no errors, then go ahead and mount!&lt;&#x2F;p&gt;
&lt;p&gt;At this point, lvm started to resync the raid, so I&#x27;ll leave that to
complete before I take any further action to detach the loopback device.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;how-to-handle-this-next-time&quot;&gt;How to Handle This Next Time&lt;&#x2F;h2&gt;
&lt;p&gt;The cause of this issue really comes from vgreduce --removemissing
removing the device when a cache member can&#x27;t be found. I plan to
report this as a bug.&lt;&#x2F;p&gt;
&lt;p&gt;However another key challenge was the inability to restore the lvm
metadata when the metadata archive reported a missing device. This is
what stopped me from being able to restore the array in the first place,
even though I had a &amp;quot;fake&amp;quot; replacement. This is also an issue I intend
to raise.&lt;&#x2F;p&gt;
&lt;p&gt;Next time I would:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Activate the array as a partial&lt;&#x2F;li&gt;
&lt;li&gt;Remove the cache device first&lt;&#x2F;li&gt;
&lt;li&gt;Then stop the raid&lt;&#x2F;li&gt;
&lt;li&gt;Then perform the vgreduction&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;I really hope this doesn&#x27;t happen to you!&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Upgrading OpenSUSE 15.0 to 15.1</title>
          <pubDate>Wed, 25 Sep 2019 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2019-09-25-upgrading-opensuse-15-0-to-15-1/</link>
          <guid>https://fy.blackhats.net.au/blog/2019-09-25-upgrading-opensuse-15-0-to-15-1/</guid>
          <description>&lt;h1 id=&quot;upgrading-opensuse-15-0-to-15-1&quot;&gt;Upgrading OpenSUSE 15.0 to 15.1&lt;&#x2F;h1&gt;
&lt;p&gt;It&#x27;s a little bit un-obvious how to do this. You have to edit the repo
files to change the release version, then refresh + update.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;sed -ri &amp;#39;s&#x2F;15\.0&#x2F;15.1&#x2F;&amp;#39; &#x2F;etc&#x2F;zypp&#x2F;repos.d&#x2F;*.repo
&lt;&#x2F;span&gt;&lt;span&gt;zypper ref
&lt;&#x2F;span&gt;&lt;span&gt;zypper dup
&lt;&#x2F;span&gt;&lt;span&gt;reboot
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Note this works on a transactional host too:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;sed -ri &amp;#39;s&#x2F;15\.0&#x2F;15.1&#x2F;&amp;#39; &#x2F;etc&#x2F;zypp&#x2F;repos.d&#x2F;*.repo
&lt;&#x2F;span&gt;&lt;span&gt;transactional-update dup
&lt;&#x2F;span&gt;&lt;span&gt;reboot
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;It would be nice if these was an upgrade tool that would attempt the
upgrade and revert the repo files, or use temporary repo files for the
upgrade though. It would be a bit nicer as a user experience than sed of
the repo files.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Announcing Kanidm - A new IDM project</title>
          <pubDate>Wed, 18 Sep 2019 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2019-09-18-announcing-kanidm-a-new-idm-project/</link>
          <guid>https://fy.blackhats.net.au/blog/2019-09-18-announcing-kanidm-a-new-idm-project/</guid>
          <description>&lt;h1 id=&quot;announcing-kanidm-a-new-idm-project&quot;&gt;Announcing Kanidm - A new IDM project&lt;&#x2F;h1&gt;
&lt;p&gt;Today I&#x27;m starting to talk about my new project - Kanidm. Kanidm is an
IDM project designed to be correct, simple and scalable. As an IDM
project we should be able to store the identities and groups of people,
authenticate them securely to various other infrastructure components
and services, and much more.&lt;&#x2F;p&gt;
&lt;p&gt;You can find the source for &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;Firstyear&#x2F;kanidm&#x2F;blob&#x2F;master&#x2F;README.md&quot;&gt;kanidm on
github&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;For more details about what the project is planning to achieve, and what
we have already implemented please see the github.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-about-389-directory-server&quot;&gt;What about 389 Directory Server&lt;&#x2F;h2&gt;
&lt;p&gt;I&#x27;m still part of the project, and working hard on making it the best
LDAP server possible. Kanidm and 389-ds have different goals. 389
Directory Server is a globally scalable, distributed database, that can
store huge amounts of data and process thousands of operations per
second. 389-ds let&#x27;s you build a system ontop, in any way you want. If
you want an authentication system today, use 389-ds. We are even working
on a self-service web portal soon too (one of our most requested
features!). Besides my self, no one on the (amazing) 389 DS team has any
association with kanidm (yet?).&lt;&#x2F;p&gt;
&lt;p&gt;Kanidm is an opinionated IDM system, and has strong ideas about how
authentication and users should be processed. We aim to be scalable, but
that&#x27;s a long road ahead. We also want to have more web integrations,
client tools and more. We&#x27;ll eventually write a kanidm to 389-ds sync
tool.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;why-not-integrate-something-with-389-why-something-new&quot;&gt;Why not integrate something with 389? Why something new?&lt;&#x2F;h2&gt;
&lt;p&gt;There are a lot of limitations with LDAP when it comes to modern
web-focused auth processes such as webauthn. Because of this, I wanted
to make something that didn&#x27;t have the same limitations, and had
different ideas about data storage and apis. That&#x27;s why I wanted to
make something new in parallel. It was a really hard decision to want to
make something outside of 389 Directory Server (Because I really do love
the project, and have great pride in the team), but I felt like it was
going to be more productive to build in parallel, than ontop.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;when-will-it-be-ready&quot;&gt;When will it be ready?&lt;&#x2F;h2&gt;
&lt;p&gt;I think that a single-server deployment will be usable for small
installations early 2020, and a fully fledged system with replication
would be late 2020. It depends on how much time I have and what parts I
implement in what order. Current rough work order (late 2019) is
indexing, RADIUS integration, claims, and then self-service&#x2F;web ui.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>OpenSUSE leap as a virtualisation host</title>
          <pubDate>Mon, 02 Sep 2019 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2019-09-02-opensuse-leap-as-a-virtualisation-host/</link>
          <guid>https://fy.blackhats.net.au/blog/2019-09-02-opensuse-leap-as-a-virtualisation-host/</guid>
          <description>&lt;h1 id=&quot;opensuse-leap-as-a-virtualisation-host&quot;&gt;OpenSUSE leap as a virtualisation host&lt;&#x2F;h1&gt;
&lt;p&gt;I&#x27;ve been rebuilding my network to use SUSE from CentOS, and the final
server was my hypervisor. Most of the reason for this is the change in
my employment, so I feel it&#x27;s right to dogfood for my workplace.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-you-will-need&quot;&gt;What you will need&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Some computer parts (assembaly may be required)&lt;&#x2F;li&gt;
&lt;li&gt;OpenSUSE LEAP 15.1 media (dd if=opensuse.iso of=&#x2F;dev&#x2F;a_usb_i_hope)&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;what-are-we-aiming-for&quot;&gt;What are we aiming for?&lt;&#x2F;h2&gt;
&lt;p&gt;My new machine has dual NVME and dual 8TB spinning disks. The intent is
to have the OS on the NVME and to have a large part of the NVME act as
LVM cache for the spinning disk. The host won&#x27;t run any applications
beside libvirt, and has to connect a number of vlans over a link
aggregation.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;useful-commands&quot;&gt;Useful commands&lt;&#x2F;h2&gt;
&lt;p&gt;Through out this document I&#x27;ll assume some details about your devices
and partitions. To find your own, and to always check and confirm what
you are doing, some command will help:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;lsblk  # Shows all block storage devices, and how (if) they are mounted.
&lt;&#x2F;span&gt;&lt;span&gt;lvs  # shows all active logical volumes
&lt;&#x2F;span&gt;&lt;span&gt;vgs  # shows all active volume groups
&lt;&#x2F;span&gt;&lt;span&gt;pvs  # shows all active physical volumes
&lt;&#x2F;span&gt;&lt;span&gt;dmidecode  # show hardware information
&lt;&#x2F;span&gt;&lt;span&gt;ls -al &#x2F;dev&#x2F;disk&#x2F;by-&amp;lt;ID TYPE&amp;gt;&#x2F;  # how to resolve disk path to a uuid etc.
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;I&#x27;m going to assume you have devices like:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;dev&#x2F;nvme0  # the first nvme of your system that you install to.
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;dev&#x2F;nvme1  # the second nvme, used later
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;dev&#x2F;sda    # Two larger block storage devices.
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;dev&#x2F;sdb
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;install&quot;&gt;Install&lt;&#x2F;h2&gt;
&lt;p&gt;Install and follow the prompts. Importantly when you install you install
to a single NVME, and choose transactional server + lvm, then put btrfs
on the &#x2F;root in the lvm. You want to partition such that there is free
space still in the NVME - I left about 400GB unpartitioned for this. In
other words, the disk should be like:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;[ &#x2F;efi | pv + vg system               | pv (unused) ]
&lt;&#x2F;span&gt;&lt;span&gt;       | &#x2F;root (btrfs), &#x2F;boot, &#x2F;home  |
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Remember to leave about 1GB of freespace on the vg system to allow raid
1 metadata later!&lt;&#x2F;p&gt;
&lt;p&gt;Honestly, it may take you a try or two to get this right with YaST, and
it was probably the trickiest part of the install.&lt;&#x2F;p&gt;
&lt;p&gt;You should also select that network management is via networkmanager,
not wicked. You may want to enable ssh here. I disabled the firewall
personally because there are no applications and it interfers with the
bridging for the vms.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;packages&quot;&gt;Packages&lt;&#x2F;h2&gt;
&lt;p&gt;Because this is suse transactional we need to add packages and reboot
each time. Here is what I used, but you may find you don&#x27;t need
everything here:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;transactional-update pkg install libvirt libvirt-daemon libvirt-daemon-qemu \
&lt;&#x2F;span&gt;&lt;span&gt;  sssd sssd-ad sssd-ldap sssd-tools docker zsh ipcalc python3-docker rdiff-backup \
&lt;&#x2F;span&gt;&lt;span&gt;  vim rsync iotop tmux fwupdate fwupdate-efi bridge-utils qemu-kvm apcupsd
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Reboot, and you are ready to partition.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;partitioning-post-install&quot;&gt;Partitioning - post install&lt;&#x2F;h2&gt;
&lt;p&gt;First, copy your gpt from the first NVME to the second. You can do this
by hand with:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;gdisk &#x2F;dev&#x2F;nvme0
&lt;&#x2F;span&gt;&lt;span&gt;p
&lt;&#x2F;span&gt;&lt;span&gt;q
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;gdisk &#x2F;dev&#x2F;nvme1
&lt;&#x2F;span&gt;&lt;span&gt;c
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;duplicate the parameters as required&amp;gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now we&#x27;ll make your &#x2F;efi at least a little redundant&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;mkfs.fat &#x2F;dev&#x2F;nvme1p0
&lt;&#x2F;span&gt;&lt;span&gt;ls -al &#x2F;dev&#x2F;disk&#x2F;by-uuid&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;# In the above, look for your new &#x2F;efi fs, IE CE0A-2C1D -&amp;gt; ..&#x2F;..&#x2F;nvme1n1p1
&lt;&#x2F;span&gt;&lt;span&gt;# Now add a line to &#x2F;etc&#x2F;fstab like:
&lt;&#x2F;span&gt;&lt;span&gt;UUID=CE0A-2C1D    &#x2F;boot&#x2F;efi2              vfat   defaults                      0  0
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now to really make this work, because it&#x27;s transactional, you have to
make a change to the &#x2F;root, which is readonly! To do this run&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;transactional-update shell dup
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This put&#x27;s you in a shell at the end. Run:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;mkdir &#x2F;boot&#x2F;efi2
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now reboot. After the reboot your second efi should be mounted. rsync
&#x2F;boot&#x2F;efi&#x2F;* to &#x2F;boot&#x2F;efi2&#x2F;. I leave it to the reader to decide how to
sync this periodically.&lt;&#x2F;p&gt;
&lt;p&gt;Next you can setup the raid 1 mirror for &#x2F;root and the system vg.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;pvcreate &#x2F;dev&#x2F;nvme1p1
&lt;&#x2F;span&gt;&lt;span&gt;vgextend system &#x2F;dev&#x2F;nvme1p1
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now we have enough pvs to make a raid 1, so we convert all our volumes:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;lvconvert --type raid1 --mirrors 1 system&#x2F;home
&lt;&#x2F;span&gt;&lt;span&gt;lvconvert --type raid1 --mirrors 1 system&#x2F;root
&lt;&#x2F;span&gt;&lt;span&gt;lvconvert --type raid1 --mirrors 1 system&#x2F;boot
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If this fails with &amp;quot;not enough space to alloc metadata&amp;quot;, it&#x27;s because
you didn&#x27;t leave space on the vg during install. Honestly, I made this
mistake twice due to confusion about things leading to two reinstalls
...&lt;&#x2F;p&gt;
&lt;h2 id=&quot;getting-ready-to-cache&quot;&gt;Getting ready to cache&lt;&#x2F;h2&gt;
&lt;p&gt;Now lets get ready to cache some data. We&#x27;ll make pvs and vgs for data:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;pvcreate &#x2F;dev&#x2F;nvme0p2
&lt;&#x2F;span&gt;&lt;span&gt;pvcreate &#x2F;dev&#x2F;nvme1p2
&lt;&#x2F;span&gt;&lt;span&gt;pvcreate &#x2F;dev&#x2F;sda1
&lt;&#x2F;span&gt;&lt;span&gt;pvcreate &#x2F;dev&#x2F;sda2
&lt;&#x2F;span&gt;&lt;span&gt;vgcreate data &#x2F;dev&#x2F;nvme0p2 &#x2F;dev&#x2F;nvme1p2 &#x2F;dev&#x2F;sda1 &#x2F;dev&#x2F;sdb2
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Create the larger volume&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;lvcreate --type raid1 --mirrors 1 -L7.5T -n libvirt_t2 data &#x2F;dev&#x2F;sda1 &#x2F;dev&#x2F;sdb1
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Prepare the caches&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;lvcreate --type raid1 --mirrors 1 -L 4G -n libvirt_t2_meta data
&lt;&#x2F;span&gt;&lt;span&gt;lvcreate --type raid1 --mirrors 1 -L 400G -n libvirt_t2_cache data
&lt;&#x2F;span&gt;&lt;span&gt;lvconvert --type cache-pool --poolmetadata data&#x2F;libvirt_t2_meta data&#x2F;libvirt_t2_cache
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now put the caches in front of the disks. It&#x27;s important for you to
check you have the correct cachemode at this point, because you can&#x27;t
change it without removing and re-adding the cache. I choose writeback
because my nvme devices are in a raid 1 mirror, and it helps to
accelerate writes. You may err to use the default where the SSD&#x27;s are
read cache only.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;lvconvert --type cache --cachemode writeback --cachepool data&#x2F;libvirt_t2_cache data&#x2F;libvirt_t2
&lt;&#x2F;span&gt;&lt;span&gt;mkfs.xfs &#x2F;dev&#x2F;mapper&#x2F;data-libvirt_t2
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You can monitor the amount of &amp;quot;cached&amp;quot; data in the data column of lvs.&lt;&#x2F;p&gt;
&lt;p&gt;Now you can add this to &#x2F;etc&#x2F;fstab as any other xfs drive. I mounted it
to &#x2F;var&#x2F;lib&#x2F;libvirt&#x2F;images.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;network-manager&quot;&gt;Network Manager&lt;&#x2F;h2&gt;
&lt;p&gt;Now, I have to assemble the network bridges. Network Manager has some
specific steps to follow to achieve this. I have:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;two intel gigabit ports&lt;&#x2F;li&gt;
&lt;li&gt;the ports are link aggregated by 802.3ad&lt;&#x2F;li&gt;
&lt;li&gt;there are multiple vlans ontop of the link agg&lt;&#x2F;li&gt;
&lt;li&gt;bridges must be built on top of the vlans&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;This requires a specific set of steps to layer this, because network
manager sees the bridge and the lagg as seperate things that require the
vlan to tie them together.&lt;&#x2F;p&gt;
&lt;p&gt;Configure the link agg, and add our two ethernet phys&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;nmcli conn add type bond con-name bond0 ifname bond0 mode 802.3ad ipv4.method disabled ipv6.method ignore
&lt;&#x2F;span&gt;&lt;span&gt;nmcli connection add type ethernet con-name bond0-eth1 ifname eth1 master bond0 slave-type bond
&lt;&#x2F;span&gt;&lt;span&gt;nmcli connection add type ethernet con-name bond0-eth2 ifname eth2 master bond0 slave-type bond
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Add a bridge for a vlan:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;nmcli connection add type bridge con-name net_18 ifname net_18 ipv4.method disabled ipv6.method ignore
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now tie together a vlan on the bond, to the bridge we created.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;nmcli connection add type vlan con-name bond0.18 ifname bond0.18 dev bond0 id 18 master net_18 slave-type bridge
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You will need to repeat these last two commands as required for the
vlans you have.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;house-keeping&quot;&gt;House Keeping&lt;&#x2F;h2&gt;
&lt;p&gt;Finally you need to do some house keeping. Transactional server will
automatically reboot and update so you need to be ready for this. You
may disable this with:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;systemctl disable transactional-update.timer
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You likely want to edit:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;etc&#x2F;sysconfig&#x2F;libvirt-guests
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;To be able to handle guest shutdown policy due to a UPS failure or a
reboot.&lt;&#x2F;p&gt;
&lt;p&gt;Now you can enable and start libvirt:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;systemctl enable libvirtd
&lt;&#x2F;span&gt;&lt;span&gt;systemctl start libvirtd
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Finally you can build and import virtualmachines.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>LDAP Filter Syntax Validation</title>
          <pubDate>Thu, 29 Aug 2019 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2019-08-29-ldap-filter-syntax-validation/</link>
          <guid>https://fy.blackhats.net.au/blog/2019-08-29-ldap-filter-syntax-validation/</guid>
          <description>&lt;h1 id=&quot;ldap-filter-syntax-validation&quot;&gt;LDAP Filter Syntax Validation&lt;&#x2F;h1&gt;
&lt;p&gt;Today I want to do a deep-dive into a change that will be released in
389 Directory Server 1.4.2. It&#x27;s a reasonably complicated change for
our server, but it has a simple user interaction for admins and
developers. I want to peel back some of the layers to explain what kind
of experience, thought and team work goes into a change like this.&lt;&#x2F;p&gt;
&lt;p&gt;TL;DR - just keep upgrading your 389 Directory Server instance, and our
&#x27;correct by default&#x27; policy will apply, and you&#x27;ll keep having the
best LDAP server we can make :)&lt;&#x2F;p&gt;
&lt;h2 id=&quot;ldap-filters-and-how-they-work&quot;&gt;LDAP Filters and How They Work&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;a href=&quot;&#x2F;blog&#x2F;html&#x2F;pages&#x2F;ldap_guide_part_3_filters.html&quot;&gt;LDAP filters&lt;&#x2F;a&gt; are one
of the primary methods of expression in LDAP, and are used in almost
every aspect of the system - from finding who you are when you login, to
asserting you are member of a group or have other security attributes.&lt;&#x2F;p&gt;
&lt;p&gt;For the purposes of this discussion we&#x27;ll look at this filter:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&amp;#39;(|(cn=william)(cn=claire))&amp;#39;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;In order to execute these queries quickly (LDAP is designed to handle
thousands of operations per second) we heavily rely on indexing.
Indexing is often a topic where people believe it to be some kind of
&amp;quot;magic&amp;quot; but it&#x27;s reasonably simple: indexes are pre-computed partial
result sets. So why do we need these?&lt;&#x2F;p&gt;
&lt;p&gt;We&#x27;ll imagine we have two entries (invalid, and truncated for brevity).&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;dn: cn=william,...
&lt;&#x2F;span&gt;&lt;span&gt;cn: william
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;dn: cn=claire,...
&lt;&#x2F;span&gt;&lt;span&gt;cn: claire
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;These entries both have entry-ids - these id&#x27;s are &lt;em&gt;per-server&lt;&#x2F;em&gt; in a
replication group and are integers. You can show them by requesting
entryid as an attribute in 389.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;dn: cn=william,...
&lt;&#x2F;span&gt;&lt;span&gt;entryid: 1
&lt;&#x2F;span&gt;&lt;span&gt;cn: william
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;dn: cn=claire,...
&lt;&#x2F;span&gt;&lt;span&gt;entryid: 2
&lt;&#x2F;span&gt;&lt;span&gt;cn: claire
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Our entries are stored in the main-entry database in
&lt;em&gt;&#x2F;var&#x2F;lib&#x2F;dirsrv&#x2F;slapd-standalone1&#x2F;db&#x2F;userRoot&lt;&#x2F;em&gt; in the file
&amp;quot;id2entry.db4&amp;quot;. This is a key-value database where the keys are the
entryid, and the value is the serialised entry itself. Roughly, it&#x27;s:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;[ ID ][ Entry             ]
&lt;&#x2F;span&gt;&lt;span&gt;  1     dn: cn=william,...
&lt;&#x2F;span&gt;&lt;span&gt;        cn: william
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;  2     dn: cn=claire,...
&lt;&#x2F;span&gt;&lt;span&gt;        cn: claire
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now, if we had NO indexes, to evaluate our filters we have to scan every
entry of id2entry to determine if the filter matches. This algorithm is:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;candidate_set = []
&lt;&#x2F;span&gt;&lt;span&gt;for id in id-min to id-max:
&lt;&#x2F;span&gt;&lt;span&gt;    entry = load_entry_by_id(id)
&lt;&#x2F;span&gt;&lt;span&gt;    if apply_filter(filter, entry):
&lt;&#x2F;span&gt;&lt;span&gt;        candidate_set.append(entry)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;For two entries, this may be fast, but when you have 1000, 10.000, or
even millions, this is extremely slow. We call these searches &lt;em&gt;full
table scans&lt;&#x2F;em&gt; or in 389 DS, &lt;em&gt;ALLIDS&lt;&#x2F;em&gt; searches.&lt;&#x2F;p&gt;
&lt;p&gt;To make our searches faster we have indexes. An index is a mapping of a
partial query term to an id list (In 389 we call these IDLs). An IDL is
a set of integers. Our index for these examples would likely be
something like:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;cn
&lt;&#x2F;span&gt;&lt;span&gt;=william: [1, ]
&lt;&#x2F;span&gt;&lt;span&gt;=claire: [2, ]
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;These indexes are also stored in key-value databases in userRoot - you
can see this as cn.db4.&lt;&#x2F;p&gt;
&lt;p&gt;So when we have an indexed term, to evaluate the query, we&#x27;ll load the
indexes, then using mathematical set operations, we then produce a
candidate_id_set, and we can then load the entries that only match.&lt;&#x2F;p&gt;
&lt;p&gt;For example in psuedo python code:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# Assume query is: (cn=william)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;attr = filter.get_attr_name()
&lt;&#x2F;span&gt;&lt;span&gt;with open(&amp;#39;%s.db&amp;#39; % attr) as index:
&lt;&#x2F;span&gt;&lt;span&gt;    idl = index.get(&amp;#39;=william&amp;#39;) # from the filter :)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;for id in idl:
&lt;&#x2F;span&gt;&lt;span&gt;    ... # as before.
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;So we can see now that when we load the idl for cn index, this would
give us the set [1, ]. Even if the database had 100 million entries,
as our idl is a single value, we only need to load the one entry that
matches. Neat!&lt;&#x2F;p&gt;
&lt;p&gt;When we have a more complex operation such as AND and OR, we can now
manipulate the idl sets. For example:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;(|(uid=claire)(uid=william))
&lt;&#x2F;span&gt;&lt;span&gt;   uid =claire -&amp;gt; idl [2, ]
&lt;&#x2F;span&gt;&lt;span&gt;   uid =william -&amp;gt; idl [1, ]
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;candidate_idl_set = union([2, ], [1, ])
&lt;&#x2F;span&gt;&lt;span&gt;# [1, 2]
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This means again, even with millions of entries, we only need to load
entry 1 and 2 to uphold the query provided to us.&lt;&#x2F;p&gt;
&lt;p&gt;So we finally know enough to understand how our example query is
executed. PHEW!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;unindexed-attributes&quot;&gt;Unindexed Attributes&lt;&#x2F;h2&gt;
&lt;p&gt;However, it&#x27;s not always so easy. When we have an attribute that isn&#x27;t
indexed, we have to handle this situation. In these cases, while we
operate on the idl set, we may insert an idl with the value of ALLIDS
(which as previously mentioned, is the &amp;quot;set of all entries&amp;quot;). This can
have various effects.&lt;&#x2F;p&gt;
&lt;p&gt;If this was an AND query, we can annotate that the filter is &lt;em&gt;partially&lt;&#x2F;em&gt;
resolved. This means that if we had:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;(&amp;amp;(cn=william)(unindexed=foo))
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Because an AND condition, both filter components must be satisfied, we
have a partial candidate set from cn=william of [1, ]. We can load
this partial candidate set, and then apply the filter test as in the
full table scan case, but as we only apply it to a single entry this is
really fast.&lt;&#x2F;p&gt;
&lt;p&gt;The real problem is OR queries. If we had:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;(|(cn=william)(unindexed=foo))
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Because OR means that both filter components &lt;em&gt;could&lt;&#x2F;em&gt; be satisfied, we
have to turn unindexd into ALLIDS, and the result of the OR as a whole
is ALLIDS. So even if we have 30 indexed values in the OR, a single
ALLIDS (unindexed value) will always turn that OR into a full table
scan. This is not good for performance!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;missing-attributes&quot;&gt;Missing Attributes&lt;&#x2F;h2&gt;
&lt;p&gt;So as a weirder case ... what if the attribute doesn&#x27;t exist in schema
at all? For example we could search for Microsoft AD attributes in 389
Directory Server, or we could submit bogus filters like
&amp;quot;(whargarble=foo)&amp;quot;. What happens here?&lt;&#x2F;p&gt;
&lt;p&gt;Well, historically we treated these the same as &lt;em&gt;unindexed&lt;&#x2F;em&gt; queries.
Which means that any term that is not in schema, would be treated as
ALLIDS. This led to a &amp;quot;quitely known&amp;quot; denial of service attack again
389 Directory Server where you could emit a large number of queries for
attributes that don&#x27;t exist, causing the server to attempt many ALLIDS
scans. We have some defences like the allids limit (how many entries you
can full table scan before giving up). But it can still cause entry
cache churn and other performance issues.&lt;&#x2F;p&gt;
&lt;p&gt;I was first made aware of this issue in 2014 while working for
University of Adelaide where our VMWare service would query LDAP for MS
attributes, causing a large performance issue. We resolved this by
adding the MS attributes to schema and indexing them so that they would
create empty indexes - now we would call this in 389 Directory Server
and &amp;quot;idl_alloc(0)&amp;quot; or &amp;quot;empty IDL&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;When initially hired by Red Hat in 2015 I knew this issue existed but I
didn&#x27;t know enough about the server core to really fix it, so it went
in the back of my mind ... it was rare to have a customer raise this
issue, but we had the work around and so I was able to advise support
services on how to mitigate this.&lt;&#x2F;p&gt;
&lt;p&gt;In 2019 however, while investigating an issue related to filter
optimisation, I was made aware of an issue with FreeIPA where they were
doing certmap queries that requested MS Cert attributes. However it
would cause large performance issues. We now had the issue again, and in
a large widely installed product so it was time to tackle it.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;how-to-handle-this&quot;&gt;How to handle this?&lt;&#x2F;h2&gt;
&lt;p&gt;A major issue in this is &amp;quot;never breaking customers&amp;quot;. Because we had
always supported this behaviour there is a risk that any solution would
cause customer queries to &amp;quot;silently&amp;quot; begin to break if we issued a fix
or change. More accurately, any change to how we execute the filters
could cause results of the filters to change, which would disrupt
customers.&lt;&#x2F;p&gt;
&lt;p&gt;Saying this, there is also precedent that 389 Directory Server was
handling this incorrectly. From the RFC for LDAP it was noted:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;Any assertion about the values of such an attribute is only defined if
the AttributeType is known by the evaluating mechanism, the purported
AttributeValue(s) conforms to the attribute syntax defined for that
attribute type, the implied or indicated matching rule is applicable to
that attribute type, and (when used) a presented matchValue conforms to
the syntax defined for the indicated matching rules. When these
conditions are not met, the FilterItem shall evaluate to the logical
value UNDEFINED. An assertion which is defined by these conditions
additionally evaluates to UNDEFINED if it relates to an attribute value
and the attribute type is not present in an attribute against which the
assertion is being tested. An assertion which is defined by these
conditions and relates to the presence of an attribute type evaluates to
FALSE.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Translation: If a filter component (IE nonexist=foo) is in a filter but
NOT in the schema, the result of the filter&#x27;s evaluation is an
empty-set aka undefined.&lt;&#x2F;p&gt;
&lt;p&gt;It was also clear that if an engaged and active consumer like FreeIPA is
making this mistake, then it must be overlooked by many others without
notice. So there is sometimes value in helping to raise the standard so
that everyone benefits, and highlight mistakes quicker.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-technical-solution&quot;&gt;The Technical Solution&lt;&#x2F;h2&gt;
&lt;p&gt;This is the easy part - we add a new configuration option with three
states. &amp;quot;on&amp;quot;, &amp;quot;off&amp;quot;, &amp;quot;warn&amp;quot;. &amp;quot;On&amp;quot; would enable the strictest
handling of filters, rejecting them an not continuing if any attribute
requested was not in the schema. &amp;quot;Warn&amp;quot; would provide the rfc
compliant behaviour, mapping to empty-set index, and notifying in the
logs that this occured. Finally, &amp;quot;off&amp;quot; would be the previous
&amp;quot;silently allow&amp;quot; behaviour.&lt;&#x2F;p&gt;
&lt;p&gt;This was easily achieved in filter parsing, by checking the attribute of
each filter component against our schema hashmap. We then tag the filter
element, and depending on the current setting level reject or continue.&lt;&#x2F;p&gt;
&lt;p&gt;In the query execution code, we now check the filter tag to understand
if the attribute is schema present or not. If it&#x27;s flagged as
&amp;quot;undefined&amp;quot;, then we immediately shortcut to return idl_alloc(0)
instead of returning ALLIDS on the failure to find the relevant index
db.&lt;&#x2F;p&gt;
&lt;p&gt;We can show the performance impact of this change:&lt;&#x2F;p&gt;
&lt;p&gt;Before with non-existant attribute&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;Average rate:    7.40&#x2F;thr
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;After with &amp;quot;warn&amp;quot; enabled (map to empty set)&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;Average rate: 4808.70&#x2F;thr
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This is a huge improvement, and certainly shows the risk of DOS and how
effective the solution was!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-social-solution&quot;&gt;The Social Solution&lt;&#x2F;h2&gt;
&lt;p&gt;Of course, this is the hard part - the 389 Directory Server team are all
amazingly smart people, from many countries, and all live around the
world. They all care that the server is the best possible, and that our
standards as a team are high. That means when introducing a change that
has a risk of affecting query result sets like this, they pay attention,
and ask many difficult questions about how the feature will be
implemented.&lt;&#x2F;p&gt;
&lt;p&gt;The first important justification - is a change like this worth while?
We can see from the performance results that the risk of DOS is
reasonable, so the answer there becomes Yes from a security view. But
it&#x27;s also important to consider the cost on consumers - is this change
going to benefit FreeIPA for example? As I am biased being the author I
want to say &amp;quot;yes&amp;quot; - by notifying or rejecting invalid filters earlier,
we can help FreeIPA developers improve their code quality, without
expecting them to know LDAP inside and out.&lt;&#x2F;p&gt;
&lt;p&gt;The next major question is performance - before the feature was
developed there is clearly a risk of DOS, but when we implement this we
are performing additional locking on the schema. Is that a risk to our
standalone performance or normal operating conditions. This had to also
be discussed and assessed.&lt;&#x2F;p&gt;
&lt;p&gt;A really important point that was raised by Thierry is how we
communicated these errors too. Previously we would use the &amp;quot;notes=&amp;quot;
field of the access log. It looks like this:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;conn=1 op=4 RESULT err=0 tag=101 nentries=13 etime=0.0003795424 notes=U
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The challenge with the notes= field, is that it&#x27;s easy to overlook, and
unless you are familar, hard to see what this is indicating. In this
case, notes=U means partially unindexed query (one filter component but
not all returned ALLIDS).&lt;&#x2F;p&gt;
&lt;p&gt;We can&#x27;t change the notes field due to the risk of breaking our own
scripts like logconv.pl, support tools developed by RH or SUSE, or even
integrations to platforms like splunk. But clearly we need a way to
detail what is happening with your filter. So Thierry suggested an
extension to have details about the provided notes. Now we get:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;conn=1 op=4 RESULT err=0 tag=101 nentries=13 etime=0.0003795424 notes=U details=&amp;quot;Partially Unindexed Filter&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;conn=1 op=8 RESULT err=0 tag=101 nentries=0 etime=0.0001886208 notes=F details=&amp;quot;Filter Element Missing From Schema&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;So we have extended our log message, but without breaking existing
integrations.&lt;&#x2F;p&gt;
&lt;p&gt;The final question is what our defaults should be. It&#x27;s one thing to
have this feature, but what should we ship with? Do we strictly reject
filters? Warn? Or disable, and expect people to turn this on.&lt;&#x2F;p&gt;
&lt;p&gt;This became a long discussion with Ludwig, Thierry and I - we discussed
the risk of DOS in the first place, what the impact of the levels could
be, how it could break legacy applications or sites using deprecated
features or with weird data imports. Many different aspects were
considered. We decided to default to &amp;quot;warn&amp;quot; (non-existant becomes
empty-set), and we settled on communication with support to advise them
of the upcoming change, but also we considered that our &amp;quot;back out&amp;quot;
plan is to change the default and ship a patch if there is a large
volume of negative feedback.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;&#x2F;h2&gt;
&lt;p&gt;As of today, the PR is merged, and the code on it&#x27;s way to the next
release. It&#x27;s a long process but the process exists to ensure we do
what&#x27;s best for our users, while we try to balance many different
aspects. We have a great team of people, with decades of experience from
many backgrounds which means that these discussions can be long and
detailed, but in the end, we hope to give what is the best product
possible to our community.&lt;&#x2F;p&gt;
&lt;p&gt;It&#x27;s also valuable to share how much thought and effort goes into
projects - in your life you may only interact with 1% of our work
through our configuration and system, but we have an iceberg of
decisions and design process that affects you every day, where we have
to be responsible and considerate in our actions.&lt;&#x2F;p&gt;
&lt;p&gt;I hope you enjoyed this exploration of this change!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;references&quot;&gt;References&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;pagure.io&#x2F;389-ds-base&#x2F;pull-request&#x2F;50379&quot;&gt;PR#50379&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Using ramdisks with Cargo</title>
          <pubDate>Mon, 26 Aug 2019 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2019-08-26-using-ramdisks-with-cargo/</link>
          <guid>https://fy.blackhats.net.au/blog/2019-08-26-using-ramdisks-with-cargo/</guid>
          <description>&lt;h1 id=&quot;using-ramdisks-with-cargo&quot;&gt;Using ramdisks with Cargo&lt;&#x2F;h1&gt;
&lt;p&gt;I have a bit of a history of killing SSDs - probably because I do a bit
too much compiling and management of thousands of tiny files. Plenty of
developers have this problem! So while thinking one evening, I was
curious if I could setup a ramdisk on my mac for my cargo work to output
to.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;making-the-ramdisk&quot;&gt;Making the ramdisk&lt;&#x2F;h2&gt;
&lt;p&gt;On Linux you&#x27;ll need to use tmpfs or some access to &#x2F;dev&#x2F;shm.&lt;&#x2F;p&gt;
&lt;p&gt;On OSX you need to run a script like the following:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;diskutil partitionDisk $(hdiutil attach -nomount ram:&#x2F;&#x2F;4096000) 1 GPTFormat APFS &amp;#39;ramdisk&amp;#39; &amp;#39;100%&amp;#39;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This creates and mounts a 4GB ramdisk to &#x2F;Volumes&#x2F;ramdisk. Make sure you
have enough ram!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;asking-cargo-to-use-it&quot;&gt;Asking cargo to use it&lt;&#x2F;h2&gt;
&lt;p&gt;We probably don&#x27;t want to make our changes permant in Cargo.toml, so
we&#x27;ll use the environment:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;CARGO_TARGET_DIR=&#x2F;Volumes&#x2F;ramdisk&#x2F;rs cargo ...
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;does-it-work&quot;&gt;Does it work?&lt;&#x2F;h2&gt;
&lt;p&gt;Yes!&lt;&#x2F;p&gt;
&lt;p&gt;Disk Build (SSD, 2018MBP)&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;Finished dev [unoptimized + debuginfo] target(s) in 2m 29s
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;4 GB APFS ramdisk&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;Finished dev [unoptimized + debuginfo] target(s) in 1m 53s
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;For me it&#x27;s more valuable to try and save those precious SSD write
cycles, so I think I&#x27;ll try to stick with this setup. You can see how
much rust writes by doing a clean + build. My project used the
following:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;Filesystem                             Size   Used  Avail Capacity    iused               ifree %iused  Mounted on
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;dev&#x2F;disk110s1                        2.0Gi  1.2Gi  751Mi    63%       3910 9223372036854771897    0%   &#x2F;Volumes&#x2F;ramdisk
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;make-it-permanent&quot;&gt;Make it permanent&lt;&#x2F;h2&gt;
&lt;p&gt;Put the following in
&#x2F;Library&#x2F;LaunchDaemons&#x2F;au.net.blackhats.fy.ramdisk.plist&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;!DOCTYPE plist PUBLIC &amp;quot;-&#x2F;&#x2F;Apple&#x2F;&#x2F;DTD PLIST 1.0&#x2F;&#x2F;EN&amp;quot; &amp;quot;http:&#x2F;&#x2F;www.apple.com&#x2F;DTDs&#x2F;PropertyList-1.0.dtd&amp;quot;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;plist version=&amp;quot;1.0&amp;quot;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;lt;dict&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;                &amp;lt;key&amp;gt;Label&amp;lt;&#x2F;key&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;                &amp;lt;string&amp;gt;au.net.blackhats.fy.ramdisk&amp;lt;&#x2F;string&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;                &amp;lt;key&amp;gt;Program&amp;lt;&#x2F;key&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;                &amp;lt;string&amp;gt;&#x2F;usr&#x2F;local&#x2F;libexec&#x2F;ramdisk.sh&amp;lt;&#x2F;string&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;                &amp;lt;key&amp;gt;RunAtLoad&amp;lt;&#x2F;key&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;                &amp;lt;true&#x2F;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;                &amp;lt;key&amp;gt;StandardOutPath&amp;lt;&#x2F;key&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;                &amp;lt;string&amp;gt;&#x2F;var&#x2F;log&#x2F;ramdisk.log&amp;lt;&#x2F;string&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;lt;&#x2F;dict&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&#x2F;plist&amp;gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;And the following into &#x2F;usr&#x2F;local&#x2F;libexec&#x2F;ramdisk.sh&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;#!&#x2F;bin&#x2F;bash
&lt;&#x2F;span&gt;&lt;span&gt;date
&lt;&#x2F;span&gt;&lt;span&gt;diskutil partitionDisk $(hdiutil attach -nomount ram:&#x2F;&#x2F;4096000) 1 GPTFormat APFS &amp;#39;ramdisk&amp;#39; &amp;#39;100%&amp;#39;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Finally put this in your &lt;a href=&quot;https:&#x2F;&#x2F;doc.rust-lang.org&#x2F;cargo&#x2F;reference&#x2F;config.html&quot;&gt;cargo file of
choice&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;[build]
&lt;&#x2F;span&gt;&lt;span&gt;target-dir = &amp;quot;&#x2F;Volumes&#x2F;ramdisk&#x2F;rs&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Future william will need to work out if there are negative consequences
to multiple cargo projects sharing the same target directory ... hope
not!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;launchctl-tips&quot;&gt;Launchctl tips&lt;&#x2F;h2&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# Init the service
&lt;&#x2F;span&gt;&lt;span&gt;launchctl load &#x2F;Library&#x2F;LaunchDaemons&#x2F;au.net.blackhats.fy.ramdisk.plist
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;references&quot;&gt;References&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;www.launchd.info&#x2F;&quot;&gt;lanuchd.info&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>CPU atomics and orderings explained</title>
          <pubDate>Tue, 16 Jul 2019 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2019-07-16-cpu-atomics-and-orderings-explained/</link>
          <guid>https://fy.blackhats.net.au/blog/2019-07-16-cpu-atomics-and-orderings-explained/</guid>
          <description>&lt;h1 id=&quot;cpu-atomics-and-orderings-explained&quot;&gt;CPU atomics and orderings explained&lt;&#x2F;h1&gt;
&lt;p&gt;Sometimes the question comes up about how CPU memory orderings work, and
what they do. I hope this post explains it in a really accessible way.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;short-version-i-wanna-code&quot;&gt;Short Version - I wanna code!&lt;&#x2F;h2&gt;
&lt;p&gt;Summary - The memory model you commonly see is from C++ and it defines:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Relaxed&lt;&#x2F;li&gt;
&lt;li&gt;Acquire&lt;&#x2F;li&gt;
&lt;li&gt;Release&lt;&#x2F;li&gt;
&lt;li&gt;Acquire&#x2F;Release (sometimes AcqRel)&lt;&#x2F;li&gt;
&lt;li&gt;SeqCst&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;There are memory orderings - every operation is &amp;quot;atomic&amp;quot;, so will work
correctly, but there rules define how the memory and code &lt;em&gt;around&lt;&#x2F;em&gt; the
atomic are influenced.&lt;&#x2F;p&gt;
&lt;p&gt;If in doubt - use SeqCst - it&#x27;s the strongest guarantee and prevents
all re-ordering of operations and will do the right thing.&lt;&#x2F;p&gt;
&lt;p&gt;The summary is:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Relaxed - no ordering guarantees, just execute the atomic as is.&lt;&#x2F;li&gt;
&lt;li&gt;Acquire - all code after this atomic, will be executed after the
atomic.&lt;&#x2F;li&gt;
&lt;li&gt;Release - all code before this atomic, will be executed before the
atomic.&lt;&#x2F;li&gt;
&lt;li&gt;Acquire&#x2F;Release - both Acquire and Release - ie code stays before
and after.&lt;&#x2F;li&gt;
&lt;li&gt;SeqCst - Stronger consistency of Acquire&#x2F;Release.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;long-version-let-s-begin&quot;&gt;Long Version ... let&#x27;s begin ...&lt;&#x2F;h2&gt;
&lt;p&gt;So why do we have memory and operation orderings at all? Let&#x27;s look at
some code to explain:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;let mut x = 0;
&lt;&#x2F;span&gt;&lt;span&gt;let mut y = 0;
&lt;&#x2F;span&gt;&lt;span&gt;x = x + 3;
&lt;&#x2F;span&gt;&lt;span&gt;y = y + 7;
&lt;&#x2F;span&gt;&lt;span&gt;x = x + 4;
&lt;&#x2F;span&gt;&lt;span&gt;x = y + x;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Really trivial example - now to us as a human, we read this and see a
set of operations that are linear by time. That means, they execute from
top to bottom, in order.&lt;&#x2F;p&gt;
&lt;p&gt;However, this is not how computers work. First, compilers will optimise
your code, and optimisation means re-ordering of the operations to
achieve better results. A compiler may optimise this to:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;let mut x = 0;
&lt;&#x2F;span&gt;&lt;span&gt;let mut y = 0;
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;&#x2F; Note removal of the x + 3 and x + 4, folded to a single operation.
&lt;&#x2F;span&gt;&lt;span&gt;x = x + 7
&lt;&#x2F;span&gt;&lt;span&gt;y = y + 7;
&lt;&#x2F;span&gt;&lt;span&gt;x = y + x;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now there is a second element. Your CPU presents the illusion of running
as a linear system, but it&#x27;s actually an asynchronous, out-of-order
task execution engine. That means a CPU will reorder your instructions,
and may even run them concurrently and asynchronously.&lt;&#x2F;p&gt;
&lt;p&gt;For example, your CPU will have both x + 7 and y + 7 in the pipeline,
even though neither operation has completed - they are effectively
running at the &amp;quot;same time&amp;quot; (concurrently).&lt;&#x2F;p&gt;
&lt;p&gt;When you write a single thread program, you generally won&#x27;t notice this
behaviour. This is because a lot of smart people write compilers and
CPU&#x27;s to give the illusion of linear ordering, even though both of them
are operating very differently.&lt;&#x2F;p&gt;
&lt;p&gt;Now we want to write a multithreaded application. Suddenly this is the
challenge:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;We write a concurrent program, in a linear language, executed on a
concurrent asynchronous machine.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;This means there is a challenge is the translation between our mind
(thinking about the concurrent problem), the program (which we have to
express as a linear set of operations), which then runs on our CPU (an
async concurrent device).&lt;&#x2F;p&gt;
&lt;p&gt;Phew. How do computers even work in this scenario?!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;why-are-cpu-s-async&quot;&gt;Why are CPU&#x27;s async?&lt;&#x2F;h2&gt;
&lt;p&gt;CPU&#x27;s have to be async to be fast - remember spectre and meltdown?
These are attacks based on measuring the side effects of CPU&#x27;s
asynchronous behaviour. While computers are &amp;quot;fast&amp;quot; these attacks will
always be possible, because to make a CPU synchronous is &lt;em&gt;slow&lt;&#x2F;em&gt; - and
asynchronous behaviour will always have measurable side effects. Every
modern CPU&#x27;s performance is an illusion of async forbidden magic.&lt;&#x2F;p&gt;
&lt;p&gt;A large portion of the async behaviour comes from the interaction of the
CPU, cache, and memory.&lt;&#x2F;p&gt;
&lt;p&gt;In order to provide the &amp;quot;illusion&amp;quot; of a coherent synchronous memory
interface there is no seperation of your programs cache and memory. When
the cpu wants to access &amp;quot;memory&amp;quot; the CPU cache is utilised
transparently and will handle the request, and only on a cache miss,
will we retrieve the values from RAM.&lt;&#x2F;p&gt;
&lt;p&gt;(Aside: in almost all cases more CPU cache, not frequency will make your
system perform better, because a cache miss will mean your task stalls
waiting on RAM. Ohh no!)&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;CPU -&amp;gt; Cache -&amp;gt; RAM
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;When you have multiple CPU&#x27;s, each CPU has it&#x27;s own L1 cache:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;CPU1 -&amp;gt; L1 Cache -&amp;gt; |              |
&lt;&#x2F;span&gt;&lt;span&gt;CPU2 -&amp;gt; L1 Cache -&amp;gt; | Shared L2&#x2F;L3 | -&amp;gt; RAM
&lt;&#x2F;span&gt;&lt;span&gt;CPU3 -&amp;gt; L1 Cache -&amp;gt; |              |
&lt;&#x2F;span&gt;&lt;span&gt;CPU4 -&amp;gt; L1 Cache -&amp;gt; |              |
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Ahhh! Suddenly we can see where problems can occur - each CPU has an L1
cache, which is transparent to memory but &lt;em&gt;unique&lt;&#x2F;em&gt; to the CPU. This
means that each CPU can make a change to the same piece of memory in
their L1 cache &lt;em&gt;without the other CPU knowing&lt;&#x2F;em&gt;. To help explain, let&#x27;s
show a demo.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;cpu-just-trash-my-variables&quot;&gt;CPU just trash my variables&lt;&#x2F;h2&gt;
&lt;p&gt;We&#x27;ll assume we now have two threads - my code is in rust again, and
there is a good reason for the unsafes - this code really is unsafe!&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;&#x2F; assume global x: usize = 0; y: usize = 0;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;THREAD 1                        THREAD 2
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;if unsafe { *x == 1 } {          unsafe {
&lt;&#x2F;span&gt;&lt;span&gt;    unsafe { *y += 1 }              *y = 10;
&lt;&#x2F;span&gt;&lt;span&gt;}                                   *x = 1;
&lt;&#x2F;span&gt;&lt;span&gt;                                }
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;At the end of execution, what state will X and Y be in? The answer is
&amp;quot;it depends&amp;quot;:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;What order did the threads run?&lt;&#x2F;li&gt;
&lt;li&gt;The state of the L1 cache of each CPU&lt;&#x2F;li&gt;
&lt;li&gt;The possible interleavings of the operations.&lt;&#x2F;li&gt;
&lt;li&gt;Compiler re-ordering&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;In the end the result of x will always be 1 - because x is only mutated
in one thread, the caches will &amp;quot;eventually&amp;quot; (explained soon) become
consistent.&lt;&#x2F;p&gt;
&lt;p&gt;The real question is y. y could be:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;10&lt;&#x2F;li&gt;
&lt;li&gt;11&lt;&#x2F;li&gt;
&lt;li&gt;1&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;em&gt;10&lt;&#x2F;em&gt; - This can occur because in thread 2, x = 1 is re-ordered above y =
10, causing the thread 1 &amp;quot;y += 1&amp;quot; to execute, followed by thread 2
assign 10 directly to y. It can also occur because the check for x == 1
occurs first, so y += 1 is skipped, then thread 2 is run, causing y =
10. Two ways to achieve the same result!&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;11&lt;&#x2F;em&gt; - This occurs in the &amp;quot;normal&amp;quot; execution path - all things
considered it&#x27;s a miracle :)&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;1&lt;&#x2F;em&gt; - This is the most complex one - The y = 10 in thread 2 is applied,
but the result is never sent to THREAD 1&#x27;s cache, so x = 1 occurs and
&lt;em&gt;is&lt;&#x2F;em&gt; made available to THREAD 1 (yes, this is possible to have different
values made available to each cpu ...). Then thread 1 executes y (0) +=
1, which is then sent back trampling the value of y = 10 from thread 2.&lt;&#x2F;p&gt;
&lt;p&gt;If you want to know more about this and many other horrors of CPU
execution, Paul McKenny is an expert in this field and has many talks at
LCA and others on the topic. He can be found on
&lt;a href=&quot;https:&#x2F;&#x2F;twitter.com&#x2F;paulmckrcu&quot;&gt;twitter&lt;&#x2F;a&gt; and is super helpful if you
have questions.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;so-how-does-a-cpu-work-at-all&quot;&gt;So how does a CPU work at all?&lt;&#x2F;h2&gt;
&lt;p&gt;Obviously your system (likely a multicore system) works today - so it
must be possible to write correct concurrent software. Cache&#x27;s are kept
in sync via a protocol called MESI. This is a state machine describing
the states of memory and cache, and how they can be synchronised. The
states are:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Modified&lt;&#x2F;li&gt;
&lt;li&gt;Exclusive&lt;&#x2F;li&gt;
&lt;li&gt;Shared&lt;&#x2F;li&gt;
&lt;li&gt;Invalid&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;What&#x27;s interesting about MESI is that each cache line is maintaining
it&#x27;s own state machine of the memory addresses - it&#x27;s not a global
state machine. To coordinate CPU&#x27;s asynchronously message each other.&lt;&#x2F;p&gt;
&lt;p&gt;A CPU can be messaged via IPC (Inter-Processor-Communication) to say
that another CPU wants to &amp;quot;claim&amp;quot; exclusive ownership of a memory
address, or to indicate that it has changed the content of a memory
address and you should discard your version. It&#x27;s important to
understand these messages are &lt;em&gt;asynchronous&lt;&#x2F;em&gt;. When a CPU modifies an
address it does not immediately send the invalidation message to all
other CPU&#x27;s - and when a CPU recieves the invalidation request it does
not immediately act upon that message.&lt;&#x2F;p&gt;
&lt;p&gt;If CPU&#x27;s did &amp;quot;synchronously&amp;quot; act on all these messages, they would be
spending so much time handling IPC traffic, they would never get
anything done!&lt;&#x2F;p&gt;
&lt;p&gt;As a result, it must be possible to indicate to a CPU that it&#x27;s time to
send or acknowledge these invalidations in the cache line. This is where
barriers, or the memory orderings come in.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Relaxed - No messages are sent or acknowledged.&lt;&#x2F;li&gt;
&lt;li&gt;Release - flush all pending invalidations to be sent to other CPUS&lt;&#x2F;li&gt;
&lt;li&gt;Acquire - Acknowledge and process all invalidation requests in my
queue&lt;&#x2F;li&gt;
&lt;li&gt;Acquire&#x2F;Release - flush all outgoing invalidations, and process my
incomming queue&lt;&#x2F;li&gt;
&lt;li&gt;SeqCst - as AcqRel, but with some other guarantees around ordering
that are beyond this discussion.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;understand-a-mutex&quot;&gt;Understand a Mutex&lt;&#x2F;h2&gt;
&lt;p&gt;With this knowledge in place, we are finally in a position to understand
the operations of a Mutex&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;&#x2F; Assume mutex: Mutex&amp;lt;usize&amp;gt; = Mutex::new(0);
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;THREAD 1                            THREAD 2
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;{                                   {
&lt;&#x2F;span&gt;&lt;span&gt;    let guard = mutex.lock()            let guard = mutex.lock()
&lt;&#x2F;span&gt;&lt;span&gt;    *guard += 1;                        println!(*guard)
&lt;&#x2F;span&gt;&lt;span&gt;}                                   }
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;We know very clearly that this will print 1 or 0 - it&#x27;s safe, no weird
behaviours. Let&#x27;s explain this case though:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;THREAD 1
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;    let guard = mutex.lock()
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; Acquire here!
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; All invalidation handled, guard is 0.
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; Compiler is told &amp;quot;all following code must stay after .lock()&amp;quot;.
&lt;&#x2F;span&gt;&lt;span&gt;    *guard += 1;
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; content of usize is changed, invalid req is queue
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;&#x2F; Release here!
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;&#x2F; Guard goes out of scope, invalidation reqs sent to all CPU&amp;#39;s
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;&#x2F; Compiler told all proceeding code must stay above this point.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;            THREAD 2
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;            {
&lt;&#x2F;span&gt;&lt;span&gt;                let guard = mutex.lock()
&lt;&#x2F;span&gt;&lt;span&gt;                &#x2F;&#x2F; Acquire here!
&lt;&#x2F;span&gt;&lt;span&gt;                &#x2F;&#x2F; All invalidations handled - previous cache of usize discarded
&lt;&#x2F;span&gt;&lt;span&gt;                &#x2F;&#x2F; and read from THREAD 1 cache into S state.
&lt;&#x2F;span&gt;&lt;span&gt;                &#x2F;&#x2F; Compiler is told &amp;quot;all following code must stay after .lock()&amp;quot;.
&lt;&#x2F;span&gt;&lt;span&gt;                println(*guard);
&lt;&#x2F;span&gt;&lt;span&gt;            }
&lt;&#x2F;span&gt;&lt;span&gt;            &#x2F;&#x2F; Release here!
&lt;&#x2F;span&gt;&lt;span&gt;            &#x2F;&#x2F; Guard goes out of scope, no invalidations sent due to
&lt;&#x2F;span&gt;&lt;span&gt;            &#x2F;&#x2F; no modifications.
&lt;&#x2F;span&gt;&lt;span&gt;            &#x2F;&#x2F; Compiler told all proceeding code must stay above this point.
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;And there we have it! How barriers allow us to define an ordering in
code and a CPU, to ensure our caches and compiler outputs are correct
and consistent.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;benefits-of-rust&quot;&gt;Benefits of Rust&lt;&#x2F;h2&gt;
&lt;p&gt;A nice benefit of Rust, and knowing these MESI states now, we can see
that the best way to run a system is to minimise the number of
invalidations being sent and acknowledged as this always causes a delay
on CPU time. Rust variables are always mutable or immutable. These map
almost directly to the E and S states of MESI. A mutable value is always
exclusive to a single cache line, with no contention - and immutable
values can be placed into the Shared state allowing each CPU to maintain
a cache copy for higher performance.&lt;&#x2F;p&gt;
&lt;p&gt;This is one of the reasons for Rust&#x27;s amazing concurrency story is that
the memory in your program map to cache states very clearly.&lt;&#x2F;p&gt;
&lt;p&gt;It&#x27;s also why it&#x27;s unsafe to mutate a pointer between two threads (a
global) - because the cache of the two cpus&#x27; won&#x27;t be coherent, and
you may not cause a crash, but one threads work will absolutely be lost!&lt;&#x2F;p&gt;
&lt;p&gt;Finally, it&#x27;s important to see that this is why using the correct
concurrency primitives matter -it can highly influence your cache
behaviour in your program and how that affects cache line contention and
performance.&lt;&#x2F;p&gt;
&lt;p&gt;For comments and more, please feel free to &lt;a href=&quot;mailto:william@blackhats.net.au&quot;&gt;email
me!&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;shameless-plug&quot;&gt;Shameless Plug&lt;&#x2F;h2&gt;
&lt;p&gt;I&#x27;m the author and maintainer of Conc Read - a concurrently readable
datastructure library for Rust. &lt;a href=&quot;https:&#x2F;&#x2F;crates.io&#x2F;crates&#x2F;concread&quot;&gt;Check it out on
crates.io!&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;references&quot;&gt;References&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;people.freebsd.org&#x2F;~lstewart&#x2F;articles&#x2F;cpumemory.pdf&quot;&gt;What every programmer should know about memory
(pdf)&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;doc.rust-lang.org&#x2F;nomicon&#x2F;atomics.html&quot;&gt;Rust-nomicon - memory
ordering&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;gamozolabs.github.io&#x2F;metrology&#x2F;2019&#x2F;08&#x2F;19&#x2F;sushi_roll.html&quot;&gt;Microarchitectural inspection with Sushi
Roll&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>I no longer recommend FreeIPA</title>
          <pubDate>Wed, 10 Jul 2019 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2019-07-10-i-no-longer-recommend-freeipa/</link>
          <guid>https://fy.blackhats.net.au/blog/2019-07-10-i-no-longer-recommend-freeipa/</guid>
          <description>&lt;h1 id=&quot;i-no-longer-recommend-freeipa&quot;&gt;I no longer recommend FreeIPA&lt;&#x2F;h1&gt;
&lt;p&gt;It&#x27;s probably taken me a few years to write this, but I can no longer
recommend FreeIPA for IDM installations.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;why-not&quot;&gt;Why not?&lt;&#x2F;h2&gt;
&lt;p&gt;The FreeIPA project focused on Kerberos and SSSD, with enough other
parts glued on to look like a complete IDM project. Now that&#x27;s fine,
but it means that concerns in other parts of the project are largely
ignored. It creates design decisions that are not scalable or robust.&lt;&#x2F;p&gt;
&lt;p&gt;Due to these decisions IPA has stability issues and scaling issues that
other products do not.&lt;&#x2F;p&gt;
&lt;p&gt;To be clear: security systems like IDM or LDAP can &lt;em&gt;never&lt;&#x2F;em&gt; go down.
That&#x27;s not acceptable.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-do-you-recommend-instead&quot;&gt;What do you recommend instead?&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;kanidm.github.io&#x2F;kanidm&#x2F;stable&#x2F;&quot;&gt;Kanidm&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;Samba with AD&lt;&#x2F;li&gt;
&lt;li&gt;AzureAD&lt;&#x2F;li&gt;
&lt;li&gt;389 Directory Server&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;All of these projects are very reliable, secure, scalable.&lt;&#x2F;p&gt;
&lt;p&gt;Kanidm specifically is my own project built from the ground up, which
has tried to learn from the mistakes and successes of AD, FreeIPA and
389-ds. It&#x27;s what I recommend the most.&lt;&#x2F;p&gt;
&lt;p&gt;Additionally, we have done a lot of work into 389 to improve our out of
box IDM capabilities too, but there is more to be done too. The Samba AD
team have done great things too, and deserve a lot of respect for what
they have done.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;is-there-more-detail-than-this&quot;&gt;Is there more detail than this?&lt;&#x2F;h2&gt;
&lt;p&gt;Yes - buy me a drink and I&#x27;ll talk :)&lt;&#x2F;p&gt;
&lt;h2 id=&quot;didn-t-you-help&quot;&gt;Didn&#x27;t you help?&lt;&#x2F;h2&gt;
&lt;p&gt;I tried and it was not taken on board. Issues I reported years ago still
exist today 🙃.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Using 389ds with docker</title>
          <pubDate>Fri, 05 Jul 2019 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2019-07-05-using-389ds-with-docker/</link>
          <guid>https://fy.blackhats.net.au/blog/2019-07-05-using-389ds-with-docker/</guid>
          <description>&lt;h1 id=&quot;using-389ds-with-docker&quot;&gt;Using 389ds with docker&lt;&#x2F;h1&gt;
&lt;p&gt;I&#x27;ve been wanting to containerise 389 Directory Server for a long
time - it&#x27;s been a long road to get here, but I think that our
container support is getting very close to a production ready and
capable level. It took so long due to health issues and generally my
obsession to do everything right.&lt;&#x2F;p&gt;
&lt;p&gt;Today, container support along with our new command line tools makes 389
a complete breeze to administer. So lets go through an example of a
deployment now.&lt;&#x2F;p&gt;
&lt;p&gt;Please note: the container image here is a git-master build and is not
production ready as of 2019-07, hopefully this changes soon.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;getting-the-container&quot;&gt;Getting the Container&lt;&#x2F;h2&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;docker pull firstyear&#x2F;389ds:latest
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If you want to run an ephemeral instance (IE you will LOSE all your data
on a restart)&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;docker run firstyear&#x2F;389ds:latest
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If you want your data to persist, you need to attach a volume at &#x2F;data:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;docker volume create 389ds_data
&lt;&#x2F;span&gt;&lt;span&gt;docker run -v 389ds_data:&#x2F;data firstyear&#x2F;389ds:latest
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The image exposes ports 3389 and 3636, so you may want to consider
publishing these if you want external access.&lt;&#x2F;p&gt;
&lt;p&gt;The container should now setup and run an instance! That&#x27;s it, LDAP has
never been easier to deploy!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;actually-adding-some-data&quot;&gt;Actually Adding Some Data ...&lt;&#x2F;h2&gt;
&lt;p&gt;LDAP only really matters if we have some data! So we&#x27;ll create a new
backend. You need to run these instructions inside the current
container, so I prefix these with:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;docker exec -i -t &amp;lt;name of container&amp;gt; &amp;lt;command&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;docker exec -i -t 389inst dsconf ....
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This uses the ldapi socket via &#x2F;data, and authenticates you based on
your process uid to map you to the LDAP administrator account -
basically, it&#x27;s secure, host only admin access to your data.&lt;&#x2F;p&gt;
&lt;p&gt;Now you can choose any suffix you like, generally based on your dns name
(IE I use dc=blackhats,dc=net,dc=au).&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;dsconf localhost backend create --suffix dc=example,dc=com --be-name userRoot
&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt; The database was sucessfully created
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now fill in the suffix details into your configuration of the container.
You&#x27;ll need to find where docker stores the volume on your host for
this (docker inspect will help you). My location is listed here:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;vim &#x2F;var&#x2F;lib&#x2F;docker&#x2F;volumes&#x2F;389ds_data&#x2F;_data&#x2F;config&#x2F;container.inf
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;--&amp;gt; change
&lt;&#x2F;span&gt;&lt;span&gt;# basedn ...
&lt;&#x2F;span&gt;&lt;span&gt;--&amp;gt; to
&lt;&#x2F;span&gt;&lt;span&gt;basedn = dc=example,dc=com
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now you can populate data into that: The dsidm command is our tool to
manage users and groups of a backend, and it can provide initialised
data which has best-practice aci&#x27;s, demo users and groups and starts as
a great place for you to build an IDM system.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;dsidm localhost initialise
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;That&#x27;s it! You can now see you have a user and a group!&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;dsidm localhost user list
&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt; demo_user
&lt;&#x2F;span&gt;&lt;span&gt;dsidm localhost group list
&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt; demo_group
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You can create your own user:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;dsidm localhost user create --uid william --cn William --displayName &amp;#39;William Brown&amp;#39; --uidNumber 1000 --gidNumber 1000 --homeDirectory &#x2F;home&#x2F;william
&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt; Successfully created william
&lt;&#x2F;span&gt;&lt;span&gt;dsidm localhost user get william
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;It&#x27;s trivial to add an ssh key to the user:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;dsidm localhost user modify william add:nsSshPublicKey:AAA...
&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt; Successfully modified uid=william,ou=people,dc=example,dc=com
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Or to add them to a group:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;dsidm localhost group add_member demo_group uid=william,ou=people,dc=example,dc=com
&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt; added member: uid=william,ou=people,dc=example,dc=com
&lt;&#x2F;span&gt;&lt;span&gt;dsidm localhost group members demo_group
&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt; dn: uid=william,ou=people,dc=example,dc=com
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Finally, we can even generale config templates for your applications:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;dsidm localhost client_config sssd.conf
&lt;&#x2F;span&gt;&lt;span&gt;dsidm localhost client_config ldap.conf
&lt;&#x2F;span&gt;&lt;span&gt;dsidm localhost client_config display
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;I&#x27;m happy to say, LDAP administration has never been easier - we plan
to add more functionality to enabled broader ranges of administrative
tasks, especially in the IDM area and management of the configuration.
It&#x27;s honestly hard to beleve that in a shortlist of commands you can
now have a fully functional LDAP IDM solution working.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Implementing Webauthn - a series of complexities ...</title>
          <pubDate>Sun, 28 Apr 2019 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2019-04-28-implementing-webauthn-a-series-of-complexities/</link>
          <guid>https://fy.blackhats.net.au/blog/2019-04-28-implementing-webauthn-a-series-of-complexities/</guid>
          <description>&lt;h1 id=&quot;implementing-webauthn-a-series-of-complexities&quot;&gt;Implementing Webauthn - a series of complexities ...&lt;&#x2F;h1&gt;
&lt;p&gt;I have recently started to work on a rust webauthn library, to allow
servers to be implemented. However, in this process I have noticed a few
complexities to an API that should have so much promise for improving
the state of authentication. So far I can say I have not found any
cryptographic issues, but the design of the standard does raise
questions about the ability for people to correctly implement Webauthn
servers.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;odd-structure-decisions&quot;&gt;Odd structure decisions&lt;&#x2F;h2&gt;
&lt;p&gt;Webauth is made up of multiple encoding standards. There is a good
reason for this, which is that the json parts are for the webbrowser,
and the cbor parts are for ctap and the authenticator device.&lt;&#x2F;p&gt;
&lt;p&gt;However, I quickly noticed an issue in the Attestation Object, as
described here &lt;a href=&quot;https:&#x2F;&#x2F;w3c.github.io&#x2F;webauthn&#x2F;#sctn-attestation&quot;&gt;https:&#x2F;&#x2F;w3c.github.io&#x2F;webauthn&#x2F;#sctn-attestation&lt;&#x2F;a&gt; . Can
you see the problem?&lt;&#x2F;p&gt;
&lt;p&gt;The problem is that the Authenticator Data relies on hand-parsing bytes,
and has two structures that are concatenated with no length. This means:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;You have to hand parse bytes 0 -&amp;gt; 36&lt;&#x2F;li&gt;
&lt;li&gt;You then have to CBOR deserialise the Attested Cred Data (if
present)&lt;&#x2F;li&gt;
&lt;li&gt;You then need to serialise the ACD back to bytes and record that
length (if your library doesn&#x27;t tell you how long the amount of
data is parsed was).&lt;&#x2F;li&gt;
&lt;li&gt;Then you need to CBOR deserialise the Extensions.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;What&#x27;s more insulting about this situation is that the Authenticator
Data literally is part of the AttestationObject which is already
provided as CBOR! There seems to be no obvious reason for this to
require hand-parsing, as the Authenticator Data which will be signature
checked, has it&#x27;s byte form checked, so you could have the
AttestationObject store authDataBytes, then you can CBOR decode the
nested structure (allowing the hashing of the bytes later).&lt;&#x2F;p&gt;
&lt;p&gt;There are many risks here because now you have requirements to length
check all the parameters which people could get wrong - when CBOR would
handle this correctly for you you and provides a good level of
correctness that the structure is altered. I also trust the CBOR parser
authors to do proper length checks too compared to my crappy byte
parsing code!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;confusing-naming-conventions-and-layout&quot;&gt;Confusing Naming Conventions and Layout&lt;&#x2F;h2&gt;
&lt;p&gt;The entire standard is full of various names and structures, which are
complex, arbitrarily nested and hard to see why they are designed this
way. Perhaps it&#x27;s a legacy compatability issue? More likely I think
it&#x27;s object-oriented programming leaking into the specification, which
is a paradigm that is not universally applicable.&lt;&#x2F;p&gt;
&lt;p&gt;Regardless, it would be good if the structures were flatter, and named
better. There are many confusing structure names throughout the
standard, and it can sometimes be hard to identify what you require and
don&#x27;t require.&lt;&#x2F;p&gt;
&lt;p&gt;Additionally, naming of fields and their use, uses abbrivations to save
bandwidth, but makes it hard to follow. I did honestly get confused
about the difference between rp (the relying party name) and rp_id,
where the challenge provides rp, and the browser response use rp_id.&lt;&#x2F;p&gt;
&lt;p&gt;It can be easy to point fingers and say &amp;quot;ohh William, you&#x27;re just not
reading it properly and are stupid&amp;quot;. Am I? Or is it that humans find it
really hard to parse data like this, and our brains are better suited to
other tasks? Human factors are important to consider in specification
design both in naming of values, consistency of their use, and
appropriate communication as to how they are used properly. I&#x27;m finding
this to be a barrier to correct implementation now (especially as the
signature verification section is very fragmented and hard to follow
...).&lt;&#x2F;p&gt;
&lt;h2 id=&quot;crypto-steps-seem-complex-or-too-static&quot;&gt;Crypto Steps seem complex or too static&lt;&#x2F;h2&gt;
&lt;p&gt;There are a lot of possible choices here - there are 6 attestation
formats and 5 attestation types. As some formats only do some types,
there are then 11 verification paths you need to implement for all
possible authenticators. I think this level of complexity will lead to
mistakes over a large number of possible code branch paths, or lacking
support for some device types which people may not have access to.&lt;&#x2F;p&gt;
&lt;p&gt;I think it may have been better to limit the attestation format to one,
well defined format, and within that to limit the attestation types
available to suit a more broad range of uses.&lt;&#x2F;p&gt;
&lt;p&gt;It feels a lot like these choice are part of some internal
Google&#x2F;MS&#x2F;Other internal decisions for high security devices, or custom
deviges, which will be internally used. It&#x27;s leaked into the spec and
it raises questions about the ability for people to meaningfully
implement the full specification for all possible devices, let alone
correctly.&lt;&#x2F;p&gt;
&lt;p&gt;Some parts even omit details in a cryptographic operation, such as
&lt;a href=&quot;https:&#x2F;&#x2F;w3c.github.io&#x2F;webauthn&#x2F;#fido-u2f-attestation&quot;&gt;here&lt;&#x2F;a&gt; in
verification step 2, it doesn&#x27;t even list what format the bytes are.
(Hint: it&#x27;s DER x509).&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-would-i-change&quot;&gt;What would I change?&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Be more specific&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;There should be no assumptions about format types, what is in bytes. Be
verbose, detailed and without ambiguity.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Use type safe, length checked structures.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;I would probably make the entire thing a single CBOR structure which
contains other nested structures as required. We should never have to
hand-parse bytes in 2019, especially when there is a great deal of
evidence to show the risks of expecting people to do this.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Don&#x27;t assume object orientation&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;I think simpler, flatter structures in the json&#x2F;cbor would have helped,
and been clearer to implement, rather than the really complex maze of
types currently involved.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;&#x2F;h2&gt;
&lt;p&gt;Despite these concerns, I still think webauthn is a really good
standard, and I really do think it will become the future of
authentication. I&#x27;m hoping to help make that a reality in opensource
and I hope that in the future I can contribute to further development
and promotion of webauthn.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>The Case for Ethics in OpenSource</title>
          <pubDate>Sun, 28 Apr 2019 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2019-04-28-the-case-for-ethics-in-opensource/</link>
          <guid>https://fy.blackhats.net.au/blog/2019-04-28-the-case-for-ethics-in-opensource/</guid>
          <description>&lt;h1 id=&quot;the-case-for-ethics-in-opensource&quot;&gt;The Case for Ethics in OpenSource&lt;&#x2F;h1&gt;
&lt;p&gt;For a long time there have been incidents in technology which have
caused negative effects on people - from leaks of private data, to
interfaces that are not accessible, to even issues like UI&#x27;s doing
things that may try to subvert a persons intent. I&#x27;m sure there are
many more: and we could be here all day listing the various issues that
exist in technology, from small to great.&lt;&#x2F;p&gt;
&lt;p&gt;The theme however is that these issues continue to happen: we continue
to make decisions in applications that can have consequences to humans.&lt;&#x2F;p&gt;
&lt;p&gt;Software is pointless without people. People create software, people
deploy software, people interact with software, and even software
indirectly can influence people&#x27;s lives. At every layer people exist,
and all software will affect them in some ways.&lt;&#x2F;p&gt;
&lt;p&gt;I think that today, we have made a lot of progress in our communities
around the deployment of code&#x27;s of conduct. These are great, and really
help us to discuss the decisions and actions we take within our
communities - with the people who create the software. I would like this
to go further, where we can have a framework to discuss the effect of
software on people that we write: the people that deploy, interact with
and are influenced by our work.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;disclaimers&quot;&gt;Disclaimers&lt;&#x2F;h2&gt;
&lt;p&gt;I&#x27;m not a specialist in ethics or morality: I&#x27;m not a registered or
certified engineer in the legal sense. Finally, like all humans I am a
product of my experiences which causes all my view points to be biased
through the lens of my experience.&lt;&#x2F;p&gt;
&lt;p&gt;Additionally, I specialise in Identity Management software, so many of
the ideas and issues I have encountered are really specific to this
domain - which means I may overlook the issues in other areas. I also
have a &amp;quot;security&amp;quot; mindset which also factors into my decisions too.&lt;&#x2F;p&gt;
&lt;p&gt;Regardless I hope that this is a starting point to recieve further input
and advice from others, and a place where we can begin to improve.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-problem&quot;&gt;The Problem&lt;&#x2F;h2&gt;
&lt;p&gt;TODO: Discuss data handling practices&lt;&#x2F;p&gt;
&lt;p&gt;Let&#x27;s consider some issues and possible solutions in work that I&#x27;m
familiar with - identity management software. Lets list a few
&amp;quot;features&amp;quot;. (Please don&#x27;t email me about how these are wrong, I know
they are ...)&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Storing usernames as first and last name&lt;&#x2F;li&gt;
&lt;li&gt;Storing passwords in cleartext.&lt;&#x2F;li&gt;
&lt;li&gt;Deleting an account sets a flag to mark deletion&lt;&#x2F;li&gt;
&lt;li&gt;Names are used as the primary key&lt;&#x2F;li&gt;
&lt;li&gt;We request sex on signup&lt;&#x2F;li&gt;
&lt;li&gt;To change account details, you have to use a command line tool&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Now &amp;quot;technically&amp;quot;, none of these decisions are incorrect at all. There
is literally no bad technical decision here, and everything is
&amp;quot;technically correct&amp;quot; (not always the best kind of correct).&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-do-we-want-to-achieve&quot;&gt;What do we want to achieve?&lt;&#x2F;h2&gt;
&lt;p&gt;There are lots of different issues here, but really want to prevent harm
to a person. What is harm? Well that&#x27;s a complex topic. To me, it could
be emotional harm, disrespect of their person, it could be a feeling of
a lack of control.&lt;&#x2F;p&gt;
&lt;p&gt;I don&#x27;t believe it&#x27;s correct to dictate a set of rules that people
should follow. People will be fatigued, and will find the process too
hard. We need to trust that people can learn and want to improve.
Instead I believe it&#x27;s important we provide important points that
people should be able to consider in a discussion around the development
of software. The same way we discuss technical implementation details,
we should discuss potential human impact in every change we have. To
realise this, we need a short list of important factors that relate to
humans.&lt;&#x2F;p&gt;
&lt;p&gt;I think the following points are important to consider when designing
software. These relate to general principles which I have learnt and
researched.&lt;&#x2F;p&gt;
&lt;p&gt;People should be respected to have:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Informed consent&lt;&#x2F;li&gt;
&lt;li&gt;Choice over how they are identified&lt;&#x2F;li&gt;
&lt;li&gt;Ability to be forgotten&lt;&#x2F;li&gt;
&lt;li&gt;Individual Autonomy&lt;&#x2F;li&gt;
&lt;li&gt;Free from Harmful Discrimination&lt;&#x2F;li&gt;
&lt;li&gt;Privacy&lt;&#x2F;li&gt;
&lt;li&gt;Ability to meaningfully access and use software&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;There is already some evidence in research papers to show that there are
strong reasons for moral positions in software. For example, to prevent
harm to come to people, to respect peoples autonomy and to conform to
privacy legislation (
&lt;a href=&quot;https:&#x2F;&#x2F;plato.stanford.edu&#x2F;entries&#x2F;it-privacy&#x2F;#MorReaForProPerDat&quot;&gt;source&lt;&#x2F;a&gt;
).&lt;&#x2F;p&gt;
&lt;h2 id=&quot;let-s-apply-these&quot;&gt;Let&#x27;s apply these&lt;&#x2F;h2&gt;
&lt;p&gt;Given our set of &amp;quot;features&amp;quot;, lets now discuss these with the above
points in mind.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Storing usernames as first and last name&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;This point clearly is in violation of the ability to choose how people
are identified - some people may only have a single name, some may have
multiple family names. On a different level this also violates the
harmful discrimination rule due to the potential to disrespect
individuals with cultures that have different name schemes compared to
western&#x2F;English societies.&lt;&#x2F;p&gt;
&lt;p&gt;A better way to approach this is &amp;quot;displayName&amp;quot; as a freetext UTF8 case
sensitive field, and to allow substring search over the content (rather
than attempting to sort by first&#x2F;last name which also has a stack of
issues).&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Storing passwords in cleartext.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;This one is a violation of privacy, that we risk the exposure of a
password which &lt;em&gt;may&lt;&#x2F;em&gt; have been reused (we can&#x27;t really stop password
reuse, we need to respect human behaviour). Not only that some people
may assume we DO hash these correctly, so we actually are violating
informed consent as we didn&#x27;t disclose the method of how we store these
details.&lt;&#x2F;p&gt;
&lt;p&gt;A better thing here is to hash the password, or at least to disclose how
it will be stored and used.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Deleting an account sets a flag to mark deletion&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;This violates the ability to be forgotten, because we aren&#x27;t really
deleting the account. It also breaks informed consent, because we are
being &amp;quot;deceptive&amp;quot; about what our software is actually doing compared
to the intent of the users request&lt;&#x2F;p&gt;
&lt;p&gt;A better thing is to just delete the account, or if not possible, delete
all user data and leave a tombstone inplace that represents &amp;quot;an account
was here, but no details associated&amp;quot;.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Names are used as the primary key&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;This violates choice over identification, especially for women who have
a divorce, or individuals who are transitioning or just people who want
to change their name in general. The reason for the name change doesn&#x27;t
matter - what matters is we need to respect peoples right to
identification.&lt;&#x2F;p&gt;
&lt;p&gt;A better idea is to use UUID&#x2F;ID numbers as a primary key, and have name
able to be changed at any point in time.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;We request sex on signup&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Violates a privacy as a first point - we probably have no need for the
data unless we are a medical application, so we should never ask for
this at all. We also need to disclose why we need this data to satisfy
informed consent, and potentially to allow them to opt-out of providing
the data. Finally (if we really require this), to not violate self
identification, we need to allow this to be a free-text field rather
than a Male&#x2F;Female boolean. This is not just in respect of individuals
who are LGBTQI+, but the reality that there are biologically people who
medically are neither. We also need to allow this to be changed at any
time in the future. This in mind Sex and Gender are different concepts,
so we should be careful which we request - Sex is the medical term of a
person&#x27;s genetics, and Gender is who the person identifies as.&lt;&#x2F;p&gt;
&lt;p&gt;Not only this, because this is a very personal piece of information, we
must disclose how we protect this information from access, who can see
it, and if or how we&#x27;ll ever share it with other systems or
authorities.&lt;&#x2F;p&gt;
&lt;p&gt;Generally, we probably don&#x27;t need to know, so don&#x27;t ask for it at all.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;To change account details, you have to use a command line tool&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;This violates a users ability to meaningfully access and use software -
remember, people come from many walks of life and all have different
skill sets, but using command line tools is not something we can
universally expect.&lt;&#x2F;p&gt;
&lt;p&gt;A proper solution here is at minimum a web&#x2F;graphical self management
portal that is easy to access and follows proper UX&#x2F;UI design rules, and
for a business deploying, a service desk with humans involved that can
support and help people change details on their account on their behalf
if the person is unable to self-support via the web service.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;proposal&quot;&gt;Proposal&lt;&#x2F;h2&gt;
&lt;p&gt;I think that OpenSource should aim to have a code of ethics - the same
way we have a code of conduct to guide our behaviour internally to a
project, we should have a framework to promote discussion of people&#x27;s
rights that use, interact with and are affected by our work. We should
not focus on technical matters only, but should be promoting people at
the core of all our work. Every decision we make is not just technical,
but social.&lt;&#x2F;p&gt;
&lt;p&gt;I&#x27;m sure that there are more points that could be considere than what I
have listed here: I&#x27;d love to hear feedback to william at
blackhats.net.au. Thanks!&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Using Rust Generics to Enforce DB Record State</title>
          <pubDate>Sat, 13 Apr 2019 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2019-04-13-using-rust-generics-to-enforce-db-record-state/</link>
          <guid>https://fy.blackhats.net.au/blog/2019-04-13-using-rust-generics-to-enforce-db-record-state/</guid>
          <description>&lt;h1 id=&quot;using-rust-generics-to-enforce-db-record-state&quot;&gt;Using Rust Generics to Enforce DB Record State&lt;&#x2F;h1&gt;
&lt;p&gt;In a database, entries go through a lifecycle which represents what
attributes they have have, db record keys, and if they have conformed to
schema checking.&lt;&#x2F;p&gt;
&lt;p&gt;I&#x27;m currently working on a (private in 2019, public in july 2019)
project which is a NoSQL database writting in Rust. To help us manage
the correctness and lifecycle of database entries, I have been using
advice from the &lt;a href=&quot;https:&#x2F;&#x2F;docs.rust-embedded.org&#x2F;book&#x2F;static-guarantees&#x2F;state-machines.html&quot;&gt;Rust Embedded Group&#x27;s
Book.&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;As I have mentioned in the past, state machines are a great way to
design code, so let&#x27;s plot out the state machine we have for Entries:&lt;&#x2F;p&gt;
&lt;h2 id=&quot;entry-state-machine&quot;&gt;Entry State Machine&lt;&#x2F;h2&gt;
&lt;p&gt;The lifecyle is:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;A new entry is submitted by the user for creation&lt;&#x2F;li&gt;
&lt;li&gt;We schema check that entry&lt;&#x2F;li&gt;
&lt;li&gt;If it passes schema, we commit it and assign internal ID&#x27;s&lt;&#x2F;li&gt;
&lt;li&gt;When we search the entry, we retrieve it by internal ID&#x27;s&lt;&#x2F;li&gt;
&lt;li&gt;When we modify the entry, we need to recheck it&#x27;s schema before we
commit it back&lt;&#x2F;li&gt;
&lt;li&gt;When we delete, we just remove the entry.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;This leads to a state machine of:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;|
&lt;&#x2F;span&gt;&lt;span&gt;(create operation)
&lt;&#x2F;span&gt;&lt;span&gt;|
&lt;&#x2F;span&gt;&lt;span&gt;v
&lt;&#x2F;span&gt;&lt;span&gt;[ New + Invalid ] -(schema check)-&amp;gt; [ New + Valid ]
&lt;&#x2F;span&gt;&lt;span&gt;                                  |
&lt;&#x2F;span&gt;&lt;span&gt;                           (send to backend)
&lt;&#x2F;span&gt;&lt;span&gt;                                  |
&lt;&#x2F;span&gt;&lt;span&gt;                                  v    v-------------\
&lt;&#x2F;span&gt;&lt;span&gt;[Commited + Invalid] &amp;lt;-(modify operation)- [ Commited + Valid ]          |
&lt;&#x2F;span&gt;&lt;span&gt;|                                          ^   \       (write to backend)
&lt;&#x2F;span&gt;&lt;span&gt;\--------------(schema check)-------------&#x2F;     ---------------&#x2F;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This is a bit rough - The version on my whiteboard was better :)&lt;&#x2F;p&gt;
&lt;p&gt;The main observation is that we are focused only on the commitability
and validty of entries - not about where they are or if the commit was a
success.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;entry-structs&quot;&gt;Entry Structs&lt;&#x2F;h2&gt;
&lt;p&gt;So to make these states work we have the following structs:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;struct EntryNew;
&lt;&#x2F;span&gt;&lt;span&gt;struct EntryCommited;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;struct EntryValid;
&lt;&#x2F;span&gt;&lt;span&gt;struct EntryInvalid;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;struct Entry&amp;lt;STATE, VALID&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;    state: STATE,
&lt;&#x2F;span&gt;&lt;span&gt;    valid: VALID,
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; Other db junk goes here :)
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;We can then use these to establish the lifecycle with functions
(similar) to this:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;impl Entry&amp;lt;EntryNew, EntryInvalid&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;    fn new() -&amp;gt; Self {
&lt;&#x2F;span&gt;&lt;span&gt;        Entry {
&lt;&#x2F;span&gt;&lt;span&gt;            state: EntryNew,
&lt;&#x2F;span&gt;&lt;span&gt;            valid: EntryInvalid,
&lt;&#x2F;span&gt;&lt;span&gt;            ...
&lt;&#x2F;span&gt;&lt;span&gt;        }
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;impl&amp;lt;STATE&amp;gt; Entry&amp;lt;STATE, EntryInvalid&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;    fn validate(self, schema: Schema) -&amp;gt; Result&amp;lt;Entry&amp;lt;STATE, EntryValid&amp;gt;, ()&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;        if schema.check(self) {
&lt;&#x2F;span&gt;&lt;span&gt;            Ok(Entry {
&lt;&#x2F;span&gt;&lt;span&gt;                state: self.state,
&lt;&#x2F;span&gt;&lt;span&gt;                valid: EntryValid,
&lt;&#x2F;span&gt;&lt;span&gt;                ...
&lt;&#x2F;span&gt;&lt;span&gt;            })
&lt;&#x2F;span&gt;&lt;span&gt;        } else {
&lt;&#x2F;span&gt;&lt;span&gt;            Err(())
&lt;&#x2F;span&gt;&lt;span&gt;        }
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    fn modify(&amp;amp;mut self, ...) {
&lt;&#x2F;span&gt;&lt;span&gt;        &#x2F;&#x2F; Perform any modifications on the entry you like, only works
&lt;&#x2F;span&gt;&lt;span&gt;        &#x2F;&#x2F; on invalidated entries.
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;impl&amp;lt;STATE&amp;gt; Entry&amp;lt;STATE, EntryValid&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;    fn seal(self) -&amp;gt; Entry&amp;lt;EntryCommitted, EntryValid&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;        &#x2F;&#x2F; Assign internal id&amp;#39;s etc
&lt;&#x2F;span&gt;&lt;span&gt;        Entry {
&lt;&#x2F;span&gt;&lt;span&gt;            state: EntryCommited,
&lt;&#x2F;span&gt;&lt;span&gt;            valid: EntryValid,
&lt;&#x2F;span&gt;&lt;span&gt;        }
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    fn compare(&amp;amp;self, other: Entry&amp;lt;STATE, EntryValid&amp;gt;) -&amp;gt; ... {
&lt;&#x2F;span&gt;&lt;span&gt;        &#x2F;&#x2F; Only allow compares on schema validated&#x2F;normalised
&lt;&#x2F;span&gt;&lt;span&gt;        &#x2F;&#x2F; entries, so that checks don&amp;#39;t have to be schema aware
&lt;&#x2F;span&gt;&lt;span&gt;        &#x2F;&#x2F; as the entries are already in a comparable state.
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;impl Entry&amp;lt;EntryCommited, EntryValid&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;    fn invalidate(self) -&amp;gt; Entry&amp;lt;EntryCommited, EntryInvalid&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;        &#x2F;&#x2F; Invalidate an entry, to allow modifications to be performed
&lt;&#x2F;span&gt;&lt;span&gt;        &#x2F;&#x2F; note that modifications can only be applied once an entry is created!
&lt;&#x2F;span&gt;&lt;span&gt;        Entry {
&lt;&#x2F;span&gt;&lt;span&gt;            state: self.state,
&lt;&#x2F;span&gt;&lt;span&gt;            valid: EntryInvalid,
&lt;&#x2F;span&gt;&lt;span&gt;        }
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;What this allows us to do importantly is to control when we apply search
terms, send entries to the backend for storage and more. Benefit is this
is compile time checked, so you can never send an entry to a backend
that is &lt;em&gt;not&lt;&#x2F;em&gt; schema checked, or run comparisons or searches on entries
that aren&#x27;t schema checked, and you can even only modify or delete
something once it&#x27;s created. For example other parts of the code now
have:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;impl BackendStorage {
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; Can only create if no db id&amp;#39;s are assigned, IE it must be new.
&lt;&#x2F;span&gt;&lt;span&gt;    fn create(&amp;amp;self, ..., entry: Entry&amp;lt;EntryNew, EntryValid&amp;gt;) -&amp;gt; Result&amp;lt;...&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; Can only modify IF it has been created, and is validated.
&lt;&#x2F;span&gt;&lt;span&gt;    fn modify(&amp;amp;self, ..., entry: Entry&amp;lt;EntryCommited, EntryValid&amp;gt;) -&amp;gt; Result&amp;lt;...&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; Can only delete IF it has been created and committed.
&lt;&#x2F;span&gt;&lt;span&gt;    fn delete(&amp;amp;self, ..., entry: Entry&amp;lt;EntryCommited, EntryValid&amp;gt;) -&amp;gt; Result&amp;lt;...&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;impl Filter&amp;lt;STATE&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; Can only apply filters (searches) if the entry is schema checked. This has an
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; important behaviour, where we can schema normalise. Consider a case-insensitive
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; type, we can schema-normalise this on the entry, then our compare can simply
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; be a string.compare, because we assert both entries *must* have been through
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; the normalisation routines!
&lt;&#x2F;span&gt;&lt;span&gt;    fn apply_filter(&amp;amp;self, ..., entry: &amp;amp;Entry&amp;lt;STATE, EntryValid&amp;gt;) -&amp;gt; Result&amp;lt;bool, ...&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;using-this-with-serde&quot;&gt;Using this with Serde?&lt;&#x2F;h2&gt;
&lt;p&gt;I have noticed that when we serialise the entry, that this causes the
valid&#x2F;state field to &lt;em&gt;not&lt;&#x2F;em&gt; be compiled away - because they &lt;em&gt;have&lt;&#x2F;em&gt; to be
serialised, regardless of the empty content meaning the compiler can&#x27;t
eliminate them.&lt;&#x2F;p&gt;
&lt;p&gt;A future cleanup will be to have a serialised DBEntry form such as the
following:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;struct DBEV1 {
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; entry data here
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;enum DBEntryVersion {
&lt;&#x2F;span&gt;&lt;span&gt;    V1(DBEV1)
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;struct DBEntry {
&lt;&#x2F;span&gt;&lt;span&gt;    data: DBEntryVersion
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;impl From&amp;lt;Entry&amp;lt;EntryNew, EntryValid&amp;gt;&amp;gt; for DBEntry {
&lt;&#x2F;span&gt;&lt;span&gt;    fn from(e: Entry&amp;lt;EntryNew, EntryValid&amp;gt;) -&amp;gt; Self {
&lt;&#x2F;span&gt;&lt;span&gt;        &#x2F;&#x2F; assign db id&amp;#39;s, and return a serialisable entry.
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;impl From&amp;lt;Entry&amp;lt;EntryCommited, EntryValid&amp;gt;&amp;gt; for DBEntry {
&lt;&#x2F;span&gt;&lt;span&gt;    fn from(e: Entry&amp;lt;EntryCommited, EntryValid&amp;gt;) -&amp;gt; Self {
&lt;&#x2F;span&gt;&lt;span&gt;        &#x2F;&#x2F; Just translate the entry to a serialisable form
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This way we still have the zero-cost state on Entry, but we are able to
move to a versioned seralised structure, and we minimise the run time
cost.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;testing-the-entry&quot;&gt;Testing the Entry&lt;&#x2F;h2&gt;
&lt;p&gt;To help with testing, I needed to be able to shortcut and move between
anystate of the entry so I could quickly make fake entries, so I added
some unsafe methods:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;#[cfg(test)]
&lt;&#x2F;span&gt;&lt;span&gt;unsafe fn to_new_valid(self, Entry&amp;lt;EntryNew, EntryInvalid&amp;gt;) -&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;    Entry {
&lt;&#x2F;span&gt;&lt;span&gt;        state: EntryNew,
&lt;&#x2F;span&gt;&lt;span&gt;        valid: EntryValid
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;These allow me to setup and create small unit tests where I may not have
a full backend or schema infrastructure, so I can test specific aspects
of the entries and their lifecycle. It&#x27;s limited to test runs only, and
marked unsafe. It&#x27;s not &amp;quot;technically&amp;quot; memory unsafe, but it&#x27;s unsafe
from the view of &amp;quot;it could absolutely mess up your database consistency
guarantees&amp;quot; so you have to really want it.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;&#x2F;h2&gt;
&lt;p&gt;Using statemachines like this, really helped me to clean up my code,
make stronger assertions about the correctness of what I was doing for
entry lifecycles, and means that I have more faith when I and
future-contributors will work on the code base that we&#x27;ll have compile
time checks to ensure we are doing the right thing - to prevent data
corruption and inconsistency.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Debugging MacOS bluetooth audio stutter</title>
          <pubDate>Mon, 08 Apr 2019 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2019-04-08-debugging-macos-bluetooth-audio-stutter/</link>
          <guid>https://fy.blackhats.net.au/blog/2019-04-08-debugging-macos-bluetooth-audio-stutter/</guid>
          <description>&lt;h1 id=&quot;debugging-macos-bluetooth-audio-stutter&quot;&gt;Debugging MacOS bluetooth audio stutter&lt;&#x2F;h1&gt;
&lt;p&gt;I was noticing that audio to my bluetooth headphones from my iPhone was
always flawless, but I started to noticed stutter and drops from my MBP.
After exhausting some basic ideas, I was stumped.&lt;&#x2F;p&gt;
&lt;p&gt;To the duck duck go machine, and I searched for issues with bluetooth
known issues. Nothing appeared.&lt;&#x2F;p&gt;
&lt;p&gt;However, I then decided to debug the issue - thankfully there was plenty
of advice on this matter. Press shift + option while clicking bluetooth
in the menu-bar, and then you have a debug menu. You can also open
Console.app and search for &amp;quot;bluetooth&amp;quot; to see all the bluetooth
related logs.&lt;&#x2F;p&gt;
&lt;p&gt;I noticed that when the audio stutter occured that the following pattern
was observed.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;default 11:25:45.840532 +1000   wirelessproxd   About to scan for type: 9 - rssi: -90 - payload: &amp;lt;00000000 00000000 00000000 00000000 00000000 0000&amp;gt; - mask: &amp;lt;00000000 00000000 00000000 00000000 00000000 0000&amp;gt; - peers: 0
&lt;&#x2F;span&gt;&lt;span&gt;default 11:25:45.840878 +1000   wirelessproxd   Scan options changed: YES
&lt;&#x2F;span&gt;&lt;span&gt;error   11:25:46.225839 +1000   bluetoothaudiod Error sending audio packet: 0xe00002e8
&lt;&#x2F;span&gt;&lt;span&gt;error   11:25:46.225899 +1000   bluetoothaudiod Too many outstanding packets. Drop packet of 8 frames (total drops:451 total sent:60685 percentDropped:0.737700) Outstanding:17
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;There was always a scan, just before the stutter initiated. So what was
scanning?&lt;&#x2F;p&gt;
&lt;p&gt;I searched for the error related to packets, and there were a lot of
false leads. From weird apps to dodgy headphones. In this case I could
eliminate both as the headphones worked with other devices, and I don&#x27;t
have many apps installed.&lt;&#x2F;p&gt;
&lt;p&gt;So I went back and thought about what macOS services could be the
problem, and I found that airdrop would scan periodically for other
devices to send and recieve files. Disabling Airdrop from the sharing
menu in System Prefrences cleared my audio right up.&lt;&#x2F;p&gt;
&lt;p&gt;UPDATE 2019-12-20: It looks like the Airdrop sharing option in system
preferences has been removed in 10.15, so I don&#x27;t believe it&#x27;s
possible to resove this issue now - audio stutter forever!&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>GDB autoloads for 389 DS</title>
          <pubDate>Wed, 03 Apr 2019 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2019-04-03-gdb-autoloads-for-389-ds/</link>
          <guid>https://fy.blackhats.net.au/blog/2019-04-03-gdb-autoloads-for-389-ds/</guid>
          <description>&lt;h1 id=&quot;gdb-autoloads-for-389-ds&quot;&gt;GDB autoloads for 389 DS&lt;&#x2F;h1&gt;
&lt;p&gt;I&#x27;ve been writing a set of extensions to help debug 389-ds a bit
easier. Thanks to the magic of python, writing GDB extensions is really
easy.&lt;&#x2F;p&gt;
&lt;p&gt;On OpenSUSE, when you start your DS instance under GDB, all of the
extensions are automatically loaded. This will help make debugging a
breeze.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;zypper in 389-ds gdb
&lt;&#x2F;span&gt;&lt;span&gt;gdb &#x2F;usr&#x2F;sbin&#x2F;ns-slapd
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;GNU gdb (GDB; openSUSE Tumbleweed) 8.2
&lt;&#x2F;span&gt;&lt;span&gt;(gdb) ds-
&lt;&#x2F;span&gt;&lt;span&gt;ds-access-log  ds-backtrace
&lt;&#x2F;span&gt;&lt;span&gt;(gdb) set args -d 0 -D &#x2F;etc&#x2F;dirsrv&#x2F;slapd-&amp;lt;instance name&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;(gdb) run
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;All the extensions are under the ds- namespace, so they are easy to
find. There are some new ones on the way, which I&#x27;ll discuss here too:&lt;&#x2F;p&gt;
&lt;h2 id=&quot;ds-backtrace&quot;&gt;ds-backtrace&lt;&#x2F;h2&gt;
&lt;p&gt;As DS is a multithreaded process, it can be really hard to find the
active thread involved in a problem. So we provided a command that knows
how to fold duplicated stacks, and to highlight idle threads that you
can (generally) skip over.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;===== BEGIN ACTIVE THREADS =====
&lt;&#x2F;span&gt;&lt;span&gt;Thread 37 (LWP 70054))
&lt;&#x2F;span&gt;&lt;span&gt;Thread 36 (LWP 70053))
&lt;&#x2F;span&gt;&lt;span&gt;Thread 35 (LWP 70052))
&lt;&#x2F;span&gt;&lt;span&gt;Thread 34 (LWP 70051))
&lt;&#x2F;span&gt;&lt;span&gt;Thread 33 (LWP 70050))
&lt;&#x2F;span&gt;&lt;span&gt;Thread 32 (LWP 70049))
&lt;&#x2F;span&gt;&lt;span&gt;Thread 31 (LWP 70048))
&lt;&#x2F;span&gt;&lt;span&gt;Thread 30 (LWP 70047))
&lt;&#x2F;span&gt;&lt;span&gt;Thread 29 (LWP 70046))
&lt;&#x2F;span&gt;&lt;span&gt;Thread 28 (LWP 70045))
&lt;&#x2F;span&gt;&lt;span&gt;Thread 27 (LWP 70044))
&lt;&#x2F;span&gt;&lt;span&gt;Thread 26 (LWP 70043))
&lt;&#x2F;span&gt;&lt;span&gt;Thread 25 (LWP 70042))
&lt;&#x2F;span&gt;&lt;span&gt;Thread 24 (LWP 70041))
&lt;&#x2F;span&gt;&lt;span&gt;Thread 23 (LWP 70040))
&lt;&#x2F;span&gt;&lt;span&gt;Thread 22 (LWP 70039))
&lt;&#x2F;span&gt;&lt;span&gt;Thread 21 (LWP 70038))
&lt;&#x2F;span&gt;&lt;span&gt;Thread 20 (LWP 70037))
&lt;&#x2F;span&gt;&lt;span&gt;Thread 19 (LWP 70036))
&lt;&#x2F;span&gt;&lt;span&gt;Thread 18 (LWP 70035))
&lt;&#x2F;span&gt;&lt;span&gt;Thread 17 (LWP 70034))
&lt;&#x2F;span&gt;&lt;span&gt;Thread 16 (LWP 70033))
&lt;&#x2F;span&gt;&lt;span&gt;Thread 15 (LWP 70032))
&lt;&#x2F;span&gt;&lt;span&gt;Thread 14 (LWP 70031))
&lt;&#x2F;span&gt;&lt;span&gt;Thread 13 (LWP 70030))
&lt;&#x2F;span&gt;&lt;span&gt;Thread 12 (LWP 70029))
&lt;&#x2F;span&gt;&lt;span&gt;Thread 11 (LWP 70028))
&lt;&#x2F;span&gt;&lt;span&gt;Thread 10 (LWP 70027))
&lt;&#x2F;span&gt;&lt;span&gt;#0  0x00007ffff65db03c in pthread_cond_wait@@GLIBC_2.3.2 () at &#x2F;lib64&#x2F;libpthread.so.0
&lt;&#x2F;span&gt;&lt;span&gt;#1  0x00007ffff66318b0 in PR_WaitCondVar () at &#x2F;usr&#x2F;lib64&#x2F;libnspr4.so
&lt;&#x2F;span&gt;&lt;span&gt;#2  0x00000000004220e0 in [IDLE THREAD] connection_wait_for_new_work (pb=0x608000498020, interval=4294967295) at &#x2F;home&#x2F;william&#x2F;development&#x2F;389ds&#x2F;ds&#x2F;ldap&#x2F;servers&#x2F;slapd&#x2F;connection.c:970
&lt;&#x2F;span&gt;&lt;span&gt;#3  0x0000000000425a31 in connection_threadmain () at &#x2F;home&#x2F;william&#x2F;development&#x2F;389ds&#x2F;ds&#x2F;ldap&#x2F;servers&#x2F;slapd&#x2F;connection.c:1536
&lt;&#x2F;span&gt;&lt;span&gt;#4  0x00007ffff6637484 in None () at &#x2F;usr&#x2F;lib64&#x2F;libnspr4.so
&lt;&#x2F;span&gt;&lt;span&gt;#5  0x00007ffff65d4fab in start_thread () at &#x2F;lib64&#x2F;libpthread.so.0
&lt;&#x2F;span&gt;&lt;span&gt;#6  0x00007ffff6afc6af in clone () at &#x2F;lib64&#x2F;libc.so.6
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This example shows that there are 17 idle threads (look at frame 2)
here, that all share the same trace.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;ds-access-log&quot;&gt;ds-access-log&lt;&#x2F;h2&gt;
&lt;p&gt;The access log is buffered before writing, so if you have a coredump,
and want to see the last few events &lt;em&gt;before&lt;&#x2F;em&gt; they were written to disk,
you can use this to display the content:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;(gdb) ds-access-log
&lt;&#x2F;span&gt;&lt;span&gt;===== BEGIN ACCESS LOG =====
&lt;&#x2F;span&gt;&lt;span&gt;$2 = 0x7ffff3c3f800 &amp;quot;[03&#x2F;Apr&#x2F;2019:10:58:42.836246400 +1000] conn=1 fd=64 slot=64 connection from 127.0.0.1 to 127.0.0.1
&lt;&#x2F;span&gt;&lt;span&gt;[03&#x2F;Apr&#x2F;2019:10:58:42.837199400 +1000] conn=1 op=0 BIND dn=\&amp;quot;\&amp;quot; method=128 version=3
&lt;&#x2F;span&gt;&lt;span&gt;[03&#x2F;Apr&#x2F;2019:10:58:42.837694800 +1000] conn=1 op=0 RESULT err=0 tag=97 nentries=0 etime=0.0001200300 dn=\&amp;quot;\&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;[03&#x2F;Apr&#x2F;2019:10:58:42.838881800 +1000] conn=1 op=1 SRCH base=\&amp;quot;\&amp;quot; scope=2 filter=\&amp;quot;(objectClass=*)\&amp;quot; attrs=ALL
&lt;&#x2F;span&gt;&lt;span&gt;[03&#x2F;Apr&#x2F;2019:10:58:42.839107600 +1000] conn=1 op=1 RESULT err=32 tag=101 nentries=0 etime=0.0001070800
&lt;&#x2F;span&gt;&lt;span&gt;[03&#x2F;Apr&#x2F;2019:10:58:42.840687400 +1000] conn=1 op=2 UNBIND
&lt;&#x2F;span&gt;&lt;span&gt;[03&#x2F;Apr&#x2F;2019:10:58:42.840749500 +1000] conn=1 op=2 fd=64 closed - U1
&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;, &amp;#39;\276&amp;#39; &amp;lt;repeats 3470 times&amp;gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;At the end the line that repeats shows the log is &amp;quot;empty&amp;quot; in that
segment of the buffer.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;ds-entry-print&quot;&gt;ds-entry-print&lt;&#x2F;h2&gt;
&lt;p&gt;This command shows the in-memory entry. It can be common to see
Slapi_Entry * pointers in the codebase, so being able to display these
is really helpful to isolate what&#x27;s occuring on the entry. Your first
argument should be the Slapi_Entry pointer.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;(gdb) ds-entry-print ec
&lt;&#x2F;span&gt;&lt;span&gt;Display Slapi_Entry: cn=config
&lt;&#x2F;span&gt;&lt;span&gt;cn: config
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: top
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: extensibleObject
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: nsslapdConfig
&lt;&#x2F;span&gt;&lt;span&gt;nsslapd-schemadir: &#x2F;opt&#x2F;dirsrv&#x2F;etc&#x2F;dirsrv&#x2F;slapd-standalone1&#x2F;schema
&lt;&#x2F;span&gt;&lt;span&gt;nsslapd-lockdir: &#x2F;opt&#x2F;dirsrv&#x2F;var&#x2F;lock&#x2F;dirsrv&#x2F;slapd-standalone1
&lt;&#x2F;span&gt;&lt;span&gt;nsslapd-tmpdir: &#x2F;tmp
&lt;&#x2F;span&gt;&lt;span&gt;nsslapd-certdir: &#x2F;opt&#x2F;dirsrv&#x2F;etc&#x2F;dirsrv&#x2F;slapd-standalone1
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
</description>
      </item>
      <item>
          <title>Programming Lessons and Methods</title>
          <pubDate>Tue, 26 Feb 2019 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2019-02-26-programming-lessons-and-methods/</link>
          <guid>https://fy.blackhats.net.au/blog/2019-02-26-programming-lessons-and-methods/</guid>
          <description>&lt;h1 id=&quot;programming-lessons-and-methods&quot;&gt;Programming Lessons and Methods&lt;&#x2F;h1&gt;
&lt;p&gt;Everyone has their own lessons and methods that they use when they
approaching programming. These are the lessons that I have learnt, which
I think are the most important when it comes to design, testing and
communication.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;comments-and-design&quot;&gt;Comments and Design&lt;&#x2F;h2&gt;
&lt;p&gt;Programming is the art of writing human readable code, that a machine
will eventually run. Your program needs to be reviewed, discussed and
parsed by another human. That means you need to write your program in a
way they can understand first.&lt;&#x2F;p&gt;
&lt;p&gt;Rather than rushing into code, and hacking until it works, I find it&#x27;s
great to start with comments such as:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;fn data_access(search: Search) -&amp;gt; Type {
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; First check the search is valid
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F;  * No double terms
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F;  * All schema is valid
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; Retrieve our data based on the search
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; if debug, do an un-indexed assert the search matches
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; Do any need transform
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; Return the data
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;After that, I walk away, think about the issue, come back, maybe tweak
these comments. When I eventually fill in the code inbetween, I leave
all the comments in place. This really helps my future self understand
what I was thinking, but it also helps other people understand too.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;state-machines&quot;&gt;State Machines&lt;&#x2F;h2&gt;
&lt;p&gt;State machines are a way to design and reason about the states a program
can be in. They allow exhaustive represenations of all possible outcomes
of a function. A simple example is a microwave door.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;----\            &#x2F;----- close ----\          &#x2F;-----\
&lt;&#x2F;span&gt;&lt;span&gt;|     \          &#x2F;                 v         v      |
&lt;&#x2F;span&gt;&lt;span&gt;|    -------------                ---------------   |
&lt;&#x2F;span&gt;&lt;span&gt;open   | Door Open |                | Door Closed |  close
&lt;&#x2F;span&gt;&lt;span&gt;|    -------------                ---------------   |
&lt;&#x2F;span&gt;&lt;span&gt;|    ^          ^                  &#x2F;          \     |
&lt;&#x2F;span&gt;&lt;span&gt;\---&#x2F;            \------ open ----&#x2F;            \----&#x2F;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;When the door is open, opening it again does nothing. Only when the door
is open, and we close the door (and event), does the door close (a
transition). Once closed, the door can not be closed any more (event
does nothing). It&#x27;s when we open the door now, that a state change can
occur.&lt;&#x2F;p&gt;
&lt;p&gt;There is much more to state machines than this, but they allow us as
humans to reason about our designs and model our programs to have all
possible outcomes considered.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;zero-one-and-infinite&quot;&gt;Zero, One and Infinite&lt;&#x2F;h2&gt;
&lt;p&gt;In mathematics there are only three numbers that matter. Zero, One and
Infinite. It turns out the same is true in a computer too.&lt;&#x2F;p&gt;
&lt;p&gt;When we are making a function, we can define limits in these terms. For
example:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;fn thing(argument: Type)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;In this case, argument is &amp;quot;One&amp;quot; thing, and must be one thing.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;fn thing(argument: Option&amp;lt;Type&amp;gt;)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now we have argument as an option, so it&#x27;s &amp;quot;Zero&amp;quot; or &amp;quot;One&amp;quot;.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;fn thing(argument: Vec&amp;lt;Type&amp;gt;)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now we have argument as vec (array), so it&#x27;s &amp;quot;Zero&amp;quot; to &amp;quot;Infinite&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;When we think about this, our functions have to handle these cases
properly. We don&#x27;t write functions that take a vec with only two items,
we write a function with two arguments where each one must exist. It&#x27;s
hard to handle &amp;quot;two&amp;quot; - it&#x27;s easy to handle two cases of &amp;quot;one&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;It also is a good guide for how to handle data sets, assuming they could
always be infinite in size (or at least any arbitrary size).&lt;&#x2F;p&gt;
&lt;p&gt;You can then apply this to tests. In a test given a function of:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;fn test_me(a: Option&amp;lt;Type&amp;gt;, b: Vec&amp;lt;Type&amp;gt;)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;We know we need to test permutations of:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;a is &amp;quot;Zero&amp;quot; or &amp;quot;One&amp;quot; (Some, None)&lt;&#x2F;li&gt;
&lt;li&gt;b is &amp;quot;Zero&amp;quot;, &amp;quot;One&amp;quot; or &amp;quot;Infinite&amp;quot; (.len() == 0, .len() == 1,
.len() &amp;gt; 0)&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Note: Most languages don&#x27;t have an array type that is &amp;quot;One to
Infinite&amp;quot;, IE non-empty. If you want this condition (at least one
item), you have to assert it yourself ontop of the type system.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;correct-simple-fast&quot;&gt;Correct, Simple, Fast&lt;&#x2F;h2&gt;
&lt;p&gt;Finally, we can put all these above tools together and apply a general
philosophy. When writing a program, first make it correct, then simpify
the program, then make it fast.&lt;&#x2F;p&gt;
&lt;p&gt;If you don&#x27;t do it in this order you will hit barriers - social and
technical. For example, if you make something fast, simple, correct, you
will likely have issues that can be fixed without making a decrease in
performance. People don&#x27;t like it when you introduce a patch that drops
performance, so as a result correctness is now sacrificed. (Spectre
anyone?)&lt;&#x2F;p&gt;
&lt;p&gt;If you make something too simple, you may never be able to make it
correctly handle all cases that exist in your application - likely
facilitating a future rewrite to make it correct.&lt;&#x2F;p&gt;
&lt;p&gt;If you do correct, fast, simple, then your program will be correct, and
fast, but hard for a human to understand. Because programming is the art
of communicating intent to a person sacrificing simplicity in favour of
fast will make it hard to involve new people and educate and mentor them
into development of your project.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Correct: Does it behave correctly, handle all states and inputs
correctly?&lt;&#x2F;li&gt;
&lt;li&gt;Simple: Is it easy to comprehend and follow for a human reader?&lt;&#x2F;li&gt;
&lt;li&gt;Fast: Is it performant?&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</description>
      </item>
      <item>
          <title>Meaningful 2fa on modern linux</title>
          <pubDate>Tue, 12 Feb 2019 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2019-02-12-meaningful-2fa-on-modern-linux/</link>
          <guid>https://fy.blackhats.net.au/blog/2019-02-12-meaningful-2fa-on-modern-linux/</guid>
          <description>&lt;h1 id=&quot;meaningful-2fa-on-modern-linux&quot;&gt;Meaningful 2fa on modern linux&lt;&#x2F;h1&gt;
&lt;p&gt;Recently I heard of someone asking the question:&lt;&#x2F;p&gt;
&lt;p&gt;&amp;quot;I have an AD environment connected with &amp;lt;product&amp;gt; IDM. I want to
have 2fa&#x2F;mfa to my linux machines for ssh, that works when the central
servers are offline. What&#x27;s the best way to achieve this?&amp;quot;&lt;&#x2F;p&gt;
&lt;p&gt;Today I&#x27;m going to break this down - but the conclusion for the lazy
is:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;This is not realistically possible today: use ssh keys with ldap
distribution, and mfa on the workstations, with full disk encryption&lt;&#x2F;em&gt;.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;background&quot;&gt;Background&lt;&#x2F;h2&gt;
&lt;p&gt;So there are a few parts here. AD is for intents and purposes an LDAP
server. The &amp;lt;product&amp;gt; is also an LDAP server, that syncs to AD. We
don&#x27;t care if that&#x27;s 389-ds, freeipa or vendor solution. The results
are basically the same.&lt;&#x2F;p&gt;
&lt;p&gt;Now the linux auth stack is, and will always use pam for the
authentication, and nsswitch for user id lookups. Today, we assume that
most people run sssd, but pam modules for different options are
possible.&lt;&#x2F;p&gt;
&lt;p&gt;There are a stack of possible options, and they all have various flaws.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;FreeIPA + 2fa&lt;&#x2F;li&gt;
&lt;li&gt;PAM TOTP modules&lt;&#x2F;li&gt;
&lt;li&gt;PAM radius to a TOTP server&lt;&#x2F;li&gt;
&lt;li&gt;Smartcards&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;freeipa-2fa&quot;&gt;FreeIPA + 2fa&lt;&#x2F;h2&gt;
&lt;p&gt;Now this is the one most IDM people would throw out. The issue here is
the person already has AD and a vendor product. They don&#x27;t need a third
solution.&lt;&#x2F;p&gt;
&lt;p&gt;Next is the fact that FreeIPA stores the TOTP in the LDAP, which means
FreeIPA has to be online for it to work. So this is eliminated by the
&amp;quot;central servers offline&amp;quot; requirement.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;pam-radius-to-totp-server&quot;&gt;PAM radius to TOTP server&lt;&#x2F;h2&gt;
&lt;p&gt;Same as above: An extra product, and you have a source of truth that can
go down.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;pam-totp-module-on-hosts&quot;&gt;PAM TOTP module on hosts&lt;&#x2F;h2&gt;
&lt;p&gt;Okay, even if you can get this to scale, you need to send the private
seed material of every TOTP device that could login to the machine, to
every machine. That means &lt;em&gt;any&lt;&#x2F;em&gt; compromise, compromises every TOTP token
on your network. Bad place to be in.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;smartcards&quot;&gt;Smartcards&lt;&#x2F;h2&gt;
&lt;p&gt;Are notoriously difficult to have functional, let alone with SSH. Don&#x27;t
bother. (Where the Smartcard does TLS auth to the SSH server this is.)&lt;&#x2F;p&gt;
&lt;h2 id=&quot;come-on-william-why-are-you-so-doom-and-gloom&quot;&gt;Come on William, why are you so doom and gloom!&lt;&#x2F;h2&gt;
&lt;p&gt;Lets back up for a second and think about what we we are trying to
prevent by having mfa at all. We want to prevent single factor
compromise from having a large impact &lt;em&gt;and&lt;&#x2F;em&gt; we want to prevent brute
force attacks. (There are probably more reasons, but these are the ones
I&#x27;ll focus on).&lt;&#x2F;p&gt;
&lt;p&gt;So the best answer: Use mfa on the workstation (password + totp), then
use ssh keys to the hosts.&lt;&#x2F;p&gt;
&lt;p&gt;This means the target of the attack is small, and the workstation can be
protected by things like full disk encryption and group policy. To sudo
on the host you still need the password. This makes sudo MFA to root as
you need something know, and something you have.&lt;&#x2F;p&gt;
&lt;p&gt;If you are extra conscious you can put your ssh keys on smartcards. This
works on linux and osx workstations with yubikeys as I am aware.
Apparently you can have ssh keys in TPM, which would give you tighter
hardware binding, but I don&#x27;t know how to achieve this (yet).&lt;&#x2F;p&gt;
&lt;p&gt;To make all this better, you can distributed your ssh public keys in
ldap, which means you gain the benefits of LDAP account
locking&#x2F;revocation, you can remove the keys instantly if they are
breached, and you have very little admin overhead to configuration of
this service on the linux server side. Think about how easy onboarding
is if you only need to put your ssh key in one place and it works on
every server! Let alone shutting down a compromised account: lock it in
one place, and they are denied access to every server.&lt;&#x2F;p&gt;
&lt;p&gt;SSSD as the LDAP client on the server can also cache the passwords
(hashed) and the ssh public keys, which means a disconnected client will
still be able to be authenticated to.&lt;&#x2F;p&gt;
&lt;p&gt;At this point, because you have ssh key auth working, you could even
&lt;em&gt;deny&lt;&#x2F;em&gt; password auth as an option in ssh altogether, eliminating an
entire class of bruteforce vectors.&lt;&#x2F;p&gt;
&lt;p&gt;For bonus marks: You can use AD as the generic LDAP server that stores
your SSH keys. No additional vendor products needed, you already have
everything required today, for free. Everyone loves free.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;&#x2F;h2&gt;
&lt;p&gt;If you want strong, offline capable, distributed mfa on linux servers,
the only choice today is LDAP with SSH key distribution.&lt;&#x2F;p&gt;
&lt;p&gt;Want to know more? This blog contains how-tos on SSH key distribution
for AD, SSH keys on smartcards, and how to configure SSSD to use SSH
keys from LDAP.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Using the latest 389-ds on OpenSUSE</title>
          <pubDate>Wed, 30 Jan 2019 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2019-01-30-using-the-latest-389-ds-on-opensuse/</link>
          <guid>https://fy.blackhats.net.au/blog/2019-01-30-using-the-latest-389-ds-on-opensuse/</guid>
          <description>&lt;h1 id=&quot;using-the-latest-389-ds-on-opensuse&quot;&gt;Using the latest 389-ds on OpenSUSE&lt;&#x2F;h1&gt;
&lt;p&gt;Thanks to some help from my friend who works on OBS, I&#x27;ve finally got a
good package in review for submission to tumbleweed. However, if you are
impatient and want to use the &amp;quot;latest&amp;quot; and greatest 389-ds version on
OpenSUSE.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;zypper ar obs:&#x2F;&#x2F;network:ldap network:ldap
&lt;&#x2F;span&gt;&lt;span&gt;zypper in 389-ds
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;docker&quot;&gt;Docker&lt;&#x2F;h2&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;docker run --rm -i -t registry.opensuse.org&#x2F;home&#x2F;firstyear&#x2F;containers&#x2F;389-ds-container:latest
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;To make it persistent:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;docker run -v 389ds_data:&#x2F;data &amp;lt;your options here ...&amp;gt; registry.opensuse.org&#x2F;home&#x2F;firstyear&#x2F;containers&#x2F;389-ds-container:latest
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Then to run the admin tools:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;docker exec -i -t &amp;lt;container name&amp;gt; &#x2F;usr&#x2F;sbin&#x2F;dsconf ...
&lt;&#x2F;span&gt;&lt;span&gt;docker exec -i -t &amp;lt;container name&amp;gt; &#x2F;usr&#x2F;sbin&#x2F;dsidm ...
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;testing-in-docker&quot;&gt;Testing in docker?&lt;&#x2F;h2&gt;
&lt;p&gt;If you are &amp;quot;testing&amp;quot; in docker (please don&#x27;t do this in production:
for production see above) you&#x27;ll need to do some tweaks to get around
the lack of systemd.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;docker run -i -t opensuse&#x2F;tumbleweed:latest
&lt;&#x2F;span&gt;&lt;span&gt;zypper ar obs:&#x2F;&#x2F;network:ldap network:ldap
&lt;&#x2F;span&gt;&lt;span&gt;zypper in 389-ds
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;vim &#x2F;usr&#x2F;share&#x2F;dirsrv&#x2F;inf&#x2F;defaults.inf
&lt;&#x2F;span&gt;&lt;span&gt;# change the following to match:
&lt;&#x2F;span&gt;&lt;span&gt;with_systemd = 0
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;what-next&quot;&gt;What next?&lt;&#x2F;h2&gt;
&lt;p&gt;After this, you should now be able to follow our &lt;a href=&quot;http:&#x2F;&#x2F;www.port389.org&#x2F;docs&#x2F;389ds&#x2F;howto&#x2F;quickstart.html&quot;&gt;new quickstart
guide&lt;&#x2F;a&gt; on the
389-ds website.&lt;&#x2F;p&gt;
&lt;p&gt;If you followed the docker steps, skip to &lt;a href=&quot;http:&#x2F;&#x2F;www.port389.org&#x2F;docs&#x2F;389ds&#x2F;howto&#x2F;quickstart.html#add-users-and-groups&quot;&gt;adding users and
groups&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The network:ldap repo and the container listed are updated when upstream
makes releases so you&#x27;ll always get the latest 389-ds&lt;&#x2F;p&gt;
&lt;p&gt;EDIT: Updated 2019-04-03 to change repo as changes have progressed
forward.&lt;&#x2F;p&gt;
&lt;p&gt;EDIT: Updated 2019-08-27 Improve clarity about when you need to do
docker tweaks, and add docker image steps&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Structuring Rust Transactions</title>
          <pubDate>Sat, 19 Jan 2019 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2019-01-19-structuring-rust-transactions/</link>
          <guid>https://fy.blackhats.net.au/blog/2019-01-19-structuring-rust-transactions/</guid>
          <description>&lt;h1 id=&quot;structuring-rust-transactions&quot;&gt;Structuring Rust Transactions&lt;&#x2F;h1&gt;
&lt;p&gt;I&#x27;ve been working on a database-related project in Rust recently, which
takes advantage of my &lt;a href=&quot;https:&#x2F;&#x2F;crates.io&#x2F;crates&#x2F;concread&quot;&gt;concurrently readable
datastructures.&lt;&#x2F;a&gt; However I ran into a
problem of how to structure Read&#x2F;Write transaction structures that
shared the reader code, and container multiple inner read&#x2F;write types.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;some-constraints&quot;&gt;Some Constraints&lt;&#x2F;h2&gt;
&lt;p&gt;To be clear, there are some constraints. A &amp;quot;parent&amp;quot; write, will only
ever contain write transaction guards, and a read will only ever contain
read transaction guards. This means we aren&#x27;t going to hit any
deadlocks in the code. Rust can&#x27;t protect us from mis-ording locks. An
additional requirement is that readers and a single write must be able
to proceed simultaneously - but having a rwlock style writer or readers
behaviour would still work here.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;some-background&quot;&gt;Some Background&lt;&#x2F;h2&gt;
&lt;p&gt;To simplify this, imagine we have two concurrently readable
datastructures. We&#x27;ll call them db_a and db_b.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;struct db_a { ... }
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;struct db_b { ... }
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now, each of db_a and db_b has their own way to protect their inner
content, but they&#x27;ll return a DBWriteGuard or DBReadGuard when we call
db_a.read()&#x2F;write() respectively.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;impl db_a {
&lt;&#x2F;span&gt;&lt;span&gt;    pub fn read(&amp;amp;self) -&amp;gt; DBReadGuard {
&lt;&#x2F;span&gt;&lt;span&gt;        ...
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    pub fn write(&amp;amp;self) -&amp;gt; DBWriteGuard {
&lt;&#x2F;span&gt;&lt;span&gt;        ...
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now we make a &amp;quot;parent&amp;quot; wrapper transaction such as:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;struct server {
&lt;&#x2F;span&gt;&lt;span&gt;    a: db_a,
&lt;&#x2F;span&gt;&lt;span&gt;    b: db_b,
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;struct server_read {
&lt;&#x2F;span&gt;&lt;span&gt;    a: DBReadGuard,
&lt;&#x2F;span&gt;&lt;span&gt;    b: DBReadGuard,
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;struct server_write {
&lt;&#x2F;span&gt;&lt;span&gt;    a: DBWriteGuard,
&lt;&#x2F;span&gt;&lt;span&gt;    b: DBWriteGuard,
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;impl server {
&lt;&#x2F;span&gt;&lt;span&gt;    pub fn read(&amp;amp;self) -&amp;gt; server_read {
&lt;&#x2F;span&gt;&lt;span&gt;        server_read {
&lt;&#x2F;span&gt;&lt;span&gt;            self.a.read(),
&lt;&#x2F;span&gt;&lt;span&gt;            self.b.read(),
&lt;&#x2F;span&gt;&lt;span&gt;        }
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    pub fn write(&amp;amp;self) -&amp;gt; server_write {
&lt;&#x2F;span&gt;&lt;span&gt;        server_read {
&lt;&#x2F;span&gt;&lt;span&gt;            self.a.write(),
&lt;&#x2F;span&gt;&lt;span&gt;            self.b.write(),
&lt;&#x2F;span&gt;&lt;span&gt;        }
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;the-problem&quot;&gt;The Problem&lt;&#x2F;h2&gt;
&lt;p&gt;Now the problem is that on my server_read and server_write I want to
implement a function for &amp;quot;search&amp;quot; that uses the same code. Search or a
read or write should behave identically! I wanted to also avoid the use
of macros as the can hide issues while stepping in a debugger like
LLDB&#x2F;GDB.&lt;&#x2F;p&gt;
&lt;p&gt;Often the answer with rust is &amp;quot;traits&amp;quot;, to create an interface that
types adhere to. Rust also allows default trait implementations, which
sounds like it could be a solution here.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;pub trait server_read_trait {
&lt;&#x2F;span&gt;&lt;span&gt;    fn search(&amp;amp;self) -&amp;gt; SomeResult {
&lt;&#x2F;span&gt;&lt;span&gt;        let result_a = self.a.search(...);
&lt;&#x2F;span&gt;&lt;span&gt;        let result_b = self.b.search(...);
&lt;&#x2F;span&gt;&lt;span&gt;        SomeResult(result_a, result_b)
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;In this case, the issue is that &amp;amp;self in a trait is not aware of the
fields in the struct - traits don&#x27;t define that fields &lt;em&gt;must&lt;&#x2F;em&gt; exist, so
the compiler can&#x27;t assume they exist at all.&lt;&#x2F;p&gt;
&lt;p&gt;Second, the type of self.a&#x2F;b is unknown to the trait - because in a read
it&#x27;s a &amp;quot;a: DBReadGuard&amp;quot;, and for a write it&#x27;s &amp;quot;a: DBWriteGuard&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;The first problem can be solved by using a get_field type in the trait.
Rust will also compile this out as an inline, so the &lt;em&gt;correct&lt;&#x2F;em&gt; thing for
the type system is also the &lt;em&gt;optimal&lt;&#x2F;em&gt; thing at run time. So we&#x27;ll
update this to:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;pub trait server_read_trait {
&lt;&#x2F;span&gt;&lt;span&gt;    fn get_a(&amp;amp;self) -&amp;gt; ???;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    fn get_b(&amp;amp;self) -&amp;gt; ???;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    fn search(&amp;amp;self) -&amp;gt; SomeResult {
&lt;&#x2F;span&gt;&lt;span&gt;        let result_a = self.get_a().search(...); &#x2F;&#x2F; note the change from self.a to self.get_a()
&lt;&#x2F;span&gt;&lt;span&gt;        let result_b = self.get_b().search(...);
&lt;&#x2F;span&gt;&lt;span&gt;        SomeResult(result_a, result_b)
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;impl server_read_trait for server_read {
&lt;&#x2F;span&gt;&lt;span&gt;    fn get_a(&amp;amp;self) -&amp;gt; &amp;amp;DBReadGuard {
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;amp;self.a
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; get_b is similar, so ommitted
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;impl server_read_trait for server_write {
&lt;&#x2F;span&gt;&lt;span&gt;    fn get_a(&amp;amp;self) -&amp;gt; &amp;amp;DBWriteGuard {
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;amp;self.a
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; get_b is similar, so ommitted
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;So now we have the second problem remaining: for the server_write we
have DBWriteGuard, and read we have a DBReadGuard. There was a much
longer experimentation process, but eventually the answer was simpler
than I was expecting. Rust allows traits to have Self types that enforce
trait bounds rather than a concrete type.&lt;&#x2F;p&gt;
&lt;p&gt;So provided that DBReadGuard and DBWriteGuard both implement
&amp;quot;DBReadTrait&amp;quot;, then we can have the server_read_trait have a self type
that enforces this. It looks something like:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;pub trait DBReadTrait {
&lt;&#x2F;span&gt;&lt;span&gt;    fn search(&amp;amp;self) -&amp;gt; ...;
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;impl DBReadTrait for DBReadGuard {
&lt;&#x2F;span&gt;&lt;span&gt;    fn search(&amp;amp;self) -&amp;gt; ... { ... }
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;impl DBReadTrait for DBWriteGuard {
&lt;&#x2F;span&gt;&lt;span&gt;    fn search(&amp;amp;self) -&amp;gt; ... { ... }
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;pub trait server_read_trait {
&lt;&#x2F;span&gt;&lt;span&gt;    type GuardType: DBReadTrait; &#x2F;&#x2F; Say that GuardType must implement DBReadTrait
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    fn get_a(&amp;amp;self) -&amp;gt; &amp;amp;Self::GuardType; &#x2F;&#x2F; implementors must return that type implementing the trait.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    fn get_b(&amp;amp;self) -&amp;gt; &amp;amp;Self::GuardType;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    fn search(&amp;amp;self) -&amp;gt; SomeResult {
&lt;&#x2F;span&gt;&lt;span&gt;        let result_a = self.get_a().search(...);
&lt;&#x2F;span&gt;&lt;span&gt;        let result_b = self.get_b().search(...);
&lt;&#x2F;span&gt;&lt;span&gt;        SomeResult(result_a, result_b)
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;impl server_read_trait for server_read {
&lt;&#x2F;span&gt;&lt;span&gt;    fn get_a(&amp;amp;self) -&amp;gt; &amp;amp;DBReadGuard {
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;amp;self.a
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; get_b is similar, so ommitted
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;impl server_read_trait for server_write {
&lt;&#x2F;span&gt;&lt;span&gt;    fn get_a(&amp;amp;self) -&amp;gt; &amp;amp;DBWriteGuard {
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;amp;self.a
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F; get_b is similar, so ommitted
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This works! We now have a way to write a single &amp;quot;search&amp;quot; type for our
server read and write types. In my case, the DBReadTrait also uses a
similar technique to define a search type shared between the DBReadGuard
and DBWriteGuard.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>SUSE Open Build Service cheat sheet</title>
          <pubDate>Sat, 19 Jan 2019 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2019-01-19-suse-open-build-system-cheat-sheet/</link>
          <guid>https://fy.blackhats.net.au/blog/2019-01-19-suse-open-build-system-cheat-sheet/</guid>
          <description>&lt;h1 id=&quot;suse-open-build-service-cheat-sheet&quot;&gt;SUSE Open Build Service cheat sheet&lt;&#x2F;h1&gt;
&lt;p&gt;Part of starting at SUSE has meant that I get to learn about Open Build
Service. I&#x27;ve known that the project existed for a long time but I have
never had a chance to use it. So far I&#x27;m thoroughly impressed by how it
works and the features it offers.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;as-a-consumer&quot;&gt;As A Consumer&lt;&#x2F;h2&gt;
&lt;p&gt;The best part of OBS is that it&#x27;s trivial on OpenSUSE to consume
content from it. Zypper can add projects with the command:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;zypper ar obs:&#x2F;&#x2F;&amp;lt;project name&amp;gt; &amp;lt;repo nickname&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;zypper ar obs:&#x2F;&#x2F;network:ldap network:ldap
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;I like to give the repo nickname (your choice) to be the same as the
project name so I know what I have enabled. Once you run this you can
easily consume content from OBS.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;package-management&quot;&gt;Package Management&lt;&#x2F;h2&gt;
&lt;p&gt;As someone who has started to contribute to the suse 389-ds package,
I&#x27;ve been slowly learning how this work flow works. OBS similar to
GitHub&#x2F;Lab allows a branching and request model.&lt;&#x2F;p&gt;
&lt;p&gt;On OpenSUSE you will want to use the osc tool for your workflow:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;zypper in osc
&lt;&#x2F;span&gt;&lt;span&gt;# If you plan to use the &amp;quot;service&amp;quot; command
&lt;&#x2F;span&gt;&lt;span&gt;zypper in obs-service-tar obs-service-obs_scm obs-service-recompress obs-service-set_version obs-service-download_files python-xml obs-service-format_spec_file
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You can branch from an existing project to make changes with:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;osc branch &amp;lt;project&amp;gt; &amp;lt;package&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;osc branch network:ldap 389-ds
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This will branch the project to my home namespace. For me this will land
in &amp;quot;home:firstyear:branches:network:ldap&amp;quot;. Now I can checkout the
content on to my machine to work on it.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;osc co &amp;lt;project&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;osc co home:firstyear:branches:network:ldap
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This will create the folder &amp;quot;home:...:ldap&amp;quot; in the current working
directory.&lt;&#x2F;p&gt;
&lt;p&gt;From here you can now work on the project. Some useful commands are:&lt;&#x2F;p&gt;
&lt;p&gt;Add new files to the project (patches, new source tarballs etc).&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;osc add &amp;lt;path to file&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;osc add feature.patch
&lt;&#x2F;span&gt;&lt;span&gt;osc add new-source.tar.xz
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Edit the change log of the project (I think this is used in release
notes?)&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;osc vc
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;To ammend your changes, use:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;osc vc -e
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Build your changes locally matching the system you are on. Packages
normally build on all&#x2F;most OpenSUSE versions and architectures, this
will build just for your local system and arch.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;osc build
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Make sure you clean up files you aren&#x27;t using any more with:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;osc rm &amp;lt;filename&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;# This commands removes anything untracked by osc.
&lt;&#x2F;span&gt;&lt;span&gt;osc clean
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Commit your changes to the OBS server, where a complete build will be
triggered:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;osc commit
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;View the results of the last commit:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;osc results
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Enable people to use your branch&#x2F;project as a repository. You edit the
project metadata and enable repo publishing:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;osc meta prj -e &amp;lt;name of project&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;osc meta prj -e home:firstyear:branches:network:ldap
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# When your editor opens, change this section to enabled (disabled by default):
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;publish&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;  &amp;lt;enabled &#x2F;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&#x2F;publish&amp;gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;NOTE: In some cases if you have the package already installed, and you
add the repo&#x2F;update it won&#x27;t install from your repo. This is because in
SUSE packages have a notion of &amp;quot;vendoring&amp;quot;. They continue to update
from the same repo as they were originally installed from. So if you
want to change this you use:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;zypper [d]up --from &amp;lt;repo name&amp;gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You can then create a &amp;quot;request&amp;quot; to merge your branch changes back to
the project origin. This is:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;osc sr
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;A helpful maintainer will then review your changes. You can see this
with.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;osc rq show &amp;lt;your request id&amp;gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If you change your request, to submit again, use:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;osc sr
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;And it will ask if you want to replace (supercede) the previous request.&lt;&#x2F;p&gt;
&lt;p&gt;I was also helped by a friend to provie a &amp;quot;service&amp;quot; configuration that
allows generation of tar balls from git. It&#x27;s not always appropriate to
use this, but if the repo has a &amp;quot;_service&amp;quot; file, you can regenerate
the tar with:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;osc service ra
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;So far this is as far as I have gotten with OBS, but I already
appreciate how great this work flow is for package maintainers,
reviewers and consumers. It&#x27;s a pleasure to work with software this
well built.&lt;&#x2F;p&gt;
&lt;p&gt;As an additional piece of information, it&#x27;s a good idea to read the &lt;a href=&quot;https:&#x2F;&#x2F;en.opensuse.org&#x2F;openSUSE:Packaging_Patches_guidelines&quot;&gt;OBS Packaging Guidelines&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;:   to be sure that you are doing the right thing!&lt;&#x2F;p&gt;
&lt;p&gt;# Acts as tail&lt;&#x2F;p&gt;
&lt;p&gt;:   osc bl osc r -v&lt;&#x2F;p&gt;
&lt;p&gt;# How to access the meta and docker stuff&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;osc meta pkg -e osc meta prj -e&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;(will add vim to the buildroot), then you can chroot (allow editing in
the build root)&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;osc chroot osc build -x vim&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;-k &amp;lt;dir&amp;gt; keeps artifacts in directory dir IE rpm outputs&lt;&#x2F;p&gt;
&lt;p&gt;oscrc buildroot variable, mount tmpfs to that location.&lt;&#x2F;p&gt;
&lt;p&gt;docker privs SYS_ADMIN, SYS_CHROOT&lt;&#x2F;p&gt;
&lt;p&gt;Multiple spec: commit second spec to pkg then:&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;osc linkpac prj pkg prj new-link-pkg&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;rpm --eval &#x27;%{variable}&#x27;&lt;&#x2F;p&gt;
&lt;p&gt;%setup -n &amp;quot;name of what the directory unpacks to, not what to rename
to&amp;quot;&lt;&#x2F;p&gt;
&lt;p&gt;When no link exists&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;osc submitpac destprj deskpkg&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
</description>
      </item>
      <item>
          <title>The idea of CI and Engineering</title>
          <pubDate>Wed, 02 Jan 2019 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2019-01-02-the-idea-of-ci-and-engineering/</link>
          <guid>https://fy.blackhats.net.au/blog/2019-01-02-the-idea-of-ci-and-engineering/</guid>
          <description>&lt;h1 id=&quot;the-idea-of-ci-and-engineering&quot;&gt;The idea of CI and Engineering&lt;&#x2F;h1&gt;
&lt;p&gt;In software development I see and interesting trend and push towards
continuous integration, continually testing, and testing in production.
These techniques are designed to allow faster feedback on errors, use
real data for application testing, and to deliver features and changes
faster.&lt;&#x2F;p&gt;
&lt;p&gt;But is that really how people use software on devices? When we consider
an operation like google or amazon, this always online technique may
work, but what happens when we apply a continous integration and
&amp;quot;we&#x27;ll patch it later&amp;quot; mindset to devices like phones or internet of
things?&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-happens-in-other-disciplines&quot;&gt;What happens in other disciplines?&lt;&#x2F;h2&gt;
&lt;p&gt;In real engineering disciplines like aviation or construction,
techniques like this don&#x27;t really work. We don&#x27;t continually build
bridges, then fix them when they break or collapse. There are people who
provide formal analysis of materials, their characteristics. Engineers
consider careful designs, constraints, loads and situations that may
occur. The structure is planned, reviewed and verified mathematically.
Procedures and oversight is applied to ensure correct building of the
structure. Lessons are learnt from past failures and incidents and are
applied into every layer of the design and construction process.
Communication between engineers and many other people is critical to the
process. Concerns are always addressed and managed.&lt;&#x2F;p&gt;
&lt;p&gt;The first thing to note is that if we just built lots of scale-model
bridges and continually broke them until we found their limits, this
would waste many resources to do this. Bridges are carefully planned and
proven.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;so-whats-the-point-with-software&quot;&gt;So whats the point with software?&lt;&#x2F;h2&gt;
&lt;p&gt;Today we still have a mindset that continually breaking and building is
a reasonable path to follow. It&#x27;s not! It means that the only way to
achieve quality is to have a large test suite (requires people and time
to write), which has to be further derived from failures (and those
failures can negatively affect real people), then we have to apply large
amounts of electrical energy to continually run the tests. The test
suites can&#x27;t even guarantee complete coverage of all situations and
occurances!&lt;&#x2F;p&gt;
&lt;p&gt;This puts CI techniques out of reach of many application developers due
to time and energy (translated to dollars) limits. Services like travis
on github certainly helps to lower the energy requirement, but it
doesn&#x27;t stop the time and test writing requirements.&lt;&#x2F;p&gt;
&lt;p&gt;No matter how many tests we have for a program, if that program is
written in C or something else, we continually see faults and
security&#x2F;stability issues in that software.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-if-we-ci-on-a-phone&quot;&gt;What if we CI on ... a phone?&lt;&#x2F;h2&gt;
&lt;p&gt;Today we even have hardware devices that are approached as though they
&amp;quot;test in production&amp;quot; is a reasonable thing. It&#x27;s not! People don&#x27;t
patch, telcos don&#x27;t allow updates out to users, and those that are
aware, have to do custom rom deployment. This creates an odd dichomtemy
of &amp;quot;haves&amp;quot; and &amp;quot;haves not&amp;quot;, of those in technical know how who have
a better experience, and the &amp;quot;haves not&amp;quot; who have to suffer
potentially insecure devices. This is especially terrifying given how
deeply personal phones are.&lt;&#x2F;p&gt;
&lt;p&gt;This is a reality of our world. People do not patch. They do not patch
phones, laptops, network devices and more. Even enterprises will avoid
patching if possible. Rather than trying to shift the entire culture of
humans to &amp;quot;update always&amp;quot;, we need to write software that can cope in
harsh conditions, for long term. We only need to look to software in
aviation to see we can absolutely achieve this!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-should-we-do&quot;&gt;What should we do?&lt;&#x2F;h2&gt;
&lt;p&gt;I believe that for software developers to properly become software
engineers we should look to engineers in civil and aviation industries.
We need to apply:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Regualation and ethics (Safety of people is always first)&lt;&#x2F;li&gt;
&lt;li&gt;Formal verification&lt;&#x2F;li&gt;
&lt;li&gt;Consider all software will run long term (5+ years)&lt;&#x2F;li&gt;
&lt;li&gt;Improve team work and collaboration on designs and development&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;The reality of our world is people are deploying devices (routers,
networks, phones, lights, laptops more ...) where they may never be
updated or patched in their service life. Even I&#x27;m guilty (I have a
modem that&#x27;s been unpatched for about 6 years but it&#x27;s pretty locked
down ...). As a result we need to rely on proof that the device &lt;em&gt;can
not&lt;&#x2F;em&gt; fail at build time, rather than &lt;em&gt;patch it later&lt;&#x2F;em&gt; which may never
occur! Putting formal verification first, and always considering user
safety and rights first, shifts a large burden to us in terms of time.
But many tools (Coq, fstar, rust ...) all make formal verification more
accessible to use in our industry. Verifying our software is a far
stronger assertion of quality than &amp;quot;throw tests at it and hope it
works&amp;quot;.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;you-re-crazy-william-and-also-wrong&quot;&gt;You&#x27;re crazy William, and also wrong&lt;&#x2F;h2&gt;
&lt;p&gt;Am I? Looking at &amp;quot;critical&amp;quot; systems like iPhone encryption hardware,
they are running the formally verified Sel4. We also heard at Kiwicon in
2018 that Microsoft and XBox are using formal verification to design
their low levels of their system to prevent exploits from occuring in
the first place.&lt;&#x2F;p&gt;
&lt;p&gt;Over time our industry will evolve, and it will become easier and more
cost effective to formally verify than to operate and deploy CI. This
doesn&#x27;t mean we don&#x27;t need tests - it means that the first line of
quality should be in verification of correctness using formal techniques
rather than using tests and CI to prove correct behaviour. Tests are
certainly still required to assert further behavioural elements of
software.&lt;&#x2F;p&gt;
&lt;p&gt;Today, if you want to do this, you should be looking at Coq and program
extraction, fstar and the kremlin (project everest, a formally verified
https stack), Rust (which has a subset of the safe language formally
proven). I&#x27;m sure there are more, but these are the ones I know off the
top of my head.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;&#x2F;h2&gt;
&lt;p&gt;Over time our industry &lt;em&gt;must&lt;&#x2F;em&gt; evolve to put the safety of humans first.
To achive this we must look to other safety driven cultures such as
aviation and civil engineering. Only by learning from their strict
disciplines and behaviours can we start to provide software that matches
behavioural and quality expectations humans have for software.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Useful USG pro 4 commands and hints</title>
          <pubDate>Wed, 02 Jan 2019 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2019-01-02-useful-usg-pro-4-commands-and-hints/</link>
          <guid>https://fy.blackhats.net.au/blog/2019-01-02-useful-usg-pro-4-commands-and-hints/</guid>
          <description>&lt;h1 id=&quot;useful-usg-pro-4-commands-and-hints&quot;&gt;Useful USG pro 4 commands and hints&lt;&#x2F;h1&gt;
&lt;p&gt;I&#x27;ve recently changed from a FreeBSD vm as my router to a Ubiquiti PRO
USG4. It&#x27;s a solid device, with many great features, and I&#x27;m really
impressed at how it &amp;quot;just works&amp;quot; in many cases. So far my only
disappointment is lack of documentation about the CLI, especially for
debugging and auditing what is occuring in the system, and for
troubleshooting steps. This post will aggregate some of my knowledge
about the topic.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;current-config&quot;&gt;Current config&lt;&#x2F;h2&gt;
&lt;p&gt;Show the current config with:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;mca-ctrl -t dump-cfg
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You can show system status with the &amp;quot;show&amp;quot; command. Pressing ? will
cause the current compeletion options to be displayed. For example:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# show &amp;lt;?&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;arp              date             dhcpv6-pd        hardware
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;dns&quot;&gt;DNS&lt;&#x2F;h2&gt;
&lt;p&gt;The following commands show the DNS statistics, the DNS configuration,
and allow changing the cache-size. The cache-size is measured in number
of records cached, rather than KB&#x2F;MB. To make this permanent, you need
to apply the change to config.json in your controllers sites folder.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;show dns forwarding statistics
&lt;&#x2F;span&gt;&lt;span&gt;show system name-server
&lt;&#x2F;span&gt;&lt;span&gt;set service dns forwarding cache-size 10000
&lt;&#x2F;span&gt;&lt;span&gt;clear dns forwarding cache
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;logging&quot;&gt;Logging&lt;&#x2F;h2&gt;
&lt;p&gt;You can see and aggregate of system logs with&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;show log
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Note that when you set firewall rules to &amp;quot;log on block&amp;quot; they go to
dmesg, not syslog, so as a result you need to check dmesg for these.&lt;&#x2F;p&gt;
&lt;p&gt;It&#x27;s a great idea to forward your logs in the controller to a syslog
server as this allows you to aggregate and see all the events occuring
in a single time series (great when I was diagnosing an issue recently).&lt;&#x2F;p&gt;
&lt;h2 id=&quot;interfaces&quot;&gt;Interfaces&lt;&#x2F;h2&gt;
&lt;p&gt;To show the system interfaces&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;show interfaces
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;To restart your pppoe dhcp6c:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;release dhcpv6-pd interface pppoe0
&lt;&#x2F;span&gt;&lt;span&gt;renew dhcpv6-pd interface pppoe0
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;There is a current issue where the firmware will start dhcp6c on eth2
and pppoe0, but the session on eth2 blocks the pppoe0 client. As a
result, you need to release on eth2, then renew of pppoe0&lt;&#x2F;p&gt;
&lt;p&gt;If you are using a dynamic prefix rather than static, you may need to
reset your dhcp6c duid.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;delete dhcpv6-pd duid
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;To restart an interface with the vyatta tools:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;disconnect interface pppoe
&lt;&#x2F;span&gt;&lt;span&gt;connect interface pppoe
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;openvpn&quot;&gt;OpenVPN&lt;&#x2F;h2&gt;
&lt;p&gt;I have setup customised OpenVPN tunnels. To show these:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;show interfaces openvpn detail
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;These are configured in config.json with:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# Section: config.json - interfaces - openvpn
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;vtun0&amp;quot;: {
&lt;&#x2F;span&gt;&lt;span&gt;            &amp;quot;encryption&amp;quot;: &amp;quot;aes256&amp;quot;,
&lt;&#x2F;span&gt;&lt;span&gt;            # This assigns the interface to the firewall zone relevant.
&lt;&#x2F;span&gt;&lt;span&gt;            &amp;quot;firewall&amp;quot;: {
&lt;&#x2F;span&gt;&lt;span&gt;                    &amp;quot;in&amp;quot;: {
&lt;&#x2F;span&gt;&lt;span&gt;                            &amp;quot;ipv6-name&amp;quot;: &amp;quot;LANv6_IN&amp;quot;,
&lt;&#x2F;span&gt;&lt;span&gt;                            &amp;quot;name&amp;quot;: &amp;quot;LAN_IN&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;                    },
&lt;&#x2F;span&gt;&lt;span&gt;                    &amp;quot;local&amp;quot;: {
&lt;&#x2F;span&gt;&lt;span&gt;                            &amp;quot;ipv6-name&amp;quot;: &amp;quot;LANv6_LOCAL&amp;quot;,
&lt;&#x2F;span&gt;&lt;span&gt;                            &amp;quot;name&amp;quot;: &amp;quot;LAN_LOCAL&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;                    },
&lt;&#x2F;span&gt;&lt;span&gt;                    &amp;quot;out&amp;quot;: {
&lt;&#x2F;span&gt;&lt;span&gt;                            &amp;quot;ipv6-name&amp;quot;: &amp;quot;LANv6_OUT&amp;quot;,
&lt;&#x2F;span&gt;&lt;span&gt;                            &amp;quot;name&amp;quot;: &amp;quot;LAN_OUT&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;                    }
&lt;&#x2F;span&gt;&lt;span&gt;            },
&lt;&#x2F;span&gt;&lt;span&gt;            &amp;quot;mode&amp;quot;: &amp;quot;server&amp;quot;,
&lt;&#x2F;span&gt;&lt;span&gt;            # By default, ubnt adds a number of parameters to the CLI, which
&lt;&#x2F;span&gt;&lt;span&gt;            # you can see with ps | grep openvpn
&lt;&#x2F;span&gt;&lt;span&gt;            &amp;quot;openvpn-option&amp;quot;: [
&lt;&#x2F;span&gt;&lt;span&gt;                    # If you are making site to site tunnels, you need the ccd
&lt;&#x2F;span&gt;&lt;span&gt;                    # directory, with hostname for the file name and
&lt;&#x2F;span&gt;&lt;span&gt;                    # definitions such as:
&lt;&#x2F;span&gt;&lt;span&gt;                    # iroute 172.20.0.0 255.255.0.0
&lt;&#x2F;span&gt;&lt;span&gt;                    &amp;quot;--client-config-dir &#x2F;config&#x2F;auth&#x2F;openvpn&#x2F;ccd&amp;quot;,
&lt;&#x2F;span&gt;&lt;span&gt;                    &amp;quot;--keepalive 10 60&amp;quot;,
&lt;&#x2F;span&gt;&lt;span&gt;                    &amp;quot;--user nobody&amp;quot;,
&lt;&#x2F;span&gt;&lt;span&gt;                    &amp;quot;--group nogroup&amp;quot;,
&lt;&#x2F;span&gt;&lt;span&gt;                    &amp;quot;--proto udp&amp;quot;,
&lt;&#x2F;span&gt;&lt;span&gt;                    &amp;quot;--port 1195&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;            ],
&lt;&#x2F;span&gt;&lt;span&gt;            &amp;quot;server&amp;quot;: {
&lt;&#x2F;span&gt;&lt;span&gt;                    &amp;quot;push-route&amp;quot;: [
&lt;&#x2F;span&gt;&lt;span&gt;                            &amp;quot;172.24.0.0&#x2F;17&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;                    ],
&lt;&#x2F;span&gt;&lt;span&gt;                    &amp;quot;subnet&amp;quot;: &amp;quot;172.24.251.0&#x2F;24&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;            },
&lt;&#x2F;span&gt;&lt;span&gt;            &amp;quot;tls&amp;quot;: {
&lt;&#x2F;span&gt;&lt;span&gt;                    &amp;quot;ca-cert-file&amp;quot;: &amp;quot;&#x2F;config&#x2F;auth&#x2F;openvpn&#x2F;vps&#x2F;vps-ca.crt&amp;quot;,
&lt;&#x2F;span&gt;&lt;span&gt;                    &amp;quot;cert-file&amp;quot;: &amp;quot;&#x2F;config&#x2F;auth&#x2F;openvpn&#x2F;vps&#x2F;vps-server.crt&amp;quot;,
&lt;&#x2F;span&gt;&lt;span&gt;                    &amp;quot;dh-file&amp;quot;: &amp;quot;&#x2F;config&#x2F;auth&#x2F;openvpn&#x2F;dh2048.pem&amp;quot;,
&lt;&#x2F;span&gt;&lt;span&gt;                    &amp;quot;key-file&amp;quot;: &amp;quot;&#x2F;config&#x2F;auth&#x2F;openvpn&#x2F;vps&#x2F;vps-server.key&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;            }
&lt;&#x2F;span&gt;&lt;span&gt;    },
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;netflow&quot;&gt;Netflow&lt;&#x2F;h2&gt;
&lt;p&gt;Net flows allow a set of connection tracking data to be sent to a remote
host for aggregation and analysis. Sadly this process was mostly
undocumented, bar some useful forum commentors. Here is the process that
I came up with. This is how you configure it live:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;set system flow-accounting interface eth3.11
&lt;&#x2F;span&gt;&lt;span&gt;set system flow-accounting netflow server 172.24.10.22 port 6500
&lt;&#x2F;span&gt;&lt;span&gt;set system flow-accounting netflow version 5
&lt;&#x2F;span&gt;&lt;span&gt;set system flow-accounting netflow sampling-rate 1
&lt;&#x2F;span&gt;&lt;span&gt;set system flow-accounting netflow timeout max-active-life 1
&lt;&#x2F;span&gt;&lt;span&gt;commit
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;To make this persistent:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&amp;quot;system&amp;quot;: {
&lt;&#x2F;span&gt;&lt;span&gt;            &amp;quot;flow-accounting&amp;quot;: {
&lt;&#x2F;span&gt;&lt;span&gt;                    &amp;quot;interface&amp;quot;: [
&lt;&#x2F;span&gt;&lt;span&gt;                            &amp;quot;eth3.11&amp;quot;,
&lt;&#x2F;span&gt;&lt;span&gt;                            &amp;quot;eth3.12&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;                    ],
&lt;&#x2F;span&gt;&lt;span&gt;                    &amp;quot;netflow&amp;quot;: {
&lt;&#x2F;span&gt;&lt;span&gt;                            &amp;quot;sampling-rate&amp;quot;: &amp;quot;1&amp;quot;,
&lt;&#x2F;span&gt;&lt;span&gt;                            &amp;quot;version&amp;quot;: &amp;quot;5&amp;quot;,
&lt;&#x2F;span&gt;&lt;span&gt;                            &amp;quot;server&amp;quot;: {
&lt;&#x2F;span&gt;&lt;span&gt;                                    &amp;quot;172.24.10.22&amp;quot;: {
&lt;&#x2F;span&gt;&lt;span&gt;                                            &amp;quot;port&amp;quot;: &amp;quot;6500&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;                                    }
&lt;&#x2F;span&gt;&lt;span&gt;                            },
&lt;&#x2F;span&gt;&lt;span&gt;                            &amp;quot;timeout&amp;quot;: {
&lt;&#x2F;span&gt;&lt;span&gt;                                    &amp;quot;max-active-life&amp;quot;: &amp;quot;1&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;                            }
&lt;&#x2F;span&gt;&lt;span&gt;                    }
&lt;&#x2F;span&gt;&lt;span&gt;            }
&lt;&#x2F;span&gt;&lt;span&gt;    },
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;To show the current state of your flows:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;show flow-accounting
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
</description>
      </item>
      <item>
          <title>Nextcloud and badrequest filesize incorrect</title>
          <pubDate>Mon, 31 Dec 2018 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2018-12-31-nextcloud-and-badrequest-filesize-incorrect/</link>
          <guid>https://fy.blackhats.net.au/blog/2018-12-31-nextcloud-and-badrequest-filesize-incorrect/</guid>
          <description>&lt;h1 id=&quot;nextcloud-and-badrequest-filesize-incorrect&quot;&gt;Nextcloud and badrequest filesize incorrect&lt;&#x2F;h1&gt;
&lt;p&gt;My friend came to my house and was trying to share some large files with
my nextcloud instance. Part way through the upload an error occurred.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&amp;quot;Exception&amp;quot;:&amp;quot;Sabre\\DAV\\Exception\\BadRequest&amp;quot;,&amp;quot;Message&amp;quot;:&amp;quot;expected filesize 1768906752 got 1768554496&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;It turns out this error can be caused by many sources. It could be
timeouts, bad requests, network packet loss, incorrect nextcloud
configuration or more.&lt;&#x2F;p&gt;
&lt;p&gt;We tried uploading larger files (by a factor of 10 times) and they
worked. This eliminated timeouts as a cause, and probably network loss.
Being on ethernet direct to the server generally also helps to eliminate
packet loss as a cause compared to say internet.&lt;&#x2F;p&gt;
&lt;p&gt;We also knew that the server must not have been misconfigured because a
larger file did upload, so no file or resource limits were being hit.&lt;&#x2F;p&gt;
&lt;p&gt;This also indicated that the client was likely doing the right thing
because larger and smaller files would upload correctly. The symptom now
only affected a single file.&lt;&#x2F;p&gt;
&lt;p&gt;At this point I realised, what if the client and server were both
victims to a lower level issue? I asked my friend to ls the file and
read me the number of bytes long. It was 1768906752, as expected in
nextcloud.&lt;&#x2F;p&gt;
&lt;p&gt;Then I asked him to cat that file into a new file, and to tell me the
length of the new file. Cat encountered an error, but ls on the new file
indeed showed a size of 1768554496. That means filesystem corruption!
What could have lead to this?&lt;&#x2F;p&gt;
&lt;p&gt;HFS+&lt;&#x2F;p&gt;
&lt;p&gt;Apple&#x27;s legacy filesystem (and the reason I stopped using macs) is well
known for silently eating files and corrupting content. Here we had yet
another case of that damage occuring, and triggering errors elsewhere.&lt;&#x2F;p&gt;
&lt;p&gt;Bisecting these issues and eliminating possibilities through a
scientific method is always the best way to resolve the cause, and it
may come from surprising places!&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Identity ideas ...</title>
          <pubDate>Fri, 21 Dec 2018 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2018-12-21-identity-ideas/</link>
          <guid>https://fy.blackhats.net.au/blog/2018-12-21-identity-ideas/</guid>
          <description>&lt;h1 id=&quot;identity-ideas&quot;&gt;Identity ideas ...&lt;&#x2F;h1&gt;
&lt;p&gt;I&#x27;ve been meaning to write this post for a long time. Taking half a
year away from the 389-ds team, and exploring a lot of ideas from other
projects has led me to come up with some really interesting ideas about
what we do well, and what we don&#x27;t. I feel like this blog could be
divisive, as I really think that for our services to stay relevant we
need to make changes that really change our own identity - so that we
can better represent yours.&lt;&#x2F;p&gt;
&lt;p&gt;So strap in, this is going to be long ...&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-s-currently-on-the-market&quot;&gt;What&#x27;s currently on the market&lt;&#x2F;h2&gt;
&lt;p&gt;Right now the market for identity has two extremes. At one end we have
the legacy &amp;quot;create your own&amp;quot; systems, that are build on technologies
like LDAP and Kerberos. I&#x27;m thinking about things like 389 Directory
Server, OpenLDAP, Active Directory, FreeIPA and more. These all happen
to be constrained heavily by complexity, fragility, and administrative
workload. You need to spend months to learn these and even still, you
will make mistakes and there will be problems.&lt;&#x2F;p&gt;
&lt;p&gt;At the other end we have hosted &amp;quot;Identity as a Service&amp;quot; options like
Azure AD and Auth0. These have very intelligently, unbound themself from
legacy, and tend to offer HTTP apis, 2fa and other features that &amp;quot;just
work&amp;quot;. But they are all in the cloud, and outside your control.&lt;&#x2F;p&gt;
&lt;p&gt;But there is nothing in the middle. There is no option that &amp;quot;just
works&amp;quot;, supports modern standards, and is unhindered by legacy that you
can self deploy with minimal administrative fuss - or years of
experience.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-do-i-like-from-389&quot;&gt;What do I like from 389?&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Replication&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;The replication system is extremely robust, and has passed many complex
tests for cases of eventual consistency correctness. It&#x27;s very rare to
hear of any kind of data corruption or loss within our replication
system, and that&#x27;s testament to the great work of people who spent
years looking at the topic.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Performance&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;We aren&#x27;t as fast as OpenLDAP is 1 vs 1 server, but our replication
scalability is much higher, where in any size of MMR or read-only
replica topology, we have higher horizontal scaling, nearly linear based
on server additions. If you want to run a cloud scale replicated
database, we scale to it (and people already do this!).&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Stability&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Our server stability is well known with administrators, and honestly is
a huge selling point. We see servers that only go down when
administrators are performing upgrades. Our work with sanitising tools
and the careful eyes of the team has ensured our code base is reliable
and solid. Having extensive tests and amazing dedicated quality
engineers also goes a long way.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Feature rich&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;There are a lot of features I really like, and are really useful as an
admin deploying this service. Things like memberof (which is actually a
group resolution cache when you think about it ...), automember, online
backup, unique attribute enforcement, dereferencing, and more.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;The team&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;We have a wonderful team of really smart people, all of whom are caring
and want to advance the state of identity management. Not only do they
want to keep up with technical changes and excellence, they are
listening to and want to improve our social awareness of identity
management.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;pain-points&quot;&gt;Pain Points&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;C&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Because DS is written in C, it&#x27;s risky and difficult to make changes.
People constantly make mistakes that introduce unsafety (even myself),
and worse. No amount of tooling or intelligence can take away the fact
that C is just hard to use, and people need to be perfect (people are
not perfect!) and today we have better tools. We can not spend our time
chasing our tails on pointless issues that C creates, when we should be
doing better things.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Everything about dynamic admin, config, and plugins is hard and
can&#x27;t scale&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Because we need to maintain consistency through operations from start to
end but we also allow changing config, plugins, and more during the
servers operation the current locking design just doesn&#x27;t scale. It&#x27;s
also not 100% safe either as the values are changed by atomics, not
managed by transactions. We could use copy-on-write for this, but why?
Config should be managed by tools like ansible, but today our dynamic
config and plugins is both a performance over head and an admin overhead
because we exclude best practice tools and have to spend a large amount
of time to maintain consistent data when we shouldn&#x27;t need to. Less
features is less support overhead on us, and simpler to test and assert
quality and correct behaviour.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Plugins to address shortfalls, but a bit odd.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;We have all these features to address issues, but they all do it ...
kind of the odd way. Managed Entries creates user private groups on
object creation. But the problem is &amp;quot;unix requires a private group&amp;quot;
and &amp;quot;ldap schema doesn&#x27;t allow a user to be a group and user at the
same time&amp;quot;. So the answer is actually to create a new objectClass that
let&#x27;s a user ALSO be it&#x27;s own UPG, not &amp;quot;create an object that links
to the user&amp;quot;. (Or have a client generate the group from user attributes
but we shouldn&#x27;t shift responsibility to the client.)&lt;&#x2F;p&gt;
&lt;p&gt;Distributed Numeric Assignment is based on the AD rid model, but it&#x27;s
all about &amp;quot;how can we assign a value to a user that&#x27;s unique?&amp;quot;. We
already have a way to do this, in the UUID, so why not derive the
UID&#x2F;GID from the UUID. This means there is no complex inter-server
communication, pooling, just simple isolated functionality.&lt;&#x2F;p&gt;
&lt;p&gt;We have lots of features that just are a bit complex, and could have
been made simpler, that now we have to support, and can&#x27;t change to
make them better. If we rolled a new &amp;quot;fixed&amp;quot; version, we would then
have to support both because projects like FreeIPA aren&#x27;t going to just
change over.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;client tools are controlled by others and complex (sssd, openldap)&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Every tool for dealing with ldap is really confusing and arcane. They
all have wild (unhelpful) defaults, and generally this scares people
off. I took months of work to get a working ldap server in the past.
Why? It&#x27;s 2018, things need to &amp;quot;just work&amp;quot;. Our tools should &amp;quot;just
work&amp;quot;. Why should I need to hand edit pam? Why do I need to set weird
options in SSSD.conf? All of this makes the whole experience poor.&lt;&#x2F;p&gt;
&lt;p&gt;We are making client tools that can help (to an extent), but they are
really limited to system administration and they aren&#x27;t &amp;quot;generic&amp;quot;
tools for every possible configuration that exists. So at some point
people will still find a limit where they have to touch ldap commands. A
common request is a simple to use web portal for password resets, which
today only really exists in FreeIPA, and that limits it&#x27;s application
already.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;hard to change legacy&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;It&#x27;s really hard to make code changes because our surface area is so
broad and the many use cases means that we risk breakage every time we
do. I have even broken customer deployments like this. It&#x27;s almost
impossible to get away from, and that holds us back because it means we
are scared to make changes because we have to support the 1 million
existing work flows. To add another is more support risk.&lt;&#x2F;p&gt;
&lt;p&gt;Many deployments use legacy schema elements that holds us back, ranging
from the inet types, schema that enforces a first&#x2F;last name, schema that
won&#x27;t express users + groups in a simple away. It&#x27;s hard to ask people
to just up and migrate their data, and even if we wanted too, ldap
allows too much freedom so we are more likely to break data, than
migrate it correctly if we tried.&lt;&#x2F;p&gt;
&lt;p&gt;This holds us back from technical changes, and social representation
changes. People are more likely to engage with a large migrational
change, than an incremental change that disturbs their current workflow
(IE moving from on prem to cloud, rather than invest in smaller
iterative changes to make their local solutions better).&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;ACI&#x27;s are really complex&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;389&#x27;s access controls are good because they are in the tree and
replicated, but bad because the syntax is awful, complex, and has lots
of traps and complexity. Even I need to look up how to write them when I
have to. This is not good for a project that has such deep security
concerns, where your ACI&#x27;s can look correct but actually expose all
your data to risks.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;LDAP as a protocol is like an 90&#x27;s drug experience&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;LDAP may be the lingua franca of authentication, but it&#x27;s complex, hard
to use and hard to write implementations for. That&#x27;s why in opensource
we have a monoculture of using the openldap client libraries because &lt;em&gt;no
one can work out how to write a standalone library&lt;&#x2F;em&gt;. Layer on top the
complexity of the object and naming model, and we have a situation where
no one wants to interact with LDAP and rather keeps it at arm length.&lt;&#x2F;p&gt;
&lt;p&gt;It&#x27;s going to be extremely hard to move forward here, because the
community is so fragmented and small, and the working groups dispersed
that the idea of LDAPv4 is a dream that no one should pursue, even
though it&#x27;s desperately needed.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;TLS&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;TLS is great. NSS databases and tools are not.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;GSSAPI + SSO&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;GSSAPI and Kerberos are a piece of legacy that we just can&#x27;t escape
from. They are a curse almost, and one we need to break away from as
it&#x27;s completely unusable (even if it what it promises is amazing). We
need to do better.&lt;&#x2F;p&gt;
&lt;p&gt;That and SSO allows loads of attacks to proceed, where we actually want
isolated token auth with limited access scopes ...&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-could-we-offer&quot;&gt;What could we offer&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Web application as a first class consumer.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;People want web portals for their clients, and they want to be able to
use web applications as the consumer of authentication. The HTTP
protocols must be the first class integration point for anything in
identity management today. This means using things like OAUTH&#x2F;OIDC.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Systems security as a first class consumer.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Administrators still need to SSH to machines, and people still need
their systems to have identities running on them. Having pam&#x2F;nsswitch
modules is a very major requirement, where those modules have to be
fast, simple, and work correctly. Users should &amp;quot;imply&amp;quot; a private
group, and UID&#x2F;GID should by dynamic from UUID (or admins can override
it).&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;2FA&#x2F;u2f&#x2F;TOTP.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Multi-factor auth is here (not coming, here), and we are behind the
game. We already have Apple and MS pushing for webauthn in their
devices. We need to be there for these standards to work, and to support
the next authentication tool after that.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Good RADIUS integration.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;RADIUS is not going away, and is important in education providers and
business networks, so RADIUS must &amp;quot;just work&amp;quot;. Importantly, this means
mschapv2 which is the universal default for all clients to operate with,
which means nthash.&lt;&#x2F;p&gt;
&lt;p&gt;However, we can make the nthash unlinked from your normal password, so
you can then have wifi password and a seperate loging password. We could
even generate an NTHash containing the TOTP token for more high security
environments.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;better data structure (flat, defined by object types).&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;The tree structure of LDAP is confusing, but a flatter structure is
easier to manage and understand. We can use ideas from kubernetes like
tags&#x2F;labels which can be used to provide certain controls and filtering
capabilities for searches and access profiles to apply to.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;structured logging, with in built performance profiling.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Being able to diagnose why an operation is slow is critical and having
structured logs with profiling information is key to allowing admins and
developers to resolve performance issues at scale. It&#x27;s also critical
to have auditing of every single change made in the system, including
internal changes that occur during operations.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;access profiles with auditing capability.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Access profiles that express what you can access, and how. Easier to
audit, generate, and should be tightly linked to group membership for
real RBAC style capabilities.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;transactions by allowing batch operations.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;LDAP wants to provide a transaction system over a set of operations, but
that may cause performance issues on write paths. Instead, why not allow
submission of batches of changes that all must occur &amp;quot;at the same
time&amp;quot; or &amp;quot;none&amp;quot;. This is faster network wise, protocol wise, and
simpler for a server to implement.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-s-next-then&quot;&gt;What&#x27;s next then ...&lt;&#x2F;h2&gt;
&lt;p&gt;Instead of fixing what we have, why not take the best of what we have,
and offer something new in parallel? Start a new front end that speaks
in an accessible way, that has modern structures, and has learnt from
the lessons of the past? We can build it to standalone, or proxy from
the robust core of 389 Directory Server allowing migration paths, but
eschew the pain of trying to bring people to the modern world. We can
offer something unique, an open source identity system that&#x27;s easy to
use, fast, secure, that you can run on your terms, or in the cloud.&lt;&#x2F;p&gt;
&lt;p&gt;This parallel project seems like a good idea ... I wonder what to name
it ...&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Work around docker exec bug</title>
          <pubDate>Sun, 09 Dec 2018 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2018-12-09-work-around-docker-exec-bug/</link>
          <guid>https://fy.blackhats.net.au/blog/2018-12-09-work-around-docker-exec-bug/</guid>
          <description>&lt;h1 id=&quot;work-around-docker-exec-bug&quot;&gt;Work around docker exec bug&lt;&#x2F;h1&gt;
&lt;p&gt;There is currently a docker exec bug in Centos&#x2F;RHEL 7 that causes errors
such as:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# docker exec -i -t instance &#x2F;bin&#x2F;sh
&lt;&#x2F;span&gt;&lt;span&gt;rpc error: code = 2 desc = oci runtime error: exec failed: container_linux.go:247: starting container process caused &amp;quot;process_linux.go:110: decoding init error from pipe caused \&amp;quot;read parent: connection reset by peer\&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;As a work around you can use nsenter instead:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;PID=docker inspect --format {{.State.Pid}} &amp;lt;name of container&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;nsenter --target $PID --mount --uts --ipc --net --pid &#x2F;bin&#x2F;sh
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;For more information, you can see the &lt;a href=&quot;https:&#x2F;&#x2F;bugzilla.redhat.com&#x2F;show_bug.cgi?id=1655214&quot;&gt;bugreport
here.&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>High Available RADVD on Linux</title>
          <pubDate>Thu, 01 Nov 2018 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2018-11-01-high-available-radvd-on-linux/</link>
          <guid>https://fy.blackhats.net.au/blog/2018-11-01-high-available-radvd-on-linux/</guid>
          <description>&lt;h1 id=&quot;high-available-radvd-on-linux&quot;&gt;High Available RADVD on Linux&lt;&#x2F;h1&gt;
&lt;p&gt;Recently I was experimenting again with high availability router
configurations so that in the cause of an outage or a failover the other
router will take over and traffic is still served.&lt;&#x2F;p&gt;
&lt;p&gt;This is usually done through protocols like VRRP to allow virtual ips to
exist that can be failed between. However with ipv6 one needs to still
allow clients to find the router, and in the cause of a failure, the
router advertisments still must continue for client renewals.&lt;&#x2F;p&gt;
&lt;p&gt;To achieve this we need two parts. A shared Link Local address, and a
special RADVD configuration.&lt;&#x2F;p&gt;
&lt;p&gt;Because of howe ipv6 routers work, all traffic (even global) is still
sent to your link local router. We can use an address like:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;fe80::1:1
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This doesn&#x27;t clash with any reserved or special ipv6 addresses, and
it&#x27;s easy to remember. Because of how link local works, we can put this
on many interfaces of the router (many vlans) with no conflict.&lt;&#x2F;p&gt;
&lt;p&gt;So now to the two components.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;keepalived&quot;&gt;Keepalived&lt;&#x2F;h2&gt;
&lt;p&gt;Keepalived is a VRRP implementation for linux. It has extensive
documentation and sometimes uses some implementation specific language,
but it works well for what it does.&lt;&#x2F;p&gt;
&lt;p&gt;Our configuration looks like:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;#  &#x2F;etc&#x2F;keepalived&#x2F;keepalived.conf
&lt;&#x2F;span&gt;&lt;span&gt;global_defs {
&lt;&#x2F;span&gt;&lt;span&gt;  vrrp_version 3
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;vrrp_sync_group G1 {
&lt;&#x2F;span&gt;&lt;span&gt; group {
&lt;&#x2F;span&gt;&lt;span&gt;   ipv6_ens256
&lt;&#x2F;span&gt;&lt;span&gt; }
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;vrrp_instance ipv6_ens256 {
&lt;&#x2F;span&gt;&lt;span&gt;   interface ens256
&lt;&#x2F;span&gt;&lt;span&gt;   virtual_router_id 62
&lt;&#x2F;span&gt;&lt;span&gt;   priority 50
&lt;&#x2F;span&gt;&lt;span&gt;   advert_int 1.0
&lt;&#x2F;span&gt;&lt;span&gt;   virtual_ipaddress {
&lt;&#x2F;span&gt;&lt;span&gt;    fe80::1:1
&lt;&#x2F;span&gt;&lt;span&gt;    2001:db8::1
&lt;&#x2F;span&gt;&lt;span&gt;   }
&lt;&#x2F;span&gt;&lt;span&gt;   nopreempt
&lt;&#x2F;span&gt;&lt;span&gt;   garp_master_delay 1
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Note that we provide both a global address and an LL address for the
failover. This is important for services and DNS for the router to have
the global, but you could omit this. The LL address however is critical
to this configuration and must be present.&lt;&#x2F;p&gt;
&lt;p&gt;Now you can start up vrrp, and you should see one of your two linux
machines pick up the address.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;radvd&quot;&gt;RADVD&lt;&#x2F;h2&gt;
&lt;p&gt;For RADVD to work, a feature of the 2.x series is required. Packaging
this for el7 is out of scope of this post, but fedora ships the version
required.&lt;&#x2F;p&gt;
&lt;p&gt;The feature is that RADVD can be configured to specify which address it
advertises for the router, rather than assuming the interface LL
autoconf address is the address to advertise. The configuration appears
as:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# &#x2F;etc&#x2F;radvd.conf
&lt;&#x2F;span&gt;&lt;span&gt;interface ens256
&lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;    AdvSendAdvert on;
&lt;&#x2F;span&gt;&lt;span&gt;    MinRtrAdvInterval 30;
&lt;&#x2F;span&gt;&lt;span&gt;    MaxRtrAdvInterval 100;
&lt;&#x2F;span&gt;&lt;span&gt;    AdvRASrcAddress {
&lt;&#x2F;span&gt;&lt;span&gt;        fe80::1:1;
&lt;&#x2F;span&gt;&lt;span&gt;    };
&lt;&#x2F;span&gt;&lt;span&gt;    prefix 2001:db8::&#x2F;64
&lt;&#x2F;span&gt;&lt;span&gt;    {
&lt;&#x2F;span&gt;&lt;span&gt;        AdvOnLink on;
&lt;&#x2F;span&gt;&lt;span&gt;        AdvAutonomous on;
&lt;&#x2F;span&gt;&lt;span&gt;        AdvRouterAddr off;
&lt;&#x2F;span&gt;&lt;span&gt;    };
&lt;&#x2F;span&gt;&lt;span&gt;};
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Note the AdvRASrcAddress parameter? This defines a priority list of
address to advertise that could be available on the interface.&lt;&#x2F;p&gt;
&lt;p&gt;Now start up radvd on your two routers, and try failing over between
them while you ping from your client. Remember to ping LL from a client
you need something like:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ping6 fe80::1:1%en1
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Where the outgoing interface of your client traffic is denoted after the
&#x27;%&#x27;.&lt;&#x2F;p&gt;
&lt;p&gt;Happy failover routing!&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Rust RwLock and Mutex Performance Oddities</title>
          <pubDate>Fri, 19 Oct 2018 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2018-10-19-rust-rwlock-and-mutex-performance-oddities/</link>
          <guid>https://fy.blackhats.net.au/blog/2018-10-19-rust-rwlock-and-mutex-performance-oddities/</guid>
          <description>&lt;h1 id=&quot;rust-rwlock-and-mutex-performance-oddities&quot;&gt;Rust RwLock and Mutex Performance Oddities&lt;&#x2F;h1&gt;
&lt;p&gt;Recently I have been working on Rust datastructures once again. In the
process I wanted to test how my work performed compared to a standard
library RwLock and Mutex. On my home laptop the RwLock was 5 times
faster, the Mutex 2 times faster than my work.&lt;&#x2F;p&gt;
&lt;p&gt;So checking out my code on my workplace workstation and running my bench
marks I noticed the Mutex was the same - 2 times faster. However, the
RwLock was 4000 times slower.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-s-a-rwlock-and-mutex-anyway&quot;&gt;What&#x27;s a RwLock and Mutex anyway?&lt;&#x2F;h2&gt;
&lt;p&gt;In a multithreaded application, it&#x27;s important that data that needs to
be shared between threads is consistent when accessed. This consistency
is not just logical consistency of the data, but affects hardware
consistency of the memory in cache. As a simple example, let&#x27;s examine
an update to a bank account done by two threads:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;acc = 10
&lt;&#x2F;span&gt;&lt;span&gt;deposit = 3
&lt;&#x2F;span&gt;&lt;span&gt;withdrawl = 5
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[ Thread A ]            [ Thread B ]
&lt;&#x2F;span&gt;&lt;span&gt;acc = load_balance()    acc = load_balance()
&lt;&#x2F;span&gt;&lt;span&gt;acc = acc + deposit     acc = acc - withdrawl
&lt;&#x2F;span&gt;&lt;span&gt;store_balance(acc)      store_balance(acc)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;What will the account balance be at the end? The answer is &amp;quot;it
depends&amp;quot;. Because threads are working in parallel these operations
could happen:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;At the same time&lt;&#x2F;li&gt;
&lt;li&gt;Interleaved (various possibilities)&lt;&#x2F;li&gt;
&lt;li&gt;Sequentially&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;This isn&#x27;t very healthy for our bank account. We could lose our
deposit, or have invalid data. Valid outcomes at the end are that acc
could be 13, 5, 8. Only one of these is correct.&lt;&#x2F;p&gt;
&lt;p&gt;A mutex protects our data in multiple ways. It provides hardware
consistency operations so that our cpus cache state is valid. It also
allows only a single thread inside of the mutex at a time so we can
linearise operations. Mutex comes from the word &amp;quot;Mutual Exclusion&amp;quot;
after all.&lt;&#x2F;p&gt;
&lt;p&gt;So our example with a mutex now becomes:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;acc = 10
&lt;&#x2F;span&gt;&lt;span&gt;deposit = 3
&lt;&#x2F;span&gt;&lt;span&gt;withdrawl = 5
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[ Thread A ]            [ Thread B ]
&lt;&#x2F;span&gt;&lt;span&gt;mutex.lock()            mutex.lock()
&lt;&#x2F;span&gt;&lt;span&gt;acc = load_balance()    acc = load_balance()
&lt;&#x2F;span&gt;&lt;span&gt;acc = acc + deposit     acc = acc - withdrawl
&lt;&#x2F;span&gt;&lt;span&gt;store_balance(acc)      store_balance(acc)
&lt;&#x2F;span&gt;&lt;span&gt;mutex.unlock()          mutex.unlock()
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now only one thread will access our account at a time: The other thread
will block until the mutex is released.&lt;&#x2F;p&gt;
&lt;p&gt;A RwLock is a special extension to this pattern. Where a mutex
guarantees single access to the data in a read and write form, a RwLock
(Read Write Lock) allows multiple read-only views OR single read and
writer access. Importantly when a writer wants to access the lock, all
readers must complete their work and &amp;quot;drain&amp;quot;. Once the write is
complete readers can begin again. So you can imagine it as:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;Time -&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;T1: -- read --&amp;gt; x
&lt;&#x2F;span&gt;&lt;span&gt;T3:     -- read --&amp;gt; x                x -- read --&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;T3:     -- read --&amp;gt; x                x -- read --&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;T4:                   | -- write -- |
&lt;&#x2F;span&gt;&lt;span&gt;T5:                                  x -- read --&amp;gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;test-case-for-the-rwlock&quot;&gt;Test Case for the RwLock&lt;&#x2F;h2&gt;
&lt;p&gt;My test case is simple. Given a set of 12 threads, we spawn:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;8 readers. Take a read lock, read the value, release the read lock.
If the value == target then stop the thread.&lt;&#x2F;li&gt;
&lt;li&gt;4 writers. Take a write lock, read the value. Add one and write.
Continue until value == target then stop.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Other conditions:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;The test code is identical between Mutex&#x2F;RwLock (beside the locking
costruct)&lt;&#x2F;li&gt;
&lt;li&gt;--release is used for compiler optimisations&lt;&#x2F;li&gt;
&lt;li&gt;The test hardware is as close as possible (i7 quad core)&lt;&#x2F;li&gt;
&lt;li&gt;The tests are run multiple time to construct averages of the
performance&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;The idea being that X target number of writes must occur, while many
readers contend as fast as possible on the read. We are pressuring the
system of choice between &amp;quot;many readers getting to read fast&amp;quot; or
&amp;quot;writers getting priority to drain&#x2F;block readers&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;On OSX given a target of 500 writes, this was able to complete in 0.01
second for the RwLock. (MBP 2011, 2.8GHz)&lt;&#x2F;p&gt;
&lt;p&gt;On Linux given a target of 500 writes, this completed in 42 seconds.
This is a 4000 times difference. (i7-7700 CPU @ 3.60GHz)&lt;&#x2F;p&gt;
&lt;p&gt;All things considered the Linux machine should have an advantage - it&#x27;s
a desktop processor, of a newer generation, and much faster clock speed.
So why is the RwLock performance so much different on Linux?&lt;&#x2F;p&gt;
&lt;h2 id=&quot;to-the-source-code&quot;&gt;To the source code!&lt;&#x2F;h2&gt;
&lt;p&gt;Examining the &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;rust-lang&#x2F;rust&#x2F;blob&#x2F;master&#x2F;src&#x2F;libstd&#x2F;sys&#x2F;unix&#x2F;rwlock.rs&quot;&gt;Rust source
code&lt;&#x2F;a&gt;
, many OS primitives come from libc. This is because they require OS
support to function. RwLock is an example of this as is mutex and many
more. The unix implementation for Rust consumes the pthread_rwlock
primitive. This means we need to read man pages to understand the
details of each.&lt;&#x2F;p&gt;
&lt;p&gt;OSX uses FreeBSD userland components, so we can assume they follow the
BSD man pages. In the FreeBSD man page for pthread_rwlock_rdlock we see:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;IMPLEMENTATION NOTES
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt; To prevent writer starvation, writers are favored over readers.
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Linux however, uses different constructs. Looking at the Linux man page:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;PTHREAD_RWLOCK_PREFER_READER_NP
&lt;&#x2F;span&gt;&lt;span&gt;  This is the default.  A thread may hold multiple read locks;
&lt;&#x2F;span&gt;&lt;span&gt;  that is, read locks are recursive.  According to The Single
&lt;&#x2F;span&gt;&lt;span&gt;  Unix Specification, the behavior is unspecified when a reader
&lt;&#x2F;span&gt;&lt;span&gt;  tries to place a lock, and there is no write lock but writers
&lt;&#x2F;span&gt;&lt;span&gt;  are waiting.  Giving preference to the reader, as is set by
&lt;&#x2F;span&gt;&lt;span&gt;  PTHREAD_RWLOCK_PREFER_READER_NP, implies that the reader will
&lt;&#x2F;span&gt;&lt;span&gt;  receive the requested lock, even if a writer is waiting.  As
&lt;&#x2F;span&gt;&lt;span&gt;  long as there are readers, the writer will be starved.
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;reader-vs-writer-preferences&quot;&gt;Reader vs Writer Preferences?&lt;&#x2F;h2&gt;
&lt;p&gt;Due to the policy of a RwLock having multiple readers OR a single
writer, a preference is given to one or the other. The preference
basically boils down to the choice of:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Do you respond to write requests and have new readers block?&lt;&#x2F;li&gt;
&lt;li&gt;Do you favour readers but let writers block until reads are
complete?&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;The difference is that on a &lt;em&gt;read&lt;&#x2F;em&gt; heavy workload, a write will continue
to be delayed so that readers can begin &lt;em&gt;and&lt;&#x2F;em&gt; complete (up until some
threshold of time). However, on a writer focused workload, you allow
readers to stall so that writes can complete sooner.&lt;&#x2F;p&gt;
&lt;p&gt;On Linux, they choose a reader preference. On OSX&#x2F;BSD they choose a
writer preference.&lt;&#x2F;p&gt;
&lt;p&gt;Because our test is about how fast can a target of write operations
complete, the writer preference of BSD&#x2F;OSX causes this test to be much
faster. Our readers still &amp;quot;read&amp;quot; but are giving way to writers, which
completes our test sooner.&lt;&#x2F;p&gt;
&lt;p&gt;However, the linux &amp;quot;reader favour&amp;quot; policy means that our readers
(designed for creating conteniton) are allowed to skip the queue and
block writers. This causes our writers to starve. Because the test is
only concerned with writer completion, the result is (correctly) showing
our writers are heavily delayed - even though many more readers are
completing.&lt;&#x2F;p&gt;
&lt;p&gt;If we were to track the number of reads that completed, I am sure we
would see a large factor of difference where Linux has allow many more
readers to complete than the OSX version.&lt;&#x2F;p&gt;
&lt;p&gt;Linux pthread_rwlock does allow you to change this policy
(PTHREAD_RWLOCK_PREFER_WRITER_NP) but this isn&#x27;t exposed via Rust. This
means today, you accept (and trust) the OS default. Rust is just unaware
at compile time and run time that such a different policy exists.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;&#x2F;h2&gt;
&lt;p&gt;Rust like any language consumes operating system primitives. Every OS
implements these differently and these differences in OS policy can
cause real performance differences in applications between development
and production.&lt;&#x2F;p&gt;
&lt;p&gt;It&#x27;s well worth understanding the constructions used in programming
languages and how they affect the performance of your application - and
the decisions behind those tradeoffs.&lt;&#x2F;p&gt;
&lt;p&gt;This isn&#x27;t meant to say &amp;quot;don&#x27;t use RwLock in Rust on Linux&amp;quot;. This is
meant to say &amp;quot;choose it when it makes sense - on read heavy loads,
understanding writers will delay&amp;quot;. For my project (A copy on write
cell) I will likely conditionally compile rwlock on osx, but mutex on
linux as I require a writer favoured behaviour. There are certainly
applications that will benefit from the reader priority in linux
(especially if there is low writer volume and low penalty to delayed
writes).&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Photography - Why You Should Use JPG (not RAW)</title>
          <pubDate>Mon, 06 Aug 2018 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2018-08-06-photography-why-you-should-use-jpg-not-raw/</link>
          <guid>https://fy.blackhats.net.au/blog/2018-08-06-photography-why-you-should-use-jpg-not-raw/</guid>
          <description>&lt;h1 id=&quot;photography-why-you-should-use-jpg-not-raw&quot;&gt;Photography - Why You Should Use JPG (not RAW)&lt;&#x2F;h1&gt;
&lt;p&gt;When I started my modern journey into photography, I simply shot in JPG.
I was happy with the results, and the images I was able to produce. It
was only later that I was introduced to a now good friend and he said:
&amp;quot;You should always shoot RAW! You can edit so much more if you do.&amp;quot;.
It&#x27;s not hard to find many &#x27;beginner&#x27; videos all touting the value of
RAW for post editing, and how it&#x27;s the step from beginner to serious
photographer (and editor).&lt;&#x2F;p&gt;
&lt;p&gt;Today, I would like to explore why I have turned off RAW on my camera
bodies for good. This is a deeply personal decision, and I hope that my
experience helps you to think about your own creative choices. If you
want to stay shooting RAW and editing - good on you. If this encourages
you to try turning back to JPG - good on you too.&lt;&#x2F;p&gt;
&lt;p&gt;There are two primary reasons for why I turned off RAW:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Colour reproduction of in body JPG is better to the eye today.&lt;&#x2F;li&gt;
&lt;li&gt;Photography is about composing an image from what you have infront
of you.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;colour-is-about-experts-and-detail&quot;&gt;Colour is about experts (and detail)&lt;&#x2F;h2&gt;
&lt;p&gt;I have always been unhappy with the colour output of my editing software
when processing RAW images. As someone who is colour blind I did not
know if it was just my perception, or if real issues existed. No one
else complained so it must just be me right!&lt;&#x2F;p&gt;
&lt;p&gt;Eventually I stumbled on an article about how to develop real colour and
extract camera film simulations for my editor. I was interested in both
the ability to get &lt;em&gt;true&lt;&#x2F;em&gt; reflections of colour in my images, but also
to use the film simulations in post (the black and white of my camera
body is beautiful and soft, but my editor is harsh).&lt;&#x2F;p&gt;
&lt;p&gt;I spent a solid week testing and profiling both of my cameras. I quickly
realised a great deal about what was occuring in my editor, but also my
camera body.&lt;&#x2F;p&gt;
&lt;p&gt;The editor I have, is attempting to generalise over the entire set of
sensors that a manufacturer has created. They are also attempting to
create a &lt;em&gt;true&lt;&#x2F;em&gt; colour output profile, that is as reflective of reality
as possible. So when I was exporting RAWs to JPG, I was seeing the
&lt;em&gt;differences&lt;&#x2F;em&gt; between what my camera hardware is, vs the editors
profiles. (This was particularly bad on my older body, so I suspect the
RAW profiles are designed for the newer sensor).&lt;&#x2F;p&gt;
&lt;p&gt;I then created film simulations and quickly noticed the subtle changes.
Blacks were blacker, but retained more fine detail with the simulation.
Skin tone was softer. Exposure was more even across a variety of image
types. How? RAW and my editor is meant to create the best image
possible? Why is a film-simulation I have &amp;quot;extracted&amp;quot; creating better
images?&lt;&#x2F;p&gt;
&lt;p&gt;As any good engineer would do I created sample images. A&#x2F;B testing. I
would provide the RAW processed by my editor, and a RAW processed with
my film simulation. I would vary the left&#x2F;right of the image, exposure,
subject, and more. After about 10 tests across 5 people, only on one
occasion did someone prefer the RAW from my editor.&lt;&#x2F;p&gt;
&lt;p&gt;At this point I realised that my camera manufacturer is hiring experts
who build, live and breath colour technology. They have tested and
examined everything about the body I have, and likely calibrated it
individually in the process to make produce exact reproductions as they
see in a lab. They are developing colour profiles that are not just
broadly applicable, but also &lt;em&gt;pleasing&lt;&#x2F;em&gt; to look at (even if not accurate
reproductions).&lt;&#x2F;p&gt;
&lt;p&gt;So how can my film simulations I extracted and built in a week, measure
up to the experts? I decided to find out. I shot test images in JPG and
RAW and began to provide A&#x2F;B&#x2F;C tests to people.&lt;&#x2F;p&gt;
&lt;p&gt;If the editor RAW was washed out compared to the RAW with my film
simulation, the JPG from the body made them pale in comparison. Every
detail was better, across a range of conditions. The features in my
camera body are &lt;em&gt;better&lt;&#x2F;em&gt; than my editor. Noise reduction, dynamic range,
sharpening, softening, colour saturation. I was holding in my hands a
device that has thousands of hours of expert design, that could eclipse
anything I built on a weekend for fun to achieve the same.&lt;&#x2F;p&gt;
&lt;p&gt;It was then I came to think about and realise ...&lt;&#x2F;p&gt;
&lt;h2 id=&quot;composition-and-effects-is-about-you&quot;&gt;Composition (and effects) is about you&lt;&#x2F;h2&gt;
&lt;p&gt;Photography is a complex skill. It&#x27;s not having a fancy camera and just
clicking the shutter, or zooming in. Photography is about taking that
camera and putting it in a position to take a well composed image based
on many rules (and exceptions) that I am still continually learning.&lt;&#x2F;p&gt;
&lt;p&gt;When you stop to look at an image you should always think &amp;quot;how can I
compose the best image possible?&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;So why shoot in RAW? RAW is all about enabling editing in &lt;em&gt;post&lt;&#x2F;em&gt;. After
you have already composed and taken the image. There are valid times and
useful functions of editing. For example whitebalance correction and
minor cropping in some cases. Both of these are easily conducted with
JPG with no loss in quality compared to the RAW. I still commonly do
both of these.&lt;&#x2F;p&gt;
&lt;p&gt;However RAW allows you to recover mistakes during composition (to a
point). For example, the powerful base-curve fusion module allows
dynamic range &amp;quot;after the fact&amp;quot;. You may even add high or low pass
filters, or mask areas to filter and affect the colour to make things
pop, or want that RAW data to make your vibrance control as perfect as
possible. You may change the perspective, or even add filters and more.
Maybe you want to optimise de-noise to make smooth high ISO images.
There are so many options!&lt;&#x2F;p&gt;
&lt;p&gt;But all these things are you composing &lt;em&gt;after&lt;&#x2F;em&gt;. Today, many of these
functions are in your camera - and better performing. So while I&#x27;m
composing I can enable dynamic range for the darker elements of the
frame. I can compose and add my colour saturation (or remove it). I can
sharpen, soften. I can move my own body to change perspective. All at
the time I am building the image in my mind, as I compose, I am able to
decide on the creative effects I want to place in that image. I&#x27;m not
longer just composing within a frame, but a canvas of potential effects.&lt;&#x2F;p&gt;
&lt;p&gt;To me this was an important distinction. I always found I was editing
poorly-composed images in an attempt to &amp;quot;fix&amp;quot; them to something
acceptable. Instead I should have been looking at how to compose them
from the start to be great, using the tool in my hand - my camera.&lt;&#x2F;p&gt;
&lt;p&gt;Really, this is a decision that is yours. Do you spend more time now to
make the image you want? Or do you spend it later editing to achieve
what you want?&lt;&#x2F;p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;&#x2F;h2&gt;
&lt;p&gt;Photography is a creative process. You will have your own ideas of how
that process should look, and how you want to work with it. Great! This
was my experience and how I have arrived at a creative process that I am
satisfied with. I hope that it provides you an alternate perspective to
the generally accepted &amp;quot;RAW is imperative&amp;quot; line that many people
advertise.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Extracting Formally Verified C with FStar and KreMLin</title>
          <pubDate>Mon, 30 Apr 2018 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2018-04-30-extracting-formally-verified-c-with-fstar-and-kremlin/</link>
          <guid>https://fy.blackhats.net.au/blog/2018-04-30-extracting-formally-verified-c-with-fstar-and-kremlin/</guid>
          <description>&lt;h1 id=&quot;extracting-formally-verified-c-with-fstar-and-kremlin&quot;&gt;Extracting Formally Verified C with FStar and KreMLin&lt;&#x2F;h1&gt;
&lt;p&gt;As software engineering has progressed, the correctness of software has
become a major issue. However the tools that exist today to help us
create correct programs have been lacking. Human&#x27;s continue to make
mistakes that cause harm to others (even I do!).&lt;&#x2F;p&gt;
&lt;p&gt;Instead, tools have now been developed that allow the verification of
programs and algorithms as correct. These have not gained widespread
adoption due to the complexities of their tool chains or other social
and cultural issues.&lt;&#x2F;p&gt;
&lt;p&gt;The Project Everest research has aimed to create a formally verified
webserver and cryptography library. To achieve this they have developed
a language called F* (FStar) and KreMLin as an extraction tool. This
allows an FStar verified algorithm to be extracted to a working set of C
source code - C source code that can be easily added to existing
projects.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;setting-up-a-fstar-and-kremlin-environment&quot;&gt;Setting up a FStar and KreMLin environment&lt;&#x2F;h2&gt;
&lt;p&gt;Today there are a number of undocumented gotchas with opam - the OCaml
package manager. Most of these are silent errors. I used the following
steps to get to a working environment.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# It&amp;#39;s important to have bzip2 here else opam silently fails!
&lt;&#x2F;span&gt;&lt;span&gt;dnf install -y rsync git patch opam bzip2 which gmp gmp-devel m4 \
&lt;&#x2F;span&gt;&lt;span&gt;        hg unzip pkgconfig redhat-rpm-config
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;opam init
&lt;&#x2F;span&gt;&lt;span&gt;# You need 4.02.3 else wasm will not compile.
&lt;&#x2F;span&gt;&lt;span&gt;opam switch create 4.02.3
&lt;&#x2F;span&gt;&lt;span&gt;opam switch 4.02.3
&lt;&#x2F;span&gt;&lt;span&gt;echo &amp;quot;. &#x2F;home&#x2F;Work&#x2F;.opam&#x2F;opam-init&#x2F;init.sh &amp;gt; &#x2F;dev&#x2F;null 2&amp;gt; &#x2F;dev&#x2F;null || true&amp;quot; &amp;gt;&amp;gt; .bashrc
&lt;&#x2F;span&gt;&lt;span&gt;opam install batteries fileutils yojson ppx_deriving_yojson zarith fix pprint menhir process stdint ulex wasm
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;PATH &amp;quot;~&#x2F;z3&#x2F;bin:~&#x2F;FStar&#x2F;bin:~&#x2F;kremlin:$PATH&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;# You can get the &amp;quot;correct&amp;quot; z3 version from https:&#x2F;&#x2F;github.com&#x2F;FStarLang&#x2F;binaries&#x2F;raw&#x2F;master&#x2F;z3-tested&#x2F;z3-4.5.1.1f29cebd4df6-x64-ubuntu-14.04.zip
&lt;&#x2F;span&gt;&lt;span&gt;unzip z3-4.5.1.1f29cebd4df6-x64-ubuntu-14.04.zip
&lt;&#x2F;span&gt;&lt;span&gt;mv z3-4.5.1.1f29cebd4df6-x64-ubuntu-14.04 z3
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# You will need a &amp;quot;stable&amp;quot; release of FStar https:&#x2F;&#x2F;github.com&#x2F;FStarLang&#x2F;FStar&#x2F;archive&#x2F;stable.zip
&lt;&#x2F;span&gt;&lt;span&gt;unzip stable.zip
&lt;&#x2F;span&gt;&lt;span&gt;mv FStar-stable Fstar
&lt;&#x2F;span&gt;&lt;span&gt;cd ~&#x2F;FStar
&lt;&#x2F;span&gt;&lt;span&gt;opam config exec -- make -C src&#x2F;ocaml-output -j
&lt;&#x2F;span&gt;&lt;span&gt;opam config exec -- make -C ulib&#x2F;ml
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# You need a master branch of kremlin https:&#x2F;&#x2F;github.com&#x2F;FStarLang&#x2F;kremlin&#x2F;archive&#x2F;master.zip
&lt;&#x2F;span&gt;&lt;span&gt;cd ~
&lt;&#x2F;span&gt;&lt;span&gt;unzip master.zip
&lt;&#x2F;span&gt;&lt;span&gt;mv kremlin-master kremlin
&lt;&#x2F;span&gt;&lt;span&gt;cd kremlin
&lt;&#x2F;span&gt;&lt;span&gt;opam config exec -- make
&lt;&#x2F;span&gt;&lt;span&gt;opam config exec -- make test
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;your-first-fstar-extraction&quot;&gt;Your first FStar extraction&lt;&#x2F;h2&gt;
</description>
      </item>
      <item>
          <title>AD directory admins group setup</title>
          <pubDate>Thu, 26 Apr 2018 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2018-04-26-ad-directory-admins-group-setup/</link>
          <guid>https://fy.blackhats.net.au/blog/2018-04-26-ad-directory-admins-group-setup/</guid>
          <description>&lt;h1 id=&quot;ad-directory-admins-group-setup&quot;&gt;AD directory admins group setup&lt;&#x2F;h1&gt;
&lt;p&gt;Recently I have been reading many of the Microsoft Active Directory best
practices for security and hardening. These are great resources, and
very well written. The major theme of the articles is &amp;quot;least
privilege&amp;quot;, where accounts like Administrators or Domain Admins are
over used and lead to further compromise.&lt;&#x2F;p&gt;
&lt;p&gt;A suggestion that is put forward by the author is to have a group that
has no other permissions but to manage the directory service. This
should be used to temporarily make a user an admin, then after a period
of time they should be removed from the group.&lt;&#x2F;p&gt;
&lt;p&gt;This way you have no Administrators or Domain Admins, but you have an AD
only group that can temporarily grant these permissions when required.&lt;&#x2F;p&gt;
&lt;p&gt;I want to explore how to create this and configure the correct access
controls to enable this scheme.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;create-our-group&quot;&gt;Create our group&lt;&#x2F;h2&gt;
&lt;p&gt;First, lets create a &amp;quot;Directory Admins&amp;quot; group which will contain our
members that have the rights to modify or grant other privileges.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# &#x2F;usr&#x2F;local&#x2F;samba&#x2F;bin&#x2F;samba-tool group add &amp;#39;Directory Admins&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;Added group Directory Admins
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;It&#x27;s a really good idea to add this to the &amp;quot;Denied RODC Password
Replication Group&amp;quot; to limit the risk of these accounts being
compromised during an attack. Additionally, you probably want to make
your &amp;quot;admin storage&amp;quot; group also a member of this, but I&#x27;ll leave that
to you.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# &#x2F;usr&#x2F;local&#x2F;samba&#x2F;bin&#x2F;samba-tool group addmembers &amp;quot;Denied RODC Password Replication Group&amp;quot; &amp;quot;Directory Admins&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now that we have this, lets add a member to it. I strongly advise you
create special accounts just for the purpose of directory
administration - don&#x27;t use your daily account for this!&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# &#x2F;usr&#x2F;local&#x2F;samba&#x2F;bin&#x2F;samba-tool user create da_william
&lt;&#x2F;span&gt;&lt;span&gt;User &amp;#39;da_william&amp;#39; created successfully
&lt;&#x2F;span&gt;&lt;span&gt;# &#x2F;usr&#x2F;local&#x2F;samba&#x2F;bin&#x2F;samba-tool group addmembers &amp;#39;Directory Admins&amp;#39; da_william
&lt;&#x2F;span&gt;&lt;span&gt;Added members to group Directory Admins
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;configure-the-permissions&quot;&gt;Configure the permissions&lt;&#x2F;h2&gt;
&lt;p&gt;Now we need to configure the correct dsacls to allow Directory Admins
full control over directory objects. It could be possible to constrain
this to &lt;em&gt;only&lt;&#x2F;em&gt; modification of the cn=builtin and cn=users container
however, as directory admins might not need so much control for things
like dns modification.&lt;&#x2F;p&gt;
&lt;p&gt;If you want to constrain these permissions, only apply the following to
cn=builtins instead - or even just the target groups like Domain Admins.&lt;&#x2F;p&gt;
&lt;p&gt;First we need the objectSID of our Directory Admins group so we can
build the ACE.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# &#x2F;usr&#x2F;local&#x2F;samba&#x2F;bin&#x2F;samba-tool group show &amp;#39;directory admins&amp;#39; --attributes=cn,objectsid
&lt;&#x2F;span&gt;&lt;span&gt;dn: CN=Directory Admins,CN=Users,DC=adt,DC=blackhats,DC=net,DC=au
&lt;&#x2F;span&gt;&lt;span&gt;cn: Directory Admins
&lt;&#x2F;span&gt;&lt;span&gt;objectSid: S-1-5-21-2488910578-3334016764-1009705076-1104
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now with this we can construct the ACE.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;(A;CI;RPWPLCLORC;;;S-1-5-21-2488910578-3334016764-1009705076-1104)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This permission grants:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;RP: read property&lt;&#x2F;li&gt;
&lt;li&gt;WP: write property&lt;&#x2F;li&gt;
&lt;li&gt;LC: list child objects&lt;&#x2F;li&gt;
&lt;li&gt;LO: list objects&lt;&#x2F;li&gt;
&lt;li&gt;RC: read control&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;It could be possible to expand these rights: it depends if you want
directory admins to be able to do &amp;quot;day to day&amp;quot; ad control jobs, or if
you just use them for granting of privileges. That&#x27;s up to you. An
expanded ACE might be:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# Same as Enterprise Admins
&lt;&#x2F;span&gt;&lt;span&gt;(A;CI;RPWPCRCCDCLCLORCWOWDSW;;;S-1-5-21-2488910578-3334016764-1009705076-1104)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now lets actually apply this and do a test:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# &#x2F;usr&#x2F;local&#x2F;samba&#x2F;bin&#x2F;samba-tool dsacl set --sddl=&amp;#39;(A;CI;RPWPLCLORC;;;S-1-5-21-2488910578-3334016764-1009705076-1104)&amp;#39; --objectdn=&amp;#39;dc=adt,dc=blackhats,dc=net,dc=au&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;# &#x2F;usr&#x2F;local&#x2F;samba&#x2F;bin&#x2F;samba-tool group addmembers &amp;#39;directory admins&amp;#39; administrator -U &amp;#39;da_william%...&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;Added members to group directory admins
&lt;&#x2F;span&gt;&lt;span&gt;# &#x2F;usr&#x2F;local&#x2F;samba&#x2F;bin&#x2F;samba-tool group listmembers &amp;#39;directory admins&amp;#39; -U &amp;#39;da_william%...&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;da_william
&lt;&#x2F;span&gt;&lt;span&gt;Administrator
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;After we have completed our tasks, we remove da_william from the
directory admins group as we no longer required the privileges. You can
self-remove, or have the Administrator account do the removal.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# &#x2F;usr&#x2F;local&#x2F;samba&#x2F;bin&#x2F;samba-tool group removemembers &amp;#39;directory admins&amp;#39; da_william -U &amp;#39;da_william%...&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;Removed members from group directory admins
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# &#x2F;usr&#x2F;local&#x2F;samba&#x2F;bin&#x2F;samba-tool group removemembers &amp;#39;directory admins&amp;#39; da_william -U &amp;#39;Administrator&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;Removed members from group directory admins
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Finally check that da_william is no longer in the group.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# &#x2F;usr&#x2F;local&#x2F;samba&#x2F;bin&#x2F;samba-tool group listmembers &amp;#39;directory admins&amp;#39; -U &amp;#39;da_william%...&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;Administrator
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;&#x2F;h2&gt;
&lt;p&gt;With these steps we have created a secure account that has limited admin
rights, able to temporarily promote users with privileges for
administrative work - and able to remove it once the work is complete.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Understanding AD Access Control Entries</title>
          <pubDate>Fri, 20 Apr 2018 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2018-04-20-understanding-ad-access-control-entries/</link>
          <guid>https://fy.blackhats.net.au/blog/2018-04-20-understanding-ad-access-control-entries/</guid>
          <description>&lt;h1 id=&quot;understanding-ad-access-control-entries&quot;&gt;Understanding AD Access Control Entries&lt;&#x2F;h1&gt;
&lt;p&gt;A few days ago I set out to work on making samba 4 my default LDAP
server. In the process I was forced to learn about Active Directory
Access controls. I found that while there was significant documentation
around the syntax of these structures, very little existed explaining
how to use them effectively.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-s-in-an-ace&quot;&gt;What&#x27;s in an ACE?&lt;&#x2F;h2&gt;
&lt;p&gt;If you look at the the ACL of an entry in AD you&#x27;ll see something like:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;O:DAG:DAD:AI
&lt;&#x2F;span&gt;&lt;span&gt;(A;CI;RPLCLORC;;;AN)
&lt;&#x2F;span&gt;&lt;span&gt;(A;;RPWPCRCCDCLCLORCWOWDSDDTSW;;;SY)
&lt;&#x2F;span&gt;&lt;span&gt;(A;;RPWPCRCCDCLCLORCWOWDSW;;;DA)
&lt;&#x2F;span&gt;&lt;span&gt;(OA;;CCDC;bf967aba-0de6-11d0-a285-00aa003049e2;;AO)
&lt;&#x2F;span&gt;&lt;span&gt;(OA;;CCDC;bf967a9c-0de6-11d0-a285-00aa003049e2;;AO)
&lt;&#x2F;span&gt;&lt;span&gt;(OA;;CCDC;bf967aa8-0de6-11d0-a285-00aa003049e2;;PO)
&lt;&#x2F;span&gt;&lt;span&gt;(A;;RPLCLORC;;;AU)
&lt;&#x2F;span&gt;&lt;span&gt;(OA;;CCDC;4828cc14-1437-45bc-9b07-ad6f015e5f28;;AO)
&lt;&#x2F;span&gt;&lt;span&gt;(OA;CIIOID;RP;4c164200-20c0-11d0-a768-00aa006e0529;4828cc14-1437-45bc-9b07-ad6f015e5f28;RU)
&lt;&#x2F;span&gt;&lt;span&gt;(OA;CIIOID;RP;4c164200-20c0-11d0-a768-00aa006e0529;bf967aba-0de6-11d0-a285-00aa003049e2;RU)
&lt;&#x2F;span&gt;&lt;span&gt;(OA;CIIOID;RP;5f202010-79a5-11d0-9020-00c04fc2d4cf;4828cc14-1437-45bc-9b07-ad6f015e5f28;RU)
&lt;&#x2F;span&gt;&lt;span&gt;(OA;CIIOID;RP;5f202010-79a5-11d0-9020-00c04fc2d4cf;bf967aba-0de6-11d0-a285-00aa003049e2;RU)
&lt;&#x2F;span&gt;&lt;span&gt;(OA;CIIOID;RP;bc0ac240-79a9-11d0-9020-00c04fc2d4cf;4828cc14-1437-45bc-9b07-ad6f015e5f28;RU)
&lt;&#x2F;span&gt;&lt;span&gt;(OA;CIIOID;RP;bc0ac240-79a9-11d0-9020-00c04fc2d4cf;bf967aba-0de6-11d0-a285-00aa003049e2;RU)
&lt;&#x2F;span&gt;&lt;span&gt;(OA;CIIOID;RP;59ba2f42-79a2-11d0-9020-00c04fc2d3cf;4828cc14-1437-45bc-9b07-ad6f015e5f28;RU)
&lt;&#x2F;span&gt;&lt;span&gt;(OA;CIIOID;RP;59ba2f42-79a2-11d0-9020-00c04fc2d3cf;bf967aba-0de6-11d0-a285-00aa003049e2;RU)
&lt;&#x2F;span&gt;&lt;span&gt;(OA;CIIOID;RP;037088f8-0ae1-11d2-b422-00a0c968f939;4828cc14-1437-45bc-9b07-ad6f015e5f28;RU)
&lt;&#x2F;span&gt;&lt;span&gt;(OA;CIIOID;RP;037088f8-0ae1-11d2-b422-00a0c968f939;bf967aba-0de6-11d0-a285-00aa003049e2;RU)
&lt;&#x2F;span&gt;&lt;span&gt;(OA;CIIOID;RP;b7c69e6d-2cc7-11d2-854e-00a0c983f608;bf967a86-0de6-11d0-a285-00aa003049e2;ED)
&lt;&#x2F;span&gt;&lt;span&gt;(OA;CIIOID;RP;b7c69e6d-2cc7-11d2-854e-00a0c983f608;bf967a9c-0de6-11d0-a285-00aa003049e2;ED)
&lt;&#x2F;span&gt;&lt;span&gt;(OA;CIIOID;RP;b7c69e6d-2cc7-11d2-854e-00a0c983f608;bf967aba-0de6-11d0-a285-00aa003049e2;ED)
&lt;&#x2F;span&gt;&lt;span&gt;(OA;CIIOID;RPLCLORC;;4828cc14-1437-45bc-9b07-ad6f015e5f28;RU)
&lt;&#x2F;span&gt;&lt;span&gt;(OA;CIIOID;RPLCLORC;;bf967a9c-0de6-11d0-a285-00aa003049e2;RU)
&lt;&#x2F;span&gt;&lt;span&gt;(OA;CIIOID;RPLCLORC;;bf967aba-0de6-11d0-a285-00aa003049e2;RU)
&lt;&#x2F;span&gt;&lt;span&gt;(OA;CIID;RPWPCR;91e647de-d96f-4b70-9557-d63ff4f3ccd8;;PS)
&lt;&#x2F;span&gt;&lt;span&gt;(A;CIID;RPWPCRCCDCLCLORCWOWDSDDTSW;;;EA)
&lt;&#x2F;span&gt;&lt;span&gt;(A;CIID;LC;;;RU)
&lt;&#x2F;span&gt;&lt;span&gt;(A;CIID;RPWPCRCCLCLORCWOWDSDSW;;;BA)
&lt;&#x2F;span&gt;&lt;span&gt;S:AI
&lt;&#x2F;span&gt;&lt;span&gt;(OU;CIIOIDSA;WP;f30e3bbe-9ff0-11d1-b603-0000f80367c1;bf967aa5-0de6-11d0-a285-00aa003049e2;WD)
&lt;&#x2F;span&gt;&lt;span&gt;(OU;CIIOIDSA;WP;f30e3bbf-9ff0-11d1-b603-0000f80367c1;bf967aa5-0de6-11d0-a285-00aa003049e2;WD)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This seems very confusing and complex (and someone should write a tool
to explain these ... maybe me). But once you can see the structure it
starts to make sense.&lt;&#x2F;p&gt;
&lt;p&gt;Most of the access controls you are viewing here are DACLs or
Discrestionary Access Control Lists. These make up the majority of the
output after &#x27;O:DAG:DAD:AI&#x27;. TODO: What does &#x27;O:DAG:DAD:AI&#x27; mean
completely?&lt;&#x2F;p&gt;
&lt;p&gt;After that there are many ACEs defined in SDDL or ???. The structure is
as follows:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;(type;flags;rights;object_guid;inherit_object_guid;sid(;attribute))
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Each of these fields can take varies types. These interact to form the
access control rules that allow or deny access. Thankfully, you don&#x27;t
need to adjust many fields to make useful ACE entries.&lt;&#x2F;p&gt;
&lt;p&gt;MS maintains a document of these &lt;a href=&quot;https:&#x2F;&#x2F;msdn.microsoft.com&#x2F;en-us&#x2F;library&#x2F;aa374928(d=printer,v=vs.85).aspx&quot;&gt;field values
here.&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;They also maintain a list of wellknown &lt;a href=&quot;https:&#x2F;&#x2F;msdn.microsoft.com&#x2F;en-us&#x2F;library&#x2F;aa379602(d=printer,v=vs.85).aspx&quot;&gt;SID values
here&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I want to cover some common values you may see though:&lt;&#x2F;p&gt;
&lt;h2 id=&quot;type&quot;&gt;type&lt;&#x2F;h2&gt;
&lt;p&gt;Most of the types you&#x27;ll see are &amp;quot;A&amp;quot; and &amp;quot;OA&amp;quot;. These mean the ACE
allows an access by the SID.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;flags&quot;&gt;flags&lt;&#x2F;h2&gt;
&lt;p&gt;These change the behaviour of the ACE. Common values you may want to set
are CI and OI. These determine that the ACE should be inherited to child
objects. As far as the MS docs say, these behave the same way.&lt;&#x2F;p&gt;
&lt;p&gt;If you see ID in this field it means the ACE has been inherited from a
parent object. In this case the inherit_object_guid field will be set to
the guid of the parent that set the ACE. This is great, as it allows you
to backtrace the origin of access controls!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;rights&quot;&gt;rights&lt;&#x2F;h2&gt;
&lt;p&gt;This is the important part of the ACE - it determines what access the
SID has over this object. The MS docs are very comprehensive of what
this does, but common values are:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;RP: read property&lt;&#x2F;li&gt;
&lt;li&gt;WP: write property&lt;&#x2F;li&gt;
&lt;li&gt;CR: control rights&lt;&#x2F;li&gt;
&lt;li&gt;CC: child create (create new objects)&lt;&#x2F;li&gt;
&lt;li&gt;DC: delete child&lt;&#x2F;li&gt;
&lt;li&gt;LC: list child objects&lt;&#x2F;li&gt;
&lt;li&gt;LO: list objects&lt;&#x2F;li&gt;
&lt;li&gt;RC: read control&lt;&#x2F;li&gt;
&lt;li&gt;WO: write owner (change the owner of an object)&lt;&#x2F;li&gt;
&lt;li&gt;WD: write dac (allow writing ACE)&lt;&#x2F;li&gt;
&lt;li&gt;SW: self write&lt;&#x2F;li&gt;
&lt;li&gt;SD: standard delete&lt;&#x2F;li&gt;
&lt;li&gt;DT: delete tree&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;I&#x27;m not 100% sure of all the subtle behaviours of these, because they
are &lt;em&gt;not&lt;&#x2F;em&gt; documented that well. If someone can help explain these to me,
it would be great.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;sid&quot;&gt;sid&lt;&#x2F;h2&gt;
&lt;p&gt;We will skip some fields and go straight to SID. This is the SID of the
object that is allowed the rights from the rights field. This field can
take a GUID of the object, or it can take a &amp;quot;well known&amp;quot; value of the
SID. For example &#x27;AN&#x27; means &amp;quot;anonymous users&amp;quot;, or &#x27;AU&#x27; meaning
authenticated users.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;conclusion&lt;&#x2F;h2&gt;
&lt;p&gt;I won&#x27;t claim to be an AD ACE expert, but I did find the docs hard to
interpret at first. Having a breakdown and explanation of the behaviour
of the fields can help others, and I really want to hear from people who
know more about this topic on me so that I can expand this resource to
help others really understand how AD ACE&#x27;s work.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Making Samba 4 the default LDAP server</title>
          <pubDate>Wed, 18 Apr 2018 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2018-04-18-making-samba-4-the-default-ldap-server/</link>
          <guid>https://fy.blackhats.net.au/blog/2018-04-18-making-samba-4-the-default-ldap-server/</guid>
          <description>&lt;h1 id=&quot;making-samba-4-the-default-ldap-server&quot;&gt;Making Samba 4 the default LDAP server&lt;&#x2F;h1&gt;
&lt;p&gt;Earlier this year Andrew Bartlett set me the challenge: how could we
make Samba 4 the default LDAP server in use for Linux and UNIX systems?
I&#x27;ve finally decided to tackle this, and write up some simple changes
we can make, and decide on some long term goals to make this a reality.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-makes-a-unix-directory-anyway&quot;&gt;What makes a unix directory anyway?&lt;&#x2F;h2&gt;
&lt;p&gt;Great question - this is such a broad topic, even I don&#x27;t know if I can
single out what it means. For the purposes of this exercise I&#x27;ll treat
it as &amp;quot;what would we need from my previous workplace&amp;quot;. My previous
workplace had a dedicated set of 389 Directory Server machines that
served lookups mainly for email routing, application authentication and
more. The didn&#x27;t really process a great deal of login traffic as the
majority of the workstations were Windows - thus connected to AD.&lt;&#x2F;p&gt;
&lt;p&gt;What it did show was that Linux clients and applications:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Want to use anonymous binds and searchs - Applications and clients
are NOT domain members - they just want to do searches&lt;&#x2F;li&gt;
&lt;li&gt;The content of anonymous lookups should be &amp;quot;public safe&amp;quot;
information. (IE nothing private)&lt;&#x2F;li&gt;
&lt;li&gt;LDAPS is a must for binds&lt;&#x2F;li&gt;
&lt;li&gt;MemberOf and group filtering is very important for access control&lt;&#x2F;li&gt;
&lt;li&gt;sshPublicKey and userCertificate;binary is important for 2fa&#x2F;secure
logins&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;This seems like a pretty simple list - but it&#x27;s not the model Samba 4
or AD ship with.&lt;&#x2F;p&gt;
&lt;p&gt;You&#x27;ll also want to harden a few default settings. These include:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Disable Guest&lt;&#x2F;li&gt;
&lt;li&gt;Disable 10 machine join policy&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;AD works under the assumption that all clients are authenticated via
kerberos, and that kerberos is the primary authentication and trust
provider. As a result, AD often ships with:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Disabled anonymous binds - All clients are domain members or service
accounts&lt;&#x2F;li&gt;
&lt;li&gt;No anonymous content available to search&lt;&#x2F;li&gt;
&lt;li&gt;No LDAPS (GSSAPI is used instead)&lt;&#x2F;li&gt;
&lt;li&gt;no sshPublicKey or userCertificates (pkinit instead via krb)&lt;&#x2F;li&gt;
&lt;li&gt;Access control is much more complex topic than just &amp;quot;matching an
ldap filter&amp;quot;.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;As a result, it takes a bit of effort to change Samba 4 to work in a way
that suits both, securely.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;isn-t-anonymous-binding-insecure&quot;&gt;Isn&#x27;t anonymous binding insecure?&lt;&#x2F;h2&gt;
&lt;p&gt;Let&#x27;s get this one out the way - no it&#x27;s not. In every pen test I have
seen if you can get access to a domain joined machine, you probably have
a good chance of taking over the domain in various ways. Domain joined
systems and krb allows lateral movement and other issues that are beyond
the scope of this document.&lt;&#x2F;p&gt;
&lt;p&gt;The lack of anonymous lookup is more about preventing information
disclosure - security via obscurity. But it doesn&#x27;t take long to
realise that this is trivially defeated (get one user account, guest
account, domain member and you can search ...).&lt;&#x2F;p&gt;
&lt;p&gt;As a result, in some cases it may be better to allow anonymous lookups
because then you don&#x27;t have spurious service accounts, you have a clear
understanding of what is and is not accessible as readable data, and you
&lt;em&gt;don&#x27;t&lt;&#x2F;em&gt; need every machine on the network to be domain joined - you
prevent a possible foothold of lateral movement.&lt;&#x2F;p&gt;
&lt;p&gt;So anonymous binding is just fine, as the unix world has shown for a
long time. That&#x27;s why I have very few concerns about enabling it. Your
safety is in the access controls for searches, not in blocking anonymous
reads outright.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;installing-your-dc&quot;&gt;Installing your DC&lt;&#x2F;h2&gt;
&lt;p&gt;As I run fedora, you will need to build and install samba for source so
you can access the heimdal kerberos functions. Fedora&#x27;s samba 4 ships
ADDC support now, but lacks some features like RODC that you may want.
In the future I expect this will change though.&lt;&#x2F;p&gt;
&lt;p&gt;These documents will help guide you:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;wiki.samba.org&#x2F;index.php&#x2F;Package_Dependencies_Required_to_Build_Samba#Fedora_26&quot;&gt;requirements&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;wiki.samba.org&#x2F;index.php&#x2F;Build_Samba_from_Source#Introduction&quot;&gt;build
steps&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;wiki.samba.org&#x2F;index.php&#x2F;Setting_up_Samba_as_an_Active_Directory_Domain_Controller&quot;&gt;install a
domain&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I strongly advise you use options similar to:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;usr&#x2F;local&#x2F;samba&#x2F;bin&#x2F;samba-tool domain provision --server-role=dc --use-rfc2307 --dns-backend=SAMBA_INTERNAL --realm=SAMDOM.EXAMPLE.COM --domain=SAMDOM --adminpass=Passw0rd
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;allow-anonymous-binds-and-searches&quot;&gt;Allow anonymous binds and searches&lt;&#x2F;h2&gt;
&lt;p&gt;Now that you have a working domain controller, we should test you have
working ldap:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;usr&#x2F;local&#x2F;samba&#x2F;bin&#x2F;samba-tool forest directory_service dsheuristics 0000002 -H ldaps:&#x2F;&#x2F;localhost --simple-bind-dn=&amp;#39;administrator@samdom.example.com&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;ldapsearch -b DC=samdom,DC=example,DC=com -H ldaps:&#x2F;&#x2F;localhost -x
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You can see the domain object but nothing else. Many other blogs and
sites recommend a blanket &amp;quot;anonymous read all&amp;quot; access control, but I
think that&#x27;s too broad. A better approach is to add the anonymous read
to only the few containers that require it.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;usr&#x2F;local&#x2F;samba&#x2F;bin&#x2F;samba-tool dsacl set --objectdn=DC=samdom,DC=example,DC=com --sddl=&amp;#39;(A;;RPLCLORC;;;AN)&amp;#39; --simple-bind-dn=&amp;quot;administrator@samdom.example.com&amp;quot; --password=Passw0rd
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;usr&#x2F;local&#x2F;samba&#x2F;bin&#x2F;samba-tool dsacl set --objectdn=CN=Users,DC=samdom,DC=example,DC=com --sddl=&amp;#39;(A;CI;RPLCLORC;;;AN)&amp;#39; --simple-bind-dn=&amp;quot;administrator@samdom.example.com&amp;quot; --password=Passw0rd
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;usr&#x2F;local&#x2F;samba&#x2F;bin&#x2F;samba-tool dsacl set --objectdn=CN=Builtin,DC=samdom,DC=example,DC=com --sddl=&amp;#39;(A;CI;RPLCLORC;;;AN)&amp;#39; --simple-bind-dn=&amp;quot;administrator@samdom.example.com&amp;quot; --password=Passw0rd
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;In AD groups and users are found in cn=users, and some groups are in
cn=builtin. So we allow read to the root domain object, then we set a
read on cn=users and cn=builtin that inherits to it&#x27;s child objects.
The attribute policies are derived elsewhere, so we can assume that
things like kerberos data and password material are safe with these
simple changes.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;configuring-ldaps&quot;&gt;Configuring LDAPS&lt;&#x2F;h2&gt;
&lt;p&gt;This is a reasonable simple exercise. Given a ca cert, key and cert we
can place these in the correct locations samba expects. By default this
is the private directory. In a custom install, that&#x27;s
&#x2F;usr&#x2F;local&#x2F;samba&#x2F;private&#x2F;tls&#x2F;, but for distros I think it&#x27;s
&#x2F;var&#x2F;lib&#x2F;samba&#x2F;private. Simply replace ca.pem, cert.pem and key.pem with
your files and restart.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;adding-schema&quot;&gt;Adding schema&lt;&#x2F;h2&gt;
&lt;p&gt;To allow adding schema to samba 4 you need to reconfigure the dsdb
config on the schema master. To show the current schema master you can
use:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;usr&#x2F;local&#x2F;samba&#x2F;bin&#x2F;samba-tool fsmo show -H ldaps:&#x2F;&#x2F;localhost --simple-bind-dn=&amp;#39;administrator@adt.blackhats.net.au&amp;#39; --password=Password1
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Look for the value:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;SchemaMasterRole owner: CN=NTDS Settings,CN=LDAPKDC,CN=Servers,CN=Default-First-Site-Name,CN=Sites,CN=Configuration,DC=adt,DC=blackhats,DC=net,DC=au
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;And note the CN=ldapkdc = that&#x27;s the hostname of the current schema
master.&lt;&#x2F;p&gt;
&lt;p&gt;On the schema master we need to adjust the smb.conf. The change you need
to make is:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;[global]
&lt;&#x2F;span&gt;&lt;span&gt;    dsdb:schema update allowed = yes
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now restart the instance and we can update the schema. The following
LDIF should work if you replace ${DOMAINDN} with your namingContext.
You can apply it with ldapmodify&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;dn: CN=sshPublicKey,CN=Schema,CN=Configuration,DC=adt,DC=blackhats,DC=net,DC=au
&lt;&#x2F;span&gt;&lt;span&gt;changetype: add
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: top
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: attributeSchema
&lt;&#x2F;span&gt;&lt;span&gt;attributeID: 1.3.6.1.4.1.24552.500.1.1.1.13
&lt;&#x2F;span&gt;&lt;span&gt;cn: sshPublicKey
&lt;&#x2F;span&gt;&lt;span&gt;name: sshPublicKey
&lt;&#x2F;span&gt;&lt;span&gt;lDAPDisplayName: sshPublicKey
&lt;&#x2F;span&gt;&lt;span&gt;description: MANDATORY: OpenSSH Public key
&lt;&#x2F;span&gt;&lt;span&gt;attributeSyntax: 2.5.5.10
&lt;&#x2F;span&gt;&lt;span&gt;oMSyntax: 4
&lt;&#x2F;span&gt;&lt;span&gt;isSingleValued: FALSE
&lt;&#x2F;span&gt;&lt;span&gt;searchFlags: 8
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;dn: CN=ldapPublicKey,CN=Schema,CN=Configuration,DC=adt,DC=blackhats,DC=net,DC=au
&lt;&#x2F;span&gt;&lt;span&gt;changetype: add
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: top
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: classSchema
&lt;&#x2F;span&gt;&lt;span&gt;governsID: 1.3.6.1.4.1.24552.500.1.1.2.0
&lt;&#x2F;span&gt;&lt;span&gt;cn: ldapPublicKey
&lt;&#x2F;span&gt;&lt;span&gt;name: ldapPublicKey
&lt;&#x2F;span&gt;&lt;span&gt;description: MANDATORY: OpenSSH LPK objectclass
&lt;&#x2F;span&gt;&lt;span&gt;lDAPDisplayName: ldapPublicKey
&lt;&#x2F;span&gt;&lt;span&gt;subClassOf: top
&lt;&#x2F;span&gt;&lt;span&gt;objectClassCategory: 3
&lt;&#x2F;span&gt;&lt;span&gt;defaultObjectCategory: CN=ldapPublicKey,CN=Schema,CN=Configuration,DC=adt,DC=blackhats,DC=net,DC=au
&lt;&#x2F;span&gt;&lt;span&gt;mayContain: sshPublicKey
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;dn: CN=User,CN=Schema,CN=Configuration,DC=adt,DC=blackhats,DC=net,DC=au
&lt;&#x2F;span&gt;&lt;span&gt;changetype: modify
&lt;&#x2F;span&gt;&lt;span&gt;replace: auxiliaryClass
&lt;&#x2F;span&gt;&lt;span&gt;auxiliaryClass: ldapPublicKey
&lt;&#x2F;span&gt;&lt;span&gt;auxiliaryClass: posixAccount
&lt;&#x2F;span&gt;&lt;span&gt;auxiliaryClass: shadowAccount
&lt;&#x2F;span&gt;&lt;span&gt;-
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;sudo ldapmodify -f sshpubkey.ldif -D &amp;#39;administrator@adt.blackhats.net.au&amp;#39; -w Password1 -H ldaps:&#x2F;&#x2F;localhost 
&lt;&#x2F;span&gt;&lt;span&gt;adding new entry &amp;quot;CN=sshPublicKey,CN=Schema,CN=Configuration,DC=adt,DC=blackhats,DC=net,DC=au&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;adding new entry &amp;quot;CN=ldapPublicKey,CN=Schema,CN=Configuration,DC=adt,DC=blackhats,DC=net,DC=au&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;modifying entry &amp;quot;CN=User,CN=Schema,CN=Configuration,DC=adt,DC=blackhats,DC=net,DC=au&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;To my surprise, userCertificate already exists! The reason I missed it
is a subtle ad schema behaviour I missed. The &lt;em&gt;ldap attribute&lt;&#x2F;em&gt; name is
stored in the lDAPDisplayName and may not be the same as the CN of the
schema element. As a result, you can find this with:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ldapsearch -H ldaps:&#x2F;&#x2F;localhost -b CN=Schema,CN=Configuration,DC=adt,DC=blackhats,DC=net,DC=au -x -D &amp;#39;administrator@adt.blackhats.net.au&amp;#39; -W &amp;#39;(attributeId=2.5.4.36)&amp;#39;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This doesn&#x27;t solve my issues: Because I am a long time user of 389-ds,
that means I need some ns compat attributes. Here I add the nsUniqueId
value so that I can keep some compatability.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;dn: CN=nsUniqueId,CN=Schema,CN=Configuration,DC=adt,DC=blackhats,DC=net,DC=au
&lt;&#x2F;span&gt;&lt;span&gt;changetype: add
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: top
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: attributeSchema
&lt;&#x2F;span&gt;&lt;span&gt;attributeID: 2.16.840.1.113730.3.1.542
&lt;&#x2F;span&gt;&lt;span&gt;cn: nsUniqueId
&lt;&#x2F;span&gt;&lt;span&gt;name: nsUniqueId
&lt;&#x2F;span&gt;&lt;span&gt;lDAPDisplayName: nsUniqueId
&lt;&#x2F;span&gt;&lt;span&gt;description: MANDATORY: nsUniqueId compatability
&lt;&#x2F;span&gt;&lt;span&gt;attributeSyntax: 2.5.5.10
&lt;&#x2F;span&gt;&lt;span&gt;oMSyntax: 4
&lt;&#x2F;span&gt;&lt;span&gt;isSingleValued: TRUE
&lt;&#x2F;span&gt;&lt;span&gt;searchFlags: 9
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;dn: CN=nsOrgPerson,CN=Schema,CN=Configuration,DC=adt,DC=blackhats,DC=net,DC=au
&lt;&#x2F;span&gt;&lt;span&gt;changetype: add
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: top
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: classSchema
&lt;&#x2F;span&gt;&lt;span&gt;governsID: 2.16.840.1.113730.3.2.334
&lt;&#x2F;span&gt;&lt;span&gt;cn: nsOrgPerson
&lt;&#x2F;span&gt;&lt;span&gt;name: nsOrgPerson
&lt;&#x2F;span&gt;&lt;span&gt;description: MANDATORY: Netscape DS compat person
&lt;&#x2F;span&gt;&lt;span&gt;lDAPDisplayName: nsOrgPerson
&lt;&#x2F;span&gt;&lt;span&gt;subClassOf: top
&lt;&#x2F;span&gt;&lt;span&gt;objectClassCategory: 3
&lt;&#x2F;span&gt;&lt;span&gt;defaultObjectCategory: CN=nsOrgPerson,CN=Schema,CN=Configuration,DC=adt,DC=blackhats,DC=net,DC=au
&lt;&#x2F;span&gt;&lt;span&gt;mayContain: nsUniqueId
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;dn: CN=User,CN=Schema,CN=Configuration,DC=adt,DC=blackhats,DC=net,DC=au
&lt;&#x2F;span&gt;&lt;span&gt;changetype: modify
&lt;&#x2F;span&gt;&lt;span&gt;replace: auxiliaryClass
&lt;&#x2F;span&gt;&lt;span&gt;auxiliaryClass: ldapPublicKey
&lt;&#x2F;span&gt;&lt;span&gt;auxiliaryClass: posixAccount
&lt;&#x2F;span&gt;&lt;span&gt;auxiliaryClass: shadowAccount
&lt;&#x2F;span&gt;&lt;span&gt;auxiliaryClass: nsOrgPerson
&lt;&#x2F;span&gt;&lt;span&gt;-
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now with this you can extend your users with the required data for SSH,
certificates and maybe 389-ds compatability.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;usr&#x2F;local&#x2F;samba&#x2F;bin&#x2F;samba-tool user edit william  -H ldaps:&#x2F;&#x2F;localhost --simple-bind-dn=&amp;#39;administrator@adt.blackhats.net.au&amp;#39;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;performance&quot;&gt;Performance&lt;&#x2F;h2&gt;
&lt;p&gt;Out of the box a number of the unix attributes are not indexed by Active
Directory. To fix this you need to update the search flags in the
schema.&lt;&#x2F;p&gt;
&lt;p&gt;Again, temporarily allow changes:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;[global]
&lt;&#x2F;span&gt;&lt;span&gt;    dsdb:schema update allowed = yes
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now we need to add some indexes for common types. Note that in the
nsUniqueId schema I already added the search flags. We also want to set
that these values should be preserved if they become tombstones so we
can recove them.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;usr&#x2F;local&#x2F;samba&#x2F;bin&#x2F;samba-tool schema attribute modify uid --searchflags=9
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;usr&#x2F;local&#x2F;samba&#x2F;bin&#x2F;samba-tool schema attribute modify nsUniqueId --searchflags=9
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;usr&#x2F;local&#x2F;samba&#x2F;bin&#x2F;samba-tool schema attribute modify uidnumber --searchflags=9
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;usr&#x2F;local&#x2F;samba&#x2F;bin&#x2F;samba-tool schema attribute modify gidnumber --searchflags=9
&lt;&#x2F;span&gt;&lt;span&gt;# Preserve on tombstone but don&amp;#39;t index
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;usr&#x2F;local&#x2F;samba&#x2F;bin&#x2F;samba-tool schema attribute modify x509-cert --searchflags=8
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;usr&#x2F;local&#x2F;samba&#x2F;bin&#x2F;samba-tool schema attribute modify sshPublicKey --searchflags=8
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;usr&#x2F;local&#x2F;samba&#x2F;bin&#x2F;samba-tool schema attribute modify gecos --searchflags=8
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;usr&#x2F;local&#x2F;samba&#x2F;bin&#x2F;samba-tool schema attribute modify loginShell --searchflags=8
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;usr&#x2F;local&#x2F;samba&#x2F;bin&#x2F;samba-tool schema attribute modify home-directory --searchflags=24
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;ad-hardening&quot;&gt;AD Hardening&lt;&#x2F;h2&gt;
&lt;p&gt;We want to harden a few default settings that could be considered
insecure. First, let&#x27;s stop &amp;quot;any user from being able to domain join
machines&amp;quot;.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;usr&#x2F;local&#x2F;samba&#x2F;bin&#x2F;samba-tool domain settings account_machine_join_quota 0 -H ldaps:&#x2F;&#x2F;localhost --simple-bind-dn=&amp;#39;administrator@adt.blackhats.net.au&amp;#39;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now let&#x27;s disable the Guest account&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;usr&#x2F;local&#x2F;samba&#x2F;bin&#x2F;samba-tool user disable Guest -H ldaps:&#x2F;&#x2F;localhost --simple-bind-dn=&amp;#39;administrator@adt.blackhats.net.au&amp;#39;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;I plan to write a more complete samba-tool extension for auditing these
and more options, so stay tuned!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;sssd-configuration&quot;&gt;SSSD configuration&lt;&#x2F;h2&gt;
&lt;p&gt;Now that our directory service is configured, we need to configure our
clients to utilise it correctly.&lt;&#x2F;p&gt;
&lt;p&gt;Here is my SSSD configuration, that supports sshPublicKey distribution,
userCertificate authentication on workstations and SID -&amp;gt; uid mapping.
In the future I want to explore sudo rules in LDAP with AD, and maybe
even HBAC rules rather than GPO.&lt;&#x2F;p&gt;
&lt;p&gt;Please refer to my other blog posts on configuration of the
userCertificates and sshKey distribution.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;[domain&#x2F;blackhats.net.au]
&lt;&#x2F;span&gt;&lt;span&gt;ignore_group_members = False
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;debug_level=3
&lt;&#x2F;span&gt;&lt;span&gt;# There is a bug in SSSD where this actually means &amp;quot;ipv6 only&amp;quot;.
&lt;&#x2F;span&gt;&lt;span&gt;# lookup_family_order=ipv6_first
&lt;&#x2F;span&gt;&lt;span&gt;cache_credentials = True
&lt;&#x2F;span&gt;&lt;span&gt;id_provider = ldap
&lt;&#x2F;span&gt;&lt;span&gt;auth_provider = ldap
&lt;&#x2F;span&gt;&lt;span&gt;access_provider = ldap
&lt;&#x2F;span&gt;&lt;span&gt;chpass_provider = ldap
&lt;&#x2F;span&gt;&lt;span&gt;ldap_search_base = dc=blackhats,dc=net,dc=au
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# This prevents an infinite referral loop.
&lt;&#x2F;span&gt;&lt;span&gt;ldap_referrals = False
&lt;&#x2F;span&gt;&lt;span&gt;ldap_id_mapping = True
&lt;&#x2F;span&gt;&lt;span&gt;ldap_schema = ad
&lt;&#x2F;span&gt;&lt;span&gt;# Rather that being in domain users group, create a user private group
&lt;&#x2F;span&gt;&lt;span&gt;# automatically on login.
&lt;&#x2F;span&gt;&lt;span&gt;# This is very important as a security setting on unix!!!
&lt;&#x2F;span&gt;&lt;span&gt;# See this bug if it doesn&amp;#39;t work correctly.
&lt;&#x2F;span&gt;&lt;span&gt;# https:&#x2F;&#x2F;pagure.io&#x2F;SSSD&#x2F;sssd&#x2F;issue&#x2F;3723
&lt;&#x2F;span&gt;&lt;span&gt;auto_private_groups = true
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;ldap_uri = ldaps:&#x2F;&#x2F;ad.blackhats.net.au
&lt;&#x2F;span&gt;&lt;span&gt;ldap_tls_reqcert = demand
&lt;&#x2F;span&gt;&lt;span&gt;ldap_tls_cacert = &#x2F;etc&#x2F;pki&#x2F;tls&#x2F;certs&#x2F;bh_ldap.crt
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Workstation access
&lt;&#x2F;span&gt;&lt;span&gt;ldap_access_filter = (memberOf=CN=Workstation Operators,CN=Users,DC=blackhats,DC=net,DC=au)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;ldap_user_member_of = memberof
&lt;&#x2F;span&gt;&lt;span&gt;ldap_user_gecos = cn
&lt;&#x2F;span&gt;&lt;span&gt;ldap_user_uuid = objectGUID
&lt;&#x2F;span&gt;&lt;span&gt;ldap_group_uuid = objectGUID
&lt;&#x2F;span&gt;&lt;span&gt;# This is really important as it allows SSSD to respect nsAccountLock
&lt;&#x2F;span&gt;&lt;span&gt;ldap_account_expire_policy = ad
&lt;&#x2F;span&gt;&lt;span&gt;ldap_access_order = filter, expire
&lt;&#x2F;span&gt;&lt;span&gt;# Setup for ssh keys
&lt;&#x2F;span&gt;&lt;span&gt;ldap_user_ssh_public_key = sshPublicKey
&lt;&#x2F;span&gt;&lt;span&gt;# This does not require ;binary tag with AD.
&lt;&#x2F;span&gt;&lt;span&gt;ldap_user_certificate = userCertificate
&lt;&#x2F;span&gt;&lt;span&gt;# This is required for the homeDirectory to be looked up in the sssd schema
&lt;&#x2F;span&gt;&lt;span&gt;ldap_user_home_directory = homeDirectory
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[sssd]
&lt;&#x2F;span&gt;&lt;span&gt;services = nss, pam, ssh, sudo
&lt;&#x2F;span&gt;&lt;span&gt;config_file_version = 2
&lt;&#x2F;span&gt;&lt;span&gt;certificate_verification = no_verification
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;domains = blackhats.net.au
&lt;&#x2F;span&gt;&lt;span&gt;[nss]
&lt;&#x2F;span&gt;&lt;span&gt;homedir_substring = &#x2F;home
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[pam]
&lt;&#x2F;span&gt;&lt;span&gt;pam_cert_auth = True
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[sudo]
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[autofs]
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[ssh]
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[pac]
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[ifp]
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;&#x2F;h2&gt;
&lt;p&gt;With these simple changes we can easily make samba 4 able to perform the
roles of other unix focused LDAP servers. This allows stateless clients,
secure ssh key authentication, certificate authentication and more.&lt;&#x2F;p&gt;
&lt;p&gt;Some future goals to improve this include:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Ship samba 4 with schema templates that can be used&lt;&#x2F;li&gt;
&lt;li&gt;Schema querying (what objectclass takes this attribute?)&lt;&#x2F;li&gt;
&lt;li&gt;Group editing (same as samba-tool user edit)&lt;&#x2F;li&gt;
&lt;li&gt;Security auditing tools&lt;&#x2F;li&gt;
&lt;li&gt;user&#x2F;group modification commands&lt;&#x2F;li&gt;
&lt;li&gt;Refactor and improve the cli tools python to be api driven - move
the logic from netcmd into samdb so that samdb can be an API that
python can consume easier. Prevent duplication of logic.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;The goal is so that an admin never has to see an LDIF ever again.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Smartcards and You - How To Make Them Work on Fedora&#x2F;RHEL</title>
          <pubDate>Tue, 27 Feb 2018 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2018-02-27-smartcards-and-you-how-to-make-them-work-on-fedora-rhel/</link>
          <guid>https://fy.blackhats.net.au/blog/2018-02-27-smartcards-and-you-how-to-make-them-work-on-fedora-rhel/</guid>
          <description>&lt;h1 id=&quot;smartcards-and-you-how-to-make-them-work-on-fedora-rhel&quot;&gt;Smartcards and You - How To Make Them Work on Fedora&#x2F;RHEL&lt;&#x2F;h1&gt;
&lt;p&gt;Smartcards are a great way to authenticate users. They have a device
(something you have) and a pin (something you know). They prevent
password transmission, use strong crypto and they even come in a variety
of formats. From your &amp;quot;card&amp;quot; shapes to yubikeys.&lt;&#x2F;p&gt;
&lt;p&gt;So why aren&#x27;t they used more? It&#x27;s the classic issue of usability -
the setup for them is undocumented, complex, and hard to discover. Today
I hope to change this.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-goal&quot;&gt;The Goal&lt;&#x2F;h2&gt;
&lt;p&gt;To authenticate a user with a smartcard to a physical linux system,
backed onto LDAP. The public cert in LDAP is validated, as is the chain
to the CA.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;you-will-need&quot;&gt;You Will Need&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;LDAP (&lt;a href=&quot;http:&#x2F;&#x2F;www.port389.org&#x2F;&quot;&gt;here is one I prepared earlier&lt;&#x2F;a&gt;)&lt;&#x2F;li&gt;
&lt;li&gt;One Linux - Fedora 27 or RHEL 7 work best&lt;&#x2F;li&gt;
&lt;li&gt;A smartcard (yubikey 4&#x2F;nano works)&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;I&#x27;ll be focusing on the yubikey because that&#x27;s what I own.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;preparing-the-smartcard&quot;&gt;Preparing the Smartcard&lt;&#x2F;h2&gt;
&lt;p&gt;First we need to make the smartcard hold our certificate. Because of a
crypto issue in yubikey firmware, it&#x27;s best to generate certificates
for these externally.&lt;&#x2F;p&gt;
&lt;p&gt;I&#x27;ve documented this before in another post, but for accesibility here
it is again.&lt;&#x2F;p&gt;
&lt;p&gt;Create an NSS DB, and generate a certificate signing request:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -d . -N -f pwdfile.txt
&lt;&#x2F;span&gt;&lt;span&gt;certutil -d . -R -a -o user.csr -f pwdfile.txt -g 4096 -Z SHA256 -v 24 \
&lt;&#x2F;span&gt;&lt;span&gt;--keyUsage digitalSignature,nonRepudiation,keyEncipherment,dataEncipherment --nsCertType sslClient --extKeyUsage clientAuth \
&lt;&#x2F;span&gt;&lt;span&gt;-s &amp;quot;CN=username,O=Testing,L=example,ST=Queensland,C=AU&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Once the request is signed, and your certificate is in &amp;quot;user.crt&amp;quot;,
import this to the database.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -A -d . -f pwdfile.txt -i user.crt -a -n TLS -t &amp;quot;,,&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;certutil -A -d . -f pwdfile.txt -i ca.crt -a -n TLS -t &amp;quot;CT,,&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now export that as a p12 bundle for the yubikey to import.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;pk12util -o user.p12 -d . -k pwdfile.txt -n TLS
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now import this to the yubikey - remember to use slot 9a this time! As
well make sure you set the touch policy NOW, because you can&#x27;t change
it later!&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;yubico-piv-tool -s9a -i user.p12 -K PKCS12 -aimport-key -aimport-certificate -k --touch-policy=always
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;setting-up-your-ldap-user&quot;&gt;Setting up your LDAP user&lt;&#x2F;h2&gt;
&lt;p&gt;First setup your system to work with LDAP via SSSD. You&#x27;ve done that?
Good! Now it&#x27;s time to get our user ready.&lt;&#x2F;p&gt;
&lt;p&gt;Take our user.crt and convert it to DER:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;openssl x509 -inform PEM -outform DER -in user.crt -out user.der
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now you need to transform that into something that LDAP can understand.
In the future I&#x27;ll be adding a tool to 389-ds to make this
&amp;quot;automatic&amp;quot;, but for now you can use python:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;python3
&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;&amp;gt;&amp;gt; import base64
&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;&amp;gt;&amp;gt; with open(&amp;#39;user.der&amp;#39;, &amp;#39;r&amp;#39;) as f:
&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;&amp;gt;&amp;gt;    print(base64.b64encode(f.read))
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;That should output a long base64 string on one line. Add this to your
ldap user with ldapvi:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;uid=william,ou=People,dc=...
&lt;&#x2F;span&gt;&lt;span&gt;userCertificate;binary:: &amp;lt;BASE64&amp;gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Note that &#x27;;binary&#x27; tag has an important meaning here for certificate
data, and the &#x27;::&#x27; tells ldap that this is b64 encoded, so it will
decode on addition.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;setting-up-the-system&quot;&gt;Setting up the system&lt;&#x2F;h2&gt;
&lt;p&gt;Now that you have done that, you need to teach SSSD how to intepret that
attribute.&lt;&#x2F;p&gt;
&lt;p&gt;In your various SSSD sections you&#x27;ll need to make the following
changes:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;[domain&#x2F;LDAP]
&lt;&#x2F;span&gt;&lt;span&gt;auth_provider = ldap
&lt;&#x2F;span&gt;&lt;span&gt;ldap_user_certificate = userCertificate;binary
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[sssd]
&lt;&#x2F;span&gt;&lt;span&gt;# This controls OCSP checks, you probably want this enabled!
&lt;&#x2F;span&gt;&lt;span&gt;# certificate_verification = no_verification
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[pam]
&lt;&#x2F;span&gt;&lt;span&gt;pam_cert_auth = True
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now the TRICK is letting SSSD know to use certificates. You need to run:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;sudo touch &#x2F;var&#x2F;lib&#x2F;sss&#x2F;pubconf&#x2F;pam_preauth_available
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;With out this, SSSD won&#x27;t even try to process CCID authentication!&lt;&#x2F;p&gt;
&lt;p&gt;Add your ca.crt to the system trusted CA store for SSSD to verify:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -A -d &#x2F;etc&#x2F;pki&#x2F;nssdb -i ca.crt -n USER_CA -t &amp;quot;CT,,&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Add coolkey to the database so it can find smartcards:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;modutil -dbdir &#x2F;etc&#x2F;pki&#x2F;nssdb -add &amp;quot;coolkey&amp;quot; -libfile &#x2F;usr&#x2F;lib64&#x2F;libcoolkeypk11.so
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Check that SSSD can find the certs now:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# sudo &#x2F;usr&#x2F;libexec&#x2F;sssd&#x2F;p11_child --pre --nssdb=&#x2F;etc&#x2F;pki&#x2F;nssdb
&lt;&#x2F;span&gt;&lt;span&gt;PIN for william
&lt;&#x2F;span&gt;&lt;span&gt;william
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;usr&#x2F;lib64&#x2F;libcoolkeypk11.so
&lt;&#x2F;span&gt;&lt;span&gt;0001
&lt;&#x2F;span&gt;&lt;span&gt;CAC ID Certificate
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If you get no output here you are missing something! If this doesn&#x27;t
work, nothing will!&lt;&#x2F;p&gt;
&lt;p&gt;Finally, you need to tweak PAM to make sure that pam_unix isn&#x27;t getting
in the way. I use the following configuration.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;auth        required      pam_env.so
&lt;&#x2F;span&gt;&lt;span&gt;# This skips pam_unix if the given uid is not local (IE it&amp;#39;s from SSSD)
&lt;&#x2F;span&gt;&lt;span&gt;auth        [default=1 ignore=ignore success=ok] pam_localuser.so
&lt;&#x2F;span&gt;&lt;span&gt;auth        sufficient    pam_unix.so nullok try_first_pass
&lt;&#x2F;span&gt;&lt;span&gt;auth        requisite     pam_succeed_if.so uid &amp;gt;= 1000 quiet_success
&lt;&#x2F;span&gt;&lt;span&gt;auth        sufficient    pam_sss.so prompt_always ignore_unknown_user
&lt;&#x2F;span&gt;&lt;span&gt;auth        required      pam_deny.so
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;account     required      pam_unix.so
&lt;&#x2F;span&gt;&lt;span&gt;account     sufficient    pam_localuser.so
&lt;&#x2F;span&gt;&lt;span&gt;account     sufficient    pam_succeed_if.so uid &amp;lt; 1000 quiet
&lt;&#x2F;span&gt;&lt;span&gt;account     [default=bad success=ok user_unknown=ignore] pam_sss.so
&lt;&#x2F;span&gt;&lt;span&gt;account     required      pam_permit.so
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;password    requisite     pam_pwquality.so try_first_pass local_users_only retry=3 authtok_type=
&lt;&#x2F;span&gt;&lt;span&gt;password    sufficient    pam_unix.so sha512 shadow try_first_pass use_authtok
&lt;&#x2F;span&gt;&lt;span&gt;password    sufficient    pam_sss.so use_authtok
&lt;&#x2F;span&gt;&lt;span&gt;password    required      pam_deny.so
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;session     optional      pam_keyinit.so revoke
&lt;&#x2F;span&gt;&lt;span&gt;session     required      pam_limits.so
&lt;&#x2F;span&gt;&lt;span&gt;-session    optional      pam_systemd.so
&lt;&#x2F;span&gt;&lt;span&gt;session     [success=1 default=ignore] pam_succeed_if.so service in crond quiet use_uid
&lt;&#x2F;span&gt;&lt;span&gt;session     required      pam_unix.so
&lt;&#x2F;span&gt;&lt;span&gt;session     optional      pam_sss.so
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;That&#x27;s it! Restart SSSD, and you should be good to go.&lt;&#x2F;p&gt;
&lt;p&gt;Finally, you may find SELinux isn&#x27;t allowing authentication. This is
really sad that smartcards don&#x27;t work with SELinux out of the box and I
have raised a number of bugs, but check this just in case.&lt;&#x2F;p&gt;
&lt;p&gt;Happy authentication!&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Using b43 firmware on Fedora Atomic Workstation</title>
          <pubDate>Sat, 23 Dec 2017 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2017-12-23-using-b43-firmware-on-fedora-atomic-workstation/</link>
          <guid>https://fy.blackhats.net.au/blog/2017-12-23-using-b43-firmware-on-fedora-atomic-workstation/</guid>
          <description>&lt;h1 id=&quot;using-b43-firmware-on-fedora-atomic-workstation&quot;&gt;Using b43 firmware on Fedora Atomic Workstation&lt;&#x2F;h1&gt;
&lt;p&gt;My Macbook Pro has a broadcom b43 wireless chipset. This is notorious
for being one of the most annoying wireless adapters on linux. When you
first install Fedora you don&#x27;t even see &amp;quot;wifi&amp;quot; as an option, and unless
you poke around in dmesg, you won&#x27;t find how to enable b43 to work on
your platform.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;b43&quot;&gt;b43&lt;&#x2F;h2&gt;
&lt;p&gt;The b43 driver requires proprietary firmware to be loaded else the wifi
chip will not run. There are a number of steps for this process found on
the linux wireless page . You&#x27;ll note that one of the steps is:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;export FIRMWARE_INSTALL_DIR=&amp;quot;&#x2F;lib&#x2F;firmware&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;span&gt;sudo b43-fwcutter -w &amp;quot;$FIRMWARE_INSTALL_DIR&amp;quot; broadcom-wl-5.100.138&#x2F;linux&#x2F;wl_apsta.o
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;So we need to be able to write and extract our firmware to
&#x2F;usr&#x2F;lib&#x2F;firmware, and then reboot and out wifi works.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;fedora-atomic-workstation&quot;&gt;Fedora Atomic Workstation&lt;&#x2F;h2&gt;
&lt;p&gt;Atomic WS is similar to atomic server, that it&#x27;s a read-only ostree
based deployment of fedora. This comes with a number of unique
challenges and quirks but for this issue:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;sudo touch &#x2F;usr&#x2F;lib&#x2F;firmware&#x2F;test
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;bin&#x2F;touch: cannot touch &amp;#39;&#x2F;usr&#x2F;lib&#x2F;firmware&#x2F;test&amp;#39;: Read-only file system
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;So we can&#x27;t extract our firmware!&lt;&#x2F;p&gt;
&lt;p&gt;Normally linux also supports reading from &#x2F;usr&#x2F;local&#x2F;lib&#x2F;firmware (which
on atomic IS writeable ...) but for some reason fedora doesn&#x27;t allow
this path.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;solution-layered-rpms&quot;&gt;Solution: Layered RPMs&lt;&#x2F;h2&gt;
&lt;p&gt;Atomic has support for &amp;quot;rpm layering&amp;quot;. Ontop of the ostree image (which
is composed of rpms) you can supply a supplemental list of packages that
are &amp;quot;installed&amp;quot; at rpm-ostree update time.&lt;&#x2F;p&gt;
&lt;p&gt;This way you still have an atomic base platform, with read-only
behaviours, but you gain the ability to customise your system. To achive
it, it must be possible to write to locations in &#x2F;usr during rpm
install.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;new-method-install-rpmfusion-tainted&quot;&gt;New method - install rpmfusion tainted&lt;&#x2F;h2&gt;
&lt;p&gt;As I have now learnt, the b43 data is provided as part of rpmfusion
nonfree. To enable this, you need to access the tainted repo. I a file
such as &amp;quot;&#x2F;etc&#x2F;yum.repos.d&#x2F;rpmfusion-nonfree-tainted.repo&amp;quot; add the
content:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;[rpmfusion-nonfree-tainted]
&lt;&#x2F;span&gt;&lt;span&gt;name=rpmfusion-nonfree-tainted
&lt;&#x2F;span&gt;&lt;span&gt;baseurl=https:&#x2F;&#x2F;download1.rpmfusion.org&#x2F;nonfree&#x2F;fedora&#x2F;tainted&#x2F;$releasever&#x2F;$basearch&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;enabled=1
&lt;&#x2F;span&gt;&lt;span&gt;gpgcheck=1
&lt;&#x2F;span&gt;&lt;span&gt;type=rpm
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now, you should be able to run:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;atomic host install b43-firmware
&lt;&#x2F;span&gt;&lt;span&gt;reboot
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You should have a working wifi chipset!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;custom-rpm-old-method&quot;&gt;Custom RPM - old method&lt;&#x2F;h2&gt;
&lt;p&gt;This means our problem has a simple solution: Create a b43 rpm package.
Note, that you can make this for yourself privately, but you can&#x27;t
distribute it for legal reasons.&lt;&#x2F;p&gt;
&lt;p&gt;Get setup on atomic to build the packages:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;rpm-ostree install rpm-build createrepo
&lt;&#x2F;span&gt;&lt;span&gt;reboot
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;RPM specfile:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;%define debug_package %{nil}
&lt;&#x2F;span&gt;&lt;span&gt;Summary: Allow b43 fw to install on ostree installs due to bz1512452
&lt;&#x2F;span&gt;&lt;span&gt;Name: b43-fw
&lt;&#x2F;span&gt;&lt;span&gt;Version: 1.0.0
&lt;&#x2F;span&gt;&lt;span&gt;Release: 1
&lt;&#x2F;span&gt;&lt;span&gt;License: Proprietary, DO NOT DISTRIBUTE BINARY FORMS
&lt;&#x2F;span&gt;&lt;span&gt;URL: http:&#x2F;&#x2F;linuxwireless.sipsolutions.net&#x2F;en&#x2F;users&#x2F;Drivers&#x2F;b43&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;Group: System Environment&#x2F;Kernel
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;BuildRequires: b43-fwcutter
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Source0: http:&#x2F;&#x2F;www.lwfinger.com&#x2F;b43-firmware&#x2F;broadcom-wl-5.100.138.tar.bz2
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;%description
&lt;&#x2F;span&gt;&lt;span&gt;Broadcom firmware for b43 chips.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;%prep
&lt;&#x2F;span&gt;&lt;span&gt;%setup -q -n broadcom-wl-5.100.138
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;%build
&lt;&#x2F;span&gt;&lt;span&gt;true
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;%install
&lt;&#x2F;span&gt;&lt;span&gt;pwd
&lt;&#x2F;span&gt;&lt;span&gt;mkdir -p %{buildroot}&#x2F;usr&#x2F;lib&#x2F;firmware
&lt;&#x2F;span&gt;&lt;span&gt;b43-fwcutter -w %{buildroot}&#x2F;usr&#x2F;lib&#x2F;firmware linux&#x2F;wl_apsta.o
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;%files
&lt;&#x2F;span&gt;&lt;span&gt;%defattr(-,root,root,-)
&lt;&#x2F;span&gt;&lt;span&gt;%dir %{_prefix}&#x2F;lib&#x2F;firmware&#x2F;b43
&lt;&#x2F;span&gt;&lt;span&gt;%{_prefix}&#x2F;lib&#x2F;firmware&#x2F;b43&#x2F;*
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;%changelog
&lt;&#x2F;span&gt;&lt;span&gt;* Fri Dec 22 2017 William Brown &amp;lt;william at blackhats.net.au&amp;gt; - 1.0.0
&lt;&#x2F;span&gt;&lt;span&gt;- Initial version
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now you can put this into a folder like so:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;mkdir -p ~&#x2F;rpmbuild&#x2F;{SPECS,SOURCES}
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;editor&amp;gt; ~&#x2F;rpmbuild&#x2F;SPECS&#x2F;b43-fw.spec
&lt;&#x2F;span&gt;&lt;span&gt;wget -O ~&#x2F;rpmbuild&#x2F;SOURCES&#x2F;broadcom-wl-5.100.138.tar.bz2 http:&#x2F;&#x2F;www.lwfinger.com&#x2F;b43-firmware&#x2F;broadcom-wl-5.100.138.tar.bz2
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;We are now ready to build!&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;rpmbuild -bb ~&#x2F;rpmbuild&#x2F;SPECS&#x2F;b43-fw.spec
&lt;&#x2F;span&gt;&lt;span&gt;createrepo ~&#x2F;rpmbuild&#x2F;RPMS&#x2F;x86_64&#x2F;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Finally, we can install this. Create a yum repos file:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;[local-rpms]
&lt;&#x2F;span&gt;&lt;span&gt;name=local-rpms
&lt;&#x2F;span&gt;&lt;span&gt;baseurl=file:&#x2F;&#x2F;&#x2F;home&#x2F;&amp;lt;YOUR USERNAME HERE&amp;gt;&#x2F;rpmbuild&#x2F;RPMS&#x2F;x86_64
&lt;&#x2F;span&gt;&lt;span&gt;enabled=1
&lt;&#x2F;span&gt;&lt;span&gt;gpgcheck=0
&lt;&#x2F;span&gt;&lt;span&gt;type=rpm
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;rpm-ostree install b43-fw
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now reboot and enjoy wifi on your Fedora Atomic Macbook Pro!&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Creating yubikey SSH and TLS certificates</title>
          <pubDate>Sat, 11 Nov 2017 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2017-11-11-creating-yubikey-ssh-and-tls-certificates/</link>
          <guid>https://fy.blackhats.net.au/blog/2017-11-11-creating-yubikey-ssh-and-tls-certificates/</guid>
          <description>&lt;h1 id=&quot;creating-yubikey-ssh-and-tls-certificates&quot;&gt;Creating yubikey SSH and TLS certificates&lt;&#x2F;h1&gt;
&lt;p&gt;Recently yubikeys were shown to have a hardware flaw in the way the
generated private keys. This affects the use of them to provide PIV
identies or SSH keys.&lt;&#x2F;p&gt;
&lt;p&gt;However, you can generate the keys externally, and load them to the key
to prevent this issue.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;ssh&quot;&gt;SSH&lt;&#x2F;h2&gt;
&lt;p&gt;First, we&#x27;ll create a new NSS DB on an airgapped secure machine (with
disk encryption or in memory storage!)&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -N -d . -f pwdfile.txt
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now into this, we&#x27;ll create a self-signed cert valid for 10 years.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -S -f pwdfile.txt -d . -t &amp;quot;C,,&amp;quot; -x -n &amp;quot;SSH&amp;quot; -g 2048 -s &amp;quot;cn=william,O=ssh,L=Brisbane,ST=Queensland,C=AU&amp;quot; -v 120
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;We export this now to PKCS12 for our key to import.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;pk12util -o ssh.p12 -d . -k pwdfile.txt -n SSH
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Next we import the key and cert to the hardware in slot 9c&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;yubico-piv-tool -s9c -i ssh.p12 -K PKCS12 -aimport-key -aimport-certificate -k
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Finally, we can display the ssh-key from the token.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ssh-keygen -D &#x2F;usr&#x2F;lib64&#x2F;opensc-pkcs11.so -e
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Note, we can make this always used by ssh client by adding the following
into .ssh&#x2F;config:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;PKCS11Provider &#x2F;usr&#x2F;lib64&#x2F;opensc-pkcs11.so
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;tls-identities&quot;&gt;TLS Identities&lt;&#x2F;h2&gt;
&lt;p&gt;The process is almost identical for user certificates.&lt;&#x2F;p&gt;
&lt;p&gt;First, create the request:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -d . -R -a -o user.csr -f pwdfile.txt -g 4096 -Z SHA256 -v 24 \
&lt;&#x2F;span&gt;&lt;span&gt;--keyUsage digitalSignature,nonRepudiation,keyEncipherment,dataEncipherment --nsCertType sslClient --extKeyUsage clientAuth \
&lt;&#x2F;span&gt;&lt;span&gt;-s &amp;quot;CN=username,O=Testing,L=example,ST=Queensland,C=AU&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Once the request is signed, we should have a user.crt back. Import that
to our database:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -A -d . -f pwdfile.txt -i user.crt -a -n TLS -t &amp;quot;,,&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Import our CA certificate also. Next export this to p12:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;pk12util -o user.p12 -d . -k pwdfile.txt -n TLS
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now import this to the yubikey - remember to use slot 9a this time!&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;yubico-piv-tool -s9a -i user.p12 -K PKCS12 -aimport-key -aimport-certificate -k --touch-policy=always
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Done!&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>What&#x27;s the problem with NUMA anyway?</title>
          <pubDate>Tue, 07 Nov 2017 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2017-11-07-what-s-the-problem-with-numa-anyway/</link>
          <guid>https://fy.blackhats.net.au/blog/2017-11-07-what-s-the-problem-with-numa-anyway/</guid>
          <description>&lt;h1 id=&quot;what-s-the-problem-with-numa-anyway&quot;&gt;What&#x27;s the problem with NUMA anyway?&lt;&#x2F;h1&gt;
&lt;h2 id=&quot;what-is-numa&quot;&gt;What is NUMA?&lt;&#x2F;h2&gt;
&lt;p&gt;Non-Uniform Memory Architecture is a method of seperating ram and memory
management units to be associated with CPU sockets. The reason for this
is performance - if multiple sockets shared a MMU, they will cause each
other to block, delaying your CPU.&lt;&#x2F;p&gt;
&lt;p&gt;To improve this, each NUMA region has it&#x27;s own MMU and RAM associated.
If a CPU can access it&#x27;s local MMU and RAM, this is very fast, and does
&lt;em&gt;not&lt;&#x2F;em&gt; prevent another CPU from accessing it&#x27;s own. For example:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;CPU 0   &amp;lt;-- QPI --&amp;gt; CPU 1
&lt;&#x2F;span&gt;&lt;span&gt;  |                   |
&lt;&#x2F;span&gt;&lt;span&gt;  v                   v
&lt;&#x2F;span&gt;&lt;span&gt;MMU 0               MMU 1
&lt;&#x2F;span&gt;&lt;span&gt;  |                   |
&lt;&#x2F;span&gt;&lt;span&gt;  v                   v
&lt;&#x2F;span&gt;&lt;span&gt;RAM 1               RAM 2
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;For example, on the following system, we can see 1 numa region:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# numactl --hardware
&lt;&#x2F;span&gt;&lt;span&gt;available: 1 nodes (0)
&lt;&#x2F;span&gt;&lt;span&gt;node 0 cpus: 0 1 2 3
&lt;&#x2F;span&gt;&lt;span&gt;node 0 size: 12188 MB
&lt;&#x2F;span&gt;&lt;span&gt;node 0 free: 458 MB
&lt;&#x2F;span&gt;&lt;span&gt;node distances:
&lt;&#x2F;span&gt;&lt;span&gt;node   0 
&lt;&#x2F;span&gt;&lt;span&gt;  0:  10 
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;On this system, we can see two:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# numactl --hardware
&lt;&#x2F;span&gt;&lt;span&gt;available: 2 nodes (0-1)
&lt;&#x2F;span&gt;&lt;span&gt;node 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11 24 25 26 27 28 29 30 31 32 33 34 35
&lt;&#x2F;span&gt;&lt;span&gt;node 0 size: 32733 MB
&lt;&#x2F;span&gt;&lt;span&gt;node 0 free: 245 MB
&lt;&#x2F;span&gt;&lt;span&gt;node 1 cpus: 12 13 14 15 16 17 18 19 20 21 22 23 36 37 38 39 40 41 42 43 44 45 46 47
&lt;&#x2F;span&gt;&lt;span&gt;node 1 size: 32767 MB
&lt;&#x2F;span&gt;&lt;span&gt;node 1 free: 22793 MB
&lt;&#x2F;span&gt;&lt;span&gt;node distances:
&lt;&#x2F;span&gt;&lt;span&gt;node   0   1
&lt;&#x2F;span&gt;&lt;span&gt;  0:  10  20
&lt;&#x2F;span&gt;&lt;span&gt;  1:  20  10
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This means that on the second system there is 32GB of ram per NUMA
region which is accessible, but the system has total 64GB.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-problem&quot;&gt;The problem&lt;&#x2F;h2&gt;
&lt;p&gt;The problem arises when a process running on NUMA region 0 has to access
memory from another NUMA region. Because there is no direct connection
between CPU 0 and RAM 1, we must communicate with our neighbour CPU 1 to
do this for us. IE:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;CPU 0 --&amp;gt; CPU 1 --&amp;gt; MMU 1 --&amp;gt; RAM 1
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Not only do we pay a time delay price for the QPI communication between
CPU 0 and CPU 1, but now CPU 1&#x27;s processes are waiting on the MMU 1
because we are retrieving memory on behalf of CPU 0. This is very slow
(and can be seen by the node distances in the numactl --hardware
output).&lt;&#x2F;p&gt;
&lt;h2 id=&quot;today-s-work-around&quot;&gt;Today&#x27;s work around&lt;&#x2F;h2&gt;
&lt;p&gt;The work around today is to limit your Directory Server instance to a
single NUMA region. So for our example above, we would limit the
instance to NUMA region 0 or 1, and treat the instance as though it only
has access to 32GB of local memory.&lt;&#x2F;p&gt;
&lt;p&gt;It&#x27;s possible to run two instances of DS on a single server, pinning
them to their own regions and using replication between them to provide
synchronisation. You&#x27;ll need a load balancer to fix up the TCP port
changes, or you need multiple addresses on the system for listening.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-future&quot;&gt;The future&lt;&#x2F;h2&gt;
&lt;p&gt;In the future, we&#x27;ll be adding support for better copy-on-write
techniques that allow the cores to better cache content after a QPI
negotiation - but we still have to pay the transit cost. We can minimise
this as much as possible, but there is no way today to avoid this
penalty. To use all your hardware on a single instance, there will
always be a NUMA cost somewhere.&lt;&#x2F;p&gt;
&lt;p&gt;The best solution is as above: run an instance per NUMA region, and
internally provide replication for them. Perhaps we&#x27;ll support an
automatic configuration of this in the future.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>GSoC 2017 - Mentor Report from 389 Project</title>
          <pubDate>Thu, 24 Aug 2017 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2017-08-24-gsoc-2017-mentor-report-from-389-project/</link>
          <guid>https://fy.blackhats.net.au/blog/2017-08-24-gsoc-2017-mentor-report-from-389-project/</guid>
          <description>&lt;h1 id=&quot;gsoc-2017-mentor-report-from-389-project&quot;&gt;GSoC 2017 - Mentor Report from 389 Project&lt;&#x2F;h1&gt;
&lt;p&gt;This year I have had the pleasure of being a mentor for the Google
Summer of Code program, as part of the Fedora Project organisation. I
was representing the &lt;a href=&quot;http:&#x2F;&#x2F;www.port389.org&#x2F;&quot;&gt;389 Directory Server
Project&lt;&#x2F;a&gt; and offered students the oppurtunity
to &lt;a href=&quot;https:&#x2F;&#x2F;fedoraproject.org&#x2F;wiki&#x2F;Summer_coding_ideas_for_2017#389_Directory_Server:_developing_administrative_tools&quot;&gt;work on our command line
tools&lt;&#x2F;a&gt;
written in python.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;applications&quot;&gt;Applications&lt;&#x2F;h2&gt;
&lt;p&gt;From the start we have a large number of really talented students apply
to the project. This was one of the hardest parts of the process was to
choose a student, given that I wanted to mentor all of them. Sadly I
only have so many hours in the day, so we chose Ilias, a student from
Greece. What really stood out was his interest in learning about the
project, and his desire to really be part of the community after the
project concluded.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-project&quot;&gt;The project&lt;&#x2F;h2&gt;
&lt;p&gt;The project was very deliberately &amp;quot;loose&amp;quot; in it&#x27;s specification.
Rather than giving Ilias a fixed goal of you will implement X, Y and Z,
I chose to set a &amp;quot;broad and vague&amp;quot; task. Initially I asked him to
investigate a single area of the code (the MemberOf plugin). As he
investigated this, he started to learn more about the server, ask
questions, and open doors for himself to the next tasks of the project.
As these smaller questions and self discoveries stacked up, I found
myself watching Ilias start to become a really complete developer, who
could be called a true part of our community.&lt;&#x2F;p&gt;
&lt;p&gt;Ilias&#x27; work was exceptional, and he has documented it in his &lt;a href=&quot;https:&#x2F;&#x2F;iliaswrites.wordpress.com&#x2F;2017&#x2F;08&#x2F;23&#x2F;final-gsoc-2017-report&#x2F;&quot;&gt;final
report
here&lt;&#x2F;a&gt;
.&lt;&#x2F;p&gt;
&lt;p&gt;Since his work is complete, he is now free to work on any task that
takes his interest, and he has picked a good one! He has now started to
dive deep into the server internals, looking at part of our backend
internals and how we dump databases from id2entry to various output
formats.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-next&quot;&gt;What next?&lt;&#x2F;h2&gt;
&lt;p&gt;I will be participating next year - Sadly, I think the python project
oppurtunities may be more limited as we have to finish many of these
tasks to release our new CLI toolset. This is almost a shame as the
python components are a great place to start as they ease a new
contributor into the broader concepts of LDAP and the project structure
as a whole.&lt;&#x2F;p&gt;
&lt;p&gt;Next year I really want to give this oppurtunity to an under-represented
group in tech (female, poc, etc). I personally have been really inspired
by Noriko and I hope to have the oppurtunity to pass on her lessons to
another aspiring student. We need more engineers like her in the world,
and I want to help create that future.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;advice-for-future-mentors&quot;&gt;Advice for future mentors&lt;&#x2F;h2&gt;
&lt;p&gt;Mentoring is not for everyone. It&#x27;s not a task which you can just send
a couple of emails and be done every day.&lt;&#x2F;p&gt;
&lt;p&gt;Mentoring is a process that requires engagement with the student, and
communication and the relationship is key to this. What worked well was
meeting early in the project, and working out what community worked best
for us. We found that email questions and responses worked (given we are
on nearly opposite sides of the Earth) worked well, along with irc
conversations to help fix up any other questions. It would not be
uncommon for me to spend at least 1 or 2 hours a day working through
emails from Ilias and discussions on IRC.&lt;&#x2F;p&gt;
&lt;p&gt;A really important aspect of this communication is how you do it. You
have to balance positive communication and encouragement, along with
critcism that is constructive and helpful. Empathy is a super important
part of this equation.&lt;&#x2F;p&gt;
&lt;p&gt;My number one piece of advice would be that you need to create an
environment where questions are encouraged and welcome. You can never be
dismissive of questions. If ever you dismiss a question as &amp;quot;silly&amp;quot; or
&amp;quot;dumb&amp;quot;, you will hinder a student from wanting to ask more questions.
If you can&#x27;t answer the question immediately, send a response saying
&amp;quot;hey I know this is important, but I&#x27;m really busy, I&#x27;ll answer you
as soon as I can&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;Over time you can use these questions to help teach lessons for the
student to make their own discoveries. For example, when Ilias would ask
how something worked, I would send my response structured in the way I
approached the problem. I would send back links to code, my thoughts,
and how I arrived at the conclusion. This not only answered the question
but gave a subtle lesson in how to research our codebase to arrive at
your own solutions. After a few of these emails, I&#x27;m sure that Ilias
has now become self sufficent in his research of the code base.&lt;&#x2F;p&gt;
&lt;p&gt;Another valuable skill is that overtime you can help to build confidence
through these questions. To start with Ilias would ask &amp;quot;how to
implement&amp;quot; something, and I would answer. Over time, he would start to
provide ideas on how to implement a solution, and I would say &amp;quot;X is the
right one&amp;quot;. As time went on I started to answer his question with
&amp;quot;What do you think is the right solution and why?&amp;quot;. These exchanges
and justifications have (I hope) helped him to become more confident in
his ideas, the presentation of them, and justification of his solutions.
It&#x27;s led to this &lt;a href=&quot;https:&#x2F;&#x2F;lists.fedoraproject.org&#x2F;archives&#x2F;list&#x2F;389-devel@lists.fedoraproject.org&#x2F;thread&#x2F;5VDPWUZ3E67UMEWVCATU6LEIQ5QGBGEM&#x2F;&quot;&gt;excellent
exchange&lt;&#x2F;a&gt;
on our mailing lists, where Ilias is discussing the solutions to a
problem with the broader community, and working to a really great
answer.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;final-thoughts&quot;&gt;Final thoughts&lt;&#x2F;h2&gt;
&lt;p&gt;This has been a great experience for myself and Ilias, and I really look
forward to helping another student next year. I&#x27;m sure that Ilias will
go on to do great things, and I&#x27;m happy to have been part of his
journey.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>So you want to script gdb with python ...</title>
          <pubDate>Fri, 04 Aug 2017 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2017-08-04-so-you-want-to-script-gdb-with-python/</link>
          <guid>https://fy.blackhats.net.au/blog/2017-08-04-so-you-want-to-script-gdb-with-python/</guid>
          <description>&lt;h1 id=&quot;so-you-want-to-script-gdb-with-python&quot;&gt;So you want to script gdb with python ...&lt;&#x2F;h1&gt;
&lt;p&gt;Gdb provides a python scripting interface. However the documentation is
highly technical and not at a level that is easily accessible.&lt;&#x2F;p&gt;
&lt;p&gt;This post should read as a tutorial, to help you understand the
interface and work toward creating your own python debuging tools to
help make gdb usage somewhat &amp;quot;less&amp;quot; painful.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-problem&quot;&gt;The problem&lt;&#x2F;h2&gt;
&lt;p&gt;I have created a problem program called &amp;quot;naughty&amp;quot;. You can find it
&lt;a href=&quot;..&#x2F;..&#x2F;..&#x2F;_static&#x2F;gdb_py&#x2F;naughty.c&quot;&gt;here&lt;&#x2F;a&gt; .&lt;&#x2F;p&gt;
&lt;p&gt;You can compile this with the following command:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;gcc -g -lpthread -o naughty naughty.c
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;When you run this program, your screen should be filled with:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;thread ...
&lt;&#x2F;span&gt;&lt;span&gt;thread ...
&lt;&#x2F;span&gt;&lt;span&gt;thread ...
&lt;&#x2F;span&gt;&lt;span&gt;thread ...
&lt;&#x2F;span&gt;&lt;span&gt;thread ...
&lt;&#x2F;span&gt;&lt;span&gt;thread ...
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;It looks like we have a bug! Now, we could easily see the issue if we
looked at the C code, but that&#x27;s not the point here - lets try to solve
this with gdb.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;gdb .&#x2F;naughty
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;span&gt;(gdb) run
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;span&gt;[New Thread 0x7fffb9792700 (LWP 14467)]
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;span&gt;thread ...
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Uh oh! We have threads being created here. We need to find the problem
thread. Lets look at all the threads backtraces then.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;Thread 129 (Thread 0x7fffb3786700 (LWP 14616)):
&lt;&#x2F;span&gt;&lt;span&gt;#0  0x00007ffff7bc38eb in pthread_cond_wait@@GLIBC_2.3.2 () from &#x2F;lib64&#x2F;libpthread.so.0
&lt;&#x2F;span&gt;&lt;span&gt;#1  0x00000000004007bc in lazy_thread (arg=0x7fffffffdfb0) at naughty.c:19
&lt;&#x2F;span&gt;&lt;span&gt;#2  0x00007ffff7bbd3a9 in start_thread () from &#x2F;lib64&#x2F;libpthread.so.0
&lt;&#x2F;span&gt;&lt;span&gt;#3  0x00007ffff78e936f in clone () from &#x2F;lib64&#x2F;libc.so.6
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Thread 128 (Thread 0x7fffb3f87700 (LWP 14615)):
&lt;&#x2F;span&gt;&lt;span&gt;#0  0x00007ffff7bc38eb in pthread_cond_wait@@GLIBC_2.3.2 () from &#x2F;lib64&#x2F;libpthread.so.0
&lt;&#x2F;span&gt;&lt;span&gt;#1  0x00000000004007bc in lazy_thread (arg=0x7fffffffdfb0) at naughty.c:19
&lt;&#x2F;span&gt;&lt;span&gt;#2  0x00007ffff7bbd3a9 in start_thread () from &#x2F;lib64&#x2F;libpthread.so.0
&lt;&#x2F;span&gt;&lt;span&gt;#3  0x00007ffff78e936f in clone () from &#x2F;lib64&#x2F;libc.so.6
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Thread 127 (Thread 0x7fffb4788700 (LWP 14614)):
&lt;&#x2F;span&gt;&lt;span&gt;#0  0x00007ffff7bc38eb in pthread_cond_wait@@GLIBC_2.3.2 () from &#x2F;lib64&#x2F;libpthread.so.0
&lt;&#x2F;span&gt;&lt;span&gt;#1  0x00000000004007bc in lazy_thread (arg=0x7fffffffdfb0) at naughty.c:19
&lt;&#x2F;span&gt;&lt;span&gt;#2  0x00007ffff7bbd3a9 in start_thread () from &#x2F;lib64&#x2F;libpthread.so.0
&lt;&#x2F;span&gt;&lt;span&gt;#3  0x00007ffff78e936f in clone () from &#x2F;lib64&#x2F;libc.so.6
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;We have 129 threads! Anyone of them could be the problem. We could just
read these traces forever, but that&#x27;s a waste of time. Let&#x27;s try and
script this with python to make our lives a bit easier.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;python-in-gdb&quot;&gt;Python in gdb&lt;&#x2F;h2&gt;
&lt;p&gt;Python in gdb works by bringing in a copy of the python and injecting a
special &amp;quot;gdb&amp;quot; module into the python run time. You can &lt;em&gt;only&lt;&#x2F;em&gt; access
the gdb module from within python if you are using gdb. You can not have
this work from a standard interpretter session.&lt;&#x2F;p&gt;
&lt;p&gt;We can access a dynamic python runtime from within gdb by simply calling
python.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;(gdb) python
&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;print(&amp;quot;hello world&amp;quot;)
&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;hello world
&lt;&#x2F;span&gt;&lt;span&gt;(gdb)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The python code only runs when you press Control D.&lt;&#x2F;p&gt;
&lt;p&gt;Another way to run your script is to import them as &amp;quot;new gdb
commands&amp;quot;. This is the most useful way to use python for gdb, but it
does require some boilerplate to start.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;import gdb
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;class SimpleCommand(gdb.Command):
&lt;&#x2F;span&gt;&lt;span&gt;    def __init__(self):
&lt;&#x2F;span&gt;&lt;span&gt;        # This registers our class as &amp;quot;simple_command&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;        super(SimpleCommand, self).__init__(&amp;quot;simple_command&amp;quot;, gdb.COMMAND_DATA)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    def invoke(self, arg, from_tty):
&lt;&#x2F;span&gt;&lt;span&gt;        # When we call &amp;quot;simple_command&amp;quot; from gdb, this is the method
&lt;&#x2F;span&gt;&lt;span&gt;        # that will be called.
&lt;&#x2F;span&gt;&lt;span&gt;        print(&amp;quot;Hello from simple_command!&amp;quot;)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# This registers our class to the gdb runtime at &amp;quot;source&amp;quot; time.
&lt;&#x2F;span&gt;&lt;span&gt;SimpleCommand()
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;We can run the command as follows:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;(gdb) source debug_naughty.py
&lt;&#x2F;span&gt;&lt;span&gt;(gdb) simple_command
&lt;&#x2F;span&gt;&lt;span&gt;Hello from simple_command!
&lt;&#x2F;span&gt;&lt;span&gt;(gdb)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;solving-the-problem-with-python&quot;&gt;Solving the problem with python&lt;&#x2F;h2&gt;
&lt;p&gt;So we need a way to find the &amp;quot;idle threads&amp;quot;. We want to fold all the
threads with the same frame signature into one, so that we can view
anomalies.&lt;&#x2F;p&gt;
&lt;p&gt;First, let&#x27;s make a &amp;quot;stackfold&amp;quot; command, and get it to list the
current program.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;class StackFold(gdb.Command):
&lt;&#x2F;span&gt;&lt;span&gt;def __init__(self):
&lt;&#x2F;span&gt;&lt;span&gt;    super(StackFold, self).__init__(&amp;quot;stackfold&amp;quot;, gdb.COMMAND_DATA)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;def invoke(self, arg, from_tty):
&lt;&#x2F;span&gt;&lt;span&gt;    # An inferior is the &amp;#39;currently running applications&amp;#39;. In this case we only
&lt;&#x2F;span&gt;&lt;span&gt;    # have one.
&lt;&#x2F;span&gt;&lt;span&gt;    inferiors = gdb.inferiors()
&lt;&#x2F;span&gt;&lt;span&gt;    for inferior in inferiors:
&lt;&#x2F;span&gt;&lt;span&gt;        print(inferior)
&lt;&#x2F;span&gt;&lt;span&gt;        print(dir(inferior))
&lt;&#x2F;span&gt;&lt;span&gt;        print(help(inferior))
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;StackFold()
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;To reload this in the gdb runtime, just run &amp;quot;source debug_naughty.py&amp;quot;
again. Try running this: Note that we dumped a heap of output? Python
has a neat trick that dir and help can both return strings for printing.
This will help us to explore gdb&#x27;s internals inside of our program.&lt;&#x2F;p&gt;
&lt;p&gt;We can see from the inferiors that we have threads available for us to
interact with:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;class Inferior(builtins.object)
&lt;&#x2F;span&gt;&lt;span&gt; |  GDB inferior object
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;span&gt; |  threads(...)
&lt;&#x2F;span&gt;&lt;span&gt; |      Return all the threads of this inferior.
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Given we want to fold the stacks from all our threads, we probably need
to look at this! So lets get one thread from this, and have a look at
it&#x27;s help.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;inferiors = gdb.inferiors()
&lt;&#x2F;span&gt;&lt;span&gt;for inferior in inferiors:
&lt;&#x2F;span&gt;&lt;span&gt;    thread_iter = iter(inferior.threads())
&lt;&#x2F;span&gt;&lt;span&gt;    head_thread = next(thread_iter)
&lt;&#x2F;span&gt;&lt;span&gt;    print(help(head_thread))
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now we can run this by re-running &amp;quot;source&amp;quot; on our script, and calling
stackfold again, we see help for our threads in the system.&lt;&#x2F;p&gt;
&lt;p&gt;At this point it get&#x27;s a little bit less obvious. Gdb&#x27;s python
integration relates closely to how a human would interact with gdb. In
order to access the content of a thread, we need to change the gdb
context to access the backtrace. If we were doing this by hand it would
look like this:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;(gdb) thread 121
&lt;&#x2F;span&gt;&lt;span&gt;[Switching to thread 121 (Thread 0x7fffb778e700 (LWP 14608))]
&lt;&#x2F;span&gt;&lt;span&gt;#0  0x00007ffff7bc38eb in pthread_cond_wait@@GLIBC_2.3.2 () from &#x2F;lib64&#x2F;libpthread.so.0
&lt;&#x2F;span&gt;&lt;span&gt;(gdb) bt
&lt;&#x2F;span&gt;&lt;span&gt;#0  0x00007ffff7bc38eb in pthread_cond_wait@@GLIBC_2.3.2 () from &#x2F;lib64&#x2F;libpthread.so.0
&lt;&#x2F;span&gt;&lt;span&gt;#1  0x00000000004007bc in lazy_thread (arg=0x7fffffffdfb0) at naughty.c:19
&lt;&#x2F;span&gt;&lt;span&gt;#2  0x00007ffff7bbd3a9 in start_thread () from &#x2F;lib64&#x2F;libpthread.so.0
&lt;&#x2F;span&gt;&lt;span&gt;#3  0x00007ffff78e936f in clone () from &#x2F;lib64&#x2F;libc.so.6
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;We need to emulate this behaviour with our python calls. We can swap to
the thread&#x27;s context with:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;class InferiorThread(builtins.object)
&lt;&#x2F;span&gt;&lt;span&gt; |  GDB thread object
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;span&gt; |  switch(...)
&lt;&#x2F;span&gt;&lt;span&gt; |      switch ()
&lt;&#x2F;span&gt;&lt;span&gt; |      Makes this the GDB selected thread.
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Then once we are in the context, we need to take a different approach to
explore the stack frames. We need to explore the &amp;quot;gdb&amp;quot; modules raw
context.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;inferiors = gdb.inferiors()
&lt;&#x2F;span&gt;&lt;span&gt;for inferior in inferiors:
&lt;&#x2F;span&gt;&lt;span&gt;    thread_iter = iter(inferior.threads())
&lt;&#x2F;span&gt;&lt;span&gt;    head_thread = next(thread_iter)
&lt;&#x2F;span&gt;&lt;span&gt;    # Move our gdb context to the selected thread here.
&lt;&#x2F;span&gt;&lt;span&gt;    head_thread.switch()
&lt;&#x2F;span&gt;&lt;span&gt;    print(help(gdb))
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now that we have selected our thread&#x27;s context, we can start to explore
here. gdb can do a lot within the selected context - as a result, the
help output from this call is really large, but it&#x27;s worth reading so
you can understand what is possible to achieve. In our case we need to
start to look at the stack frames.&lt;&#x2F;p&gt;
&lt;p&gt;To look through the frames we need to tell gdb to rewind to the
&amp;quot;newest&amp;quot; frame (ie, frame 0). We can then step down through
progressively older frames until we exhaust. From this we can print a
rudimentary trace:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;head_thread.switch()
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Reset the gdb frame context to the &amp;quot;latest&amp;quot; frame.
&lt;&#x2F;span&gt;&lt;span&gt;gdb.newest_frame()
&lt;&#x2F;span&gt;&lt;span&gt;# Now, work down the frames.
&lt;&#x2F;span&gt;&lt;span&gt;cur_frame = gdb.selected_frame()
&lt;&#x2F;span&gt;&lt;span&gt;while cur_frame is not None:
&lt;&#x2F;span&gt;&lt;span&gt;    print(cur_frame.name())
&lt;&#x2F;span&gt;&lt;span&gt;    # get the next frame down ....
&lt;&#x2F;span&gt;&lt;span&gt;    cur_frame = cur_frame.older()
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;(gdb) stackfold 
&lt;&#x2F;span&gt;&lt;span&gt;pthread_cond_wait@@GLIBC_2.3.2
&lt;&#x2F;span&gt;&lt;span&gt;lazy_thread
&lt;&#x2F;span&gt;&lt;span&gt;start_thread
&lt;&#x2F;span&gt;&lt;span&gt;clone
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Great! Now we just need some extra metadata from the thread to know what
thread id it is so the user can go to the correct thread context. So
lets display that too:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;head_thread.switch()
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# These are the OS pid references.
&lt;&#x2F;span&gt;&lt;span&gt;(tpid, lwpid, tid) = head_thread.ptid
&lt;&#x2F;span&gt;&lt;span&gt;# This is the gdb thread number
&lt;&#x2F;span&gt;&lt;span&gt;gtid = head_thread.num
&lt;&#x2F;span&gt;&lt;span&gt;print(&amp;quot;tpid %s, lwpid %s, tid %s, gtid %s&amp;quot; % (tpid, lwpid, tid, gtid))
&lt;&#x2F;span&gt;&lt;span&gt;# Reset the gdb frame context to the &amp;quot;latest&amp;quot; frame.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;(gdb) stackfold
&lt;&#x2F;span&gt;&lt;span&gt;tpid 14485, lwpid 14616, tid 0, gtid 129
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;At this point we have enough information to fold identical stacks.
We&#x27;ll iterate over every thread, and if we have seen the &amp;quot;pattern&amp;quot;
before, we&#x27;ll just add the gdb thread id to the list. If we haven&#x27;t
seen the pattern yet, we&#x27;ll add it. The final command looks like:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;def invoke(self, arg, from_tty):
&lt;&#x2F;span&gt;&lt;span&gt;    # An inferior is the &amp;#39;currently running applications&amp;#39;. In this case we only
&lt;&#x2F;span&gt;&lt;span&gt;    # have one.
&lt;&#x2F;span&gt;&lt;span&gt;    stack_maps = {}
&lt;&#x2F;span&gt;&lt;span&gt;    # This creates a dict where each element is keyed by backtrace.
&lt;&#x2F;span&gt;&lt;span&gt;    # Then each backtrace contains an array of &amp;quot;frames&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    #
&lt;&#x2F;span&gt;&lt;span&gt;    inferiors = gdb.inferiors()
&lt;&#x2F;span&gt;&lt;span&gt;    for inferior in inferiors:
&lt;&#x2F;span&gt;&lt;span&gt;        for thread in inferior.threads():
&lt;&#x2F;span&gt;&lt;span&gt;            # Change to our threads context
&lt;&#x2F;span&gt;&lt;span&gt;            thread.switch()
&lt;&#x2F;span&gt;&lt;span&gt;            # Get the thread IDS
&lt;&#x2F;span&gt;&lt;span&gt;            (tpid, lwpid, tid) = thread.ptid
&lt;&#x2F;span&gt;&lt;span&gt;            gtid = thread.num
&lt;&#x2F;span&gt;&lt;span&gt;            # Take a human readable copy of the backtrace, we&amp;#39;ll need this for display later.
&lt;&#x2F;span&gt;&lt;span&gt;            o = gdb.execute(&amp;#39;bt&amp;#39;, to_string=True)
&lt;&#x2F;span&gt;&lt;span&gt;            # Build the backtrace for comparison
&lt;&#x2F;span&gt;&lt;span&gt;            backtrace = []
&lt;&#x2F;span&gt;&lt;span&gt;            gdb.newest_frame()
&lt;&#x2F;span&gt;&lt;span&gt;            cur_frame = gdb.selected_frame()
&lt;&#x2F;span&gt;&lt;span&gt;            while cur_frame is not None:
&lt;&#x2F;span&gt;&lt;span&gt;                backtrace.append(cur_frame.name())
&lt;&#x2F;span&gt;&lt;span&gt;                cur_frame = cur_frame.older()
&lt;&#x2F;span&gt;&lt;span&gt;            # Now we have a backtrace like [&amp;#39;pthread_cond_wait@@GLIBC_2.3.2&amp;#39;, &amp;#39;lazy_thread&amp;#39;, &amp;#39;start_thread&amp;#39;, &amp;#39;clone&amp;#39;]
&lt;&#x2F;span&gt;&lt;span&gt;            # dicts can&amp;#39;t use lists as keys because they are non-hashable, so we turn this into a string.
&lt;&#x2F;span&gt;&lt;span&gt;            # Remember, C functions can&amp;#39;t have spaces in them ...
&lt;&#x2F;span&gt;&lt;span&gt;            s_backtrace = &amp;#39; &amp;#39;.join(backtrace)
&lt;&#x2F;span&gt;&lt;span&gt;            # Let&amp;#39;s see if it exists in the stack_maps
&lt;&#x2F;span&gt;&lt;span&gt;            if s_backtrace not in stack_maps:
&lt;&#x2F;span&gt;&lt;span&gt;                stack_maps[s_backtrace] = []
&lt;&#x2F;span&gt;&lt;span&gt;            # Now lets add this thread to the map.
&lt;&#x2F;span&gt;&lt;span&gt;            stack_maps[s_backtrace].append({&amp;#39;gtid&amp;#39;: gtid, &amp;#39;tpid&amp;#39; : tpid, &amp;#39;bt&amp;#39;: o} )
&lt;&#x2F;span&gt;&lt;span&gt;    # Now at this point we have a dict of traces, and each trace has a &amp;quot;list&amp;quot; of pids that match. Let&amp;#39;s display them
&lt;&#x2F;span&gt;&lt;span&gt;    for smap in stack_maps:
&lt;&#x2F;span&gt;&lt;span&gt;        # Get our human readable form out.
&lt;&#x2F;span&gt;&lt;span&gt;        o = stack_maps[smap][0][&amp;#39;bt&amp;#39;]
&lt;&#x2F;span&gt;&lt;span&gt;        for t in stack_maps[smap]:
&lt;&#x2F;span&gt;&lt;span&gt;            # For each thread we recorded
&lt;&#x2F;span&gt;&lt;span&gt;            print(&amp;quot;Thread %s (LWP %s))&amp;quot; % (t[&amp;#39;gtid&amp;#39;], t[&amp;#39;tpid&amp;#39;]))
&lt;&#x2F;span&gt;&lt;span&gt;        print(o)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Here is the final output.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;(gdb) stackfold
&lt;&#x2F;span&gt;&lt;span&gt;Thread 129 (LWP 14485))
&lt;&#x2F;span&gt;&lt;span&gt;Thread 128 (LWP 14485))
&lt;&#x2F;span&gt;&lt;span&gt;Thread 127 (LWP 14485))
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;span&gt;Thread 10 (LWP 14485))
&lt;&#x2F;span&gt;&lt;span&gt;Thread 9 (LWP 14485))
&lt;&#x2F;span&gt;&lt;span&gt;Thread 8 (LWP 14485))
&lt;&#x2F;span&gt;&lt;span&gt;Thread 7 (LWP 14485))
&lt;&#x2F;span&gt;&lt;span&gt;Thread 6 (LWP 14485))
&lt;&#x2F;span&gt;&lt;span&gt;Thread 5 (LWP 14485))
&lt;&#x2F;span&gt;&lt;span&gt;Thread 4 (LWP 14485))
&lt;&#x2F;span&gt;&lt;span&gt;Thread 3 (LWP 14485))
&lt;&#x2F;span&gt;&lt;span&gt;#0  0x00007ffff7bc38eb in pthread_cond_wait@@GLIBC_2.3.2 () from &#x2F;lib64&#x2F;libpthread.so.0
&lt;&#x2F;span&gt;&lt;span&gt;#1  0x00000000004007bc in lazy_thread (arg=0x7fffffffdfb0) at naughty.c:19
&lt;&#x2F;span&gt;&lt;span&gt;#2  0x00007ffff7bbd3a9 in start_thread () from &#x2F;lib64&#x2F;libpthread.so.0
&lt;&#x2F;span&gt;&lt;span&gt;#3  0x00007ffff78e936f in clone () from &#x2F;lib64&#x2F;libc.so.6
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Thread 2 (LWP 14485))
&lt;&#x2F;span&gt;&lt;span&gt;#0  0x00007ffff78d835b in write () from &#x2F;lib64&#x2F;libc.so.6
&lt;&#x2F;span&gt;&lt;span&gt;#1  0x00007ffff78524fd in _IO_new_file_write () from &#x2F;lib64&#x2F;libc.so.6
&lt;&#x2F;span&gt;&lt;span&gt;#2  0x00007ffff7854271 in __GI__IO_do_write () from &#x2F;lib64&#x2F;libc.so.6
&lt;&#x2F;span&gt;&lt;span&gt;#3  0x00007ffff7854723 in __GI__IO_file_overflow () from &#x2F;lib64&#x2F;libc.so.6
&lt;&#x2F;span&gt;&lt;span&gt;#4  0x00007ffff7847fa2 in puts () from &#x2F;lib64&#x2F;libc.so.6
&lt;&#x2F;span&gt;&lt;span&gt;#5  0x00000000004007e9 in naughty_thread (arg=0x0) at naughty.c:27
&lt;&#x2F;span&gt;&lt;span&gt;#6  0x00007ffff7bbd3a9 in start_thread () from &#x2F;lib64&#x2F;libpthread.so.0
&lt;&#x2F;span&gt;&lt;span&gt;#7  0x00007ffff78e936f in clone () from &#x2F;lib64&#x2F;libc.so.6
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Thread 1 (LWP 14485))
&lt;&#x2F;span&gt;&lt;span&gt;#0  0x00007ffff7bbe90d in pthread_join () from &#x2F;lib64&#x2F;libpthread.so.0
&lt;&#x2F;span&gt;&lt;span&gt;#1  0x00000000004008d1 in main (argc=1, argv=0x7fffffffe508) at naughty.c:51
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;With our stackfold command we can easily see that threads 129 through 3
have the same stack, and are idle. We can see that tread 1 is the main
process waiting on the threads to join, and finally we can see that
thread 2 is the culprit writing to our display.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;my-solution&quot;&gt;My solution&lt;&#x2F;h2&gt;
&lt;p&gt;You can find my solution to this problem as a &lt;a href=&quot;..&#x2F;..&#x2F;..&#x2F;_static&#x2F;gdb_py&#x2F;debug_naughty.py&quot;&gt;reference implementation
here&lt;&#x2F;a&gt; .&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Time safety and Rust</title>
          <pubDate>Wed, 12 Jul 2017 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2017-07-12-time-safety-and-rust/</link>
          <guid>https://fy.blackhats.net.au/blog/2017-07-12-time-safety-and-rust/</guid>
          <description>&lt;h1 id=&quot;time-safety-and-rust&quot;&gt;Time safety and Rust&lt;&#x2F;h1&gt;
&lt;p&gt;Recently I have had the great fortune to work on &lt;a href=&quot;https:&#x2F;&#x2F;pagure.io&#x2F;389-ds-base&#x2F;issue&#x2F;49316&quot;&gt;this
ticket&lt;&#x2F;a&gt; . This was an issue
that stemmed from an attempt to make clock performance faster.
Previously, a call to time or clock_gettime would involve a context
switch an a system call (think solaris etc). On linux we have VDSO
instead, so we can easily just swap to the use of raw time calls.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-problem&quot;&gt;The problem&lt;&#x2F;h2&gt;
&lt;p&gt;So what was the problem? And how did the engineers of the past try and
solve it?&lt;&#x2F;p&gt;
&lt;p&gt;DS heavily relies on time. As a result, we call time() a &lt;em&gt;lot&lt;&#x2F;em&gt; in the
codebase. But this would mean context switches.&lt;&#x2F;p&gt;
&lt;p&gt;So a wrapper was made called &amp;quot;current_time()&amp;quot;, which would cache a
recent output of time(), and then provide that to the caller instead of
making the costly context switch. So the code had the following:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;static time_t   currenttime;
&lt;&#x2F;span&gt;&lt;span&gt;static int      currenttime_set = 0;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;time_t
&lt;&#x2F;span&gt;&lt;span&gt;poll_current_time()
&lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;    if ( !currenttime_set ) {
&lt;&#x2F;span&gt;&lt;span&gt;        currenttime_set = 1;
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    time( &amp;amp;currenttime );
&lt;&#x2F;span&gt;&lt;span&gt;    return( currenttime );
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;time_t
&lt;&#x2F;span&gt;&lt;span&gt;current_time( void )
&lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;    if ( currenttime_set ) {
&lt;&#x2F;span&gt;&lt;span&gt;        return( currenttime );
&lt;&#x2F;span&gt;&lt;span&gt;    } else {
&lt;&#x2F;span&gt;&lt;span&gt;        return( time( (time_t *)0 ));
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;In another thread, we would poll this every second to update the
currenttime value:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;void * 
&lt;&#x2F;span&gt;&lt;span&gt;time_thread(void *nothing __attribute__((unused)))
&lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;    PRIntervalTime    interval;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    interval = PR_SecondsToInterval(1);
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    while(!time_shutdown) {
&lt;&#x2F;span&gt;&lt;span&gt;        poll_current_time();
&lt;&#x2F;span&gt;&lt;span&gt;        csngen_update_time ();
&lt;&#x2F;span&gt;&lt;span&gt;        DS_Sleep(interval);
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;*NOTREACHED*&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;    return(NULL);
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&lt;em&gt;So what is the problem here&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Besides the fact that we may not poll accurately (meaning we miss
seconds but always advance), this is not &lt;em&gt;thread safe&lt;&#x2F;em&gt;. The reason is
that CPU&#x27;s have register and buffers that may cache both stores and
writes until a series of other operations (barriers + atomics) occur to
flush back out to cache. This means the time polling thread could update
the clock and unless the POLLING thread issues a lock or a
barrier+atomic, there is &lt;em&gt;no guarantee the new value of currenttime will
be seen in any other thread&lt;&#x2F;em&gt;. This means that the only way this worked
was by luck, and no one noticing that time would jump about or often
just be wrong.&lt;&#x2F;p&gt;
&lt;p&gt;Clearly this is a broken design, but this is C - we can do anything.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-if-this-was-rust&quot;&gt;What if this was Rust?&lt;&#x2F;h2&gt;
&lt;p&gt;Rust touts mulithread safety high on it&#x27;s list. So lets try and
recreate this in rust.&lt;&#x2F;p&gt;
&lt;p&gt;First, the exact same way:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;use std::time::{SystemTime, Duration};
&lt;&#x2F;span&gt;&lt;span&gt;use std::thread;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;static mut currenttime: Option&amp;lt;SystemTime&amp;gt; = None;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;fn read_thread() {
&lt;&#x2F;span&gt;&lt;span&gt;    let interval = Duration::from_secs(1);
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    for x in 0..10 {
&lt;&#x2F;span&gt;&lt;span&gt;        thread::sleep(interval);
&lt;&#x2F;span&gt;&lt;span&gt;        let c_time = currenttime.unwrap();
&lt;&#x2F;span&gt;&lt;span&gt;        println!(&amp;quot;reading time {:?}&amp;quot;, c_time);
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;fn poll_thread() {
&lt;&#x2F;span&gt;&lt;span&gt;    let interval = Duration::from_secs(1);
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    for x in 0..10 {
&lt;&#x2F;span&gt;&lt;span&gt;        currenttime = Some(SystemTime::now());
&lt;&#x2F;span&gt;&lt;span&gt;        println!(&amp;quot;polling time&amp;quot;);
&lt;&#x2F;span&gt;&lt;span&gt;        thread::sleep(interval);
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;fn main() {
&lt;&#x2F;span&gt;&lt;span&gt;    let poll = thread::spawn(poll_thread);
&lt;&#x2F;span&gt;&lt;span&gt;    let read = thread::spawn(read_thread);
&lt;&#x2F;span&gt;&lt;span&gt;    read.join().unwrap();
&lt;&#x2F;span&gt;&lt;span&gt;    poll.join().unwrap();
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&lt;em&gt;Rust will not compile this code&lt;&#x2F;em&gt;.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&amp;gt; rustc clock.rs
&lt;&#x2F;span&gt;&lt;span&gt;error[E0133]: use of mutable static requires unsafe function or block
&lt;&#x2F;span&gt;&lt;span&gt;  --&amp;gt; clock.rs:13:22
&lt;&#x2F;span&gt;&lt;span&gt;   |
&lt;&#x2F;span&gt;&lt;span&gt;13 |         let c_time = currenttime.unwrap();
&lt;&#x2F;span&gt;&lt;span&gt;   |                      ^^^^^^^^^^^ use of mutable static
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;error[E0133]: use of mutable static requires unsafe function or block
&lt;&#x2F;span&gt;&lt;span&gt;  --&amp;gt; clock.rs:22:9
&lt;&#x2F;span&gt;&lt;span&gt;   |
&lt;&#x2F;span&gt;&lt;span&gt;22 |         currenttime = Some(SystemTime::now());
&lt;&#x2F;span&gt;&lt;span&gt;   |         ^^^^^^^^^^^ use of mutable static
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;error: aborting due to 2 previous errors
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Rust has told us that this action is &lt;em&gt;unsafe&lt;&#x2F;em&gt;, and that we shouldn&#x27;t be
modifying a global static like this.&lt;&#x2F;p&gt;
&lt;p&gt;This alone is a great reason and demonstration of why we need a language
like Rust instead of C - the compiler can tell us when actions are
dangerous at compile time, rather than being allowed to sit in
production code for years.&lt;&#x2F;p&gt;
&lt;p&gt;For bonus marks, because Rust is stricter about types than C, we don&#x27;t
have issues like:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;int c_time = time();
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Which is a 2038 problem in the making :)&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>indexed search performance for ds - the mystery of the and query</title>
          <pubDate>Mon, 26 Jun 2017 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2017-06-26-indexed-search-performance-for-ds-the-mystery-of-the-and-query/</link>
          <guid>https://fy.blackhats.net.au/blog/2017-06-26-indexed-search-performance-for-ds-the-mystery-of-the-and-query/</guid>
          <description>&lt;h1 id=&quot;indexed-search-performance-for-ds-the-mystery-of-the-and-query&quot;&gt;indexed search performance for ds - the mystery of the and query&lt;&#x2F;h1&gt;
&lt;p&gt;Directory Server is heavily based on set mathematics - one of the few
topics I enjoyed during university. Our filters really boil down to set
queries:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&amp;amp;((attr=val1)(attr=val2))
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This filter describes the intersection of sets of objects containing
&amp;quot;attr=val1&amp;quot; and &amp;quot;attr=val2&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;One of the properties of sets is that operations on them are
commutative - the sets to a union or intersection may be supplied in any
order with the same results. As a result, these are equivalent:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&amp;amp;(a)(b)(c)
&lt;&#x2F;span&gt;&lt;span&gt;&amp;amp;(b)(a)(c)
&lt;&#x2F;span&gt;&lt;span&gt;&amp;amp;(c)(b)(a)
&lt;&#x2F;span&gt;&lt;span&gt;&amp;amp;(c)(a)(b)
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;In the past I noticed an odd behaviour: that the &lt;em&gt;order&lt;&#x2F;em&gt; of filter terms
in an ldapsearch query would drastically change the performance of the
search. For example:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&amp;amp;(a)(b)(c)
&lt;&#x2F;span&gt;&lt;span&gt;&amp;amp;(c)(b)(a)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The later query may significantly outperform the former - but 10% or
greater. I have never understood the reason why though. I toyed with
ideas of re-arranging queries in the optimise step to put the terms in a
better order, but I didn&#x27;t know what factors affected this behaviour.&lt;&#x2F;p&gt;
&lt;p&gt;Over time I realised that if you put the &amp;quot;more specific&amp;quot; filters first
over the general filters, you would see a performance increase.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-was-going-on&quot;&gt;What was going on?&lt;&#x2F;h2&gt;
&lt;p&gt;Recently I was asked to investigate a full table scan issue with range
queries. This led me into an exploration of our search internals, and
yielded the answer to the issue above.&lt;&#x2F;p&gt;
&lt;p&gt;Inside of directory server, our indexes are maintained as &amp;quot;pre-baked&amp;quot;
searches. Rather than trying to search every object to see if a filter
matches, our indexes contain a list of entries that match a term. For
example:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;uid=mark: 1, 2
&lt;&#x2F;span&gt;&lt;span&gt;uid=william: 3
&lt;&#x2F;span&gt;&lt;span&gt;uid=noriko: 4
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;From each indexed term we construct an IDList, which is the set of
entries matching some term.&lt;&#x2F;p&gt;
&lt;p&gt;On a complex query we would need to intersect these. So the algorithm
would iteratively apply this:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;t1 = (a, b)
&lt;&#x2F;span&gt;&lt;span&gt;t2 = (c, t1)
&lt;&#x2F;span&gt;&lt;span&gt;t3 = (d, t2)
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;In addition, the intersection would allocate a new IDList to insert the
results into.&lt;&#x2F;p&gt;
&lt;p&gt;What would happen is that if your first terms were large, we would
allocate large IDLists, and do many copies into it. This would also
affect later filters as we would need to check large ID spaces to
perform the final intersection.&lt;&#x2F;p&gt;
&lt;p&gt;In the above example, consider a, b, c all have 10,000 candidates. This
would mean t1, t2 is at least 10,000 IDs, and we need to do at least
20,000 comparisons. If d were only 3 candidates, this means that we then
throw away the majority of work and allocations when we get to t3 = (d,
t2).&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-is-the-fix&quot;&gt;What is the fix?&lt;&#x2F;h2&gt;
&lt;p&gt;We now wrap each term in an idl_set processing api. When we get the
IDList from each AVA, we insert it to the idl_set. This tracks the
&amp;quot;minimum&amp;quot; IDList, and begins our intersection from the smallest
matching IDList. This means that we have the quickest reduction in set
size, and results in the smallest possible IDList allocation for the
results. In my tests I have seen up to 10% improvement on complex
queries.&lt;&#x2F;p&gt;
&lt;p&gt;For the example above, this means we procees d first, to reduce t1 to
the smallest possible candidate set we can.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;t1 = (d, a)
&lt;&#x2F;span&gt;&lt;span&gt;t2 = (b, t1)
&lt;&#x2F;span&gt;&lt;span&gt;t3 = (c, t2)
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This means to create t2, t3, we will do an allocation that is bounded by
the size of d (aka 3, rather than 10,000), we only need to perform fewer
queries to reach this point.&lt;&#x2F;p&gt;
&lt;p&gt;A benefit of this strategy is that it means if on the first operation we
find t1 is empty set, we can return &lt;em&gt;immediately&lt;&#x2F;em&gt; because no other
intersection will have an impact on the operation.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-is-next&quot;&gt;What is next?&lt;&#x2F;h2&gt;
&lt;p&gt;I still have not improved union performance - this is still somewhat
affected by the ordering of terms in a filter. However, I have a number
of ideas related to either bitmask indexes or disjoin set structures
that can be used to improve this performance.&lt;&#x2F;p&gt;
&lt;p&gt;Stay tuned ....&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>TLS Authentication and FreeRADIUS</title>
          <pubDate>Thu, 25 May 2017 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2017-05-25-tls-authentication-and-freeradius/</link>
          <guid>https://fy.blackhats.net.au/blog/2017-05-25-tls-authentication-and-freeradius/</guid>
          <description>&lt;h1 id=&quot;tls-authentication-and-freeradius&quot;&gt;TLS Authentication and FreeRADIUS&lt;&#x2F;h1&gt;
&lt;p&gt;In a push to try and limit the amount of passwords sent on my network,
I&#x27;m changing my wireless to use TLS certificates for authentication.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Kerberos - why the world moved on</title>
          <pubDate>Tue, 23 May 2017 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2017-05-23-kerberos-why-the-world-moved-on/</link>
          <guid>https://fy.blackhats.net.au/blog/2017-05-23-kerberos-why-the-world-moved-on/</guid>
          <description>&lt;h1 id=&quot;kerberos-why-the-world-moved-on&quot;&gt;Kerberos - why the world moved on&lt;&#x2F;h1&gt;
&lt;p&gt;For a long time I have tried to integrate and improve authentication
technologies in my own environments. I have advocated the use of GSSAPI,
IPA, AD, and others. However, the more I have learnt, the further I have
seen the world moving away. I want to explore some of my personal
experiences and views as to why this occured, and what we can do.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Custom OSTree images</title>
          <pubDate>Mon, 22 May 2017 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2017-05-22-custom-ostree-images/</link>
          <guid>https://fy.blackhats.net.au/blog/2017-05-22-custom-ostree-images/</guid>
          <description>&lt;h1 id=&quot;custom-ostree-images&quot;&gt;Custom OSTree images&lt;&#x2F;h1&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;www.projectatomic.io&#x2F;&quot;&gt;Project Atomic&lt;&#x2F;a&gt; is in my view, one of
the most promising changes to come to linux distributions in a long
time. It boasts the ability to atomicupgrade and alter your OS by
maintaining A&#x2F;B roots of the filesystem. It is currently focused on
docker and k8s runtimes, but we can use atomic in other locations.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Your Code Has Impact</title>
          <pubDate>Fri, 10 Mar 2017 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2017-03-10-your-code-has-impact/</link>
          <guid>https://fy.blackhats.net.au/blog/2017-03-10-your-code-has-impact/</guid>
          <description>&lt;h1 id=&quot;your-code-has-impact&quot;&gt;Your Code Has Impact&lt;&#x2F;h1&gt;
&lt;p&gt;As an engineer, sometimes it&#x27;s easy to forget &lt;em&gt;why&lt;&#x2F;em&gt; we are writing
programs. Deep in a bug hunt, or designing a new feature it&#x27;s really
easy to focus so hard on these small things you forget the bigger
picture. I&#x27;ve even been there and made this mistake.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>CVE-2017-2591 - DoS via OOB heap read</title>
          <pubDate>Wed, 22 Feb 2017 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2017-02-22-cve-2017-2591-dos-via-oob-heap-read/</link>
          <guid>https://fy.blackhats.net.au/blog/2017-02-22-cve-2017-2591-dos-via-oob-heap-read/</guid>
          <description>&lt;h1 id=&quot;cve-2017-2591-dos-via-oob-heap-read&quot;&gt;CVE-2017-2591 - DoS via OOB heap read&lt;&#x2F;h1&gt;
&lt;p&gt;On 18 of Jan 2017, the following &lt;a href=&quot;http:&#x2F;&#x2F;seclists.org&#x2F;oss-sec&#x2F;2017&#x2F;q1&#x2F;129&quot;&gt;email found it&#x27;s way to my
notifications&lt;&#x2F;a&gt; .&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;This is to disclose the following CVE:
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;CVE-2017-2591 389 Directory Server: DoS via OOB heap read
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Description :
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;The &amp;quot;attribute uniqueness&amp;quot; plugin did not properly NULL-terminate an array
&lt;&#x2F;span&gt;&lt;span&gt;when building up its configuration, if a so called &amp;#39;old-style&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;configuration, was being used (Using nsslapd-pluginarg&amp;lt;X&amp;gt; parameters) .
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;A attacker, authenticated, but possibly also unauthenticated, could
&lt;&#x2F;span&gt;&lt;span&gt;possibly force the plugin to read beyond allocated memory and trigger a
&lt;&#x2F;span&gt;&lt;span&gt;segfault.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;The crash could also possibly be triggered accidentally.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Upstream patch :
&lt;&#x2F;span&gt;&lt;span&gt;https:&#x2F;&#x2F;fedorahosted.org&#x2F;389&#x2F;changeset&#x2F;ffda694dd622b31277da07be76d3469fad86150f&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;Affected versions : from 1.3.4.0
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Fixed version : 1.3.6
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Impact: Low
&lt;&#x2F;span&gt;&lt;span&gt;CVSS3 scoring : 3.7 -- CVSS:3.0&#x2F;AV:N&#x2F;AC:H&#x2F;PR:N&#x2F;UI:N&#x2F;S:U&#x2F;C:N&#x2F;I:N&#x2F;A:L
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Upstream bug report : https:&#x2F;&#x2F;fedorahosted.org&#x2F;389&#x2F;ticket&#x2F;48986
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;So I decided to pull this apart: Given I found the issue and wrote the
fix, I didn&#x27;t deem it security worthy, so why was a CVE raised?&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>LCA2017 - Getting Into the Rusty Bucket</title>
          <pubDate>Mon, 23 Jan 2017 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2017-01-23-lca2017-getting-into-the-rusty-bucket/</link>
          <guid>https://fy.blackhats.net.au/blog/2017-01-23-lca2017-getting-into-the-rusty-bucket/</guid>
          <description>&lt;h1 id=&quot;lca2017-getting-into-the-rusty-bucket&quot;&gt;LCA2017 - Getting Into the Rusty Bucket&lt;&#x2F;h1&gt;
&lt;p&gt;I spoke at &lt;a href=&quot;http:&#x2F;&#x2F;lca2017.org&quot;&gt;Linux Conf Australia 2017&lt;&#x2F;a&gt; recently. I
presented techniques and lessons about integrating Rust with existing C
code bases. This is related to my work on Directory Server.&lt;&#x2F;p&gt;
&lt;p&gt;The recording of the talk can be found on
&lt;a href=&quot;https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=AWnza5JX7jQ&quot;&gt;youtube&lt;&#x2F;a&gt; and on the &lt;a href=&quot;http:&#x2F;&#x2F;mirror.linux.org.au&#x2F;pub&#x2F;linux.conf.au&#x2F;2017&#x2F;&quot;&gt;Linux
Australia Mirror&lt;&#x2F;a&gt; .&lt;&#x2F;p&gt;
&lt;p&gt;You can find the git repository for the project &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;Firstyear&#x2F;ds_rust&quot;&gt;on
github&lt;&#x2F;a&gt; .&lt;&#x2F;p&gt;
&lt;p&gt;The slides can be viewed on
&lt;a href=&quot;http:&#x2F;&#x2F;redhat.slides.com&#x2F;wibrown&#x2F;rusty-bucket?token=oPNS4Ilp&quot;&gt;slides.com&lt;&#x2F;a&gt;
.&lt;&#x2F;p&gt;
&lt;p&gt;I have already had a lot of feedback on improvements to make to this
system including the use of struct pointers instead of c_void, and the
use of bindgen in certain places.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>The next year of Directory Server</title>
          <pubDate>Mon, 23 Jan 2017 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2017-01-23-the-next-year-of-directory-server/</link>
          <guid>https://fy.blackhats.net.au/blog/2017-01-23-the-next-year-of-directory-server/</guid>
          <description>&lt;h1 id=&quot;the-next-year-of-directory-server&quot;&gt;The next year of Directory Server&lt;&#x2F;h1&gt;
&lt;p&gt;Last year I wrote a post about the vision behind Directory Server and
what I wanted to achieve in the project personally. My key aims were:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;We need to modernise our tooling, and installers.&lt;&#x2F;li&gt;
&lt;li&gt;Setting up replication groups and masters needs to be simpler.&lt;&#x2F;li&gt;
&lt;li&gt;We need to get away from long lived static masters.&lt;&#x2F;li&gt;
&lt;li&gt;During updates, we need to start to enable smarter choices by
default.&lt;&#x2F;li&gt;
&lt;li&gt;Out of the box we need smarter settings.&lt;&#x2F;li&gt;
&lt;li&gt;Web Based authentication&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</description>
      </item>
      <item>
          <title>Usability of software: The challenges facing projects</title>
          <pubDate>Mon, 23 Jan 2017 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2017-01-23-usability-of-software-the-challenges-facing-projects/</link>
          <guid>https://fy.blackhats.net.au/blog/2017-01-23-usability-of-software-the-challenges-facing-projects/</guid>
          <description>&lt;h1 id=&quot;usability-of-software-the-challenges-facing-projects&quot;&gt;Usability of software: The challenges facing projects&lt;&#x2F;h1&gt;
&lt;p&gt;I have always desired the usability of software like Directory Server to
improve. As a former system administrator, usabilty and documentation
are very important for me. Improvements to usability can eliminate load
on documentation, support services and more.&lt;&#x2F;p&gt;
&lt;p&gt;Consider a microwave. No one reads the user manual. They unbox it, plug
it in, and turn it on. You punch in a time and expect it to &amp;quot;make cold
things hot&amp;quot;. You only consult the manual if it blows up.&lt;&#x2F;p&gt;
&lt;p&gt;Many of these principles are rooted in the field of design. Design is an
important and often over looked part of software development - All the
way from the design of an API to the configuration, and even the user
interface of software.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>State of the 389 ds port, 2017</title>
          <pubDate>Fri, 06 Jan 2017 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2017-01-06-state-of-the-389-ds-port-2017/</link>
          <guid>https://fy.blackhats.net.au/blog/2017-01-06-state-of-the-389-ds-port-2017/</guid>
          <description>&lt;h1 id=&quot;state-of-the-389-ds-port-2017&quot;&gt;State of the 389 ds port, 2017&lt;&#x2F;h1&gt;
&lt;p&gt;Previously I have written about my efforts to port 389 ds to FreeBSD.&lt;&#x2F;p&gt;
&lt;p&gt;A great deal of progress has been made in the last few weeks (owing to
my taking time off work).&lt;&#x2F;p&gt;
&lt;p&gt;I have now ported nunc-stans to freebsd, which is important as it&#x27;s our
new connection management system. It has an issue with long lived
events, but I will resolve this soon.&lt;&#x2F;p&gt;
&lt;p&gt;The majority of patches for 389 ds have merged, with a single patch
remaining to be reviewed.&lt;&#x2F;p&gt;
&lt;p&gt;Finally, I have build a freebsd makefile for the &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;Firstyear&#x2F;ds-devel-root&#x2F;blob&#x2F;master&#x2F;Makefile.fbsd&quot;&gt;devel
root&lt;&#x2F;a&gt;
to make it easier for people to install and test from source.&lt;&#x2F;p&gt;
&lt;p&gt;Once the freebsd nunc-stans and final DS patch are accepted, I&#x27;ll be
able to start building the portfiles.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Openshift cluster administration</title>
          <pubDate>Mon, 02 Jan 2017 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2017-01-02-openshift-cluster-administration/</link>
          <guid>https://fy.blackhats.net.au/blog/2017-01-02-openshift-cluster-administration/</guid>
          <description>&lt;h1 id=&quot;openshift-cluster-administration&quot;&gt;Openshift cluster administration&lt;&#x2F;h1&gt;
&lt;p&gt;Over the last 6 months I have administered a three node openshift v3
cluster in my lab environment.&lt;&#x2F;p&gt;
&lt;p&gt;The summary of this expirence is that openshift is a great idea, but not
ready for production. As an administrator you will find this a
frustrating, difficult experience.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>The minssf trap</title>
          <pubDate>Wed, 23 Nov 2016 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2016-11-23-the-minssf-trap/</link>
          <guid>https://fy.blackhats.net.au/blog/2016-11-23-the-minssf-trap/</guid>
          <description>&lt;h1 id=&quot;the-minssf-trap&quot;&gt;The minssf trap&lt;&#x2F;h1&gt;
&lt;p&gt;In directory server, we often use the concept of a &amp;quot;minssf&amp;quot;, or the
&amp;quot;minimum security strength factor&amp;quot;. This is derived from cyrus sasl.
However, there are some issues that will catch you out!&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>The mysterious crashing of my laptop</title>
          <pubDate>Wed, 21 Sep 2016 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2016-09-21-the-mysterious-crashing-of-my-laptop/</link>
          <guid>https://fy.blackhats.net.au/blog/2016-09-21-the-mysterious-crashing-of-my-laptop/</guid>
          <description>&lt;h1 id=&quot;the-mysterious-crashing-of-my-laptop&quot;&gt;The mysterious crashing of my laptop&lt;&#x2F;h1&gt;
&lt;p&gt;Recently I have grown unhappy with Fedora. The updates to the i915
graphics driver have caused my laptop to kernel panic just connecting
and removing external displays: unacceptable to someone who moves their
laptop around as much as I do.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>What&#x27;s new in 389 Directory Server 1.3.5 (unofficial)</title>
          <pubDate>Wed, 21 Sep 2016 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2016-09-21-what-s-new-in-directory-server-1-3-5-unofficial/</link>
          <guid>https://fy.blackhats.net.au/blog/2016-09-21-what-s-new-in-directory-server-1-3-5-unofficial/</guid>
          <description>&lt;h1 id=&quot;what-s-new-in-389-directory-server-1-3-5-unofficial&quot;&gt;What&#x27;s new in 389 Directory Server 1.3.5 (unofficial)&lt;&#x2F;h1&gt;
&lt;p&gt;As a member of the 389 Directory Server (389DS) core team, I am always
excited about our new releases. We have some really great features in
1.3.5. However, our changelogs are always large so I want to just touch
on a few of my favourites.&lt;&#x2F;p&gt;
&lt;p&gt;389 Directory Server is an LDAPv3 compliant server, used around the
world for Identity Management, Authentication, Authorisation and much
more. It is the foundation of the FreeIPA project&#x27;s server. As a
result, it&#x27;s not something we often think about or even get excited
for: but every day many of us rely on 389 Directory Server to be
correct, secure and fast behind the scenes.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Block Chain for Identity Management</title>
          <pubDate>Mon, 18 Jul 2016 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2016-07-18-block-chain-for-identity-management/</link>
          <guid>https://fy.blackhats.net.au/blog/2016-07-18-block-chain-for-identity-management/</guid>
          <description>&lt;h1 id=&quot;block-chain-for-identity-management&quot;&gt;Block Chain for Identity Management&lt;&#x2F;h1&gt;
&lt;p&gt;On Sunday evening I was posed with a question and view of someone
interested in Block Chain.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;&amp;quot;What do you think of block chain for authentication&amp;quot;&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;A very heated debate ensued. I want to discuss this topic at length.&lt;&#x2F;p&gt;
&lt;h1 id=&quot;when-you-roll-x&quot;&gt;When you roll X ...&lt;&#x2F;h1&gt;
&lt;p&gt;We&#x27;ve heard this. &amp;quot;When writing cryptography, don&#x27;t. If you have to,
hire a cryptographer&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;This statement is true for Authentication and Authorisation systems&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;&amp;quot;When writing Authentication and Authorisation systems, don&#x27;t. If you
have to, hire an Authentication expert&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;Guess what. Authentication and Authorisation are &lt;em&gt;hard&lt;&#x2F;em&gt;. Very hard. This
is not something for the kids to play with; this is a security critical,
business critical, sensitive, scrutinised and highly conservative area
of technology.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Can I cycle through operators in C?</title>
          <pubDate>Sat, 16 Jul 2016 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2016-07-16-can-i-cycle-through-operators-in-c/</link>
          <guid>https://fy.blackhats.net.au/blog/2016-07-16-can-i-cycle-through-operators-in-c/</guid>
          <description>&lt;h1 id=&quot;can-i-cycle-through-operators-in-c&quot;&gt;Can I cycle through operators in C?&lt;&#x2F;h1&gt;
&lt;p&gt;A friend of mine who is learning to program asked me the following:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;&amp;quot;&amp;quot;&amp;quot; How do i cycle through operators in c? If I want to try every
version of + -&lt;&#x2F;em&gt; &#x2F; on an equation, so printf(&amp;quot;1 %operator 1&amp;quot;,
oneOfTheOperators); Like I&#x27;d stick them in an array and iterate over
the array incrementing on each iteration, but do you define an operator
as? They aren&#x27;t ints, floats etc &amp;quot;&amp;quot;&amp;quot;*&lt;&#x2F;p&gt;
&lt;p&gt;He&#x27;s certainly on the way to the correct answer already. There are
three key barriers to an answer.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>tracking down insane memory leaks</title>
          <pubDate>Wed, 13 Jul 2016 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2016-07-13-tracking-down-insane-memory-leaks/</link>
          <guid>https://fy.blackhats.net.au/blog/2016-07-13-tracking-down-insane-memory-leaks/</guid>
          <description>&lt;h1 id=&quot;tracking-down-insane-memory-leaks&quot;&gt;tracking down insane memory leaks&lt;&#x2F;h1&gt;
&lt;p&gt;One of the best parts of AddressSanitizer is the built in leak
sanitiser. However, sometimes it&#x27;s not as clear as you might wish!&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;I0&amp;gt; &#x2F;opt&#x2F;dirsrv&#x2F;bin&#x2F;pwdhash hello                            
&lt;&#x2F;span&gt;&lt;span&gt;{SSHA}s16epVgkKenDHQqG8hrCGhmzqkgx0H1984ttYg==
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;=================================================================
&lt;&#x2F;span&gt;&lt;span&gt;==388==ERROR: LeakSanitizer: detected memory leaks
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Direct leak of 72 byte(s) in 1 object(s) allocated from:
&lt;&#x2F;span&gt;&lt;span&gt;    #0 0x7f5f5f94dfd0 in calloc (&#x2F;lib64&#x2F;libasan.so.3+0xc6fd0)
&lt;&#x2F;span&gt;&lt;span&gt;    #1 0x7f5f5d7f72ae  (&#x2F;lib64&#x2F;libnss3.so+0x752ae)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;SUMMARY: AddressSanitizer: 72 byte(s) leaked in 1 allocation(s).
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&amp;quot;Where is &#x2F;lib64&#x2F;libnss3.so+0x752ae&amp;quot; and what can I do with it? I have
debuginfo and devel info installed, but I can&#x27;t seem to see what line
that&#x27;s at.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>NSS and OpenSSL Command Reference</title>
          <pubDate>Sun, 10 Jul 2016 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/pages/nss-and-openssl-command-reference/</link>
          <guid>https://fy.blackhats.net.au/pages/nss-and-openssl-command-reference/</guid>
          <description>&lt;h1 id=&quot;nss-and-openssl-command-reference&quot;&gt;NSS and OpenSSL Command Reference&lt;&#x2F;h1&gt;
&lt;p&gt;I am tired of the lack of documentation for how to actually use OpenSSL
and NSS to achieve things. Be it missing small important options like
&amp;quot;subjectAltNames&amp;quot; in nss commands or OpenSSL&#x27;s cryptic settings. Here
is my complete list of everything you would ever want to do with OpenSSL
and NSS.&lt;&#x2F;p&gt;
&lt;p&gt;References:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http:&#x2F;&#x2F;www.mozilla.org&#x2F;projects&#x2F;security&#x2F;pki&#x2F;nss&#x2F;tools&#x2F;certutil.html&quot;&gt;certutil
mozilla&lt;&#x2F;a&gt;.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;developer.mozilla.org&#x2F;en-US&#x2F;docs&#x2F;NSS_reference&#x2F;NSS_tools_:_certutil&quot;&gt;nss
tools&lt;&#x2F;a&gt;.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;www.openssl.org&#x2F;docs&#x2F;apps&#x2F;openssl.html&quot;&gt;openssl&lt;&#x2F;a&gt;.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;nss-specific&quot;&gt;NSS specific&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;db-creation-and-basic-listing&quot;&gt;DB creation and basic listing&lt;&#x2F;h3&gt;
&lt;p&gt;NSS does not operate on PEM or DER files like OpenSSL - it interacts
with a certificate database.&lt;&#x2F;p&gt;
&lt;p&gt;The older format database contains 3 files: key3.db, cert8.db, and
secmod.db&lt;&#x2F;p&gt;
&lt;p&gt;The newer sqlite based format contains 3 files: key4.db, cert9.db, and
pkcs11.txt&lt;&#x2F;p&gt;
&lt;p&gt;Create a new certificate database if one doesn&#x27;t exist. You should see
the files listed above. :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -N -d .
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;List all certificates in a database :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -L -d .
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;List all private keys in a database :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -K -d . [-f pwdfile.txt]
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;I have created a password file, which consists of random data on one
line in a plain text file. Something like below would suffice.
Alternately you can enter a password when prompted by the certutil
commands. If you wish to use this for directory server start up, you
need to use pin.txt which lists the &amp;quot;token name&amp;quot; and it&#x27;s
corresponding pin. :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;echo &amp;quot;Password&amp;quot; &amp;gt; pwdfile.txt
&lt;&#x2F;span&gt;&lt;span&gt;echo &amp;quot;internal:Password&amp;quot; &amp;gt; pin.txt
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;importing-certificates-to-nss&quot;&gt;Importing certificates to NSS&lt;&#x2F;h3&gt;
&lt;p&gt;Import a server certificate into the database with no certificate
authority trust flags. :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -A -n &amp;quot;Server-cert&amp;quot; -t &amp;quot;,,&amp;quot; -i nss.dev.example.com.crt -d .
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Import an openSSL generated key and certificate into an NSS database.
This needs to be formatted through a pkcs12 bundle.&lt;&#x2F;p&gt;
&lt;p&gt;You can NOT include the CA certificate in these bundles, they must be
imported seperately to NSS. :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;openssl pkcs12 -export -in server.crt -inkey server.key -out server.p12 -name Test-Server-Cert
&lt;&#x2F;span&gt;&lt;span&gt;pk12util -i server.p12 -d . -k pwdfile.txt
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;importing-a-ca-certificate&quot;&gt;Importing a CA certificate&lt;&#x2F;h3&gt;
&lt;p&gt;Import the CA public certificate into the database. Note the [-t
&amp;quot;C,,&amp;quot;]{.title-ref} flag which specifies this is trusted as a CA
certificate. The nickname has no function other than to help you
identify the certificate. :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -A -n &amp;quot;CAcert&amp;quot; -t &amp;quot;C,,&amp;quot; -i &#x2F;etc&#x2F;pki&#x2F;CA&#x2F;nss&#x2F;ca.crt -d .
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;exporting-certificates&quot;&gt;Exporting certificates&lt;&#x2F;h3&gt;
&lt;p&gt;Export a secret key and certificate from an NSS database for use with
OpenSSL. This must pass through a pkcs12 file, in reverse to the import
process above. Note that file.pem contains all of the CA cert, cert and
private key. :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;pk12util -o server-export.p12 -d . -k pwdfile.txt -n Test-Server-Cert
&lt;&#x2F;span&gt;&lt;span&gt;openssl pkcs12 -in server-export.p12 -out file.pem -nodes
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You can extract just the private key with:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;openssl pkcs12 -in server-export.p12 -out file.pem -nocerts -nodes
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Or just the cert and CAcert with&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;openssl pkcs12 -in server-export.p12 -out file.pem -nokeys -nodes
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;both-nss-and-openssl&quot;&gt;Both NSS and OpenSSL&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;self-signed-certificates&quot;&gt;Self signed certificates&lt;&#x2F;h3&gt;
&lt;p&gt;Create a self signed certificate.&lt;&#x2F;p&gt;
&lt;p&gt;For NSS, note the -n, which creates a &amp;quot;nickname&amp;quot; (should be unique in
this DB) and is how applications reference your certificate and key.
Also note the -s line, and the CN options. Finally, note the first line
has the option -g, which defines the number of bits in the created
certificate. Note also the -Z for the hash algorithm. -v is &amp;quot;valid
months&amp;quot; which we set to 1. The equivalent openssl command is below.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -S -f pwdfile.txt -d . -t &amp;quot;C,,&amp;quot; -x -n &amp;quot;Server-Cert&amp;quot; -k ec -q nistp256 \
&lt;&#x2F;span&gt;&lt;span&gt;-s &amp;quot;CN=nss.dev.example.com,O=Testing,L=example,ST=Queensland,C=AU&amp;quot; -v 1
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;openssl req -x509 -newkey ec:&amp;lt;(openssl genpkey -genparam -algorithm ec -pkeyopt ec_paramgen_curve:P-256)
&lt;&#x2F;span&gt;&lt;span&gt;-keyout key.pem -out cert.pem -days 31 -nodes
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If you choose to use RSA. 3072 bits is the equivalent in strength to 256
bit ecdsa.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -S -f pwdfile.txt -d . -t &amp;quot;C,,&amp;quot; -x -n &amp;quot;Server-Cert&amp;quot; -g 3072 -Z SHA256 \
&lt;&#x2F;span&gt;&lt;span&gt;-s &amp;quot;CN=nss.dev.example.com,O=Testing,L=example,ST=Queensland,C=AU&amp;quot; -v 1
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;openssl req -x509 -newkey rsa:3072 -keyout key.pem -out cert.pem -days 31 -nodes
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;subjectaltnames&quot;&gt;SubjectAltNames&lt;&#x2F;h3&gt;
&lt;p&gt;To add subject alternative names, use a comma seperated list with the
option -8 IE:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -S -f pwdfile.txt -d . -t &amp;quot;C,,&amp;quot; -x -n &amp;quot;Server-Cert&amp;quot; -k ec -q nistp256 \
&lt;&#x2F;span&gt;&lt;span&gt;-s &amp;quot;CN=nss.dev.example.com,O=Testing,L=example,ST=Queensland,C=AU&amp;quot; \
&lt;&#x2F;span&gt;&lt;span&gt;-8 &amp;quot;nss.dev.example.com,nss-alt.dev.example.com&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;For OpenSSL this is harder: First, you need to create an altnames.cnf
and fill in the details as required.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;[req]
&lt;&#x2F;span&gt;&lt;span&gt;req_extensions = v3_req
&lt;&#x2F;span&gt;&lt;span&gt;nsComment = &amp;quot;Certificate&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;distinguished_name  = req_distinguished_name
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[ req_distinguished_name ]
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;countryName                     = Country Name (2 letter code)
&lt;&#x2F;span&gt;&lt;span&gt;countryName_default             = AU
&lt;&#x2F;span&gt;&lt;span&gt;countryName_min                 = 2
&lt;&#x2F;span&gt;&lt;span&gt;countryName_max                 = 2
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;stateOrProvinceName             = State or Province Name (full name)
&lt;&#x2F;span&gt;&lt;span&gt;stateOrProvinceName_default     = Queensland
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;localityName                    = Locality Name (eg, city)
&lt;&#x2F;span&gt;&lt;span&gt;localityName_default            = example&#x2F;streetAddress=Level
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;0.organizationName              = Organization Name (eg, company)
&lt;&#x2F;span&gt;&lt;span&gt;0.organizationName_default      = example
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;organizationalUnitName          = Organizational Unit Name (eg, section)
&lt;&#x2F;span&gt;&lt;span&gt;organizationalUnitName_default = TS
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;commonName                      = Common Name (eg, your name or your server\&amp;#39;s hostname)
&lt;&#x2F;span&gt;&lt;span&gt;commonName_max                  = 64
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[ v3_req ]
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Extensions to add to a certificate request
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;basicConstraints = CA:FALSE
&lt;&#x2F;span&gt;&lt;span&gt;keyUsage = nonRepudiation, digitalSignature, keyEncipherment
&lt;&#x2F;span&gt;&lt;span&gt;subjectAltName = @alt_names
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[alt_names]
&lt;&#x2F;span&gt;&lt;span&gt;DNS.1 = server1.yourdomain.tld
&lt;&#x2F;span&gt;&lt;span&gt;DNS.2 = mail.yourdomain.tld
&lt;&#x2F;span&gt;&lt;span&gt;DNS.3 = www.yourdomain.tld
&lt;&#x2F;span&gt;&lt;span&gt;DNS.4 = www.sub.yourdomain.tld
&lt;&#x2F;span&gt;&lt;span&gt;DNS.5 = mx.yourdomain.tld
&lt;&#x2F;span&gt;&lt;span&gt;DNS.6 = support.yourdomain.tld
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now you run a similar command to before with the altnames configuration
added. :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;openssl req -x509 -newkey ec:&amp;lt;(openssl genpkey -genparam -algorithm ec -pkeyopt ec_paramgen_curve:P-256)
&lt;&#x2F;span&gt;&lt;span&gt;-keyout key.pem -out cert.pem -days -config altnames.cnf
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;check-a-certificate-belongs-to-a-specific-key&quot;&gt;Check a certificate belongs to a specific key&lt;&#x2F;h3&gt;
&lt;p&gt;This checks that a key, signing request and cert belong together.&lt;&#x2F;p&gt;
&lt;p&gt;In NSS when the certificate and key are in the same database, the
linkage is shown when you display all keys: :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# certutil -d . -K
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt; 0&amp;gt; ec       bb4db46fb8a5beb46f57641f8b1bf236bc139666   NSS Certificate DB:Server-Cert
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;With OpenSSL it&#x27;s possible to verify this from requests and other
parts.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;openssl ec -in key.pem -pubout | openssl sha1
&lt;&#x2F;span&gt;&lt;span&gt;openssl x509 -noout -in cert.pem -pubkey | openssl sha1
&lt;&#x2F;span&gt;&lt;span&gt;openssl req -noout -in cert.pem -pubkey | openssl sha1
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;For an RSA key and certificate. :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;openssl rsa -noout -modulus -in client.key | openssl sha1
&lt;&#x2F;span&gt;&lt;span&gt;openssl req -noout -modulus -in client.csr | openssl sha1
&lt;&#x2F;span&gt;&lt;span&gt;openssl x509 -noout -modulus -in client.crt | openssl sha1
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;view-a-certificate&quot;&gt;View a certificate&lt;&#x2F;h3&gt;
&lt;p&gt;View the cert :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -L -d . -n Test-Cert
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;openssl x509 -noout -text -in client.crt
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;View the cert in ASCII PEM form (This can be redirected to a file for
use with openssl) :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -L -d . -n Test-Cert -a
&lt;&#x2F;span&gt;&lt;span&gt;certutil -L -d . -n Test-Cert -a &amp;gt; cert.pem
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;creating-a-csr&quot;&gt;Creating a CSR&lt;&#x2F;h3&gt;
&lt;p&gt;In a &lt;em&gt;seperate&lt;&#x2F;em&gt; database to your CA.&lt;&#x2F;p&gt;
&lt;p&gt;Create a new certificate request. Again, remember -8 for subjectAltName.
This request is for a TLS server with a 24 month certificate lifetime. :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -d . -R -a -o nss.dev.example.com.csr -f pwdfile.txt -k ec -q nistp256 -v 24 \
&lt;&#x2F;span&gt;&lt;span&gt;-s &amp;quot;CN=nss.dev.example.com,O=Testing,L=example,ST=Queensland,C=AU&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If you want to request for a TLS client that can authenticate to a
server with x509. :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -d . -R -a -o user.csr -f pwdfile.txt -k ec -q nistp256 -v 24 \
&lt;&#x2F;span&gt;&lt;span&gt;--keyUsage digitalSignature,nonRepudiation,keyEncipherment,dataEncipherment --nsCertType sslClient --extKeyUsage clientAuth \
&lt;&#x2F;span&gt;&lt;span&gt;-s &amp;quot;CN=username,O=Testing,L=example,ST=Queensland,C=AU&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Using openSSL create a server key, and make a CSR. Note prime256v1 is an
alternate name for nistp256 :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;openssl ecparam -genkey -name prime256v1 -noout -out key.pem
&lt;&#x2F;span&gt;&lt;span&gt;openssl req -key key.pem -out cert.csr -days 712 -config altnames.cnf -new
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;For RSA :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;openssl genrsa -out key.pem 3072
&lt;&#x2F;span&gt;&lt;span&gt;openssl req -key key.pem -out cert.csr -days 712 -config altnames.cnf -new
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;self-signed-ca&quot;&gt;Self signed CA&lt;&#x2F;h3&gt;
&lt;p&gt;Create a self signed CA (In a different database from the one used by
your application) :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -S -n CAissuer -t &amp;quot;C,C,C&amp;quot; -x -f pwdfile.txt -d . -k ec -q nistp256 -v 24 \
&lt;&#x2F;span&gt;&lt;span&gt;--keyUsage certSigning -2 --nsCertType sslCA \
&lt;&#x2F;span&gt;&lt;span&gt;-s &amp;quot;CN=ca.nss.dev.example.com,O=Testing,L=example,ST=Queensland,C=AU&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Nss will ask you about the constraints on this certificate. Here is a
sample output. Note the path length of 0 still allows this CA to issue
certificates, but it cannot issue an intermediate CA.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;Generating key.  This may take a few moments...
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;        0 - Digital Signature
&lt;&#x2F;span&gt;&lt;span&gt;        1 - Non-repudiation
&lt;&#x2F;span&gt;&lt;span&gt;        2 - Key encipherment
&lt;&#x2F;span&gt;&lt;span&gt;        3 - Data encipherment
&lt;&#x2F;span&gt;&lt;span&gt;        4 - Key agreement
&lt;&#x2F;span&gt;&lt;span&gt;        5 - Cert signing key
&lt;&#x2F;span&gt;&lt;span&gt;        6 - CRL signing key
&lt;&#x2F;span&gt;&lt;span&gt;        Other to finish
&lt;&#x2F;span&gt;&lt;span&gt; &amp;gt; 5
&lt;&#x2F;span&gt;&lt;span&gt;        0 - Digital Signature
&lt;&#x2F;span&gt;&lt;span&gt;        1 - Non-repudiation
&lt;&#x2F;span&gt;&lt;span&gt;        2 - Key encipherment
&lt;&#x2F;span&gt;&lt;span&gt;        3 - Data encipherment
&lt;&#x2F;span&gt;&lt;span&gt;        4 - Key agreement
&lt;&#x2F;span&gt;&lt;span&gt;        5 - Cert signing key
&lt;&#x2F;span&gt;&lt;span&gt;        6 - CRL signing key
&lt;&#x2F;span&gt;&lt;span&gt;        Other to finish
&lt;&#x2F;span&gt;&lt;span&gt; &amp;gt; 9
&lt;&#x2F;span&gt;&lt;span&gt;Is this a critical extension [y&#x2F;N]?
&lt;&#x2F;span&gt;&lt;span&gt;n
&lt;&#x2F;span&gt;&lt;span&gt;Is this a CA certificate [y&#x2F;N]?
&lt;&#x2F;span&gt;&lt;span&gt;y
&lt;&#x2F;span&gt;&lt;span&gt;Enter the path length constraint, enter to skip [&amp;lt;0 for unlimited path]: &amp;gt; 0
&lt;&#x2F;span&gt;&lt;span&gt;Is this a critical extension [y&#x2F;N]?
&lt;&#x2F;span&gt;&lt;span&gt;y
&lt;&#x2F;span&gt;&lt;span&gt;        0 - SSL Client
&lt;&#x2F;span&gt;&lt;span&gt;        1 - SSL Server
&lt;&#x2F;span&gt;&lt;span&gt;        2 - S&#x2F;MIME
&lt;&#x2F;span&gt;&lt;span&gt;        3 - Object Signing
&lt;&#x2F;span&gt;&lt;span&gt;        4 - Reserved for future use
&lt;&#x2F;span&gt;&lt;span&gt;        5 - SSL CA
&lt;&#x2F;span&gt;&lt;span&gt;        6 - S&#x2F;MIME CA
&lt;&#x2F;span&gt;&lt;span&gt;        7 - Object Signing CA
&lt;&#x2F;span&gt;&lt;span&gt;        Other to finish
&lt;&#x2F;span&gt;&lt;span&gt; &amp;gt; 5
&lt;&#x2F;span&gt;&lt;span&gt;        0 - SSL Client
&lt;&#x2F;span&gt;&lt;span&gt;        1 - SSL Server
&lt;&#x2F;span&gt;&lt;span&gt;        2 - S&#x2F;MIME
&lt;&#x2F;span&gt;&lt;span&gt;        3 - Object Signing
&lt;&#x2F;span&gt;&lt;span&gt;        4 - Reserved for future use
&lt;&#x2F;span&gt;&lt;span&gt;        5 - SSL CA
&lt;&#x2F;span&gt;&lt;span&gt;        6 - S&#x2F;MIME CA
&lt;&#x2F;span&gt;&lt;span&gt;        7 - Object Signing CA
&lt;&#x2F;span&gt;&lt;span&gt;        Other to finish
&lt;&#x2F;span&gt;&lt;span&gt; &amp;gt; 9
&lt;&#x2F;span&gt;&lt;span&gt;Is this a critical extension [y&#x2F;N]?
&lt;&#x2F;span&gt;&lt;span&gt;n
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;OpenSSL is the same as a self signed cert. It&#x27;s probably wise to add
path length and other policies here, which are specified via -config :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;openssl req -x509 -newkey rsa:2048 -keyout key.pem -out cert.pem -days X -config ca.cnf
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;renewing-the-self-signed-ca&quot;&gt;Renewing the self signed CA&lt;&#x2F;h3&gt;
&lt;p&gt;This happens if your CA is about to or has expired. You need to reissue
all your certs after this is done! Be sure to substitute your domain and
certificate nicknames.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -d . -R -k &amp;quot;NSS Certificate DB:ca&amp;quot; -s &amp;quot;CN=ca.net.blackhats.net.au,O=Blackhats,L=Brisbane,ST=Queensland,C=AU&amp;quot; -a -o renew.req -1 -2 -5
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;certutil -C -d . -c &amp;quot;ca&amp;quot; -a -i renew.req -t &amp;quot;C,C,C&amp;quot; -o cacert.crt -v 12
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;certutil -A -d . -n &amp;quot;ca&amp;quot; -a -i cacert.crt -t &amp;quot;C,C,C&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;signing-with-the-ca&quot;&gt;Signing with the CA&lt;&#x2F;h2&gt;
&lt;p&gt;Create a certificate in the same database, and sign it with the CAissuer
certificate.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -S -n Test-Cert -t &amp;quot;,,&amp;quot; -c CAissuer -f pwdfile.txt -d . \
&lt;&#x2F;span&gt;&lt;span&gt;-s &amp;quot;CN=test.nss.dev.example.com,O=Testing,L=example,ST=Queensland,C=AU&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If from a CSR, review the CSR you have recieved.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;usr&#x2F;lib[64]&#x2F;nss&#x2F;unsupported-tools&#x2F;derdump -i &#x2F;etc&#x2F;httpd&#x2F;alias&#x2F;nss.dev.example.com.csr
&lt;&#x2F;span&gt;&lt;span&gt;openssl req -inform DER -text -in &#x2F;etc&#x2F;httpd&#x2F;alias&#x2F;nss.dev.example.com.csr  ## if from nss
&lt;&#x2F;span&gt;&lt;span&gt;openssl req -inform PEM -text -in server.csr  ## if from openssl
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;On the CA, sign the CSR.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -C -d . -f pwdfile.txt -a -i &#x2F;etc&#x2F;httpd&#x2F;alias&#x2F;nss.dev.example.com.csr \
&lt;&#x2F;span&gt;&lt;span&gt;-o &#x2F;etc&#x2F;httpd&#x2F;alias&#x2F;nss.dev.example.com.crt -c CAissuer
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;For openssl CSR, note the use of -a that allows an ASCII formatted PEM
input, and will create and ASCII PEM certificate output.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -C -d . -f pwdfile.txt -i server.csr -o server.crt -a -c CAissuer
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;### Note, you may need a caserial file ...
&lt;&#x2F;span&gt;&lt;span&gt;openssl x509 -req -days 1024 -in client.csr -CA root.crt -CAkey root.key -out client.crt
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;check-validity-of-a-certificate&quot;&gt;Check validity of a certificate&lt;&#x2F;h3&gt;
&lt;p&gt;Test the new cert for validity as an SSL server. This assumes the CA
cert is in the DB. (Else you need openssl or to import it). The second
example is validating a user certificate.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -V -d . -n Test-Cert -u V
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;certutil -V -d . -n usercert -u C
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;openssl verify -verbose -CAfile ca.crt client.crt
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;export-the-ca-certificate&quot;&gt;Export the CA certificate&lt;&#x2F;h3&gt;
&lt;p&gt;Export the CA public certificate :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -L -d . -n CAissuer -r &amp;gt; ca.crt
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;nss-sqlite-db&quot;&gt;NSS sqlite db&lt;&#x2F;h2&gt;
&lt;p&gt;Finally, these commands all use the old DBM formatted NSS databases. To
use the new &amp;quot;shareable&amp;quot; sqlite formatting, follow the steps found from
&lt;a href=&quot;https:&#x2F;&#x2F;blogs.oracle.com&#x2F;meena&#x2F;entry&#x2F;what_s_new_in_nss&quot;&gt;this blog
post&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;How to upgrade from cert8.db to cert9.db&lt;&#x2F;p&gt;
&lt;p&gt;You can either use environment variables or use sql: prefix in database
directory parameter of certutil:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;$export NSS_DEFAULT_DB_TYPE=sql
&lt;&#x2F;span&gt;&lt;span&gt;$certutil -K -d &#x2F;tmp&#x2F;nss -X
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;        OR
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;$certutil -K -d sql:&#x2F;tmp&#x2F;nss -X
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;When you upgrade these are the files you get&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;key3.db -&amp;gt; key4.db
&lt;&#x2F;span&gt;&lt;span&gt;cert8.db -&amp;gt; cert9.db
&lt;&#x2F;span&gt;&lt;span&gt;secmod.db -&amp;gt; pkcs11.txt
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The contents of the pkcs11.txt files are basically identical to the
contents of the old secmod.db, just not in the old Berkeley DB format.
If you run the command &amp;quot;$modutil -dbdir DBDIR -rawlist&amp;quot; on an older
secmod.db file, you should get output similar to what you see in
pkcs11.txt.&lt;&#x2F;p&gt;
&lt;p&gt;What needs to be done in programs &#x2F; C code&lt;&#x2F;p&gt;
&lt;p&gt;Either add environment variable NSS_DEFAULT_DB_TYPE &amp;quot;sql&amp;quot;&lt;&#x2F;p&gt;
&lt;p&gt;NSS_Initialize call in &lt;a href=&quot;https:&#x2F;&#x2F;developer.mozilla.org&#x2F;en&#x2F;NSS_Initialize&quot;&gt;https:&#x2F;&#x2F;developer.mozilla.org&#x2F;en&#x2F;NSS_Initialize&lt;&#x2F;a&gt;
takes this &amp;quot;configDir&amp;quot; parameter as shown below.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;NSS_Initialize(configDir, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;secmod.db&amp;quot;, NSS_INIT_READONLY);
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;For cert9.db, change this first parameter to &amp;quot;sql:&amp;quot; + configDir (like
&amp;quot;sql:&#x2F;tmp&#x2F;nss&#x2F;&amp;quot;) i.e. prefix &amp;quot;sql:&amp;quot; in the directory name where
these NSS Databases exist. This code will work with cert8.db as well if
cert9.db is not present.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;wiki.mozilla.org&#x2F;NSS_Shared_DB&quot;&gt;https:&#x2F;&#x2F;wiki.mozilla.org&#x2F;NSS_Shared_DB&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;display-a-human-readable-certificate-from-an-ssl-socket&quot;&gt;Display a human readable certificate from an SSL socket&lt;&#x2F;h2&gt;
&lt;p&gt;Note: port 636 is LDAPS, but all SSL sockets are supported. For TLS only
a limited set of protocols are supported. Add -starttls to the command.
See man 1 s_client.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;openssl s_client -connect ldap.example.com:636
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[ant@ant-its-example-edu-au ~]$ echo -n | openssl s_client -connect ldap.example.com:636 | sed -ne &amp;#39;&#x2F;-BEGIN CERTIFICATE-&#x2F;,&#x2F;-END CERTIFICATE-&#x2F;p&amp;#39; | openssl x509 -noout -text
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;depth=3 C = SE, O = AddTrust AB, OU = AddTrust External TTP Network, CN = AddTrust External CA Root
&lt;&#x2F;span&gt;&lt;span&gt;verify return:1
&lt;&#x2F;span&gt;&lt;span&gt;depth=2 C = US, ST = UT, L = Salt Lake City, O = The USERTRUST Network, OU = http:&#x2F;&#x2F;www.usertrust.com, CN = UTN-USERFirst-Hardware
&lt;&#x2F;span&gt;&lt;span&gt;verify return:1
&lt;&#x2F;span&gt;&lt;span&gt;depth=1 C = AU, O = AusCERT, OU = Certificate Services, CN = AusCERT Server CA
&lt;&#x2F;span&gt;&lt;span&gt;verify return:1
&lt;&#x2F;span&gt;&lt;span&gt;depth=0 C = AU, postalCode = 5000, ST = Queensland, L = example, street = Level, street = Place, O =Example, OU = Technology Services, CN = ldap.example.com
&lt;&#x2F;span&gt;&lt;span&gt;verify return:1
&lt;&#x2F;span&gt;&lt;span&gt;DONE
&lt;&#x2F;span&gt;&lt;span&gt;Certificate:
&lt;&#x2F;span&gt;&lt;span&gt;    Data:
&lt;&#x2F;span&gt;&lt;span&gt;        Version: 3 (0x2)
&lt;&#x2F;span&gt;&lt;span&gt;        Serial Number:
&lt;&#x2F;span&gt;&lt;span&gt;    Signature Algorithm: sha1WithRSAEncryption
&lt;&#x2F;span&gt;&lt;span&gt;        Issuer: C=AU, O=AusCERT, OU=Certificate Services, CN=AusCERT Server CA
&lt;&#x2F;span&gt;&lt;span&gt;        Validity
&lt;&#x2F;span&gt;&lt;span&gt;            Not Before: XX
&lt;&#x2F;span&gt;&lt;span&gt;            Not After : XX
&lt;&#x2F;span&gt;&lt;span&gt;        Subject: C=AU&#x2F;postalCode=4000, ST=Queensland, L=example&#x2F;street=Level &#x2F;street=Place, O=Example, OU=Technology Services, CN=ldap.example.com
&lt;&#x2F;span&gt;&lt;span&gt;        Subject Public Key Info:
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;snip&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;            X509v3 Subject Alternative Name: 
&lt;&#x2F;span&gt;&lt;span&gt;                DNS:ldap.example.com
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;snip&amp;gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You can use this to display a CA chain if you can&#x27;t get it from other
locations.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;openssl s_client -connect ldap.example.com:636 -showcerts
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
</description>
      </item>
      <item>
          <title>LDAP Guide Part 4: Schema and Objects</title>
          <pubDate>Fri, 08 Jul 2016 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/pages/ldap-guide-part-4-schema-and-objects/</link>
          <guid>https://fy.blackhats.net.au/pages/ldap-guide-part-4-schema-and-objects/</guid>
          <description>&lt;h1 id=&quot;ldap-guide-part-4-schema-and-objects&quot;&gt;LDAP Guide Part 4: Schema and Objects&lt;&#x2F;h1&gt;
&lt;p&gt;So far we have seen that LDAP is a tree based database, that allows
complex filters over objects attribute value pairs.&lt;&#x2F;p&gt;
&lt;p&gt;Unlike a no-sql or schemaless database, LDAP has a schema for it&#x27;s
objects, making it stricter than json or other similar-looking
representations. This schema is based on objectClasses, similar to
object-oriented programming.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;searching-the-schema&quot;&gt;Searching the schema&lt;&#x2F;h2&gt;
&lt;p&gt;Sadly, schema is a bit difficult to parse due to it&#x27;s representation as
a single object. You can show all the objectClasses and attributeTypes
definitions with the following search.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ldapsearch -H ldap:&#x2F;&#x2F;exampleldap.blackhats.net.au:3389 -x -b &amp;#39;cn=schema&amp;#39; &amp;#39;(objectClass=*)&amp;#39; +
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&lt;em&gt;note&lt;&#x2F;em&gt;: We have a tool in development that makes searching for these
details easier, but we haven&#x27;t released it yet.&lt;&#x2F;p&gt;
&lt;p&gt;You&#x27;ll notice two important types here. The first is an attributeType:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;attributeTypes: ( 2.5.4.4 NAME ( &amp;#39;sn&amp;#39; &amp;#39;surName&amp;#39; )  SUP name
&lt;&#x2F;span&gt;&lt;span&gt; EQUALITY caseIgnoreMatch SUBSTR caseIgnoreSubstringsMatch
&lt;&#x2F;span&gt;&lt;span&gt; SYNTAX 1.3.6.1.4.1.1466.115.121.1.15 X-ORIGIN &amp;#39;RFC 4519&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt; X-DEPRECATED &amp;#39;surName&amp;#39; )
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This is the definition of how an attribute is named and represented. We
can see this attribute can be named &amp;quot;sn&amp;quot; or &amp;quot;surName&amp;quot; (but surName
is deprecated), it uses a case-insensitive match for checks (ie Brown
and brown are the same), and the syntax oid defines the data this can
hold: in this case a utf8 string.&lt;&#x2F;p&gt;
&lt;p&gt;For the most part you won&#x27;t need to play with attributeTypes unless you
have an odd data edge case you are trying to represent.&lt;&#x2F;p&gt;
&lt;p&gt;The second important type is the objectClass definition:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;objectClasses: ( 2.5.6.6 NAME &amp;#39;person&amp;#39; SUP top STRUCTURAL MUST ( sn $ cn )
&lt;&#x2F;span&gt;&lt;span&gt; MAY ( userPassword $ telephoneNumber $ seeAlso $ description )
&lt;&#x2F;span&gt;&lt;span&gt; X-ORIGIN &amp;#39;RFC 4519&amp;#39; )
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This defines an objectClass called &amp;quot;person&amp;quot;. It&#x27;s parent is the
&amp;quot;top&amp;quot; objectClass, and for this to exist on an object the object MUST
have sn and cn attributes present. You may optionally include the MAY
attributes on the object also.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;example&quot;&gt;Example&lt;&#x2F;h2&gt;
&lt;p&gt;So using our person objectclass we can create a simple object:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;cn=user,dc=...
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: top
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: person
&lt;&#x2F;span&gt;&lt;span&gt;cn: user
&lt;&#x2F;span&gt;&lt;span&gt;sn: user
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Let&#x27;s go through a few things. First, note that the rdn (cn=user), is a
valid attribute on the object (cn: user). If we omitted this or changed
it, it would not be valid. This for example is invalid:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;cn=user,dc=...
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: top
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: person
&lt;&#x2F;span&gt;&lt;span&gt;cn: somethingelse
&lt;&#x2F;span&gt;&lt;span&gt;sn: user
&lt;&#x2F;span&gt;&lt;span&gt;description: invalid!
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If we don&#x27;t satisfy the schema&#x27;s &amp;quot;MUST&amp;quot; requirements, the object is
also invalid:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;cn=user,dc=...
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: top
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: person
&lt;&#x2F;span&gt;&lt;span&gt;sn: user
&lt;&#x2F;span&gt;&lt;span&gt;description: invalid, missing cn!
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;It IS valid to add any of the MAY types to an object of course, but they
can also be absent (as per the examples above):&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;cn=user,dc=...
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: top
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: person
&lt;&#x2F;span&gt;&lt;span&gt;cn: user
&lt;&#x2F;span&gt;&lt;span&gt;sn: user
&lt;&#x2F;span&gt;&lt;span&gt;telephoneNumber: 0118999....
&lt;&#x2F;span&gt;&lt;span&gt;description: valid with may attrs.
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;complex-objects&quot;&gt;Complex objects&lt;&#x2F;h2&gt;
&lt;p&gt;You are not limited to a single objectClass per object either. You can
list multiple objectClasses:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;objectClass: account
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: inetOrgPerson
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: inetUser
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: ldapPublicKey
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: ntUser
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: organizationalPerson
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: person
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: posixaccount
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: top
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Provided that all the MUST requirements of all objectClasses are
satisfied, this is valid.&lt;&#x2F;p&gt;
&lt;p&gt;If an attribute exists in both a MUST and a MAY of an objectClass, then
the stricter requirement is enforced, IE MUST. Here, both objectClasses
define cn, but ldapsubentry defines it as &amp;quot;MAY&amp;quot; and person as
&amp;quot;MUST&amp;quot;. Therfore, on an object that contained both of these, CN is a
must attribute.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;objectClasses: ( 2.16.840.1.113719.2.142.6.1.1 NAME &amp;#39;ldapSubEntry&amp;#39; DESC &amp;#39;LDAP 
&lt;&#x2F;span&gt;&lt;span&gt; Subentry class, version 1&amp;#39; SUP top STRUCTURAL MAY cn X-ORIGIN &amp;#39;LDAP Subentry 
&lt;&#x2F;span&gt;&lt;span&gt; Internet Draft&amp;#39; )
&lt;&#x2F;span&gt;&lt;span&gt;objectClasses: ( 2.5.6.6 NAME &amp;#39;person&amp;#39; SUP top STRUCTURAL MUST ( sn $ cn )
&lt;&#x2F;span&gt;&lt;span&gt; MAY ( userPassword $ telephoneNumber $ seeAlso $ description )
&lt;&#x2F;span&gt;&lt;span&gt; X-ORIGIN &amp;#39;RFC 4519&amp;#39; )
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;building-your-own-objects&quot;&gt;Building your own objects&lt;&#x2F;h2&gt;
&lt;p&gt;Knowing this now you can use this to create your own objects. There are
some common attributes that generally need to be satisfied to allow user
objects to resolve on unix systems. You&#x27;ll probably need:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;uid&lt;&#x2F;li&gt;
&lt;li&gt;displayName&lt;&#x2F;li&gt;
&lt;li&gt;loginShell&lt;&#x2F;li&gt;
&lt;li&gt;homeDirectory&lt;&#x2F;li&gt;
&lt;li&gt;uidNumber&lt;&#x2F;li&gt;
&lt;li&gt;gidNumber&lt;&#x2F;li&gt;
&lt;li&gt;memberOf&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;For a group to resolve you need:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;gidNumber&lt;&#x2F;li&gt;
&lt;li&gt;member&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;em&gt;NOTE&lt;&#x2F;em&gt;: This is assuming rfc2307bis behaviour for your client. In sssd
this is &amp;quot;ldap_schema = rfc2307bis&amp;quot;, in the domain provider. For other
clients you may need to alter other parameters. This is the most
efficent way to resolve groups and users on unix, so strongly consider
it.&lt;&#x2F;p&gt;
&lt;p&gt;Knowing you need these values, you can search the schema to create
objectClass definitions to match. Try this out:&lt;&#x2F;p&gt;
&lt;h2 id=&quot;answers&quot;&gt;Answers&lt;&#x2F;h2&gt;
&lt;p&gt;For the group, this is pretty easy. You should have:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;objectClass: top
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: posixGroup
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: groupOfNames
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The user is a bit tricker. You should have something similar to:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;objectClass: top
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: account
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: person
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: posixAccount
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Remember, there is more than one way to put these objects together to
have valid attributes that you require - just try to make sure you pick
classes that don&#x27;t have excess attributes. A bad choice for example is:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;objectClass: top
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: nsValueItem
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;nsValueItem gives you a &amp;quot;MUST&amp;quot; cn, but it gives &amp;quot;MAY&amp;quot; of many other
attributes you will never use or need. So account or person are better
choices. Generally the clue is in the objectClass name.&lt;&#x2F;p&gt;
&lt;p&gt;If you have your own LDAP server you can try creating objects now with
these classes.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>LDAP Guide Part 3: Filters</title>
          <pubDate>Wed, 06 Jul 2016 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/pages/ldap-guide-part-3-filters/</link>
          <guid>https://fy.blackhats.net.au/pages/ldap-guide-part-3-filters/</guid>
          <description>&lt;h1 id=&quot;ldap-guide-part-3-filters&quot;&gt;LDAP Guide Part 3: Filters&lt;&#x2F;h1&gt;
&lt;p&gt;In part 2 we discussed how to use searchbases to control what objects
were returned from a search by their organisation in the LDAP Tree. We
also touched on a simple filter to limit the result by a single search
item.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&amp;#39;(cn=HR Managers)&amp;#39;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If we change this to a different part of the tree, we&#x27;ll get back too
many entries:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;REMEMBER&lt;&#x2F;em&gt;: All examples in this page work and can be &amp;quot;copy-pasted&amp;quot; so
you can try these searches for yourself!&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ldapsearch -H ldap:&#x2F;&#x2F;exampleldap.blackhats.net.au:3389 -x -s sub -b &amp;#39;ou=People,dc=example,dc=com&amp;#39;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If this database has thousands of users, we wouldn&#x27;t be able to scale
or handle this. We need to be able to use filters to effectively search
for objects.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;simple-filters&quot;&gt;Simple Filters&lt;&#x2F;h2&gt;
&lt;p&gt;As mentioned before filters are of the format:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;(attribute operator value)
&lt;&#x2F;span&gt;&lt;span&gt;(condition (...) )
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;These filters are rooted in &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Set_(mathematics)&quot;&gt;set
mathematics&lt;&#x2F;a&gt; which may
be good as an additional reference.&lt;&#x2F;p&gt;
&lt;p&gt;Filters apply to objects attribute values - not the DN. Remember though,
the RDN &lt;em&gt;must&lt;&#x2F;em&gt; be an attribute of the object, so you can filter on this.
It&#x27;s a good idea to look at an object to understand what you could
filter on:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# test0002, People, example.com
&lt;&#x2F;span&gt;&lt;span&gt;dn: uid=test0002,ou=People,dc=example,dc=com
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: top
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: person
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: organizationalPerson
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: inetOrgPerson
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: posixAccount
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: shadowAccount
&lt;&#x2F;span&gt;&lt;span&gt;cn: guest0002
&lt;&#x2F;span&gt;&lt;span&gt;sn: guest0002
&lt;&#x2F;span&gt;&lt;span&gt;uid: guest0002
&lt;&#x2F;span&gt;&lt;span&gt;uid: test0002
&lt;&#x2F;span&gt;&lt;span&gt;givenName: givenname0002
&lt;&#x2F;span&gt;&lt;span&gt;description: description0002
&lt;&#x2F;span&gt;&lt;span&gt;mail: uid0002
&lt;&#x2F;span&gt;&lt;span&gt;uidNumber: 2
&lt;&#x2F;span&gt;&lt;span&gt;gidNumber: 2
&lt;&#x2F;span&gt;&lt;span&gt;shadowMin: 0
&lt;&#x2F;span&gt;&lt;span&gt;shadowMax: 99999
&lt;&#x2F;span&gt;&lt;span&gt;shadowInactive: 30
&lt;&#x2F;span&gt;&lt;span&gt;shadowWarning: 7
&lt;&#x2F;span&gt;&lt;span&gt;homeDirectory: &#x2F;home&#x2F;uid0002
&lt;&#x2F;span&gt;&lt;span&gt;shadowLastChange: 17427
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;equality-filters&quot;&gt;Equality Filters&lt;&#x2F;h2&gt;
&lt;p&gt;An equality filter requests all objects where attribute is equal to
value. IE:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&amp;#39;(uid=test0009)&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;ldapsearch -H ldap:&#x2F;&#x2F;exampleldap.blackhats.net.au:3389 -x -s sub -b &amp;#39;ou=People,dc=example,dc=com&amp;#39; &amp;#39;(uid=test0009)&amp;#39;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;presence-filter&quot;&gt;Presence Filter&lt;&#x2F;h2&gt;
&lt;p&gt;A presence filter requests all objects where the attribute is present
and has a valid value, but we do not care what the value is.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&amp;#39;(uid=*)&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;ldapsearch -H ldap:&#x2F;&#x2F;exampleldap.blackhats.net.au:3389 -x -s sub -b &amp;#39;ou=People,dc=example,dc=com&amp;#39; &amp;#39;(uid=*)&amp;#39;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;range-filters&quot;&gt;Range Filters&lt;&#x2F;h2&gt;
&lt;p&gt;A range filter requests all objects whose attribute values are greater
than or less than a value.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&amp;#39;(uid&amp;gt;=test0005)&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;ldapsearch -H ldap:&#x2F;&#x2F;exampleldap.blackhats.net.au:3389 -x -s sub -b &amp;#39;ou=People,dc=example,dc=com&amp;#39; &amp;#39;(uid&amp;gt;=test0005)&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;&amp;#39;(uid&amp;lt;=test0005)&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;ldapsearch -H ldap:&#x2F;&#x2F;exampleldap.blackhats.net.au:3389 -x -s sub -b &amp;#39;ou=People,dc=example,dc=com&amp;#39; &amp;#39;(uid&amp;lt;=test0005)&amp;#39;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;substring-filters&quot;&gt;Substring filters&lt;&#x2F;h2&gt;
&lt;p&gt;This requests a partial match of an attribute value on the object. You
can use the &#x27;*&#x27; operator multiple times.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&amp;#39;(uid=*005)&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;ldapsearch -H ldap:&#x2F;&#x2F;exampleldap.blackhats.net.au:3389 -x -s sub -b &amp;#39;ou=People,dc=example,dc=com&amp;#39; &amp;#39;(uid=*005)&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;&amp;#39;(uid=*st000*)&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;ldapsearch -H ldap:&#x2F;&#x2F;exampleldap.blackhats.net.au:3389 -x -s sub -b &amp;#39;ou=People,dc=example,dc=com&amp;#39; &amp;#39;(uid=*st000*)&amp;#39;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;NOTE: You should always have at least 3 characters in your substring
filter, else indexes may not operate efficently. IE this filter may not
work efficently:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&amp;#39;(uid=*05)&amp;#39;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;and-filters&quot;&gt;AND filters&lt;&#x2F;h2&gt;
&lt;p&gt;Using the filters above we can begin to construct more complex queries.
AND requires that for an object to match, all child filter elements must
match. This is the &amp;quot;intersection&amp;quot; operation.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&amp;#39;(&amp;amp;(uid=test0006)(uid=guest0006))&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;ldapsearch -H ldap:&#x2F;&#x2F;exampleldap.blackhats.net.au:3389 -x -s sub -b &amp;#39;ou=People,dc=example,dc=com&amp;#39; &amp;#39;(&amp;amp;(uid=test0006)(uid=guest0006))&amp;#39;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Because the object has both uid=test0006 and uid=guest0006, this returns
the object uid=test0006,ou=People,dc=example,dc=com. However, if we
changed this condition:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&amp;#39;(&amp;amp;(uid=test0006)(uid=guest0007))&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;ldapsearch -H ldap:&#x2F;&#x2F;exampleldap.blackhats.net.au:3389 -x -s sub -b &amp;#39;ou=People,dc=example,dc=com&amp;#39; &amp;#39;(&amp;amp;(uid=test0006)(uid=guest0007))&amp;#39;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;No objects match both predicates, so we have an empty result set.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;or-filters&quot;&gt;OR filters&lt;&#x2F;h2&gt;
&lt;p&gt;OR filters will return the aggregate of all child filters. This is the
union operation. Provided an object satisfies one condition of the OR,
it will be part of the returned set.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&amp;#39;(|(uid=test0006)(uid=guest0007))&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;ldapsearch -H ldap:&#x2F;&#x2F;exampleldap.blackhats.net.au:3389 -x -s sub -b &amp;#39;ou=People,dc=example,dc=com&amp;#39; &amp;#39;(|(uid=test0006)(uid=guest0007))&amp;#39;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If an object is matched twice in the OR filter, we only return it once.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&amp;#39;(|(uid=test0008)(uid=guest0008))&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;ldapsearch -H ldap:&#x2F;&#x2F;exampleldap.blackhats.net.au:3389 -x -s sub -b &amp;#39;ou=People,dc=example,dc=com&amp;#39; &amp;#39;(|(uid=test0008)(uid=guest0008))&amp;#39;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;not-filters&quot;&gt;NOT filters&lt;&#x2F;h2&gt;
&lt;p&gt;A NOT filter acts to invert the result of the inner set. NOT is the
equivalent of a negating AND. For example:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&amp;#39;(!(uid=test0010))&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;ldapsearch -H ldap:&#x2F;&#x2F;exampleldap.blackhats.net.au:3389 -x -s sub -b &amp;#39;ou=People,dc=example,dc=com&amp;#39; &amp;#39;(!(uid=test0010))&amp;#39;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You can&#x27;t list multiple parameters to a not condition however:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&amp;#39;(!(uid=test0010)(uid=test0009))&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;ldapsearch -H ldap:&#x2F;&#x2F;exampleldap.blackhats.net.au:3389 -x -s sub -b &amp;#39;ou=People,dc=example,dc=com&amp;#39; &amp;#39;(!(uid=test0010)(uid=test0009))&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;span&gt;ldap_search_ext: Bad search filter (-7)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;To combine NOT&#x27;s you need to use this in conjunction with AND and OR.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;complex-filters&quot;&gt;Complex filters&lt;&#x2F;h2&gt;
&lt;p&gt;Because AND OR and NOT are filters in their own right, you can nest
these to produce more complex directed queries.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&amp;#39;(&amp;amp;(objectClass=person)(objectClass=posixAccount)(|(uid=test000*))(!(uid=test0001)))&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;ldapsearch -H ldap:&#x2F;&#x2F;exampleldap.blackhats.net.au:3389 -x -s sub -b &amp;#39;ou=People,dc=example,dc=com&amp;#39; &amp;#39;(&amp;amp;(objectClass=person)(objectClass=posixAccount)(|(uid=test000*))(!(uid=test0001)))&amp;#39; uid
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;I find it useful to break this down to see what is happening&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;(&amp;amp;
&lt;&#x2F;span&gt;&lt;span&gt;    (objectClass=person)
&lt;&#x2F;span&gt;&lt;span&gt;    (objectClass=posixAccount)
&lt;&#x2F;span&gt;&lt;span&gt;    (|
&lt;&#x2F;span&gt;&lt;span&gt;        (uid=test000*)
&lt;&#x2F;span&gt;&lt;span&gt;    )
&lt;&#x2F;span&gt;&lt;span&gt;    (!(uid=test0001))
&lt;&#x2F;span&gt;&lt;span&gt;)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This query expresses &amp;quot;All person whose name starts with test000* and
not test0001&amp;quot;. Once broken down over multiple lines like this it&#x27;s
easy to see which filters belong to which logic components, and how they
will interact.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;&#x2F;h2&gt;
&lt;p&gt;While search bases can help you to direct a query, filters are how
searches are efficently expressed over databases of millions of objects.
Being able to use them effectively will help your client applications be
much faster.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>LDAP Guide Part 2: Searching</title>
          <pubDate>Tue, 05 Jul 2016 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/pages/the-ldap-guide-part-2-searching/</link>
          <guid>https://fy.blackhats.net.au/pages/the-ldap-guide-part-2-searching/</guid>
          <description>&lt;h1 id=&quot;ldap-guide-part-2-searching&quot;&gt;LDAP Guide Part 2: Searching&lt;&#x2F;h1&gt;
&lt;p&gt;In the first part, we discussed how and LDAP tree is laid out, and why
it&#x27;s called a &amp;quot;tree&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;In this part, we will discuss the most important and fundamental
component of ldap: Searching.&lt;&#x2F;p&gt;
&lt;p&gt;A note is that &lt;em&gt;all&lt;&#x2F;em&gt; examples and commands in this document &lt;em&gt;work&lt;&#x2F;em&gt;. I
have established an internet facing ldap server with which you can query
to test out searches. This will work on any RPM based system with
openldap-clients installed, or OSX.&lt;&#x2F;p&gt;
&lt;p&gt;To test connectivity you should see the following:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;I0&amp;gt; ldapsearch -H ldap:&#x2F;&#x2F;exampleldap.blackhats.net.au:3389 -b &amp;#39;&amp;#39; -s base -x -LLL vendorVersion
&lt;&#x2F;span&gt;&lt;span&gt;dn:
&lt;&#x2F;span&gt;&lt;span&gt;vendorVersion: 389-Directory&#x2F;1.3.4.0 B2016.175.1716
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If you see any other errors, you have some issue with your network or
environment.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;&#x2F;h2&gt;
&lt;p&gt;Remember that we have a tree of objects, organised by their RDN, the
Relative Distinguished Name.&lt;&#x2F;p&gt;
&lt;p&gt;An LDAP object looks like this:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;dn: ou=Groups,dc=example,dc=com
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: top
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: organizationalunit
&lt;&#x2F;span&gt;&lt;span&gt;ou: Groups
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;We see the DN, which is built from the RDN components. We have a number
of objectClasses that defined the structure and attributes of the
object. Finally, we have the attribute &amp;quot;ou&amp;quot;, which in this case
happens to be our RDN.&lt;&#x2F;p&gt;
&lt;p&gt;A more &amp;quot;complete&amp;quot; object is this example:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;dn: cn=Accounting Managers,ou=Groups,dc=example,dc=com
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: top
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: groupOfUniqueNames
&lt;&#x2F;span&gt;&lt;span&gt;cn: Accounting Managers
&lt;&#x2F;span&gt;&lt;span&gt;ou: groups
&lt;&#x2F;span&gt;&lt;span&gt;description: People who can manage accounting entries
&lt;&#x2F;span&gt;&lt;span&gt;uniqueMember: cn=Directory Manager
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Again we can see the DN, the objectclasses, and the cn, which is our
RDN. We also have a number of other attributes, such as ou, description,
uniqueMember. This are &lt;em&gt;not&lt;&#x2F;em&gt; part of the RDN, but they are still parts
of the object.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;basic-searching&quot;&gt;Basic searching&lt;&#x2F;h2&gt;
&lt;p&gt;Because LDAP is a tree, we must define a basedn: The &amp;quot;root&amp;quot; or
&amp;quot;anchor&amp;quot; point in the tree we want to search beneath. To show what
basedns are avaliable, we can query the special &#x27;&#x27; or blank rootDSE
(Directory Server Entry).&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ldapsearch -H ldap:&#x2F;&#x2F;exampleldap.blackhats.net.au:3389 -b &amp;#39;&amp;#39; -s base -x namingContexts
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;span&gt;namingContexts: dc=example,dc=com
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;We can now use this in our search command: Note the -b argument. This is
the search basedn.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ldapsearch -H ldap:&#x2F;&#x2F;exampleldap.blackhats.net.au:3389 -x -b &amp;#39;dc=example,dc=com&amp;#39;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You should see a lot of data on your screen from that last command! We
just showed every object in the tree. Here is the layout of the data in
the exampleldap server to help you understand that output.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;search-1.svg&quot; alt=&quot;image&quot; &#x2F;&gt;{width=&amp;quot;850px&amp;quot;}&lt;&#x2F;p&gt;
&lt;h2 id=&quot;using-a-different-basedn&quot;&gt;Using a different basedn&lt;&#x2F;h2&gt;
&lt;p&gt;We are not just limited to using the basedn &amp;quot;dc=example,dc=com&amp;quot;. This
returns a lot of data, so sometimes we might want to focus our search.&lt;&#x2F;p&gt;
&lt;p&gt;By default LDAP is performing what is called a &lt;em&gt;subtree&lt;&#x2F;em&gt; search. A
subtree search means &amp;quot;include all entries including the basedn in my
search&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;Lets say we wanted to see just the entries highlighted in blue.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;search-2.svg&quot; alt=&quot;image&quot; &#x2F;&gt;{width=&amp;quot;850px&amp;quot;}&lt;&#x2F;p&gt;
&lt;p&gt;The solution is to &lt;em&gt;change&lt;&#x2F;em&gt; the basedn of our search.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ldapsearch -H ldap:&#x2F;&#x2F;exampleldap.blackhats.net.au:3389 -x -b &amp;#39;ou=Groups,dc=example,dc=com&amp;#39;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now you should see that we only see the results highlighted in blue.&lt;&#x2F;p&gt;
&lt;p&gt;You can try this for other parts of the directory too.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;limiting-the-scope-of-the-search&quot;&gt;Limiting the scope of the search&lt;&#x2F;h2&gt;
&lt;p&gt;As previously mentioned, we are by default performing a subtree search
for ldap. But perhaps we only wanted to focus our search further.&lt;&#x2F;p&gt;
&lt;p&gt;This is controlled by the &#x27;-s&#x27; parameter to the ldapsearch command.&lt;&#x2F;p&gt;
&lt;p&gt;In this case, we want only the nodes again, in blue. This time we want
only the child entries of ou=Groups, but &lt;em&gt;not&lt;&#x2F;em&gt; ou=Groups itself.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;search-3.svg&quot; alt=&quot;image&quot; &#x2F;&gt;{width=&amp;quot;850px&amp;quot;}&lt;&#x2F;p&gt;
&lt;p&gt;Now we need to limit not the basedn of the search, but the &lt;em&gt;scope&lt;&#x2F;em&gt;. The
ldap search scope says which entries we should use. We have already
discussed subtree. In this case we want to use the scope called
&lt;em&gt;onelevel&lt;&#x2F;em&gt;. This means &amp;quot;search entries that are direct children of the
basedn only&amp;quot;.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ldapsearch -H ldap:&#x2F;&#x2F;exampleldap.blackhats.net.au:3389 -x -s onelevel -b &amp;#39;ou=Groups,dc=example,dc=com&amp;#39;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;From the result, you can see, we only see the entries again in blue.&lt;&#x2F;p&gt;
&lt;p&gt;A key point of onelevel is the direct children only are searched. So
were we to move the basedn back up to dc=example,dc=com, and perform a
onelevel search, we will only see the following.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;search-4.svg&quot; alt=&quot;image&quot; &#x2F;&gt;{width=&amp;quot;850px&amp;quot;}&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ldapsearch -H ldap:&#x2F;&#x2F;exampleldap.blackhats.net.au:3389 -x -s onelevel -b &amp;#39;dc=example,dc=com&amp;#39;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;In addition to subtree and onelevel we have one more search scope. The
final scope is named &#x27;base&#x27;. This search scope returns &lt;em&gt;only&lt;&#x2F;em&gt; the
basedn of the search.&lt;&#x2F;p&gt;
&lt;p&gt;So if we were to want to retrieve a single entry by DN, this is how we
would achieve that.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;search-5.svg&quot; alt=&quot;image&quot; &#x2F;&gt;{width=&amp;quot;850px&amp;quot;}&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ldapsearch -H ldap:&#x2F;&#x2F;exampleldap.blackhats.net.au:3389 -x -s base -b &amp;#39;ou=Groups,dc=example,dc=com&amp;#39;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;filtering-a-set-of-objects&quot;&gt;Filtering a set of objects&lt;&#x2F;h2&gt;
&lt;p&gt;The most important part of a search is likely the filter. This defines a
query where the objects returned must match the filter conditions.&lt;&#x2F;p&gt;
&lt;p&gt;A filter applies to every attribute of every object within the search
scope. IE It does not just apply to the RDN of the object.&lt;&#x2F;p&gt;
&lt;p&gt;Filters take the form:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;(attribute=value)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Filters can be nested also with special conditions. The condition
applies to all filters that follow within the same level of brackets.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;(condition (attribute=value)(attribute=value))
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;By default, ldapsearch provides the filter&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;(objectClass=*)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;* is a special value, representing &amp;quot;any possible value&amp;quot;. Because all
objects must have an objectClass, this filter is the equivalent to
saying &amp;quot;all objects&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;You can see this doesn&#x27;t change the output when we run these two
commands:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ldapsearch -H ldap:&#x2F;&#x2F;exampleldap.blackhats.net.au:3389 -x -s sub -b &amp;#39;ou=Groups,dc=example,dc=com&amp;#39; &amp;#39;(objectClass=*)&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;ldapsearch -H ldap:&#x2F;&#x2F;exampleldap.blackhats.net.au:3389 -x -s sub -b &amp;#39;ou=Groups,dc=example,dc=com&amp;#39;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If we were to want to retrieve &lt;em&gt;only&lt;&#x2F;em&gt; the HR Managers group, but we
didn&#x27;t know it&#x27;s RDN &#x2F; DN. Because we know it has the attribute
&amp;quot;cn=HR Managers&amp;quot;, we can construct a filter that will retrieve &amp;quot;any
object where cn exactly matches the value HR Managers.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ldapsearch -H ldap:&#x2F;&#x2F;exampleldap.blackhats.net.au:3389 -x -s sub -b &amp;#39;ou=Groups,dc=example,dc=com&amp;#39; &amp;#39;(cn=HR Managers)&amp;#39;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Say that you did not know that the HR Managers group was in ou=Groups.
The following would also be valid:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ldapsearch -H ldap:&#x2F;&#x2F;exampleldap.blackhats.net.au:3389 -x -s sub -b &amp;#39;dc=example,dc=com&amp;#39; &amp;#39;(cn=HR Managers)&amp;#39;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Thus, you often see queries using the base namingContext of the
directory, but applying filters to limit the objects returned.&lt;&#x2F;p&gt;
&lt;p&gt;More complex filters than this exist, and will be part 3 of this guide.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;attributes-limiting-what-we-get-back&quot;&gt;Attributes: Limiting what we get back&lt;&#x2F;h2&gt;
&lt;p&gt;When we are searching, we often do not want the entire object returned
to us. We only need to see one important piece of data. For our HR
Managers group, we want to know who the members are. Recall the object
is:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;dn: cn=HR Managers,ou=Groups,dc=example,dc=com
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: top
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: groupOfUniqueNames
&lt;&#x2F;span&gt;&lt;span&gt;cn: HR Managers
&lt;&#x2F;span&gt;&lt;span&gt;ou: groups
&lt;&#x2F;span&gt;&lt;span&gt;description: People who can manage HR entries
&lt;&#x2F;span&gt;&lt;span&gt;uniqueMember: cn=Directory Manager
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;We only want to know who is in the uniqueMember attribute: We do not
care for the other values.&lt;&#x2F;p&gt;
&lt;p&gt;The final part of an ldapsearch is control of what attributes are
returned. Once the scope and filters have been applied, the set of
objects returned will only display the attributes in the list.&lt;&#x2F;p&gt;
&lt;p&gt;To do this, you put a space seperated list at the end of the ldap search
command:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ldapsearch -H ldap:&#x2F;&#x2F;exampleldap.blackhats.net.au:3389 -x -s sub -b &amp;#39;dc=example,dc=com&amp;#39; &amp;#39;(cn=HR Managers)&amp;#39; uniqueMember
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You can return multiple attributes if you wish:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ldapsearch -H ldap:&#x2F;&#x2F;exampleldap.blackhats.net.au:3389 -x -s sub -b &amp;#39;dc=example,dc=com&amp;#39; &amp;#39;(cn=HR Managers)&amp;#39; uniqueMember cn
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;&#x2F;h2&gt;
&lt;p&gt;Ldapsearches tend to be very foreign to application developers and
engineers when they first encounter them. Unlike SQL they are not based
on tables and selects, and often the data is more complex is disparate.
However with these controls, being basedn, scope, filter and attributes,
you can completely direct your search to return the exact data that you
require for your application or query.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;fy.blackhats.net.au&#x2F;pages&#x2F;the-ldap-guide-part-2-searching&#x2F;ldap_guide_part_3_filters.html&quot;&gt;PART 3, filters!&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;notes&quot;&gt;Notes:&lt;&#x2F;h2&gt;
&lt;p&gt;The ldap server for this example is setup as:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;sudo yum install -y 389-ds-base
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;example-setup.inf&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;[General]
&lt;&#x2F;span&gt;&lt;span&gt;FullMachineName = localhost.localdomain
&lt;&#x2F;span&gt;&lt;span&gt;ServerRoot = &#x2F;lib&#x2F;dirsrv
&lt;&#x2F;span&gt;&lt;span&gt;SuiteSpotGroup = dirsrv
&lt;&#x2F;span&gt;&lt;span&gt;SuiteSpotUserID = dirsrv
&lt;&#x2F;span&gt;&lt;span&gt;StrictHostCheck = false
&lt;&#x2F;span&gt;&lt;span&gt;[slapd]
&lt;&#x2F;span&gt;&lt;span&gt;AddOrgEntries = Yes
&lt;&#x2F;span&gt;&lt;span&gt;AddSampleEntries = No
&lt;&#x2F;span&gt;&lt;span&gt;HashedRootDNPwd =
&lt;&#x2F;span&gt;&lt;span&gt;InstallLdifFile = suggest
&lt;&#x2F;span&gt;&lt;span&gt;RootDN = cn=Directory Manager
&lt;&#x2F;span&gt;&lt;span&gt;RootDNPwd =
&lt;&#x2F;span&gt;&lt;span&gt;ServerIdentifier = example
&lt;&#x2F;span&gt;&lt;span&gt;ServerPort = 3389
&lt;&#x2F;span&gt;&lt;span&gt;Suffix = dc=example,dc=com
&lt;&#x2F;span&gt;&lt;span&gt;bak_dir = &#x2F;var&#x2F;lib&#x2F;dirsrv&#x2F;slapd-example&#x2F;bak
&lt;&#x2F;span&gt;&lt;span&gt;bindir = &#x2F;bin
&lt;&#x2F;span&gt;&lt;span&gt;cert_dir = &#x2F;etc&#x2F;dirsrv&#x2F;slapd-example
&lt;&#x2F;span&gt;&lt;span&gt;config_dir = &#x2F;etc&#x2F;dirsrv&#x2F;slapd-example
&lt;&#x2F;span&gt;&lt;span&gt;datadir = &#x2F;share
&lt;&#x2F;span&gt;&lt;span&gt;db_dir = &#x2F;var&#x2F;lib&#x2F;dirsrv&#x2F;slapd-example&#x2F;db
&lt;&#x2F;span&gt;&lt;span&gt;ds_bename = userRoot
&lt;&#x2F;span&gt;&lt;span&gt;inst_dir = &#x2F;lib&#x2F;dirsrv&#x2F;slapd-example
&lt;&#x2F;span&gt;&lt;span&gt;ldif_dir = &#x2F;var&#x2F;lib&#x2F;dirsrv&#x2F;slapd-example&#x2F;ldif
&lt;&#x2F;span&gt;&lt;span&gt;localstatedir = &#x2F;var
&lt;&#x2F;span&gt;&lt;span&gt;lock_dir = &#x2F;var&#x2F;lock&#x2F;dirsrv&#x2F;slapd-example
&lt;&#x2F;span&gt;&lt;span&gt;log_dir = &#x2F;var&#x2F;log&#x2F;dirsrv&#x2F;slapd-example
&lt;&#x2F;span&gt;&lt;span&gt;naming_value = example
&lt;&#x2F;span&gt;&lt;span&gt;run_dir = &#x2F;var&#x2F;run&#x2F;dirsrv
&lt;&#x2F;span&gt;&lt;span&gt;sbindir = &#x2F;sbin
&lt;&#x2F;span&gt;&lt;span&gt;schema_dir = &#x2F;etc&#x2F;dirsrv&#x2F;slapd-example&#x2F;schema
&lt;&#x2F;span&gt;&lt;span&gt;sysconfdir = &#x2F;etc
&lt;&#x2F;span&gt;&lt;span&gt;tmp_dir = &#x2F;tmp
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;setup-ds.pl --silent --file example-setup.inf
&lt;&#x2F;span&gt;&lt;span&gt;firewall-cmd --zone=internal --add-service=ldap
&lt;&#x2F;span&gt;&lt;span&gt;systemctl enable dirsrv@example
&lt;&#x2F;span&gt;&lt;span&gt;systemctl stop dirsrv@example
&lt;&#x2F;span&gt;&lt;span&gt;db2ldif -Z example -n userRoot
&lt;&#x2F;span&gt;&lt;span&gt;crontab -e # Put in refresh.sh to run every 4 hours.
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;refresh.sh&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;#!&#x2F;bin&#x2F;bash
&lt;&#x2F;span&gt;&lt;span&gt;systemctl stop dirsrv@example
&lt;&#x2F;span&gt;&lt;span&gt;ldif2db -Z example -n userRoot -i &#x2F;var&#x2F;lib&#x2F;dirsrv&#x2F;slapd-example&#x2F;ldif&#x2F;example-userRoot-2016_07_05_103810.ldif
&lt;&#x2F;span&gt;&lt;span&gt;systemctl start dirsrv@example
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
</description>
      </item>
      <item>
          <title>LDAP Guide Part 1: Foundations</title>
          <pubDate>Mon, 20 Jun 2016 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/pages/the-ldap-guide-part-1-foundations/</link>
          <guid>https://fy.blackhats.net.au/pages/the-ldap-guide-part-1-foundations/</guid>
          <description>&lt;h1 id=&quot;ldap-guide-part-1-foundations&quot;&gt;LDAP Guide Part 1: Foundations&lt;&#x2F;h1&gt;
&lt;p&gt;To understand LDAP we must understand a number of concepts of
datastructures: Specifically graphs.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;undirected&quot;&gt;Undirected&lt;&#x2F;h2&gt;
&lt;p&gt;In computer science, a set of nodes, connected by some set of edges is
called a graph. Here we can see a basic example of a graph.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;graph-basic-1.svg&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Viewing this graph, we can see that it has a number of properties. It
has 4 nodes, and 4 edges. As this is undirected we can assume the link A
to B is as valid as B to A.&lt;&#x2F;p&gt;
&lt;p&gt;We also have a cycle: That is a loop between nodes. We can see this in
B, C, D. If any edge between the set of B, D or B, C, or C, D were
removed, this graph would no longer have cycles.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;directed&quot;&gt;Directed&lt;&#x2F;h2&gt;
&lt;p&gt;A directed graph is where each edge not only defines a link between two
nodes, but also the direction of the link. For example, we can see that
A to B is a valid edge, but B to A is not. We would say that the node
where the link is from is the outgoing node of the edge. Where the node
recieves an egde, IE the arrow, is an incoming edge.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;graph-basic-2.svg&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;In this graph, for a cycle to occur, we must have a set of nodes where
not only the edges exist, but the direction allows a loop. Here, the
cycle is B, C, D. Were the link between C and D reversed, we no longer
have a cycle in our directed graph.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;graph-basic-3.svg&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;trees&quot;&gt;Trees&lt;&#x2F;h2&gt;
&lt;p&gt;A tree is a special case of the directed graph. The properties of a tree
are that:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Each node has 1 and only 1 incoming edge.&lt;&#x2F;li&gt;
&lt;li&gt;The graph may have no cycles.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;An example of a tree is below. You can check and it maintains all the
properties above. Note there is no limit to outbound edges, the only
rule is maximum of one incoming.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;graph-basic-4.svg&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;A property that you regularly see is that nodes are unique in a tree, IE
A will not appear twice. This allows for &lt;em&gt;searching&lt;&#x2F;em&gt; of the tree.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;more-on-nodes&quot;&gt;More on nodes&lt;&#x2F;h2&gt;
&lt;p&gt;So far our nodes have been a bit bland. We can do more with them though.
Instead of just storing a single datum in them, we can instead store the
datum as a key to lookup the node, and then have more complex data in
the value of the node. For example, we can expand our tree to look like
this:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;graph-basic-5.svg&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;This is why having unique keys in our nodes is important. It allows us
to search the tree for that node, and to retrieve the data stored
within.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-does-ldap-look-like&quot;&gt;What does LDAP look like&lt;&#x2F;h2&gt;
&lt;p&gt;LDAP is a tree of objects. Each object has a name, or an RDN (Relative
Distinguished Name). The object itself has many key: value pairs in
it&#x27;s data field. If we visualise this, it looks like this.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;_static&#x2F;graph-basic-6.svg&quot; alt=&quot;image&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;We have the RDN (our tree node&#x27;s key value), displayed by type=value,
and then a set of attributes (the data of the node).&lt;&#x2F;p&gt;
&lt;h2 id=&quot;naming-things&quot;&gt;Naming things&lt;&#x2F;h2&gt;
&lt;p&gt;With LDAP often we want to directly reference an node in the tree. To do
so, we need a way to uniquely reference the nodes as they exist.&lt;&#x2F;p&gt;
&lt;p&gt;Unlike our example trees, where each key is likely to be unique. IE node
with key A is cannot exist twice in the tree. In ldap it &lt;em&gt;is&lt;&#x2F;em&gt; valid to
have a key exist twice, such as ou=People. This raises a challenge.
Previously, we could just &amp;quot;look for A&amp;quot;, and we would have what we
wanted. But now, we must not only know the RDN, aka key, that we want to
retrieve, but the path through the tree from the root to our target node
with the RDN.&lt;&#x2F;p&gt;
&lt;p&gt;This is done by walking down the tree til we find what we want. Looking
at the image above, consider:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;dc=com
&lt;&#x2F;span&gt;&lt;span&gt;dc=example,dc=com
&lt;&#x2F;span&gt;&lt;span&gt;ou=People,dc=example,dc=com
&lt;&#x2F;span&gt;&lt;span&gt;uid=user,ou=People,dc=example,dc=com
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;We can make a Fully Qualified Distinguished Name (FQDN), or just
Distinguished Name(DN), by joining the RDN components. For our example,
uid=user,ou=People,dc=example,dc=com. This is a unique path through the
tree to the node we wish to access.&lt;&#x2F;p&gt;
&lt;p&gt;This should explain why LDAP is called a &amp;quot;tree&amp;quot;, why objects are named
the way they are, and help you to visualise the layout of data in your
own tree.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>GDB: Using memory watch points</title>
          <pubDate>Sat, 11 Jun 2016 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2016-06-11-gdb-using-memory-watch-points/</link>
          <guid>https://fy.blackhats.net.au/blog/2016-06-11-gdb-using-memory-watch-points/</guid>
          <description>&lt;h1 id=&quot;gdb-using-memory-watch-points&quot;&gt;GDB: Using memory watch points&lt;&#x2F;h1&gt;
&lt;p&gt;While programming, we&#x27;ve all seen it.&lt;&#x2F;p&gt;
&lt;p&gt;&amp;quot;Why the hell is that variable set to 1? It should be X!&amp;quot;&lt;&#x2F;p&gt;
&lt;p&gt;A lot of programmers would stack print statements around till the find
the issue. Others, might look at function calls.&lt;&#x2F;p&gt;
&lt;p&gt;But in the arsenal of the programmer, is the debugger. Normally, the
debugger, is really overkill, and too complex to really solve a lot of
issues. But while trying to find an issue like this, it shines.&lt;&#x2F;p&gt;
&lt;p&gt;All the code we are about to discuss is &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;Firstyear&#x2F;liblfdb&quot;&gt;in the liblfdb
git&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>lock free database</title>
          <pubDate>Tue, 07 Jun 2016 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2016-06-07-lock-free-database/</link>
          <guid>https://fy.blackhats.net.au/blog/2016-06-07-lock-free-database/</guid>
          <description>&lt;h1 id=&quot;lock-free-database&quot;&gt;lock free database&lt;&#x2F;h1&gt;
&lt;p&gt;While discussing some ideas with the owner of
&lt;a href=&quot;http:&#x2F;&#x2F;liblfds.org&#x2F;&quot;&gt;liblfds&lt;&#x2F;a&gt; I was thinking about some of the issues
in the database of Directory Server, and other ldap products. What slows
us down?&lt;&#x2F;p&gt;
&lt;h2 id=&quot;why-are-locks-slow&quot;&gt;Why are locks slow?&lt;&#x2F;h2&gt;
&lt;p&gt;It&#x27;s a good idea to read &lt;a href=&quot;http:&#x2F;&#x2F;liblfds.org&#x2F;mediawiki&#x2F;index.php?title=Article:Memory_Barriers&quot;&gt;this
article&lt;&#x2F;a&gt;
to understand Memory Barriers in a cpu.&lt;&#x2F;p&gt;
&lt;p&gt;When you think about the way a mutex has to work, it takes advantage of
these primitives to create a full barrier, and do the compare and
exchange to set the value of the lock, and to guarantee the other memory
is synced to our core. This is pretty full on for cpu time, and in
reverse, to unlock you have to basically do the same again. That&#x27;s a
lot of operations! (NOTE: You do a load barrier on the way in to the
lock, and a store barrier on the unlock. The end result is the full
barrier over the set of operations as a whole.)&lt;&#x2F;p&gt;
&lt;p&gt;Lock contenion is really the killer though. If every thread is blocked
on a single lock, they cannot progress. Given the cost of our lock, if
we are stalling our threads behind a lock, we have cpus waiting to do
nothing during this process. The OS scheduler helps mask this by waking
and running another thread, but eventually contenion will win out.&lt;&#x2F;p&gt;
&lt;p&gt;If we bring NUMA into the picture, our mutex may be in a different NUMA
region than the thread requesting the lock. This adds an impact to
latency as well!&lt;&#x2F;p&gt;
&lt;p&gt;We need to try and avoid these operations if we can, to increase
performance.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;bdb&quot;&gt;BDB&lt;&#x2F;h2&gt;
&lt;p&gt;Currently, BDB basically serialises all operations over a set of locks
to access to the data.&lt;&#x2F;p&gt;
&lt;p&gt;This means that a set of readers and writers will execute &lt;em&gt;in order&lt;&#x2F;em&gt;,
with only one at a time.&lt;&#x2F;p&gt;
&lt;p&gt;Not so great for performance, but great for consistency. We are hit hard
by our locks, and we have issues with NUMA, especially accessing the
page caches, as we regularly have to cross NUMA regions to access the
required memory.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;lmdb&quot;&gt;LMDB&lt;&#x2F;h2&gt;
&lt;p&gt;LMDB does somewhat better. This is based on a COW btree, with reference
counting to accessors. There are still locks scattered through out the
tree, which will have an impact however.&lt;&#x2F;p&gt;
&lt;p&gt;But, LMDB can establish a read only transaction, of which there can be
many, and a serialised, single write transaction. These still suffer
from synchronisation of the locks across cores, because LMDB basically
allows direct memory access to the tree.&lt;&#x2F;p&gt;
&lt;p&gt;As well, NUMA is an issue again: Across a NUMA region, if you access the
DB over one of the boundaries, you will suffer a large performance hit.
LMDB tries to offset this through it&#x27;s use of the VFS for page cache.
However that&#x27;s just passing the buck. You now rely on the kernel to
have the memory pages needed in the correct region, and that&#x27;s not
guaranteed.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-can-we-do&quot;&gt;What can we do?&lt;&#x2F;h2&gt;
&lt;p&gt;We need to think about how CPU and RAM works. We need to avoid crossing
NUMA regions, and we need to avoid costly CPU instructions and
behaviour. We need to avoid contenion on single locks no matter where
they may be. We need our program to act less like a human reasons about
it, and more like how a CPU works: Asynchronously, and with
interprocessor communication. When our program behaviour matches the
hardware, we can achieve better performance, and correctness.&lt;&#x2F;p&gt;
&lt;p&gt;In the testing of lfds, the lfds author has found that Single Thread,
accessing memory within one NUMA region, and without locks, always wins
by operation count. This is compared to even lock free behaviours across
many cores.&lt;&#x2F;p&gt;
&lt;p&gt;This is because in a single thread we don&#x27;t &lt;em&gt;need&lt;&#x2F;em&gt; to lock data. It has
exclusive access, and does not need to contend with other cores. No
mutexes needed, no barriers needed.&lt;&#x2F;p&gt;
&lt;p&gt;So we must minimise our interprocessor traversal if we can, but we want
to keep data into a single CPU region. Our data should ideally be in the
NUMA region we want to access it in, in the end.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;async-db&quot;&gt;Async db&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;em&gt;Disclaimer&lt;&#x2F;em&gt;: This is just an idea, and still needs polish.&lt;&#x2F;p&gt;
&lt;p&gt;We run our database, (be it lmdb, bdb, or something new) in a single
thread, on one cpu. Now that we are within a single CPU, we can dispense
all locking mechanisms, and still have a guarantee that the view of the
data is correct.&lt;&#x2F;p&gt;
&lt;p&gt;Every thread of our application would then be &amp;quot;pinned&amp;quot; to a NUMA
region and core, to ensure that they don&#x27;t move.&lt;&#x2F;p&gt;
&lt;p&gt;We would then use the &lt;a href=&quot;http:&#x2F;&#x2F;liblfds.org&#x2F;mediawiki&#x2F;index.php?title=r7.1.0:Queue_%28bounded,_single_producer,_single_consumer%29&quot;&gt;single producer, single consumer bounded
queue&lt;&#x2F;a&gt;
from this article. Each NUMA region would establish one of these queues
to the database thread. The bounding size is the number of working
threads on the system. Each queue would be thread max for the bound,
even though there are multiple regions. This is because there may be an
unequal distribution of threads to regions, so we may have all threads
in one region.&lt;&#x2F;p&gt;
&lt;p&gt;Now, our database thread can essentially round robbin, and dequeue
requests as they enter. We can use the DB without locks, because we are
serialised within one thread. The results would then be placed back into
the queue, and the requestor of the operation would be able to examine
the results. Because we put the results into the memory space of the
requestor, we pay the NUMA price once as we retrieve the result, rather
than repeatedly like we do now where we access various caches and
allocations.&lt;&#x2F;p&gt;
&lt;p&gt;Why would this be better?&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;We have dispensed completely with ALL mutexes and locks. The queue
in liblfds is fast. Amazingly fast. Seriously, look at &lt;a href=&quot;http:&#x2F;&#x2F;liblfds.org&#x2F;mediawiki&#x2F;index.php?title=r7.1.0:Queue_%28unbounded,_many_producer,_many_consumer%29#Benchmark_Results_and_Analysis&quot;&gt;these
benchmarks&lt;&#x2F;a&gt;.
And that&#x27;s on the many many queue, which is theoretically slower
than the single single bounded queue.&lt;&#x2F;li&gt;
&lt;li&gt;We keep consistency within the database. Because we only have one
thread acting on the data, we have gained serialisation implicitly.&lt;&#x2F;li&gt;
&lt;li&gt;We keep data in the NUMA regions where it needs to be. Rather than
having a large cache that spans potentially many NUMA regions, we
get data as we need, and put it into the numa region of the DB
thread.&lt;&#x2F;li&gt;
&lt;li&gt;Because the data is within a single thread, we take advantage of the
cpu cache heavily, without the expense of the cpu caches to the
other threads. Minimising page evictions and inclusions is a good
thing.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;There are many other potential ways to improve this:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;We could potentially cache entries into the NUMA region. When a
search is requested, provided the serial of the entry hasn&#x27;t been
advanced, the entry still within our NUMA region is valid. This
prevents more moving between NUMA regions, again yielding a benefit.
It would basically be:&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;    Thread A                              Thread DB
&lt;&#x2F;span&gt;&lt;span&gt;    Queue a read transaction with
&lt;&#x2F;span&gt;&lt;span&gt;    thread ID X               --&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;                              &amp;lt;--  Open the transaction, and stash
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    Queue a search for set of IDs --&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;                                    Dequeue search request
&lt;&#x2F;span&gt;&lt;span&gt;                                    Build ID set
&lt;&#x2F;span&gt;&lt;span&gt;                                    With each ID, pair to the &amp;quot;db version&amp;quot; of the entry. IE USN style.
&lt;&#x2F;span&gt;&lt;span&gt;                              &amp;lt;--   Return ID set to queue
&lt;&#x2F;span&gt;&lt;span&gt;    Examine the local cache.
&lt;&#x2F;span&gt;&lt;span&gt;    if ID not in local cache || 
&lt;&#x2F;span&gt;&lt;span&gt;    not USN matches entry in cache
&lt;&#x2F;span&gt;&lt;span&gt;        Add Id to &amp;quot;retrieve set&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    Queue a retrieve request      --&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;                                    Dequeue the retrieve request
&lt;&#x2F;span&gt;&lt;span&gt;                                    Copy the requested IDs &#x2F; entries to Thread A
&lt;&#x2F;span&gt;&lt;span&gt;                              &amp;lt;--   Return
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    Queue a transaction complete  --&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;                              &amp;lt;--   Done
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;acknowledgement&quot;&gt;Acknowledgement&lt;&#x2F;h2&gt;
&lt;p&gt;Huge thank you to Winterflaw, the author of LibLFDS for discussing these
ideas, his future review of this idea, and for teaching me many of these
concepts.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Zero Outage Migration Of Directory Server Infrastructure</title>
          <pubDate>Fri, 03 Jun 2016 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2016-06-03-zero-outage-migration-of-directory-server-infrastructure/</link>
          <guid>https://fy.blackhats.net.au/blog/2016-06-03-zero-outage-migration-of-directory-server-infrastructure/</guid>
          <description>&lt;h1 id=&quot;zero-outage-migration-of-directory-server-infrastructure&quot;&gt;Zero Outage Migration Of Directory Server Infrastructure&lt;&#x2F;h1&gt;
&lt;p&gt;In my previous job I used to manage the Directory Servers for a
University. People used to challenge me that while doing migrations,
downtime was needed.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;They are all wrong&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;It is very possible, and achievable to have zero outage migrations of
Directory Servers. All it takes is some thought, planning, dedication
and testing.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Acis for group creation and delegataion in DS</title>
          <pubDate>Wed, 25 May 2016 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2016-05-25-acis-for-group-creation-and-delegataion-in-ds/</link>
          <guid>https://fy.blackhats.net.au/blog/2016-05-25-acis-for-group-creation-and-delegataion-in-ds/</guid>
          <description>&lt;h1 id=&quot;acis-for-group-creation-and-delegataion-in-ds&quot;&gt;Acis for group creation and delegataion in DS&lt;&#x2F;h1&gt;
&lt;p&gt;Something I get asked about frequently is ACI&#x27;s in Directory Server.
They are a little bit of an art, and they have a lot of edge cases that
you can hit.&lt;&#x2F;p&gt;
&lt;p&gt;I am asked about &amp;quot;how do I give access to uid=X to create groups in
some ou=Y&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;TL;DR: You want the ACI at the end of the post. All the others are
insecure in some way.&lt;&#x2F;p&gt;
&lt;p&gt;So lets do it.&lt;&#x2F;p&gt;
&lt;p&gt;First, I have my user:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;dn: uid=test,ou=People,dc=example,dc=com
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: top
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: account
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: simpleSecurityObject
&lt;&#x2F;span&gt;&lt;span&gt;uid: test
&lt;&#x2F;span&gt;&lt;span&gt;userPassword: {SSHA}LQKDZWFI1cw6EnnYtv74v622aPeNZ9cxXc&#x2F;QIA==
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;And I have the ou I want them to edit:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;dn: ou=custom,ou=Groups,dc=example,dc=com
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: top
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: organizationalUnit
&lt;&#x2F;span&gt;&lt;span&gt;ou: custom
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;So I would put the aci onto ou=custom,ou=Groups,dc=example,dc=com, and
away I go:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;aci: (target = &amp;quot;ldap:&#x2F;&#x2F;&#x2F;ou=custom,ou=groups,dc=example,dc=com&amp;quot;)
&lt;&#x2F;span&gt;&lt;span&gt;     (version 3.0; acl &amp;quot;example&amp;quot;; allow (read, search, write, add)
&lt;&#x2F;span&gt;&lt;span&gt;        (userdn = &amp;quot;ldap:&#x2F;&#x2F;&#x2F;uid=test,ou=People,dc=example,dc=com&amp;quot;);
&lt;&#x2F;span&gt;&lt;span&gt;     )
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Great! Now I can add a group under
ou=custom,ou=Groups,dc=example,dc=com!&lt;&#x2F;p&gt;
&lt;p&gt;But this ACI is REALLY BAD AND INSECURE. Why?&lt;&#x2F;p&gt;
&lt;p&gt;First, it allows uid=test,ou=People,dc=example,dc=com write access to
the ou=custom itself, which means that it can alter the aci, and
potentially grant further rights. That&#x27;s bad.&lt;&#x2F;p&gt;
&lt;p&gt;So lets tighten that up.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;aci: (target = &amp;quot;ldap:&#x2F;&#x2F;&#x2F;cn=*,ou=custom,ou=groups,dc=example,dc=com&amp;quot;)
&lt;&#x2F;span&gt;&lt;span&gt;     (version 3.0; acl &amp;quot;example&amp;quot;; allow (read, search, write, add) 
&lt;&#x2F;span&gt;&lt;span&gt;        (userdn = &amp;quot;ldap:&#x2F;&#x2F;&#x2F;uid=test,ou=People,dc=example,dc=com&amp;quot;);
&lt;&#x2F;span&gt;&lt;span&gt;     )
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Better! Now we can only create objects with cn=* under that ou, and we
can&#x27;t edit the ou or it&#x27;s aci&#x27;s itself. But this is still insecure!
Imagine, that I made:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;dn: cn=fake_root,ou=custom,ou=groups,dc=example,dc=com
&lt;&#x2F;span&gt;&lt;span&gt;....
&lt;&#x2F;span&gt;&lt;span&gt;uid: xxxx
&lt;&#x2F;span&gt;&lt;span&gt;userClass: secure
&lt;&#x2F;span&gt;&lt;span&gt;memberOf: cn=some_privileged_group,....
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Many sites often have their pam_ldap&#x2F;nslcd&#x2F;sssd set to search from the
&lt;em&gt;root&lt;&#x2F;em&gt; IE dc=example,dc=com. Because ldap doesn&#x27;t define a &lt;em&gt;sort&lt;&#x2F;em&gt; order
of responses, this entry may over-ride an exist admin user, or it could
be a new user that matches authorisation filters. This just granted
someone in your org access to all your servers!&lt;&#x2F;p&gt;
&lt;p&gt;But we can prevent this.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;aci: (target = &amp;quot;ldap:&#x2F;&#x2F;&#x2F;cn=*,ou=custom,ou=groups,dc=example,dc=com&amp;quot;)
&lt;&#x2F;span&gt;&lt;span&gt;     (targetfilter=&amp;quot;(&amp;amp;(objectClass=top)(objectClass=groupOfUniqueNames))&amp;quot;)
&lt;&#x2F;span&gt;&lt;span&gt;     (version 3.0; acl &amp;quot;example&amp;quot;; allow (read, search, write, add)
&lt;&#x2F;span&gt;&lt;span&gt;        (userdn = &amp;quot;ldap:&#x2F;&#x2F;&#x2F;uid=test,ou=People,dc=example,dc=com&amp;quot;);
&lt;&#x2F;span&gt;&lt;span&gt;     )
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Looks better! Now we can only create objects with objectClass top, and
groupOfUniqueNames.&lt;&#x2F;p&gt;
&lt;p&gt;Then again ....&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;dn: cn=bar,ou=custom,ou=Groups,dc=example,dc=com
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: top
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: groupOfUniqueNames
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: simpleSecurityObject
&lt;&#x2F;span&gt;&lt;span&gt;cn: bar
&lt;&#x2F;span&gt;&lt;span&gt;userPassword: {SSHA}UYVTFfPFZrN01puFXYJM3nUcn8lQcVSWtJmQIw==
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Just because we say it has to have top and groupOfUniqueNames DOESN&#x27;T
exclude adding more objectClasses!&lt;&#x2F;p&gt;
&lt;p&gt;Finally, if we make the delegation aci:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# This is the secure aci
&lt;&#x2F;span&gt;&lt;span&gt;aci: (target = &amp;quot;ldap:&#x2F;&#x2F;&#x2F;cn=*,ou=custom,ou=groups,dc=example,dc=com&amp;quot;)
&lt;&#x2F;span&gt;&lt;span&gt;     (targetfilter=&amp;quot;(&amp;amp;(objectClass=top)(objectClass=groupOfUniqueNames))&amp;quot;)
&lt;&#x2F;span&gt;&lt;span&gt;     (targetattr=&amp;quot;cn || uniqueMember || objectclass&amp;quot;)
&lt;&#x2F;span&gt;&lt;span&gt;     (version 3.0; acl &amp;quot;example&amp;quot;; allow (read, search, write, add)
&lt;&#x2F;span&gt;&lt;span&gt;        (userdn = &amp;quot;ldap:&#x2F;&#x2F;&#x2F;uid=test,ou=People,dc=example,dc=com&amp;quot;);
&lt;&#x2F;span&gt;&lt;span&gt;     )
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This aci limits creation to &lt;em&gt;only&lt;&#x2F;em&gt; groups of unique names and top, and
limits the attributes to only what can be made in those objectClasses.
&lt;em&gt;Finally&lt;&#x2F;em&gt; we have a secure aci. Even though we can add other
objectClasses, we can never actually add the attributes to satisfy them,
so we effectively limit this to the types show. Even if we add other
objectClasses that take &amp;quot;may&amp;quot; as the attribute, we can never fill in
those attributes either.&lt;&#x2F;p&gt;
&lt;p&gt;Summary: Acis are hard.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>systemd is not monolithic</title>
          <pubDate>Mon, 23 May 2016 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2016-05-23-systemd-is-not-monolithic/</link>
          <guid>https://fy.blackhats.net.au/blog/2016-05-23-systemd-is-not-monolithic/</guid>
          <description>&lt;h1 id=&quot;systemd-is-not-monolithic&quot;&gt;systemd is not monolithic&lt;&#x2F;h1&gt;
&lt;p&gt;Go ahead. Please read &lt;a href=&quot;http:&#x2F;&#x2F;0pointer.de&#x2F;blog&#x2F;projects&#x2F;the-biggest-myths.html&quot;&gt;this post by Lennart about systemd
myths&lt;&#x2F;a&gt;. I&#x27;ll
wait.&lt;&#x2F;p&gt;
&lt;p&gt;Done? Great. You noticed the first point. &amp;quot;Systemd is monolithic&amp;quot;.
Which is carefully &amp;quot;debunked&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;So this morning while building Ds, I noticed my compile failed:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;configure: checking for Systemd...
&lt;&#x2F;span&gt;&lt;span&gt;checking for --with-systemd... using systemd native features
&lt;&#x2F;span&gt;&lt;span&gt;checking for --with-journald... using journald logging: WARNING, this may cause system instability
&lt;&#x2F;span&gt;&lt;span&gt;checking for pkg-config... (cached) &#x2F;usr&#x2F;bin&#x2F;pkg-config
&lt;&#x2F;span&gt;&lt;span&gt;checking for Systemd with pkg-config... configure: error: no Systemd &#x2F; Journald pkg-config files
&lt;&#x2F;span&gt;&lt;span&gt;Makefile:84: recipe for target &amp;#39;ds-configure&amp;#39; failed
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;I hadn&#x27;t changed this part of the code, and it&#x27;s been reliably
compiling for me ... What changed?&lt;&#x2F;p&gt;
&lt;p&gt;Well on RHEL7 here is the layout of the system libraries:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;usr&#x2F;lib64&#x2F;libsystemd-daemon.so
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;usr&#x2F;lib64&#x2F;libsystemd-id128.so
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;usr&#x2F;lib64&#x2F;libsystemd-journal.so
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;usr&#x2F;lib64&#x2F;libsystemd-login.so
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;usr&#x2F;lib64&#x2F;libsystemd.so
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;usr&#x2F;lib64&#x2F;libudev.so
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;They also each come with their own very nice pkg-config file so you can
find them.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;usr&#x2F;lib64&#x2F;pkgconfig&#x2F;libsystemd-daemon.pc
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;usr&#x2F;lib64&#x2F;pkgconfig&#x2F;libsystemd-id128.pc
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;usr&#x2F;lib64&#x2F;pkgconfig&#x2F;libsystemd-journal.pc
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;usr&#x2F;lib64&#x2F;pkgconfig&#x2F;libsystemd-login.pc
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;usr&#x2F;lib64&#x2F;pkgconfig&#x2F;libsystemd.pc
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;usr&#x2F;lib64&#x2F;pkgconfig&#x2F;libudev.pc
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Sure these are big libraries, but it&#x27;s pretty modular. And it&#x27;s nice
they are seperate out.&lt;&#x2F;p&gt;
&lt;p&gt;But today, I compiled on rawhide. What&#x27;s changed:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;usr&#x2F;lib64&#x2F;libsystemd.so
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;usr&#x2F;lib64&#x2F;libudev.so
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;usr&#x2F;lib64&#x2F;pkgconfig&#x2F;libsystemd.pc
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;usr&#x2F;lib64&#x2F;pkgconfig&#x2F;libudev.pc
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;I almost thought this was an error. Surely they put libsystemd-journald
into another package.&lt;&#x2F;p&gt;
&lt;p&gt;No. No they did not.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;I0&amp;gt; readelf -Ws &#x2F;usr&#x2F;lib64&#x2F;libsystemd.so | grep -i journal_print
&lt;&#x2F;span&gt;&lt;span&gt;   297: 00000000000248c0   177 FUNC    GLOBAL DEFAULT   12 sd_journal_print@@LIBSYSTEMD_209
&lt;&#x2F;span&gt;&lt;span&gt;   328: 0000000000024680   564 FUNC    GLOBAL DEFAULT   12 sd_journal_printv@@LIBSYSTEMD_209
&lt;&#x2F;span&gt;&lt;span&gt;   352: 0000000000023d80   788 FUNC    GLOBAL DEFAULT   12 sd_journal_printv_with_location@@LIBSYSTEMD_209
&lt;&#x2F;span&gt;&lt;span&gt;   399: 00000000000240a0   162 FUNC    GLOBAL DEFAULT   12 sd_journal_print_with_location@@LIBSYSTEMD_209
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;So we went from these small modular libraries:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;-rwxr-xr-x. 1 root root  26K May 12 14:29 &#x2F;usr&#x2F;lib64&#x2F;libsystemd-daemon.so.0.0.12
&lt;&#x2F;span&gt;&lt;span&gt;-rwxr-xr-x. 1 root root  21K May 12 14:29 &#x2F;usr&#x2F;lib64&#x2F;libsystemd-id128.so.0.0.28
&lt;&#x2F;span&gt;&lt;span&gt;-rwxr-xr-x. 1 root root 129K May 12 14:29 &#x2F;usr&#x2F;lib64&#x2F;libsystemd-journal.so.0.11.5
&lt;&#x2F;span&gt;&lt;span&gt;-rwxr-xr-x. 1 root root  56K May 12 14:29 &#x2F;usr&#x2F;lib64&#x2F;libsystemd-login.so.0.9.3
&lt;&#x2F;span&gt;&lt;span&gt;-rwxr-xr-x. 1 root root 159K May 12 14:29 &#x2F;usr&#x2F;lib64&#x2F;libsystemd.so.0.6.0
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;To this monolithic library:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;-rwxr-xr-x. 1 root root 556K May 22 14:09 &#x2F;usr&#x2F;lib64&#x2F;libsystemd.so.0.15.0
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&amp;quot;Systemd is not monolithic&amp;quot;.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>389ds on freebsd update</title>
          <pubDate>Sun, 17 Apr 2016 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2016-04-17-389ds-on-freebsd-update/</link>
          <guid>https://fy.blackhats.net.au/blog/2016-04-17-389ds-on-freebsd-update/</guid>
          <description>&lt;h1 id=&quot;389ds-on-freebsd-update&quot;&gt;389ds on freebsd update&lt;&#x2F;h1&gt;
&lt;p&gt;A few months ago I posted an how to build 389-ds for freebsd. This was
to start my porting effort.&lt;&#x2F;p&gt;
&lt;p&gt;I have now finished the port. There are still issues that the perl
setup-ds.pl installer does not work, but this will be resolved soon in
other ways.&lt;&#x2F;p&gt;
&lt;p&gt;For now here are the steps for 389-ds on freebsd. You may need to wait
for a few days for the relevant patches to be in git.&lt;&#x2F;p&gt;
&lt;p&gt;You will need to install these deps:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;autotools
&lt;&#x2F;span&gt;&lt;span&gt;git
&lt;&#x2F;span&gt;&lt;span&gt;openldap-client
&lt;&#x2F;span&gt;&lt;span&gt;db5
&lt;&#x2F;span&gt;&lt;span&gt;cyrus-sasl
&lt;&#x2F;span&gt;&lt;span&gt;pkgconf
&lt;&#x2F;span&gt;&lt;span&gt;nspr
&lt;&#x2F;span&gt;&lt;span&gt;nss
&lt;&#x2F;span&gt;&lt;span&gt;net-snmp
&lt;&#x2F;span&gt;&lt;span&gt;gmake
&lt;&#x2F;span&gt;&lt;span&gt;python34
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You will need to use pip for these python dependencies.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;sudo python3.4 -m ensurepip
&lt;&#x2F;span&gt;&lt;span&gt;sudo pip3.4 install six pyasn1 pyasn1-modules 
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You will need to install svrcore.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;fetch http:&#x2F;&#x2F;www.port389.org&#x2F;binaries&#x2F;svrcore-4.1.1.tar.bz2
&lt;&#x2F;span&gt;&lt;span&gt;tar -xvzf svrcore-4.1.1.tar.bz2
&lt;&#x2F;span&gt;&lt;span&gt;cd svrcore-4.1.1
&lt;&#x2F;span&gt;&lt;span&gt;CFLAGS=&amp;quot;-fPIC &amp;quot;.&#x2F;configure --prefix=&#x2F;opt&#x2F;svrcore
&lt;&#x2F;span&gt;&lt;span&gt;make
&lt;&#x2F;span&gt;&lt;span&gt;sudo make install
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You will need the following python tools checked out:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;git clone https:&#x2F;&#x2F;git.fedorahosted.org&#x2F;git&#x2F;389&#x2F;lib389.git
&lt;&#x2F;span&gt;&lt;span&gt;git clone https:&#x2F;&#x2F;github.com&#x2F;pyldap&#x2F;pyldap.git
&lt;&#x2F;span&gt;&lt;span&gt;cd pyldap
&lt;&#x2F;span&gt;&lt;span&gt;python3.4 setup.py build
&lt;&#x2F;span&gt;&lt;span&gt;sudo python3.4 setup.py install
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now you can clone ds and try to build it:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;cd
&lt;&#x2F;span&gt;&lt;span&gt;git clone https:&#x2F;&#x2F;git.fedorahosted.org&#x2F;git&#x2F;389&#x2F;ds.git
&lt;&#x2F;span&gt;&lt;span&gt;cd ds
&lt;&#x2F;span&gt;&lt;span&gt;.&#x2F;configure --prefix=&#x2F;opt&#x2F;dirsrv --with-openldap=&#x2F;usr&#x2F;local --with-db --with-db-inc=&#x2F;usr&#x2F;local&#x2F;include&#x2F;db5&#x2F; --with-db-lib=&#x2F;usr&#x2F;local&#x2F;lib&#x2F;db5&#x2F; --with-sasl --with-sasl-inc=&#x2F;usr&#x2F;local&#x2F;include&#x2F;sasl&#x2F; --with-sasl-lib=&#x2F;usr&#x2F;local&#x2F;lib&#x2F;sasl2&#x2F; --with-svrcore-inc=&#x2F;opt&#x2F;svrcore&#x2F;include&#x2F; --with-svrcore-lib=&#x2F;opt&#x2F;svrcore&#x2F;lib&#x2F; --with-netsnmp=&#x2F;usr&#x2F;local
&lt;&#x2F;span&gt;&lt;span&gt;gmake
&lt;&#x2F;span&gt;&lt;span&gt;sudo gmake install
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Go back to the lib389 directory:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;sudo pw user add dirsrv
&lt;&#x2F;span&gt;&lt;span&gt;sudo PYTHONPATH=`pwd` python3.4 lib389&#x2F;clitools&#x2F;ds_setup.py -f ~&#x2F;setup-ds-admin.inf -v
&lt;&#x2F;span&gt;&lt;span&gt;sudo chown -R dirsrv:dirsrv &#x2F;opt&#x2F;dirsrv&#x2F;var&#x2F;{run,lock,log,lib}&#x2F;dirsrv
&lt;&#x2F;span&gt;&lt;span&gt;sudo chmod 775 &#x2F;opt&#x2F;dirsrv&#x2F;var
&lt;&#x2F;span&gt;&lt;span&gt;sudo chmod 775 &#x2F;opt&#x2F;dirsrv&#x2F;var&#x2F;*
&lt;&#x2F;span&gt;&lt;span&gt;sudo &#x2F;opt&#x2F;dirsrv&#x2F;sbin&#x2F;ns-slapd -d 0 -D &#x2F;opt&#x2F;dirsrv&#x2F;etc&#x2F;dirsrv&#x2F;slapd-localhost
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This is a really minimal setup routine right now. If it all worked, you
can now run your instance. Here is my output belowe:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;INFO:lib389.tools:Running setup with verbose
&lt;&#x2F;span&gt;&lt;span&gt;INFO:lib389.tools:Using inf from &#x2F;home&#x2F;william&#x2F;setup-ds-admin.inf
&lt;&#x2F;span&gt;&lt;span&gt;INFO:lib389.tools:Configuration [&amp;#39;general&amp;#39;, &amp;#39;slapd&amp;#39;, &amp;#39;rest&amp;#39;, &amp;#39;backend-userRoot&amp;#39;]
&lt;&#x2F;span&gt;&lt;span&gt;INFO:lib389.tools:Configuration general {&amp;#39;selinux&amp;#39;: False, &amp;#39;full_machine_name&amp;#39;: &amp;#39;localhost.localdomain&amp;#39;, &amp;#39;config_version&amp;#39;: 2, &amp;#39;strict_host_checking&amp;#39;: True}
&lt;&#x2F;span&gt;&lt;span&gt;INFO:lib389.tools:Configuration slapd {&amp;#39;secure_port&amp;#39;: 636, &amp;#39;root_password&amp;#39;: &amp;#39;password&amp;#39;, &amp;#39;port&amp;#39;: 389, &amp;#39;cert_dir&amp;#39;: &amp;#39;&#x2F;opt&#x2F;dirsrv&#x2F;etc&#x2F;dirsrv&#x2F;slapd-localhost&#x2F;&amp;#39;, &amp;#39;lock_dir&amp;#39;: &amp;#39;&#x2F;opt&#x2F;dirsrv&#x2F;var&#x2F;lock&#x2F;dirsrv&#x2F;slapd-localhost&amp;#39;, &amp;#39;ldif_dir&amp;#39;: &amp;#39;&#x2F;opt&#x2F;dirsrv&#x2F;var&#x2F;lib&#x2F;dirsrv&#x2F;slapd-localhost&#x2F;ldif&amp;#39;, &amp;#39;backup_dir&amp;#39;: &amp;#39;&#x2F;opt&#x2F;dirsrv&#x2F;var&#x2F;lib&#x2F;dirsrv&#x2F;slapd-localhost&#x2F;bak&amp;#39;, &amp;#39;prefix&amp;#39;: &amp;#39;&#x2F;opt&#x2F;dirsrv&amp;#39;, &amp;#39;instance_name&amp;#39;: &amp;#39;localhost&amp;#39;, &amp;#39;bin_dir&amp;#39;: &amp;#39;&#x2F;opt&#x2F;dirsrv&#x2F;bin&#x2F;&amp;#39;, &amp;#39;data_dir&amp;#39;: &amp;#39;&#x2F;opt&#x2F;dirsrv&#x2F;share&#x2F;&amp;#39;, &amp;#39;local_state_dir&amp;#39;: &amp;#39;&#x2F;opt&#x2F;dirsrv&#x2F;var&amp;#39;, &amp;#39;run_dir&amp;#39;: &amp;#39;&#x2F;opt&#x2F;dirsrv&#x2F;var&#x2F;run&#x2F;dirsrv&amp;#39;, &amp;#39;schema_dir&amp;#39;: &amp;#39;&#x2F;opt&#x2F;dirsrv&#x2F;etc&#x2F;dirsrv&#x2F;slapd-localhost&#x2F;schema&amp;#39;, &amp;#39;config_dir&amp;#39;: &amp;#39;&#x2F;opt&#x2F;dirsrv&#x2F;etc&#x2F;dirsrv&#x2F;slapd-localhost&#x2F;&amp;#39;, &amp;#39;root_dn&amp;#39;: &amp;#39;cn=Directory Manager&amp;#39;, &amp;#39;log_dir&amp;#39;: &amp;#39;&#x2F;opt&#x2F;dirsrv&#x2F;var&#x2F;log&#x2F;dirsrv&#x2F;slapd-localhost&amp;#39;, &amp;#39;tmp_dir&amp;#39;: &amp;#39;&#x2F;tmp&amp;#39;, &amp;#39;user&amp;#39;: &amp;#39;dirsrv&amp;#39;, &amp;#39;group&amp;#39;: &amp;#39;dirsrv&amp;#39;, &amp;#39;db_dir&amp;#39;: &amp;#39;&#x2F;opt&#x2F;dirsrv&#x2F;var&#x2F;lib&#x2F;dirsrv&#x2F;slapd-localhost&#x2F;db&amp;#39;, &amp;#39;sbin_dir&amp;#39;: &amp;#39;&#x2F;opt&#x2F;dirsrv&#x2F;sbin&amp;#39;, &amp;#39;sysconf_dir&amp;#39;: &amp;#39;&#x2F;opt&#x2F;dirsrv&#x2F;etc&amp;#39;, &amp;#39;defaults&amp;#39;: &amp;#39;1.3.5&amp;#39;}
&lt;&#x2F;span&gt;&lt;span&gt;INFO:lib389.tools:Configuration backends [{&amp;#39;name&amp;#39;: &amp;#39;userRoot&amp;#39;, &amp;#39;sample_entries&amp;#39;: True, &amp;#39;suffix&amp;#39;: &amp;#39;dc=example,dc=com&amp;#39;}]
&lt;&#x2F;span&gt;&lt;span&gt;INFO:lib389.tools:PASSED: user &#x2F; group checking
&lt;&#x2F;span&gt;&lt;span&gt;INFO:lib389.tools:PASSED: Hostname strict checking
&lt;&#x2F;span&gt;&lt;span&gt;INFO:lib389.tools:PASSED: prefix checking
&lt;&#x2F;span&gt;&lt;span&gt;INFO:lib389:dir (sys) : &#x2F;opt&#x2F;dirsrv&#x2F;etc&#x2F;sysconfig
&lt;&#x2F;span&gt;&lt;span&gt;INFO:lib389.tools:PASSED: instance checking
&lt;&#x2F;span&gt;&lt;span&gt;INFO:lib389.tools:PASSED: root user checking
&lt;&#x2F;span&gt;&lt;span&gt;INFO:lib389.tools:PASSED: network avaliability checking
&lt;&#x2F;span&gt;&lt;span&gt;INFO:lib389.tools:READY: beginning installation
&lt;&#x2F;span&gt;&lt;span&gt;INFO:lib389.tools:ACTION: creating &#x2F;opt&#x2F;dirsrv&#x2F;var&#x2F;lib&#x2F;dirsrv&#x2F;slapd-localhost&#x2F;bak
&lt;&#x2F;span&gt;&lt;span&gt;INFO:lib389.tools:ACTION: creating &#x2F;opt&#x2F;dirsrv&#x2F;etc&#x2F;dirsrv&#x2F;slapd-localhost&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;INFO:lib389.tools:ACTION: creating &#x2F;opt&#x2F;dirsrv&#x2F;etc&#x2F;dirsrv&#x2F;slapd-localhost&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;INFO:lib389.tools:ACTION: creating &#x2F;opt&#x2F;dirsrv&#x2F;var&#x2F;lib&#x2F;dirsrv&#x2F;slapd-localhost&#x2F;db
&lt;&#x2F;span&gt;&lt;span&gt;INFO:lib389.tools:ACTION: creating &#x2F;opt&#x2F;dirsrv&#x2F;var&#x2F;lib&#x2F;dirsrv&#x2F;slapd-localhost&#x2F;ldif
&lt;&#x2F;span&gt;&lt;span&gt;INFO:lib389.tools:ACTION: creating &#x2F;opt&#x2F;dirsrv&#x2F;var&#x2F;lock&#x2F;dirsrv&#x2F;slapd-localhost
&lt;&#x2F;span&gt;&lt;span&gt;INFO:lib389.tools:ACTION: creating &#x2F;opt&#x2F;dirsrv&#x2F;var&#x2F;log&#x2F;dirsrv&#x2F;slapd-localhost
&lt;&#x2F;span&gt;&lt;span&gt;INFO:lib389.tools:ACTION: creating &#x2F;opt&#x2F;dirsrv&#x2F;var&#x2F;run&#x2F;dirsrv
&lt;&#x2F;span&gt;&lt;span&gt;INFO:lib389.tools:ACTION: Creating certificate database is &#x2F;opt&#x2F;dirsrv&#x2F;etc&#x2F;dirsrv&#x2F;slapd-localhost&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;INFO:lib389.tools:ACTION: Creating dse.ldif
&lt;&#x2F;span&gt;&lt;span&gt;INFO:lib389.tools:FINISH: completed installation
&lt;&#x2F;span&gt;&lt;span&gt;Sucessfully created instance
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[17&#x2F;Apr&#x2F;2016:14:44:21.030683607 +1000] could not open config file &amp;quot;&#x2F;opt&#x2F;dirsrv&#x2F;etc&#x2F;dirsrv&#x2F;slapd-localhost&#x2F;&#x2F;slapd-collations.conf&amp;quot; - absolute path?
&lt;&#x2F;span&gt;&lt;span&gt;[17&#x2F;Apr&#x2F;2016:14:44:21.122087994 +1000] 389-Directory&#x2F;1.3.5.1 B2016.108.412 starting up
&lt;&#x2F;span&gt;&lt;span&gt;[17&#x2F;Apr&#x2F;2016:14:44:21.460033554 +1000] convert_pbe_des_to_aes:  Checking for DES passwords to convert to AES...
&lt;&#x2F;span&gt;&lt;span&gt;[17&#x2F;Apr&#x2F;2016:14:44:21.461012440 +1000] convert_pbe_des_to_aes - No DES passwords found to convert.
&lt;&#x2F;span&gt;&lt;span&gt;[17&#x2F;Apr&#x2F;2016:14:44:21.462712083 +1000] slapd started.  Listening on All Interfaces port 389 for LDAP requests
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If we do an ldapsearch:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;fbsd-389-port# uname -r -s
&lt;&#x2F;span&gt;&lt;span&gt;FreeBSD 10.2-RELEASE
&lt;&#x2F;span&gt;&lt;span&gt;fbsd-389-port# ldapsearch -h localhost -b &amp;#39;&amp;#39; -s base -x +
&lt;&#x2F;span&gt;&lt;span&gt;# extended LDIF
&lt;&#x2F;span&gt;&lt;span&gt;#
&lt;&#x2F;span&gt;&lt;span&gt;# LDAPv3
&lt;&#x2F;span&gt;&lt;span&gt;# base &amp;lt;&amp;gt; with scope baseObject
&lt;&#x2F;span&gt;&lt;span&gt;# filter: (objectclass=*)
&lt;&#x2F;span&gt;&lt;span&gt;# requesting: + 
&lt;&#x2F;span&gt;&lt;span&gt;#
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;#
&lt;&#x2F;span&gt;&lt;span&gt;dn:
&lt;&#x2F;span&gt;&lt;span&gt;creatorsName: cn=server,cn=plugins,cn=config
&lt;&#x2F;span&gt;&lt;span&gt;modifiersName: cn=server,cn=plugins,cn=config
&lt;&#x2F;span&gt;&lt;span&gt;createTimestamp: 20160417044112Z
&lt;&#x2F;span&gt;&lt;span&gt;modifyTimestamp: 20160417044112Z
&lt;&#x2F;span&gt;&lt;span&gt;subschemaSubentry: cn=schema
&lt;&#x2F;span&gt;&lt;span&gt;supportedExtension: 2.16.840.1.113730.3.5.7
&lt;&#x2F;span&gt;&lt;span&gt;supportedExtension: 2.16.840.1.113730.3.5.8
&lt;&#x2F;span&gt;&lt;span&gt;supportedExtension: 1.3.6.1.4.1.4203.1.11.3
&lt;&#x2F;span&gt;&lt;span&gt;supportedExtension: 1.3.6.1.4.1.4203.1.11.1
&lt;&#x2F;span&gt;&lt;span&gt;supportedControl: 2.16.840.1.113730.3.4.2
&lt;&#x2F;span&gt;&lt;span&gt;supportedControl: 2.16.840.1.113730.3.4.3
&lt;&#x2F;span&gt;&lt;span&gt;supportedControl: 2.16.840.1.113730.3.4.4
&lt;&#x2F;span&gt;&lt;span&gt;supportedControl: 2.16.840.1.113730.3.4.5
&lt;&#x2F;span&gt;&lt;span&gt;supportedControl: 1.2.840.113556.1.4.473
&lt;&#x2F;span&gt;&lt;span&gt;supportedControl: 2.16.840.1.113730.3.4.9
&lt;&#x2F;span&gt;&lt;span&gt;supportedControl: 2.16.840.1.113730.3.4.16
&lt;&#x2F;span&gt;&lt;span&gt;supportedControl: 2.16.840.1.113730.3.4.15
&lt;&#x2F;span&gt;&lt;span&gt;supportedControl: 2.16.840.1.113730.3.4.17
&lt;&#x2F;span&gt;&lt;span&gt;supportedControl: 2.16.840.1.113730.3.4.19
&lt;&#x2F;span&gt;&lt;span&gt;supportedControl: 1.3.6.1.1.13.1
&lt;&#x2F;span&gt;&lt;span&gt;supportedControl: 1.3.6.1.1.13.2
&lt;&#x2F;span&gt;&lt;span&gt;supportedControl: 1.3.6.1.4.1.42.2.27.8.5.1
&lt;&#x2F;span&gt;&lt;span&gt;supportedControl: 1.3.6.1.4.1.42.2.27.9.5.2
&lt;&#x2F;span&gt;&lt;span&gt;supportedControl: 1.2.840.113556.1.4.319
&lt;&#x2F;span&gt;&lt;span&gt;supportedControl: 1.3.6.1.4.1.42.2.27.9.5.8
&lt;&#x2F;span&gt;&lt;span&gt;supportedControl: 1.3.6.1.4.1.4203.666.5.16
&lt;&#x2F;span&gt;&lt;span&gt;supportedControl: 2.16.840.1.113730.3.4.14
&lt;&#x2F;span&gt;&lt;span&gt;supportedControl: 2.16.840.1.113730.3.4.20
&lt;&#x2F;span&gt;&lt;span&gt;supportedControl: 1.3.6.1.4.1.1466.29539.12
&lt;&#x2F;span&gt;&lt;span&gt;supportedControl: 2.16.840.1.113730.3.4.12
&lt;&#x2F;span&gt;&lt;span&gt;supportedControl: 2.16.840.1.113730.3.4.18
&lt;&#x2F;span&gt;&lt;span&gt;supportedFeatures: 1.3.6.1.4.1.4203.1.5.1
&lt;&#x2F;span&gt;&lt;span&gt;supportedSASLMechanisms: EXTERNAL
&lt;&#x2F;span&gt;&lt;span&gt;supportedLDAPVersion: 2
&lt;&#x2F;span&gt;&lt;span&gt;supportedLDAPVersion: 3
&lt;&#x2F;span&gt;&lt;span&gt;vendorName: 389 Project
&lt;&#x2F;span&gt;&lt;span&gt;vendorVersion: 389-Directory&#x2F;1.3.5.1 B2016.108.412
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
</description>
      </item>
      <item>
          <title>The future vision of 389-ds</title>
          <pubDate>Sat, 16 Apr 2016 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2016-04-16-the-future-vision-of-389-ds/</link>
          <guid>https://fy.blackhats.net.au/blog/2016-04-16-the-future-vision-of-389-ds/</guid>
          <description>&lt;h1 id=&quot;the-future-vision-of-389-ds&quot;&gt;The future vision of 389-ds&lt;&#x2F;h1&gt;
&lt;p&gt;Disclaimer: This is my vision and analysis of 389-ds and it&#x27;s future.
It is nothing about Red Hat&#x27;s future plans or goals. Like all
predictions, they may not even come true.&lt;&#x2F;p&gt;
&lt;p&gt;As I have said before I&#x27;m part of the 389-ds core team. I really do
have a passion for authentication and identity management: I&#x27;m sure
some of my friends would like to tell me to shut up about it sometimes.&lt;&#x2F;p&gt;
&lt;p&gt;389-ds, or rather, ns-slapd has a lot of history. Originally from the
umich code base, it has moved through Netscape, SUN, Aol and, finally to
Red Hat. It&#x27;s quite something to find myself working on code that was
written in 1996. In 1996 I was on a playground in Primary School, where
my biggest life concerns was if I could see the next episode of [anime
of choice] the next day at before school care. What I&#x27;m saying, is
ns-slapd is old. Very old. There are many dark, untrodden paths in that
code base.&lt;&#x2F;p&gt;
&lt;p&gt;You would get your nice big iron machine from SUN, you would setup the
ns-slapd instance once. You would then probably setup one other ns-slapd
master, then you would run them in production for the next 4 to 5 years
with minimal changes. Business policy would ask developers to integrate
with the LDAP server. Everything was great.&lt;&#x2F;p&gt;
&lt;p&gt;But it&#x27;s not 1996 anymore. I have managed to complete schooling and
acquire a degree in this time. ns-slapd has had many improvements, but
the work flow and way that ns-slapd in managed really hasn&#x27;t changed a
lot.&lt;&#x2F;p&gt;
&lt;p&gt;While ns-slapd has stayed roughly the same, the world has evolved. We
now have latte sipping code hipsters, sitting in trendy Melbourne cafes
programming in go and whatever js framework of this week. They deploy to
AWS, to GCE. (But not Azure, that&#x27;s not cool enough). These developers
have a certain mindset and the benefits of centralised business
authentication isn&#x27;t one of them. They want to push things to cloud,
but no system administrator would let a corporate LDAP be avaliable on
the internet. CIO&#x27;s are all drinking the &amp;quot;cloud&amp;quot; &amp;quot;disruption&amp;quot; kool
aid. The future of many technologies is certainly in question.&lt;&#x2F;p&gt;
&lt;p&gt;To me, there is no doubt that ns-slapd is still a great technology: Like
the unix philosohpy, tools should do &amp;quot;one thing&amp;quot; and &amp;quot;one thing
well&amp;quot;. When it comes to secure authentication, user identification, and
authorisation, LDAP is still king. So why are people not deploying it in
their new fancy containers and cloud disruption train that they are all
aboard?&lt;&#x2F;p&gt;
&lt;p&gt;ns-slapd is old. Our systems and installers, such as setup-ds.pl are
really designed for the &amp;quot;pet&amp;quot; mentality of servers. They are hard to
automate to replica groups, and they inist on having certain types of
information avaliable before they can run. They also don&#x27;t work with
automation, and are unable to accept certain types of ldifs as part of
the inf file that drives the install. You have to have at least a few
years experience with ns-slapd before you could probably get this
process &amp;quot;right&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;Another, well, LDAP is ... well, hard. It&#x27;s not json (which is
apparently the only thing developers understand now). Developers also
don&#x27;t care about identifying users. That&#x27;s just not &lt;em&gt;cool&lt;&#x2F;em&gt;. Why would
we try and use some &amp;quot;hard&amp;quot; LDAP system, when I can just keep some json
in a mongodb that tracks your password and groups you are in?&lt;&#x2F;p&gt;
&lt;p&gt;So what can we do? Where do I see 389-ds going in the future?&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;We need to modernise our tooling, and installers. It needs to be
easier than ever to setup an LDAP instance. Our administration needs
to move away from applying ldifs, into robust, command line tools.&lt;&#x2F;li&gt;
&lt;li&gt;Setting up replication groups and masters needs to be simpler.
Replication topologies should be &amp;quot;self managing&amp;quot; (to an extent).
Ie I should say &amp;quot;here is a new ldap server, join this replication
group&amp;quot;. The administration layer then determines all the needed
replication agreements for robust and avaliable service.&lt;&#x2F;li&gt;
&lt;li&gt;We need to get away from long lived static masters, and be able to
have rapidly deployed, and destroyed, masters. With the changes
above, this will lend itself to faster and easier deployment into
containers and other such systems.&lt;&#x2F;li&gt;
&lt;li&gt;During updates, we need to start to enable smarter choices by
default: but still allow people to fix their systems on certain
configurations to guarantee stability. For example, we add new
options and improvements to DS all the time: but we cannot always
enable them by default. This makes our system look dated, when
really a few configurations would really modernise and help improve
deployments. Having mechanisms to push the updates to clients who
want it, and enable them by default on new installs will go a long
way.&lt;&#x2F;li&gt;
&lt;li&gt;Out of the box we need smarter settings: The &lt;em&gt;default&lt;&#x2F;em&gt; install
should need almost &lt;em&gt;no changes&lt;&#x2F;em&gt; to be a strong, working LDAP system.
It should not require massive changes or huge amounts of indepth
knowledge to deploy. I&#x27;m the LDAP expert: You&#x27;re the coffee
sipping developer. You should be able to trust the defaults we give
you, and know that they will be well engineered and carefully
considered.&lt;&#x2F;li&gt;
&lt;li&gt;Finally I think what is also going to be really important is Web
Based authentication. We need to provide ways to setup and provision
SAML and OAuth systems that &amp;quot;just work&amp;quot; with our LDAP. With
improvements on the way like &lt;a href=&quot;https:&#x2F;&#x2F;tools.ietf.org&#x2F;html&#x2F;draft-wibrown-ldapssotoken-00&quot;&gt;this draft
rfc&lt;&#x2F;a&gt; will
even allow fail over between token systems, backed by the high
security and performance guarantees of LDAP.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;This is my vision of the future for 389-ds: Simplification of setup.
Polish of the configuration. Ability to automate and tools to empower
administrators. Integration with what developers want.&lt;&#x2F;p&gt;
&lt;p&gt;Lets see how much myself and the team can achieve by the end of 2016.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Disabling journald support</title>
          <pubDate>Thu, 14 Apr 2016 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2016-04-14-disabling-journald-support/</link>
          <guid>https://fy.blackhats.net.au/blog/2016-04-14-disabling-journald-support/</guid>
          <description>&lt;h1 id=&quot;disabling-journald-support&quot;&gt;Disabling journald support&lt;&#x2F;h1&gt;
&lt;p&gt;Some people may have noticed that there is a feature open for Directory
Server to support journald.&lt;&#x2F;p&gt;
&lt;p&gt;As of April 13th, we have decided to disable support for this in
Directory Server.&lt;&#x2F;p&gt;
&lt;p&gt;This isn&#x27;t because anyone necesarrily hates or dislikes systemd. All
too often people discount systemd due to a hate reflex.&lt;&#x2F;p&gt;
&lt;p&gt;This decision came about due to known, hard, technical limitations of
journald. This is not hand waving opinion, this is based on testing,
numbers, business requirements and experience.&lt;&#x2F;p&gt;
&lt;p&gt;So lets step back for a second. Directory Server is an LDAP server. On a
network, LDAP is deployed typically to be responsible for authentication
and authorisation of users to services. This is a highly security
sensitive role. This leads to an important facet of security being
auditability. For example, the need to track when and who has
authenticated to a network. The ability to audit what permisions were
requested and granted. Further more, the ability to audit and identify
&lt;em&gt;changes&lt;&#x2F;em&gt; to Directory Server data which may represent a compromise or
change of user credential or authorisation rights.&lt;&#x2F;p&gt;
&lt;p&gt;Being able to audit these is of vital importance, from small buisinesses
to large enterprise. As a security system, this audit trail must have
guarantees of &lt;em&gt;correctness&lt;&#x2F;em&gt; and &lt;em&gt;avaliablility&lt;&#x2F;em&gt;. Often a business will
have internal rules around the length of time auditing information must
be retained for. In other businesses there are legal requirements for
auditing information to be retained for long periods. Often a business
will keep in excess of 2 weeks of authentication and authorisation data
for the purposes of auditing.&lt;&#x2F;p&gt;
&lt;p&gt;Directory Server provides this auditing capability through it&#x27;s logging
functions. Directory Server is configured to produce 3 log types.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;errors - Contains Directory Server operations, plugin data, changes.
This is used by administrators to identify service behaviour and
issues.&lt;&#x2F;li&gt;
&lt;li&gt;access - Contains a log of all search and bind (authentication)
operations.&lt;&#x2F;li&gt;
&lt;li&gt;audit - Contains a log of all modifications, additions and deletions
of objects within the Directory Server.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;For the purpose of auditing in a security context the access and audit
logs are of vital importance, as is their retention times.&lt;&#x2F;p&gt;
&lt;p&gt;So why is journald not fit for purpose in this context? It seems to be
fine for many other systems?&lt;&#x2F;p&gt;
&lt;p&gt;Out of the box, journald has a &lt;em&gt;hardcoded&lt;&#x2F;em&gt; limit on the maximum capacity
of logs. This is 4GB of on disk capacity. Once this is exceeded, the
journal rotates, and begins to overwrite entries at the beginging of the
log. Think circular buffer. After testing and identifying the behaviours
of Directory Server, and the size of journald messages, I determined
that a medium to large site will cause the journal to begin a rotation
in 3 hours or less during high traffic periods.&lt;&#x2F;p&gt;
&lt;p&gt;3 hours is a far smaller number than the &amp;quot;weeks&amp;quot; of retention that is
required for auditing purposes of most businesses.&lt;&#x2F;p&gt;
&lt;p&gt;Additionally, by default journald is configured to drop events if they
enter the log to rapidly. This is a &amp;quot;performance&amp;quot; enhancement.
However, during my tests I found that 85% of Directory Server events
were being dropped. This violates the need for correct and complete
audit logs in a security system.&lt;&#x2F;p&gt;
&lt;p&gt;This &lt;em&gt;can&lt;&#x2F;em&gt; be reconfigured, but the question should be asked. Why are
log events dropped at all? On a system, log events are the basis of
auditing and accountability, forming a historical account of evidence
for an Administrator or Security personel to trace in the event of an
incident. Dropping events from Directory Server &lt;em&gt;is unacceptable&lt;&#x2F;em&gt;. As I
stated, this can be reconfigured.&lt;&#x2F;p&gt;
&lt;p&gt;But it does begin to expose the third point. Performance. Journald is
slow, and caused an increase of 15% cpu and higher IO on my testing
environments. For a system such as Directory Server, this overhead is
unacceptable. We consider performance impacts of 2% to be signifigant:
We cannot accept 15%.&lt;&#x2F;p&gt;
&lt;p&gt;As an API journald is quite nice, and has many useful features. However,
we as a team cannot support journald with these three limitations above.&lt;&#x2F;p&gt;
&lt;p&gt;If journald support is to be taken seriously by security and performance
sensitive applications the following changes are recomended.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Remove the 4G log size limit. It can either be configurable by a
user, or there should be no limits.&lt;&#x2F;li&gt;
&lt;li&gt;Log events should either not be dropped by default, or a method to
have per systemd unit file overrides to prevent dropping of certain
services events should be added.&lt;&#x2F;li&gt;
&lt;li&gt;The performance of journald should be improved as to reduce the
impact upon applications consuming the journald api.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;I hope that this explains why we have decided to remove systemd&#x27;s
journald support from Directory Server at this time.&lt;&#x2F;p&gt;
&lt;p&gt;Before I am asked: No I will not reverse my stance on this matter, and I
will continue to advise my team of the same. Systemd needs to come to
the table and improve their api before we can consider it for use.&lt;&#x2F;p&gt;
&lt;p&gt;The upstream issue can be seen here &lt;a href=&quot;https:&#x2F;&#x2F;fedorahosted.org&#x2F;389&#x2F;ticket&#x2F;47968&quot;&gt;389 ds trac
47968&lt;&#x2F;a&gt;. All of my
calculations are in this thread too.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Enabling the 389 ds nightly builds</title>
          <pubDate>Thu, 14 Apr 2016 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2016-04-14-enabling-the-389-ds-nightly-builds/</link>
          <guid>https://fy.blackhats.net.au/blog/2016-04-14-enabling-the-389-ds-nightly-builds/</guid>
          <description>&lt;h1 id=&quot;enabling-the-389-ds-nightly-builds&quot;&gt;Enabling the 389 ds nightly builds&lt;&#x2F;h1&gt;
&lt;p&gt;I maintain a copr repo which I try to keep update with &amp;quot;nightly&amp;quot;
builds of 389-ds.&lt;&#x2F;p&gt;
&lt;p&gt;You can use the following to enable them for EL7:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;sudo -s
&lt;&#x2F;span&gt;&lt;span&gt;cd &#x2F;etc&#x2F;yum.repos.d
&lt;&#x2F;span&gt;&lt;span&gt;wget https:&#x2F;&#x2F;copr.fedorainfracloud.org&#x2F;coprs&#x2F;firstyear&#x2F;ds&#x2F;repo&#x2F;epel-7&#x2F;firstyear-ds-epel-7.repo
&lt;&#x2F;span&gt;&lt;span&gt;wget https:&#x2F;&#x2F;copr.fedorainfracloud.org&#x2F;coprs&#x2F;firstyear&#x2F;svrcore&#x2F;repo&#x2F;epel-7&#x2F;firstyear-svrcore-epel-7.repo
&lt;&#x2F;span&gt;&lt;span&gt;wget https:&#x2F;&#x2F;copr.fedorainfracloud.org&#x2F;coprs&#x2F;firstyear&#x2F;rest389&#x2F;repo&#x2F;epel-7&#x2F;firstyear-rest389-epel-7.repo
&lt;&#x2F;span&gt;&lt;span&gt;wget https:&#x2F;&#x2F;copr.fedorainfracloud.org&#x2F;coprs&#x2F;firstyear&#x2F;lib389&#x2F;repo&#x2F;epel-7&#x2F;firstyear-lib389-epel-7.repo
&lt;&#x2F;span&gt;&lt;span&gt;yum install python-lib389 python-rest389 389-ds-base
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
</description>
      </item>
      <item>
          <title>389 ds aci linting tool</title>
          <pubDate>Fri, 01 Apr 2016 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2016-04-01-389-ds-aci-linting-tool/</link>
          <guid>https://fy.blackhats.net.au/blog/2016-04-01-389-ds-aci-linting-tool/</guid>
          <description>&lt;h1 id=&quot;389-ds-aci-linting-tool&quot;&gt;389 ds aci linting tool&lt;&#x2F;h1&gt;
&lt;p&gt;In the past I have discussed aci&#x27;s and their management in directory
server.&lt;&#x2F;p&gt;
&lt;p&gt;It&#x27;s a very complex topic, and there are issues that can arise.&lt;&#x2F;p&gt;
&lt;p&gt;I have now created an aci linting tool which can connect to a directory
server and detect common mistakes in acis, along with explinations of
how to correct them.&lt;&#x2F;p&gt;
&lt;p&gt;This will be in a release of lib389 in the future. For now, it&#x27;s under
review and hopefully will be accepted soon!&lt;&#x2F;p&gt;
&lt;p&gt;Here is sample output below.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;-------------------------------------------------------------------------------
&lt;&#x2F;span&gt;&lt;span&gt;Directory Server Aci Lint Error: DSALE0001
&lt;&#x2F;span&gt;&lt;span&gt;Severity: HIGH
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Affected Acis:
&lt;&#x2F;span&gt;&lt;span&gt;(targetattr!=&amp;quot;userPassword&amp;quot;)(version 3.0; acl &amp;quot;Enable anonymous access&amp;quot;; allow (read, search, compare) userdn=&amp;quot;ldap:&#x2F;&#x2F;&#x2F;anyone&amp;quot;;)
&lt;&#x2F;span&gt;&lt;span&gt;(targetattr !=&amp;quot;cn || sn || uid&amp;quot;)(targetfilter =&amp;quot;(ou=Accounting)&amp;quot;)(version 3.0;acl &amp;quot;Accounting Managers Group Permissions&amp;quot;;allow (write)(groupdn = &amp;quot;ldap:&#x2F;&#x2F;&#x2F;cn=Accounting Managers,ou=groups,dc=example,dc=com&amp;quot;);)
&lt;&#x2F;span&gt;&lt;span&gt;(targetattr !=&amp;quot;cn || sn || uid&amp;quot;)(targetfilter =&amp;quot;(ou=Human Resources)&amp;quot;)(version 3.0;acl &amp;quot;HR Group Permissions&amp;quot;;allow (write)(groupdn = &amp;quot;ldap:&#x2F;&#x2F;&#x2F;cn=HR Managers,ou=groups,dc=example,dc=com&amp;quot;);)
&lt;&#x2F;span&gt;&lt;span&gt;(targetattr !=&amp;quot;cn ||sn || uid&amp;quot;)(targetfilter =&amp;quot;(ou=Product Testing)&amp;quot;)(version 3.0;acl &amp;quot;QA Group Permissions&amp;quot;;allow (write)(groupdn = &amp;quot;ldap:&#x2F;&#x2F;&#x2F;cn=QA Managers,ou=groups,dc=example,dc=com&amp;quot;);)
&lt;&#x2F;span&gt;&lt;span&gt;(targetattr !=&amp;quot;cn || sn || uid&amp;quot;)(targetfilter =&amp;quot;(ou=Product Development)&amp;quot;)(version 3.0;acl &amp;quot;Engineering Group Permissions&amp;quot;;allow (write)(groupdn = &amp;quot;ldap:&#x2F;&#x2F;&#x2F;cn=PD Managers,ou=groups,dc=example,dc=com&amp;quot;);)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Details: 
&lt;&#x2F;span&gt;&lt;span&gt;An aci of the form &amp;quot;(targetAttr!=&amp;quot;attr&amp;quot;)&amp;quot; exists on your system. This aci
&lt;&#x2F;span&gt;&lt;span&gt;will internally be expanded to mean &amp;quot;all possible attributes including system,
&lt;&#x2F;span&gt;&lt;span&gt;excluding the listed attributes&amp;quot;.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;This may allow access to a bound user or anonymous to read more data about
&lt;&#x2F;span&gt;&lt;span&gt;directory internals, including aci state or user limits. In the case of write 
&lt;&#x2F;span&gt;&lt;span&gt;acis it may allow a dn to set their own resource limits, unlock passwords or
&lt;&#x2F;span&gt;&lt;span&gt;their own aci.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;The ability to change the aci on the object may lead to privilege escalation in
&lt;&#x2F;span&gt;&lt;span&gt;some cases.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Advice: 
&lt;&#x2F;span&gt;&lt;span&gt;Convert the aci to the form &amp;quot;(targetAttr=&amp;quot;x || y || z&amp;quot;)&amp;quot;.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;-------------------------------------------------------------------------------
&lt;&#x2F;span&gt;&lt;span&gt;Directory Server Aci Lint Error: DSALE0002
&lt;&#x2F;span&gt;&lt;span&gt;Severity: HIGH
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Affected Acis:
&lt;&#x2F;span&gt;&lt;span&gt;ou=People,dc=example,dc=com (targetattr !=&amp;quot;cn || sn || uid&amp;quot;)(targetfilter =&amp;quot;(ou=Accounting)&amp;quot;)(version 3.0;acl &amp;quot;Accounting Managers Group Permissions&amp;quot;;allow (write)(groupdn = &amp;quot;ldap:&#x2F;&#x2F;&#x2F;cn=Accounting Managers,ou=groups,dc=example,dc=com&amp;quot;);)
&lt;&#x2F;span&gt;&lt;span&gt;|- ou=People,dc=example,dc=com (targetattr !=&amp;quot;cn || sn || uid&amp;quot;)(targetfilter =&amp;quot;(ou=Human Resources)&amp;quot;)(version 3.0;acl &amp;quot;HR Group Permissions&amp;quot;;allow (write)(groupdn = &amp;quot;ldap:&#x2F;&#x2F;&#x2F;cn=HR Managers,ou=groups,dc=example,dc=com&amp;quot;);)
&lt;&#x2F;span&gt;&lt;span&gt;|- ou=People,dc=example,dc=com (targetattr !=&amp;quot;cn ||sn || uid&amp;quot;)(targetfilter =&amp;quot;(ou=Product Testing)&amp;quot;)(version 3.0;acl &amp;quot;QA Group Permissions&amp;quot;;allow (write)(groupdn = &amp;quot;ldap:&#x2F;&#x2F;&#x2F;cn=QA Managers,ou=groups,dc=example,dc=com&amp;quot;);)
&lt;&#x2F;span&gt;&lt;span&gt;|- ou=People,dc=example,dc=com (targetattr !=&amp;quot;cn || sn || uid&amp;quot;)(targetfilter =&amp;quot;(ou=Product Development)&amp;quot;)(version 3.0;acl &amp;quot;Engineering Group Permissions&amp;quot;;allow (write)(groupdn = &amp;quot;ldap:&#x2F;&#x2F;&#x2F;cn=PD Managers,ou=groups,dc=example,dc=com&amp;quot;);)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;ou=People,dc=example,dc=com (targetattr !=&amp;quot;cn || sn || uid&amp;quot;)(targetfilter =&amp;quot;(ou=Human Resources)&amp;quot;)(version 3.0;acl &amp;quot;HR Group Permissions&amp;quot;;allow (write)(groupdn = &amp;quot;ldap:&#x2F;&#x2F;&#x2F;cn=HR Managers,ou=groups,dc=example,dc=com&amp;quot;);)
&lt;&#x2F;span&gt;&lt;span&gt;|- ou=People,dc=example,dc=com (targetattr !=&amp;quot;cn || sn || uid&amp;quot;)(targetfilter =&amp;quot;(ou=Accounting)&amp;quot;)(version 3.0;acl &amp;quot;Accounting Managers Group Permissions&amp;quot;;allow (write)(groupdn = &amp;quot;ldap:&#x2F;&#x2F;&#x2F;cn=Accounting Managers,ou=groups,dc=example,dc=com&amp;quot;);)
&lt;&#x2F;span&gt;&lt;span&gt;|- ou=People,dc=example,dc=com (targetattr !=&amp;quot;cn ||sn || uid&amp;quot;)(targetfilter =&amp;quot;(ou=Product Testing)&amp;quot;)(version 3.0;acl &amp;quot;QA Group Permissions&amp;quot;;allow (write)(groupdn = &amp;quot;ldap:&#x2F;&#x2F;&#x2F;cn=QA Managers,ou=groups,dc=example,dc=com&amp;quot;);)
&lt;&#x2F;span&gt;&lt;span&gt;|- ou=People,dc=example,dc=com (targetattr !=&amp;quot;cn || sn || uid&amp;quot;)(targetfilter =&amp;quot;(ou=Product Development)&amp;quot;)(version 3.0;acl &amp;quot;Engineering Group Permissions&amp;quot;;allow (write)(groupdn = &amp;quot;ldap:&#x2F;&#x2F;&#x2F;cn=PD Managers,ou=groups,dc=example,dc=com&amp;quot;);)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;ou=People,dc=example,dc=com (targetattr !=&amp;quot;cn ||sn || uid&amp;quot;)(targetfilter =&amp;quot;(ou=Product Testing)&amp;quot;)(version 3.0;acl &amp;quot;QA Group Permissions&amp;quot;;allow (write)(groupdn = &amp;quot;ldap:&#x2F;&#x2F;&#x2F;cn=QA Managers,ou=groups,dc=example,dc=com&amp;quot;);)
&lt;&#x2F;span&gt;&lt;span&gt;|- ou=People,dc=example,dc=com (targetattr !=&amp;quot;cn || sn || uid&amp;quot;)(targetfilter =&amp;quot;(ou=Accounting)&amp;quot;)(version 3.0;acl &amp;quot;Accounting Managers Group Permissions&amp;quot;;allow (write)(groupdn = &amp;quot;ldap:&#x2F;&#x2F;&#x2F;cn=Accounting Managers,ou=groups,dc=example,dc=com&amp;quot;);)
&lt;&#x2F;span&gt;&lt;span&gt;|- ou=People,dc=example,dc=com (targetattr !=&amp;quot;cn || sn || uid&amp;quot;)(targetfilter =&amp;quot;(ou=Human Resources)&amp;quot;)(version 3.0;acl &amp;quot;HR Group Permissions&amp;quot;;allow (write)(groupdn = &amp;quot;ldap:&#x2F;&#x2F;&#x2F;cn=HR Managers,ou=groups,dc=example,dc=com&amp;quot;);)
&lt;&#x2F;span&gt;&lt;span&gt;|- ou=People,dc=example,dc=com (targetattr !=&amp;quot;cn || sn || uid&amp;quot;)(targetfilter =&amp;quot;(ou=Product Development)&amp;quot;)(version 3.0;acl &amp;quot;Engineering Group Permissions&amp;quot;;allow (write)(groupdn = &amp;quot;ldap:&#x2F;&#x2F;&#x2F;cn=PD Managers,ou=groups,dc=example,dc=com&amp;quot;);)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;ou=People,dc=example,dc=com (targetattr !=&amp;quot;cn || sn || uid&amp;quot;)(targetfilter =&amp;quot;(ou=Product Development)&amp;quot;)(version 3.0;acl &amp;quot;Engineering Group Permissions&amp;quot;;allow (write)(groupdn = &amp;quot;ldap:&#x2F;&#x2F;&#x2F;cn=PD Managers,ou=groups,dc=example,dc=com&amp;quot;);)
&lt;&#x2F;span&gt;&lt;span&gt;|- ou=People,dc=example,dc=com (targetattr !=&amp;quot;cn || sn || uid&amp;quot;)(targetfilter =&amp;quot;(ou=Accounting)&amp;quot;)(version 3.0;acl &amp;quot;Accounting Managers Group Permissions&amp;quot;;allow (write)(groupdn = &amp;quot;ldap:&#x2F;&#x2F;&#x2F;cn=Accounting Managers,ou=groups,dc=example,dc=com&amp;quot;);)
&lt;&#x2F;span&gt;&lt;span&gt;|- ou=People,dc=example,dc=com (targetattr !=&amp;quot;cn || sn || uid&amp;quot;)(targetfilter =&amp;quot;(ou=Human Resources)&amp;quot;)(version 3.0;acl &amp;quot;HR Group Permissions&amp;quot;;allow (write)(groupdn = &amp;quot;ldap:&#x2F;&#x2F;&#x2F;cn=HR Managers,ou=groups,dc=example,dc=com&amp;quot;);)
&lt;&#x2F;span&gt;&lt;span&gt;|- ou=People,dc=example,dc=com (targetattr !=&amp;quot;cn ||sn || uid&amp;quot;)(targetfilter =&amp;quot;(ou=Product Testing)&amp;quot;)(version 3.0;acl &amp;quot;QA Group Permissions&amp;quot;;allow (write)(groupdn = &amp;quot;ldap:&#x2F;&#x2F;&#x2F;cn=QA Managers,ou=groups,dc=example,dc=com&amp;quot;);)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Details: 
&lt;&#x2F;span&gt;&lt;span&gt;Acis on your system exist which are both not equals targetattr, and overlap in
&lt;&#x2F;span&gt;&lt;span&gt;scope.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;The way that directory server processes these, is to invert them to to white
&lt;&#x2F;span&gt;&lt;span&gt;lists, then union the results.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;As a result, these acis *may* allow access to the attributes you want them to
&lt;&#x2F;span&gt;&lt;span&gt;exclude.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Consider:
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;aci: (targetattr !=&amp;quot;cn&amp;quot;)(version 3.0;acl &amp;quot;Self write all but cn&amp;quot;;allow (write)
&lt;&#x2F;span&gt;&lt;span&gt;    (userdn = &amp;quot;ldap:&#x2F;&#x2F;&#x2F;self&amp;quot;);)
&lt;&#x2F;span&gt;&lt;span&gt;aci: (targetattr !=&amp;quot;sn&amp;quot;)(version 3.0;acl &amp;quot;Self write all but sn&amp;quot;;allow (write)
&lt;&#x2F;span&gt;&lt;span&gt;    (userdn = &amp;quot;ldap:&#x2F;&#x2F;&#x2F;self&amp;quot;);)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;This combination allows self write to *all* attributes within the subtree.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;In cases where the target is members of a group, it may allow a member who is
&lt;&#x2F;span&gt;&lt;span&gt;within two groups to have elevated privilege.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Advice: 
&lt;&#x2F;span&gt;&lt;span&gt;Convert the aci to the form &amp;quot;(targetAttr=&amp;quot;x || y || z&amp;quot;)&amp;quot;.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Prevent the acis from overlapping, and have them on unique subtrees.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;-------------------------------------------------------------------------------
&lt;&#x2F;span&gt;&lt;span&gt;FAIL
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
</description>
      </item>
      <item>
          <title>Trick to debug single files in ds</title>
          <pubDate>Wed, 16 Mar 2016 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2016-03-16-trick-to-debug-single-files-in-ds/</link>
          <guid>https://fy.blackhats.net.au/blog/2016-03-16-trick-to-debug-single-files-in-ds/</guid>
          <description>&lt;h1 id=&quot;trick-to-debug-single-files-in-ds&quot;&gt;Trick to debug single files in ds&lt;&#x2F;h1&gt;
&lt;p&gt;I&#x27;ve been debugging thread deadlocks in directory server. When you turn
on detailed tracing with&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ns-slapd -d 1
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You slow the server down so much that you can barely function.&lt;&#x2F;p&gt;
&lt;p&gt;A trick is that defines in the local .c file, override from the .h. Copy
paste this to the file you want to debug. This allows the logs from this
file to be emitted at -d 0, but without turning it on everywhere, so you
don&#x27;t grind the server to a halt.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;* Do this so we can get the messages at standard log levels. *&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;#define SLAPI_LOG_FATAL         0
&lt;&#x2F;span&gt;&lt;span&gt;#define SLAPI_LOG_TRACE         0
&lt;&#x2F;span&gt;&lt;span&gt;#define SLAPI_LOG_PACKETS       0
&lt;&#x2F;span&gt;&lt;span&gt;#define SLAPI_LOG_ARGS          0
&lt;&#x2F;span&gt;&lt;span&gt;#define SLAPI_LOG_CONNS         0
&lt;&#x2F;span&gt;&lt;span&gt;#define SLAPI_LOG_BER           0
&lt;&#x2F;span&gt;&lt;span&gt;#define SLAPI_LOG_FILTER        0
&lt;&#x2F;span&gt;&lt;span&gt;#define SLAPI_LOG_CONFIG        0
&lt;&#x2F;span&gt;&lt;span&gt;#define SLAPI_LOG_ACL           0
&lt;&#x2F;span&gt;&lt;span&gt;#define SLAPI_LOG_SHELL         0
&lt;&#x2F;span&gt;&lt;span&gt;#define SLAPI_LOG_PARSE         0
&lt;&#x2F;span&gt;&lt;span&gt;#define SLAPI_LOG_HOUSE         0
&lt;&#x2F;span&gt;&lt;span&gt;#define SLAPI_LOG_REPL          0
&lt;&#x2F;span&gt;&lt;span&gt;#define SLAPI_LOG_CACHE         0
&lt;&#x2F;span&gt;&lt;span&gt;#define SLAPI_LOG_PLUGIN        0
&lt;&#x2F;span&gt;&lt;span&gt;#define SLAPI_LOG_TIMING        0
&lt;&#x2F;span&gt;&lt;span&gt;#define SLAPI_LOG_BACKLDBM      0
&lt;&#x2F;span&gt;&lt;span&gt;#define SLAPI_LOG_ACLSUMMARY    0
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
</description>
      </item>
      <item>
          <title>Blog migration</title>
          <pubDate>Wed, 09 Mar 2016 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2016-03-09-blog-migration/</link>
          <guid>https://fy.blackhats.net.au/blog/2016-03-09-blog-migration/</guid>
          <description>&lt;h1 id=&quot;blog-migration&quot;&gt;Blog migration&lt;&#x2F;h1&gt;
&lt;p&gt;I&#x27;ve migrated my blog from django to tinkerer. I&#x27;ve also created a
number of helper pages to preserve all the links to old pages.&lt;&#x2F;p&gt;
&lt;p&gt;Please let me know if anything is wrong using my contact details on the
about page.&lt;&#x2F;p&gt;
&lt;p&gt;William&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>ldctl to generate test objects</title>
          <pubDate>Tue, 23 Feb 2016 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2016-02-23-ldctl-to-generate-test-objects/</link>
          <guid>https://fy.blackhats.net.au/blog/2016-02-23-ldctl-to-generate-test-objects/</guid>
          <description>&lt;h1 id=&quot;ldctl-to-generate-test-objects&quot;&gt;ldctl to generate test objects&lt;&#x2F;h1&gt;
&lt;p&gt;I was told by some coworkers today at Red Hat that I can infact use
ldctl to generate my databases for load testing with 389-ds.&lt;&#x2F;p&gt;
&lt;p&gt;First, create a template.ldif&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;objectClass: top
&lt;&#x2F;span&gt;&lt;span&gt;objectclass: person
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: organizationalPerson
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: inetorgperson
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: posixAccount
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: shadowAccount
&lt;&#x2F;span&gt;&lt;span&gt;sn: testnew[A]
&lt;&#x2F;span&gt;&lt;span&gt;cn: testnew[A]
&lt;&#x2F;span&gt;&lt;span&gt;uid: testnew[A]
&lt;&#x2F;span&gt;&lt;span&gt;givenName: testnew[A]
&lt;&#x2F;span&gt;&lt;span&gt;description: description[A]
&lt;&#x2F;span&gt;&lt;span&gt;userPassword: testnew[A]
&lt;&#x2F;span&gt;&lt;span&gt;mail: testnew[A]@redhat.com
&lt;&#x2F;span&gt;&lt;span&gt;uidNumber: 3[A]
&lt;&#x2F;span&gt;&lt;span&gt;gidNumber: 4[A]
&lt;&#x2F;span&gt;&lt;span&gt;shadowMin: 0
&lt;&#x2F;span&gt;&lt;span&gt;shadowMax: 99999
&lt;&#x2F;span&gt;&lt;span&gt;shadowInactive: 30
&lt;&#x2F;span&gt;&lt;span&gt;shadowWarning: 7
&lt;&#x2F;span&gt;&lt;span&gt;homeDirectory: &#x2F;home&#x2F;uid[A]
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now you can use ldctl to actually load in the data:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ldclt -h localhost -p 389 -D &amp;quot;cn=Directory Manager&amp;quot; -w password -b &amp;quot;ou=people,dc=example,dc=com&amp;quot; \
&lt;&#x2F;span&gt;&lt;span&gt;-I 68 -e add,commoncounter -e &amp;quot;object=&#x2F;tmp&#x2F;template.ldif,rdn=uid:[A=INCRNNOLOOP(0;3999;5)]&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Thanks to vashirov and spichugi for their advice and this example!&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Patches Welcome</title>
          <pubDate>Wed, 17 Feb 2016 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2016-02-17-patches-welcome/</link>
          <guid>https://fy.blackhats.net.au/blog/2016-02-17-patches-welcome/</guid>
          <description>&lt;h1 id=&quot;patches-welcome&quot;&gt;&amp;quot;Patches Welcome&amp;quot;&lt;&#x2F;h1&gt;
&lt;p&gt;&amp;quot;Patches Welcome&amp;quot;. We&#x27;ve all seen it in the Open Source community.
Nothing makes me angrier than these two words.&lt;&#x2F;p&gt;
&lt;p&gt;Often this is said by people who are too busy, or too lazy to implement
features that just aren&#x27;t of interest to them. This isn&#x27;t the response
you get when you submit a bad idea, or something technically unfeasible.
It&#x27;s the response that speaks of an apathy to your software&#x27;s users.&lt;&#x2F;p&gt;
&lt;p&gt;I get that we all have time limits for development. I know that we have
to prioritise. I know that it may not be of import to the business right
now. Even at the least, reach out, say you&#x27;ll create a ticket on their
behalf if they cannot. Help them work through the design, then implement
it in the future.&lt;&#x2F;p&gt;
&lt;p&gt;But do not ever consider yourself so high and mighty that the request of
a user &amp;quot;isn&#x27;t good enough for you&amp;quot;. These are your customers,
supporters, advocates, bug reporters, testers, and users. They are what
build the community. A community is not just the developers of the
software. It&#x27;s the users of it too, and their skills are separate from
those of the the developer.&lt;&#x2F;p&gt;
&lt;p&gt;Often people ask for features, but do not have the expertise, or domain
knowledge to implement them. That does not invalidate the worth of the
feature, if anything speaks to it&#x27;s value as a real customer will
benefit from this, and your project as a whole will improve. Telling
them &amp;quot;Patches Welcome&amp;quot; is like saying &amp;quot;I know you aren&#x27;t capable of
implementing this yourself. I don&#x27;t care to help you at all, and I
don&#x27;t want to waste my time on you. Go away&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;As is obvious from this blog, I&#x27;m part of the 389 Directory Server
Team.&lt;&#x2F;p&gt;
&lt;p&gt;I will &lt;em&gt;never&lt;&#x2F;em&gt; tell a user that &amp;quot;patches welcome&amp;quot;. I will always
support them to design their idea. I will ask them to lodge a ticket, or
I&#x27;ll do it for them if they cannot. If a user can and wants to try to
implement the software of their choice, I will help them and teach them.
If they cannot, I will make sure that at some time in the future, we can
deliver it to them, or if we cannot, a real, honest explanation of why.&lt;&#x2F;p&gt;
&lt;p&gt;That&#x27;s the community in 389 I am proud to be a part of.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Failed to delete old semaphore for stats file</title>
          <pubDate>Tue, 09 Feb 2016 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2016-02-09-failed-to-delete-old-semaphore-for-stats-file/</link>
          <guid>https://fy.blackhats.net.au/blog/2016-02-09-failed-to-delete-old-semaphore-for-stats-file/</guid>
          <description>&lt;h1 id=&quot;failed-to-delete-old-semaphore-for-stats-file&quot;&gt;Failed to delete old semaphore for stats file&lt;&#x2F;h1&gt;
&lt;p&gt;Today I was getting this error:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;[09&#x2F;Feb&#x2F;2016:12:21:26 +101800] - 389-Directory&#x2F;1.3.5 B2016.040.145 starting up
&lt;&#x2F;span&gt;&lt;span&gt;[09&#x2F;Feb&#x2F;2016:12:21:26 +101800] - Failed to delete old semaphore for stats file (&#x2F;opt&#x2F;dirsrv&#x2F;var&#x2F;run&#x2F;dirsrv&#x2F;slapd-localhost.stats). Error 13 (Permission denied).
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;But when you check:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;opt# ls -al &#x2F;opt&#x2F;dirsrv&#x2F;var&#x2F;run&#x2F;dirsrv&#x2F;slapd-localhost.stats
&lt;&#x2F;span&gt;&lt;span&gt;ls: cannot access &#x2F;opt&#x2F;dirsrv&#x2F;var&#x2F;run&#x2F;dirsrv&#x2F;slapd-localhost.stats: No such file or directory
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Turns out on linux this isn&#x27;t actually where the file is. You need to
remove:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;dev&#x2F;shm&#x2F;sem.slapd-localhost.stats
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;A bug will be opened shortly ....&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Securing IPA</title>
          <pubDate>Tue, 09 Feb 2016 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2016-02-09-securing-ipa/</link>
          <guid>https://fy.blackhats.net.au/blog/2016-02-09-securing-ipa/</guid>
          <description>&lt;h1 id=&quot;securing-ipa&quot;&gt;Securing IPA&lt;&#x2F;h1&gt;
&lt;p&gt;&lt;a href=&quot;&#x2F;blog&#x2F;html&#x2F;2019&#x2F;07&#x2F;10&#x2F;i_no_longer_recommend_freeipa.html&quot;&gt;I no longer recommend using FreeIPA - Read more
here!&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;By default IPA has some weak security around TLS and anonymous binds.&lt;&#x2F;p&gt;
&lt;p&gt;We can improve this by changing the following options.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;nsslapd-minssf-exclude-rootdse: on
&lt;&#x2F;span&gt;&lt;span&gt;nsslapd-minssf: 56
&lt;&#x2F;span&gt;&lt;span&gt;nsslapd-require-secure-binds: on
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The last one you may want to change is:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;nsslapd-allow-anonymous-access: on
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;I think this is important to have on, as it allows non-domain members to
use ipa, but there are arguments to disabling anon reads too.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>389 on freebsd</title>
          <pubDate>Thu, 28 Jan 2016 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2016-01-28-389-on-freebsd/</link>
          <guid>https://fy.blackhats.net.au/blog/2016-01-28-389-on-freebsd/</guid>
          <description>&lt;h1 id=&quot;389-on-freebsd&quot;&gt;389 on freebsd&lt;&#x2F;h1&gt;
&lt;p&gt;I&#x27;ve decided to start porting 389-ds to freebsd.&lt;&#x2F;p&gt;
&lt;p&gt;So tonight I took the first steps. Let&#x27;s see if we can get it to build
in a dev environment like I would use normally.&lt;&#x2F;p&gt;
&lt;p&gt;You will need to install these deps:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;autotools
&lt;&#x2F;span&gt;&lt;span&gt;git
&lt;&#x2F;span&gt;&lt;span&gt;openldap-client
&lt;&#x2F;span&gt;&lt;span&gt;db5
&lt;&#x2F;span&gt;&lt;span&gt;cyrus-sasl
&lt;&#x2F;span&gt;&lt;span&gt;pkgconf
&lt;&#x2F;span&gt;&lt;span&gt;nspr
&lt;&#x2F;span&gt;&lt;span&gt;nss
&lt;&#x2F;span&gt;&lt;span&gt;net-snmp
&lt;&#x2F;span&gt;&lt;span&gt;gmake
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You then need to install svrcore. I&#x27;ll likely add a port for this too.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;fetch https:&#x2F;&#x2F;ftp.mozilla.org&#x2F;pub&#x2F;directory&#x2F;svrcore&#x2F;releases&#x2F;4.0.4&#x2F;src&#x2F;svrcore-4.0.4.tar.bz2
&lt;&#x2F;span&gt;&lt;span&gt;tar -xvjf svrcore-4.0.4.tar.bz2
&lt;&#x2F;span&gt;&lt;span&gt;cd svrcore-4.0.4
&lt;&#x2F;span&gt;&lt;span&gt;CFLAGS=&amp;quot;-fPIC &amp;quot;.&#x2F;configure --prefix=&#x2F;opt&#x2F;svrcore
&lt;&#x2F;span&gt;&lt;span&gt;make
&lt;&#x2F;span&gt;&lt;span&gt;sudo make install
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now you can clone ds and try to build it:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;cd
&lt;&#x2F;span&gt;&lt;span&gt;git clone https:&#x2F;&#x2F;git.fedorahosted.org&#x2F;git&#x2F;389&#x2F;ds.git
&lt;&#x2F;span&gt;&lt;span&gt;cd ds
&lt;&#x2F;span&gt;&lt;span&gt;.&#x2F;configure --prefix=&#x2F;opt&#x2F;dirsrv --with-openldap=&#x2F;usr&#x2F;local --with-db --with-db-inc=&#x2F;usr&#x2F;local&#x2F;include&#x2F;db5&#x2F; --with-db-lib=&#x2F;usr&#x2F;local&#x2F;lib&#x2F;db5&#x2F; --with-sasl --with-sasl-inc=&#x2F;usr&#x2F;local&#x2F;include&#x2F;sasl&#x2F; --with-sasl-lib=&#x2F;usr&#x2F;local&#x2F;lib&#x2F;sasl2&#x2F; --with-svrcore-inc=&#x2F;opt&#x2F;svrcore&#x2F;include&#x2F; --with-svrcore-lib=&#x2F;opt&#x2F;svrcore&#x2F;lib&#x2F; --with-netsnmp=&#x2F;usr&#x2F;local
&lt;&#x2F;span&gt;&lt;span&gt;gmake
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If it&#x27;s like me you get the following:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;make: &amp;quot;&#x2F;usr&#x2F;home&#x2F;admin_local&#x2F;ds&#x2F;Makefile&amp;quot; line 10765: warning: duplicate script for target &amp;quot;%&#x2F;dirsrv&amp;quot; ignored
&lt;&#x2F;span&gt;&lt;span&gt;make: &amp;quot;&#x2F;usr&#x2F;home&#x2F;admin_local&#x2F;ds&#x2F;Makefile&amp;quot; line 10762: warning: using previous script for &amp;quot;%&#x2F;dirsrv&amp;quot; defined here
&lt;&#x2F;span&gt;&lt;span&gt;make: &amp;quot;&#x2F;usr&#x2F;home&#x2F;admin_local&#x2F;ds&#x2F;Makefile&amp;quot; line 10767: warning: duplicate script for target &amp;quot;%&#x2F;dirsrv&amp;quot; ignored
&lt;&#x2F;span&gt;&lt;span&gt;make: &amp;quot;&#x2F;usr&#x2F;home&#x2F;admin_local&#x2F;ds&#x2F;Makefile&amp;quot; line 10762: warning: using previous script for &amp;quot;%&#x2F;dirsrv&amp;quot; defined here
&lt;&#x2F;span&gt;&lt;span&gt;make: &amp;quot;&#x2F;usr&#x2F;home&#x2F;admin_local&#x2F;ds&#x2F;Makefile&amp;quot; line 10768: warning: duplicate script for target &amp;quot;%&#x2F;dirsrv&amp;quot; ignored
&lt;&#x2F;span&gt;&lt;span&gt;make: &amp;quot;&#x2F;usr&#x2F;home&#x2F;admin_local&#x2F;ds&#x2F;Makefile&amp;quot; line 10762: warning: using previous script for &amp;quot;%&#x2F;dirsrv&amp;quot; defined here
&lt;&#x2F;span&gt;&lt;span&gt;perl .&#x2F;ldap&#x2F;servers&#x2F;slapd&#x2F;mkDBErrStrs.pl -i &#x2F;usr&#x2F;local&#x2F;include&#x2F;db5&#x2F; -o .
&lt;&#x2F;span&gt;&lt;span&gt;make  all-am
&lt;&#x2F;span&gt;&lt;span&gt;make[1]: &amp;quot;&#x2F;usr&#x2F;home&#x2F;admin_local&#x2F;ds&#x2F;Makefile&amp;quot; line 10765: warning: duplicate script for target &amp;quot;%&#x2F;dirsrv&amp;quot; ignored
&lt;&#x2F;span&gt;&lt;span&gt;make[1]: &amp;quot;&#x2F;usr&#x2F;home&#x2F;admin_local&#x2F;ds&#x2F;Makefile&amp;quot; line 10762: warning: using previous script for &amp;quot;%&#x2F;dirsrv&amp;quot; defined here
&lt;&#x2F;span&gt;&lt;span&gt;make[1]: &amp;quot;&#x2F;usr&#x2F;home&#x2F;admin_local&#x2F;ds&#x2F;Makefile&amp;quot; line 10767: warning: duplicate script for target &amp;quot;%&#x2F;dirsrv&amp;quot; ignored
&lt;&#x2F;span&gt;&lt;span&gt;make[1]: &amp;quot;&#x2F;usr&#x2F;home&#x2F;admin_local&#x2F;ds&#x2F;Makefile&amp;quot; line 10762: warning: using previous script for &amp;quot;%&#x2F;dirsrv&amp;quot; defined here
&lt;&#x2F;span&gt;&lt;span&gt;make[1]: &amp;quot;&#x2F;usr&#x2F;home&#x2F;admin_local&#x2F;ds&#x2F;Makefile&amp;quot; line 10768: warning: duplicate script for target &amp;quot;%&#x2F;dirsrv&amp;quot; ignored
&lt;&#x2F;span&gt;&lt;span&gt;make[1]: &amp;quot;&#x2F;usr&#x2F;home&#x2F;admin_local&#x2F;ds&#x2F;Makefile&amp;quot; line 10762: warning: using previous script for &amp;quot;%&#x2F;dirsrv&amp;quot; defined here
&lt;&#x2F;span&gt;&lt;span&gt;depbase=`echo ldap&#x2F;libraries&#x2F;libavl&#x2F;avl.o | sed &amp;#39;s|[^&#x2F;]*$|.deps&#x2F;&amp;amp;|;s|\.o$||&amp;#39;`; cc -DHAVE_CONFIG_H -I.     -DBUILD_NUM= -DVENDOR=&amp;quot;\&amp;quot;389 Project\&amp;quot;&amp;quot; -DBRAND=&amp;quot;\&amp;quot;389\&amp;quot;&amp;quot; -DCAPBRAND=&amp;quot;\&amp;quot;389\&amp;quot;&amp;quot;  -UPACKAGE_VERSION -UPACKAGE_TARNAME -UPACKAGE_STRING -UPACKAGE_BUGREPORT -I.&#x2F;ldap&#x2F;include -I.&#x2F;ldap&#x2F;servers&#x2F;slapd -I.&#x2F;include -I.  -DLOCALSTATEDIR=&amp;quot;\&amp;quot;&#x2F;opt&#x2F;dirsrv&#x2F;var\&amp;quot;&amp;quot; -DSYSCONFDIR=&amp;quot;\&amp;quot;&#x2F;opt&#x2F;dirsrv&#x2F;etc\&amp;quot;&amp;quot;  -DLIBDIR=&amp;quot;\&amp;quot;&#x2F;opt&#x2F;dirsrv&#x2F;lib\&amp;quot;&amp;quot; -DBINDIR=&amp;quot;\&amp;quot;&#x2F;opt&#x2F;dirsrv&#x2F;bin\&amp;quot;&amp;quot;  -DDATADIR=&amp;quot;\&amp;quot;&#x2F;opt&#x2F;dirsrv&#x2F;share\&amp;quot;&amp;quot; -DDOCDIR=&amp;quot;\&amp;quot;&#x2F;opt&#x2F;dirsrv&#x2F;share&#x2F;doc&#x2F;389-ds-base\&amp;quot;&amp;quot;  -DSBINDIR=&amp;quot;\&amp;quot;&#x2F;opt&#x2F;dirsrv&#x2F;sbin\&amp;quot;&amp;quot; -DPLUGINDIR=&amp;quot;\&amp;quot;&#x2F;opt&#x2F;dirsrv&#x2F;lib&#x2F;dirsrv&#x2F;plugins\&amp;quot;&amp;quot; -DTEMPLATEDIR=&amp;quot;\&amp;quot;&#x2F;opt&#x2F;dirsrv&#x2F;share&#x2F;dirsrv&#x2F;data\&amp;quot;&amp;quot;     -g -O2 -MT ldap&#x2F;libraries&#x2F;libavl&#x2F;avl.o -MD -MP -MF $depbase.Tpo -c -o ldap&#x2F;libraries&#x2F;libavl&#x2F;avl.o ldap&#x2F;libraries&#x2F;libavl&#x2F;avl.c &amp;amp;&amp;amp; mv -f $depbase.Tpo $depbase.Po
&lt;&#x2F;span&gt;&lt;span&gt;rm -f libavl.a
&lt;&#x2F;span&gt;&lt;span&gt;ar cru libavl.a ldap&#x2F;libraries&#x2F;libavl&#x2F;avl.o
&lt;&#x2F;span&gt;&lt;span&gt;ranlib libavl.a
&lt;&#x2F;span&gt;&lt;span&gt;cc -DHAVE_CONFIG_H -I.     -DBUILD_NUM= -DVENDOR=&amp;quot;\&amp;quot;389 Project\&amp;quot;&amp;quot; -DBRAND=&amp;quot;\&amp;quot;389\&amp;quot;&amp;quot; -DCAPBRAND=&amp;quot;\&amp;quot;389\&amp;quot;&amp;quot;  -UPACKAGE_VERSION -UPACKAGE_TARNAME -UPACKAGE_STRING -UPACKAGE_BUGREPORT -I.&#x2F;ldap&#x2F;include -I.&#x2F;ldap&#x2F;servers&#x2F;slapd -I.&#x2F;include -I.  -DLOCALSTATEDIR=&amp;quot;\&amp;quot;&#x2F;opt&#x2F;dirsrv&#x2F;var\&amp;quot;&amp;quot; -DSYSCONFDIR=&amp;quot;\&amp;quot;&#x2F;opt&#x2F;dirsrv&#x2F;etc\&amp;quot;&amp;quot;  -DLIBDIR=&amp;quot;\&amp;quot;&#x2F;opt&#x2F;dirsrv&#x2F;lib\&amp;quot;&amp;quot; -DBINDIR=&amp;quot;\&amp;quot;&#x2F;opt&#x2F;dirsrv&#x2F;bin\&amp;quot;&amp;quot;  -DDATADIR=&amp;quot;\&amp;quot;&#x2F;opt&#x2F;dirsrv&#x2F;share\&amp;quot;&amp;quot; -DDOCDIR=&amp;quot;\&amp;quot;&#x2F;opt&#x2F;dirsrv&#x2F;share&#x2F;doc&#x2F;389-ds-base\&amp;quot;&amp;quot;  -DSBINDIR=&amp;quot;\&amp;quot;&#x2F;opt&#x2F;dirsrv&#x2F;sbin\&amp;quot;&amp;quot; -DPLUGINDIR=&amp;quot;\&amp;quot;&#x2F;opt&#x2F;dirsrv&#x2F;lib&#x2F;dirsrv&#x2F;plugins\&amp;quot;&amp;quot; -DTEMPLATEDIR=&amp;quot;\&amp;quot;&#x2F;opt&#x2F;dirsrv&#x2F;share&#x2F;dirsrv&#x2F;data\&amp;quot;&amp;quot;  -I.&#x2F;lib&#x2F;ldaputil -I&#x2F;usr&#x2F;local&#x2F;include  -I&#x2F;usr&#x2F;local&#x2F;include&#x2F;nss -I&#x2F;usr&#x2F;local&#x2F;include&#x2F;nss&#x2F;nss -I&#x2F;usr&#x2F;local&#x2F;include&#x2F;nspr   -I&#x2F;usr&#x2F;local&#x2F;include&#x2F;nspr   -g -O2 -MT lib&#x2F;ldaputil&#x2F;libldaputil_a-cert.o -MD -MP -MF lib&#x2F;ldaputil&#x2F;.deps&#x2F;libldaputil_a-cert.Tpo -c -o lib&#x2F;ldaputil&#x2F;libldaputil_a-cert.o `test -f &amp;#39;lib&#x2F;ldaputil&#x2F;cert.c&amp;#39; || echo &amp;#39;.&#x2F;&amp;#39;`lib&#x2F;ldaputil&#x2F;cert.c
&lt;&#x2F;span&gt;&lt;span&gt;In file included from lib&#x2F;ldaputil&#x2F;cert.c:16:
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;usr&#x2F;include&#x2F;malloc.h:3:2: error: &amp;quot;&amp;lt;malloc.h&amp;gt; has been replaced by &amp;lt;stdlib.h&amp;gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;#error &amp;quot;&amp;lt;malloc.h&amp;gt; has been replaced by &amp;lt;stdlib.h&amp;gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt; ^
&lt;&#x2F;span&gt;&lt;span&gt;1 error generated.
&lt;&#x2F;span&gt;&lt;span&gt;*** Error code 1
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Stop.
&lt;&#x2F;span&gt;&lt;span&gt;make[1]: stopped in &#x2F;usr&#x2F;home&#x2F;admin_local&#x2F;ds
&lt;&#x2F;span&gt;&lt;span&gt;*** Error code 1
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Stop.
&lt;&#x2F;span&gt;&lt;span&gt;make: stopped in &#x2F;usr&#x2F;home&#x2F;admin_local&#x2F;ds
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Time to start looking at including some #ifdef __FREEBSD__ macros.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Renaming ovirt storage targets</title>
          <pubDate>Sat, 16 Jan 2016 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2016-01-16-renaming-ovirt-storage-targets/</link>
          <guid>https://fy.blackhats.net.au/blog/2016-01-16-renaming-ovirt-storage-targets/</guid>
          <description>&lt;h1 id=&quot;renaming-ovirt-storage-targets&quot;&gt;Renaming ovirt storage targets&lt;&#x2F;h1&gt;
&lt;p&gt;I run an ovirt server, and sometimes like a tinker that I am, I like to
rename things due to new hardware or other ideas that come up.&lt;&#x2F;p&gt;
&lt;p&gt;Ovirt makes it quite hard to change the nfs target or name of a storage
volume. Although it&#x27;s not supported, I&#x27;m more than happy to dig
through the database.&lt;&#x2F;p&gt;
&lt;p&gt;NOTE: Take a backup before you start, this is some serious unsupported
magic here.&lt;&#x2F;p&gt;
&lt;p&gt;First, we need to look at the main tables that are involved in nfs
storage:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;engine=# select id,storage,storage_name from storage_domain_static;
&lt;&#x2F;span&gt;&lt;span&gt;                  id                  |               storage                |   storage_name    
&lt;&#x2F;span&gt;&lt;span&gt;--------------------------------------+--------------------------------------+-------------------
&lt;&#x2F;span&gt;&lt;span&gt; 6bffd537-badb-43c9-91b2-a922cf847533 | 842add9e-ffef-44d9-bf6d-4f8231b375eb | def_t2_nfs_import
&lt;&#x2F;span&gt;&lt;span&gt; c3aa02d8-02fd-4a16-bfe6-59f9348a0b1e | 5b8ba182-7d05-44e4-9d64-2a1bb529b797 | def_t2_nfs_iso
&lt;&#x2F;span&gt;&lt;span&gt; a8ac8bd0-cf40-45ae-9f39-b376c16b7fec | d2fd5e4b-c3de-4829-9f4a-d56246f5454b | def_t2_nfs_lcs
&lt;&#x2F;span&gt;&lt;span&gt; d719e5f2-f59d-434d-863e-3c9c31e4c02f | e2ba769c-e5a3-4652-b75d-b68959369b55 | def_t1_nfs_master
&lt;&#x2F;span&gt;&lt;span&gt; a085aca5-112c-49bf-aa91-fbf59e8bde0b | f5be3009-4c84-4d59-9cfe-a1bcedac4038 | def_t1_nfs_sas
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;engine=# select id,connection from storage_server_connections;
&lt;&#x2F;span&gt;&lt;span&gt;                  id                  |                           connection                            
&lt;&#x2F;span&gt;&lt;span&gt;--------------------------------------+-----------------------------------------------------------------
&lt;&#x2F;span&gt;&lt;span&gt; 842add9e-ffef-44d9-bf6d-4f8231b375eb | mion.ipa.example.com:&#x2F;var&#x2F;lib&#x2F;exports&#x2F;t2&#x2F;def_t2_nfs_import
&lt;&#x2F;span&gt;&lt;span&gt; 5b8ba182-7d05-44e4-9d64-2a1bb529b797 | mion.ipa.example.com:&#x2F;var&#x2F;lib&#x2F;exports&#x2F;t2&#x2F;def_t2_nfs_iso
&lt;&#x2F;span&gt;&lt;span&gt; d2fd5e4b-c3de-4829-9f4a-d56246f5454b | mion.ipa.example.com:&#x2F;var&#x2F;lib&#x2F;exports&#x2F;t2&#x2F;def_t2_nfs_lcs
&lt;&#x2F;span&gt;&lt;span&gt; e2ba769c-e5a3-4652-b75d-b68959369b55 | mion.ipa.example.com:&#x2F;var&#x2F;lib&#x2F;exports&#x2F;t1&#x2F;def_t1_nfs_master
&lt;&#x2F;span&gt;&lt;span&gt; f5be3009-4c84-4d59-9cfe-a1bcedac4038 | mion.ipa.example.com:&#x2F;var&#x2F;lib&#x2F;exports&#x2F;t1&#x2F;def_t1_nfs_sas
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;So we are going to rename the def_t2_nfs targets to def_t3_nfs. First we
need to update the mount point:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;update storage_server_connections set connection=&amp;#39;mion.ipa.example.com:&#x2F;var&#x2F;lib&#x2F;exports&#x2F;t3&#x2F;def_t3_nfs_import&amp;#39; where id=&amp;#39;842add9e-ffef-44d9-bf6d-4f8231b375eb&amp;#39;;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;update storage_server_connections set connection=&amp;#39;mion.ipa.example.com:&#x2F;var&#x2F;lib&#x2F;exports&#x2F;t3&#x2F;def_t3_nfs_iso&amp;#39; where id=&amp;#39;5b8ba182-7d05-44e4-9d64-2a1bb529b797&amp;#39;;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;update storage_server_connections set connection=&amp;#39;mion.ipa.example.com:&#x2F;var&#x2F;lib&#x2F;exports&#x2F;t2&#x2F;def_t2_nfs_lcs&amp;#39; where id=&amp;#39;d2fd5e4b-c3de-4829-9f4a-d56246f5454b&amp;#39;;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Next we are going to replace the name in the storage_domain_static
table.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;update storage_domain_static set storage_name=&amp;#39;def_t3_nfs_lcs&amp;#39; where storage=&amp;#39;d2fd5e4b-c3de-4829-9f4a-d56246f5454b&amp;#39;;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;update storage_domain_static set storage_name=&amp;#39;def_t3_nfs_iso&amp;#39; where storage=&amp;#39;5b8ba182-7d05-44e4-9d64-2a1bb529b797&amp;#39;;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;update storage_domain_static set storage_name=&amp;#39;def_t3_nfs_import&amp;#39; where storage=&amp;#39;842add9e-ffef-44d9-bf6d-4f8231b375eb&amp;#39;;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;That&#x27;s it! Now check it all looks correct and restart.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;engine=# select id,storage,storage_name from storage_domain_static;
&lt;&#x2F;span&gt;&lt;span&gt;                  id                  |               storage                |   storage_name    
&lt;&#x2F;span&gt;&lt;span&gt;--------------------------------------+--------------------------------------+-------------------
&lt;&#x2F;span&gt;&lt;span&gt; a8ac8bd0-cf40-45ae-9f39-b376c16b7fec | d2fd5e4b-c3de-4829-9f4a-d56246f5454b | def_t3_nfs_lcs
&lt;&#x2F;span&gt;&lt;span&gt; c3aa02d8-02fd-4a16-bfe6-59f9348a0b1e | 5b8ba182-7d05-44e4-9d64-2a1bb529b797 | def_t3_nfs_iso
&lt;&#x2F;span&gt;&lt;span&gt; 6bffd537-badb-43c9-91b2-a922cf847533 | 842add9e-ffef-44d9-bf6d-4f8231b375eb | def_t3_nfs_import
&lt;&#x2F;span&gt;&lt;span&gt; d719e5f2-f59d-434d-863e-3c9c31e4c02f | e2ba769c-e5a3-4652-b75d-b68959369b55 | def_t1_nfs_master
&lt;&#x2F;span&gt;&lt;span&gt; a085aca5-112c-49bf-aa91-fbf59e8bde0b | f5be3009-4c84-4d59-9cfe-a1bcedac4038 | def_t1_nfs_sas
&lt;&#x2F;span&gt;&lt;span&gt;(5 rows)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;engine=# select id,connection from storage_server_connections;
&lt;&#x2F;span&gt;&lt;span&gt;                  id                  |                           connection                            
&lt;&#x2F;span&gt;&lt;span&gt;--------------------------------------+-----------------------------------------------------------------
&lt;&#x2F;span&gt;&lt;span&gt; e2ba769c-e5a3-4652-b75d-b68959369b55 | mion.ipa.example.com:&#x2F;var&#x2F;lib&#x2F;exports&#x2F;t1&#x2F;def_t1_nfs_master
&lt;&#x2F;span&gt;&lt;span&gt; f5be3009-4c84-4d59-9cfe-a1bcedac4038 | mion.ipa.example.com:&#x2F;var&#x2F;lib&#x2F;exports&#x2F;t1&#x2F;def_t1_nfs_sas
&lt;&#x2F;span&gt;&lt;span&gt; 842add9e-ffef-44d9-bf6d-4f8231b375eb | mion.ipa.example.com:&#x2F;var&#x2F;lib&#x2F;exports&#x2F;t3&#x2F;def_t3_nfs_import
&lt;&#x2F;span&gt;&lt;span&gt; 5b8ba182-7d05-44e4-9d64-2a1bb529b797 | mion.ipa.example.com:&#x2F;var&#x2F;lib&#x2F;exports&#x2F;t3&#x2F;def_t3_nfs_iso
&lt;&#x2F;span&gt;&lt;span&gt; d2fd5e4b-c3de-4829-9f4a-d56246f5454b | mion.ipa.example.com:&#x2F;var&#x2F;lib&#x2F;exports&#x2F;t3&#x2F;def_t3_nfs_lcs
&lt;&#x2F;span&gt;&lt;span&gt;(5 rows)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
</description>
      </item>
      <item>
          <title>Running your own mailserver: Mailbox rollover</title>
          <pubDate>Fri, 15 Jan 2016 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2016-01-15-running-your-own-mailserver-mailbox-rollover/</link>
          <guid>https://fy.blackhats.net.au/blog/2016-01-15-running-your-own-mailserver-mailbox-rollover/</guid>
          <description>&lt;h1 id=&quot;running-your-own-mailserver-mailbox-rollover&quot;&gt;Running your own mailserver: Mailbox rollover&lt;&#x2F;h1&gt;
&lt;p&gt;UPDATE 2019: Don&#x27;t run your own! Use fastmail instead :D!&lt;&#x2F;p&gt;
&lt;p&gt;I go to a lot of effort to run my own email server. I don&#x27;t like
google, and I want to keep them away from my messages. While it incurs
both financial, and administrative cost, sometimes the benefits are
fantastic.&lt;&#x2F;p&gt;
&lt;p&gt;I like to sort my mail to folders based on server side filters (which
are fantastic, server side filtering is the way to go). I also like to
keep my mailboxes in yearly fashion, so they don&#x27;t grow tooo large. I
keep every email I ever receive, and it&#x27;s saved my arse a few times.&lt;&#x2F;p&gt;
&lt;p&gt;Rolling over year to year for most people would be a pain: You need to
move all the emails from one folder (mailbox) to another, which incurs a
huge time &#x2F; download &#x2F; effort cost.&lt;&#x2F;p&gt;
&lt;p&gt;Running your own mailserver though, you don&#x27;t have this issue. It takes
a few seconds to complete a year rollover. You can even script it like I
did.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;#!&#x2F;bin&#x2F;bash
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;export MAILUSER=&amp;#39;email address here&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;export LASTYEAR=&amp;#39;2015&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;export THISYEAR=&amp;#39;2016&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Stop postfix first. this way server side filters aren&amp;#39;t being used and mails routed while we fiddle around.
&lt;&#x2F;span&gt;&lt;span&gt;systemctl stop postfix
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Now we can fiddle with mailboxes
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# First, we want to make the new archive.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;doveadm mailbox create -u ${MAILUSER} archive.${THISYEAR}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Create a list of mailboxes.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;export MAILBOXES=`doveadm mailbox list -u ${MAILUSER} &amp;#39;INBOX.*&amp;#39; | awk -F &amp;#39;.&amp;#39; &amp;#39;{print $2}&amp;#39;`
&lt;&#x2F;span&gt;&lt;span&gt;echo $MAILBOXES
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Now move the directories to archive.
&lt;&#x2F;span&gt;&lt;span&gt;# Create the new equivalents
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;for MAILBOX in ${MAILBOXES}
&lt;&#x2F;span&gt;&lt;span&gt;do
&lt;&#x2F;span&gt;&lt;span&gt;    doveadm mailbox rename -u ${MAILUSER} INBOX.${MAILBOX} archive.${LASTYEAR}.${MAILBOX}
&lt;&#x2F;span&gt;&lt;span&gt;    doveadm mailbox subscribe -u ${MAILUSER} archive.${LASTYEAR}.${MAILBOX}
&lt;&#x2F;span&gt;&lt;span&gt;    doveadm mailbox create -u ${MAILUSER} INBOX.${MAILBOX}
&lt;&#x2F;span&gt;&lt;span&gt;done
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;doveadm mailbox list -u ${MAILUSER}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Start postfix back up
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;systemctl start postfix
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now I have clean, shiny mailboxes, all my filters still work, and my
previous year&#x27;s emails are tucked away for safe keeping and posterity.&lt;&#x2F;p&gt;
&lt;p&gt;The only catch with my script is you need to run it on January 1st, else
you get 2016 mails in the 2015 archive. You also still need to move the
inbox contents from 2015 manually to the archive. But it&#x27;s not nearly
the same hassle as moving thousands of mailing list messages around.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>FreeRADIUS: Using mschapv2 with freeipa</title>
          <pubDate>Wed, 13 Jan 2016 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2016-01-13-freeradius-using-mschapv2-with-freeipa/</link>
          <guid>https://fy.blackhats.net.au/blog/2016-01-13-freeradius-using-mschapv2-with-freeipa/</guid>
          <description>&lt;h1 id=&quot;freeradius-using-mschapv2-with-freeipa&quot;&gt;FreeRADIUS: Using mschapv2 with freeipa&lt;&#x2F;h1&gt;
&lt;p&gt;&lt;a href=&quot;&#x2F;blog&#x2F;html&#x2F;2019&#x2F;07&#x2F;10&#x2F;i_no_longer_recommend_freeipa.html&quot;&gt;I no longer recommend using FreeIPA - Read more
here!&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Wireless and radius is pretty much useless without mschapv2 and peap.
This is because iPhones, androids, even linux have fundamental issues
with ttls or other 802.1x modes. mschapv2 &amp;quot;just works&amp;quot;, yet it&#x27;s one
of the most obscure to get working in some cases without AD.&lt;&#x2F;p&gt;
&lt;p&gt;If you have an active directory environment, it&#x27;s pretty well a
painless process. But when you want to use anything else, you are in a
tight spot.&lt;&#x2F;p&gt;
&lt;p&gt;The FreeRADIUS team go on &lt;em&gt;a lot&lt;&#x2F;em&gt; about how mschapv2 doesn&#x27;t work with
ldap: and they are correct. mschapv2 is a challenge response protocol,
and you can&#x27;t do that in conjunction with an ldap bind.&lt;&#x2F;p&gt;
&lt;p&gt;However it &lt;em&gt;IS&lt;&#x2F;em&gt; possible to use mschapv2 with an ldap server: It&#x27;s just
not obvious or straight forwards.&lt;&#x2F;p&gt;
&lt;p&gt;The way that this works is you need freeradius to look up a user to an
ldap dn, then you read (not bind) the nthash of the user from their dn.
From there, the FreeRADIUS server is able to conduct the challenge
response component.&lt;&#x2F;p&gt;
&lt;p&gt;So the main things here to note:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;nthash are pretty much an md4. They are broken and terrible. But you
need to use them, so you need to secure the access to these.&lt;&#x2F;li&gt;
&lt;li&gt;Because you need to secure these, you need to be sure your access
controls are correct.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;We can pretty easily make this setup work with freeipa in fact.&lt;&#x2F;p&gt;
&lt;p&gt;First, follow the contents of &lt;a href=&quot;&#x2F;blog&#x2F;html&#x2F;2015&#x2F;07&#x2F;06&#x2F;FreeIPA:_Giving_permissions_to_service_accounts..html&quot;&gt;my previous blog
post&lt;&#x2F;a&gt;
on how to setup the adtrust components and the access controls.&lt;&#x2F;p&gt;
&lt;p&gt;You don&#x27;t actually need to complete the trust with AD, you just need to
run the setup util, as this triggers IPA to generate and store nthashes
in ipaNTHash on the user account.&lt;&#x2F;p&gt;
&lt;p&gt;Now armed with your service account that can read these hashes, and the
password, we need to configure FreeRADIUS.&lt;&#x2F;p&gt;
&lt;p&gt;FreeRADIUS is EXTREMELY HARD TO CONFIGURE. You can mess it up VERY
QUICKLY.&lt;&#x2F;p&gt;
&lt;p&gt;Thankfully, the developers provide an excellent default configuration
that should only need minimal tweaks to make this configuration work.&lt;&#x2F;p&gt;
&lt;p&gt;first, symlink ldap to mods-enabled&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;cd &#x2F;etc&#x2F;raddb&#x2F;mods-enabled
&lt;&#x2F;span&gt;&lt;span&gt;ln -s ..&#x2F;mods-available&#x2F;ldap .&#x2F;ldap
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now, edit the ldap config in mods-available (That way if a swap file is
made, it&#x27;s not put into mods-enabled where it may do damage)&lt;&#x2F;p&gt;
&lt;p&gt;You need to change the parameters to match your site, however the most
important setting is:&lt;&#x2F;p&gt;
&lt;p&gt;:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;identity = krbprincipalname=radius&#x2F;host.ipa.example.net.au@IPA.EXAMPLE.NET.AU,cn=services,cn=accounts,dc=ipa,dc=example,dc=net,dc=au
&lt;&#x2F;span&gt;&lt;span&gt;password = SERVICE ACCOUNT BIND PW
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;....snip.....
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;update {
&lt;&#x2F;span&gt;&lt;span&gt;      ....snip......
&lt;&#x2F;span&gt;&lt;span&gt;      control:NT-Password··   := &amp;#39;ipaNTHash&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt; .....snip ....
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;user {
&lt;&#x2F;span&gt;&lt;span&gt;       base_dn = &amp;quot;cn=users,cn=accounts,dc=ipa,dc=example,dc=net,dc=au&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;       filter = &amp;quot;(uid=%{%{Stripped-User-Name}:-%{User-Name}})&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;        ....snip....
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Next, you want to edit the mods-available&#x2F;eap&lt;&#x2F;p&gt;
&lt;p&gt;you want to change the value of default_eap_type to:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;default_eap_type = mschapv2
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Finally, you need to update your sites-available, most likely
inner-tunnel and default to make sure that they contain:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;authorize {
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;      ....snip .....
&lt;&#x2F;span&gt;&lt;span&gt;      -ldap
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;That&#x27;s it! Now you should be able to test an ldap account with radtest,
using the default NAS configured in &#x2F;etc&#x2F;raddb&#x2F;clients.conf.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;radtest -t mschap william password 127.0.0.1:1812 0 testing123
&lt;&#x2F;span&gt;&lt;span&gt;    User-Name = &amp;#39;william&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;    NAS-IP-Address = 172.24.16.13
&lt;&#x2F;span&gt;&lt;span&gt;    NAS-Port = 0
&lt;&#x2F;span&gt;&lt;span&gt;    Message-Authenticator = 0x00
&lt;&#x2F;span&gt;&lt;span&gt;    MS-CHAP-Challenge = 0x642690f62148e238
&lt;&#x2F;span&gt;&lt;span&gt;        MS-CHAP-Response = ....
&lt;&#x2F;span&gt;&lt;span&gt;Received Access-Accept Id 130 from 127.0.0.1:1812 to 127.0.0.1:56617 length 84
&lt;&#x2F;span&gt;&lt;span&gt;    MS-CHAP-MPPE-Keys = 0x
&lt;&#x2F;span&gt;&lt;span&gt;    MS-MPPE-Encryption-Policy = Encryption-Allowed
&lt;&#x2F;span&gt;&lt;span&gt;    MS-MPPE-Encryption-Types = RC4-40or128-bit-Allowed
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;why-not-use-krb&quot;&gt;Why not use KRB?&lt;&#x2F;h2&gt;
&lt;p&gt;I was asked in IRC about using KRB keytabs for authenticating the
service account. Now the configuration is quite easy - but I won&#x27;t put
it hear.&lt;&#x2F;p&gt;
&lt;p&gt;The issue is that it opens up a number of weaknesses. Between FreeRADIUS
and LDAP you have communication. Now FreeIPA&#x2F;389DS doesn&#x27;t allow GSSAPI
over LDAPS&#x2F;StartTLS. When you are doing an MSCHAPv2 authentication this
isn&#x27;t so bad: FreeRADIUS authenticates with GSSAPI with encryption
layers, then reads the NTHash. The NTHash is used inside FreeRADIUS to
generate the challenge, and the 802.1x authentication suceeds or fails.&lt;&#x2F;p&gt;
&lt;p&gt;Now what happens when we use PAP instead? FreeRADIUS can either read the
NTHash and do a comparison (as above), or it can &lt;em&gt;directly bind&lt;&#x2F;em&gt; to the
LDAP server. This means in the direct bind case, that the transport &lt;em&gt;may
not be encrypted&lt;&#x2F;em&gt; due to the keytab. See, the keytab when used for the
service account, will install encryption, but when the simple bind
occurs, we don&#x27;t have GSSAPI material, so we would send this clear
text.&lt;&#x2F;p&gt;
&lt;p&gt;Which one will occur ... Who knows! FreeRADIUS is a complex piece of
software, as is LDAP. Unless you are willing to test all the different
possibilities of 802.1x types and LDAP interactions, there is a risk
here.&lt;&#x2F;p&gt;
&lt;p&gt;Today the only secure, guaranteed way to protect your accounts is TLS.
You should use LDAPS, and this guarantees all communication will be
secure. It&#x27;s simpler, faster, and better.&lt;&#x2F;p&gt;
&lt;p&gt;That&#x27;s why I don&#x27;t document or advise how to use krb keytabs with this
configuration.&lt;&#x2F;p&gt;
&lt;p&gt;Thanks to &lt;em&gt;moep&lt;&#x2F;em&gt; for helping point out some of the issues with KRB
integration.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>db2index: entry too large (X bytes) for the buffer size (Y bytes)</title>
          <pubDate>Thu, 17 Dec 2015 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2015-12-17-db2index-entry-too-large-x-bytes-for-the-buffer-size-y-bytes/</link>
          <guid>https://fy.blackhats.net.au/blog/2015-12-17-db2index-entry-too-large-x-bytes-for-the-buffer-size-y-bytes/</guid>
          <description>&lt;h1 id=&quot;db2index-entry-too-large-x-bytes-for-the-buffer-size-y-bytes&quot;&gt;db2index: entry too large (X bytes) for the buffer size (Y bytes)&lt;&#x2F;h1&gt;
&lt;p&gt;We&#x27;ve been there: You need to reindex your dirsrv and get it back into
production as fast as you can. Then all of a sudden you get this error.&lt;&#x2F;p&gt;
&lt;p&gt;Some quick research shows no way to change the mystical buffer size
being referenced. You pull out your hair and wonder what&#x27;s going on, so
you play with some numbers, and eventually it works, but you don&#x27;t know
why.&lt;&#x2F;p&gt;
&lt;p&gt;It turns out, this is one of the more magical undocumented values that
DS sets for itself. If we look through the code, we find that this
buffer is derived from the ldbm instances c_maxsize.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;.&#x2F;ldap&#x2F;servers&#x2F;slapd&#x2F;back-ldbm&#x2F;import.c:48: 
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;job-&amp;gt;fifo.bsize = (inst-&amp;gt;inst_cache.c_maxsize&#x2F;10) &amp;lt;&amp;lt; 3;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;That c_maxsize is actually the value of cn=config,cn=ldbm
database,cn=plugins,cn=config, nsslapd-dbcachesize.&lt;&#x2F;p&gt;
&lt;p&gt;So, say that we get the error bytes is too small as it&#x27;s only (20000000
bytes) in size. We plug this in:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;(20000000 &amp;gt;&amp;gt; 3) * 10 = 25000000
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Which in my case was the size of nsslapd-dbcachesize&lt;&#x2F;p&gt;
&lt;p&gt;If we have a hypothetical value, say 28000000 bytes, and db2index can&#x27;t
run, you can use this reverse to calculate the dbcachesize you need:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;(28000000 &amp;gt;&amp;gt; 3) * 10 = 35000000
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This will create a buffersize of 28000000 so you can run the db2index
task.&lt;&#x2F;p&gt;
&lt;p&gt;In the future, this value will be configurable, rather than derived
which will improve the clarity of the error, and the remediation.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Load balanced 389 instance with freeipa kerberos domain.</title>
          <pubDate>Fri, 11 Dec 2015 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2015-12-11-load-balanced-389-instance-with-freeipa-kerberos-domain/</link>
          <guid>https://fy.blackhats.net.au/blog/2015-12-11-load-balanced-389-instance-with-freeipa-kerberos-domain/</guid>
          <description>&lt;h1 id=&quot;load-balanced-389-instance-with-freeipa-kerberos-domain&quot;&gt;Load balanced 389 instance with freeipa kerberos domain.&lt;&#x2F;h1&gt;
&lt;p&gt;&lt;a href=&quot;&#x2F;blog&#x2F;html&#x2F;2019&#x2F;07&#x2F;10&#x2F;i_no_longer_recommend_freeipa.html&quot;&gt;I no longer recommend using FreeIPA - Read more
here!&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;First, create a fake host that we can assign services too. This is for
the load balancer (f5, netscaler, ace, haproxy)&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ipa host-add haproxydemo.ipa.example.com --random --force
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now you can add the keytab for the loadbalanced service.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ipa service-add --force ldap&#x2F;haproxydemo.ipa.example.com
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Then you need to delegate the keytab to the ldap servers that will sit
behind the lb.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ipa service-add-host ldap&#x2F;haproxydemo.ipa.example.com --hosts=liza.ipa.example.com
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You should be able to extract this keytab on the host now.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ipa-getkeytab -s alina.ipa.example.com -p ldap&#x2F;haproxydemo.ipa.example.com -k &#x2F;etc&#x2F;dirsrv&#x2F;slapd-localhost&#x2F;ldap.keytab 
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;into &#x2F;etc&#x2F;sysconfig&#x2F;dirsrv-localhost&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;KRB5_KTNAME=&#x2F;etc&#x2F;dirsrv&#x2F;slapd-localhost&#x2F;ldap.keytab 
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now, restart the instance and make sure you can&#x27;t connect directly.&lt;&#x2F;p&gt;
&lt;p&gt;Setup haproxy. I had a huge amount of grief with ipv6, so I went v4 only
for this demo. :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;global
&lt;&#x2F;span&gt;&lt;span&gt;    log         127.0.0.1 local2
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    chroot      &#x2F;var&#x2F;lib&#x2F;haproxy
&lt;&#x2F;span&gt;&lt;span&gt;    pidfile     &#x2F;var&#x2F;run&#x2F;haproxy.pid
&lt;&#x2F;span&gt;&lt;span&gt;    maxconn     4000
&lt;&#x2F;span&gt;&lt;span&gt;    user        haproxy
&lt;&#x2F;span&gt;&lt;span&gt;    group       haproxy
&lt;&#x2F;span&gt;&lt;span&gt;    daemon
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    stats socket &#x2F;var&#x2F;lib&#x2F;haproxy&#x2F;stats
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;listen ldap :3389
&lt;&#x2F;span&gt;&lt;span&gt;        mode tcp
&lt;&#x2F;span&gt;&lt;span&gt;        balance roundrobin
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;        server ldap 10.0.0.2:389 check
&lt;&#x2F;span&gt;&lt;span&gt;        timeout connect        10s
&lt;&#x2F;span&gt;&lt;span&gt;        timeout server          1m
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;ldapsearch -H ldap:&#x2F;&#x2F;haproxydemo.ipa.example.com:3389 -Y GSSAPI
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Reveals a working connection!&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Debbuging and patching 389-ds.</title>
          <pubDate>Tue, 08 Dec 2015 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2015-12-08-debbuging-and-patching-389-ds/</link>
          <guid>https://fy.blackhats.net.au/blog/2015-12-08-debbuging-and-patching-389-ds/</guid>
          <description>&lt;h1 id=&quot;debbuging-and-patching-389-ds&quot;&gt;Debbuging and patching 389-ds.&lt;&#x2F;h1&gt;
&lt;p&gt;Debugging and working on software like 389-ds looks pretty daunting.
However, I think it&#x27;s one of the easiest projects to setup, debug and
contribute to (for a variety of reasons).&lt;&#x2F;p&gt;
&lt;p&gt;Fixing issues like the one referenced in this post is a good way to get
your hands dirty into C, gdb, and the project in general. It&#x27;s how I
started, by solving small issues like this, and working up to managing
larger fixes and commits. You will end up doing a lot of research and
testing, but you learn a lot for it.&lt;&#x2F;p&gt;
&lt;p&gt;Additionally, the 389-ds team are great people, and very willing to help
and walk you through debugging and issue solving like this.&lt;&#x2F;p&gt;
&lt;p&gt;Lets get started!&lt;&#x2F;p&gt;
&lt;p&gt;First, lets get your build env working.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;git clone http:&#x2F;&#x2F;git.fedorahosted.org&#x2F;git&#x2F;389&#x2F;ds.git
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If you need to apply any patches to test, now is the time:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;cd ds
&lt;&#x2F;span&gt;&lt;span&gt;git am ~&#x2F;path&#x2F;to&#x2F;patch
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now we can actually get all the dependencies. Changes these paths to
suit your environment.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;export DSPATH=~&#x2F;development&#x2F;389ds&#x2F;ds
&lt;&#x2F;span&gt;&lt;span&gt;sudo yum-builddep 389-ds-base
&lt;&#x2F;span&gt;&lt;span&gt;sudo yum install libasan llvm
&lt;&#x2F;span&gt;&lt;span&gt;mkdir -p ~&#x2F;build&#x2F;ds&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;cd ~&#x2F;build&#x2F;ds&#x2F; &amp;amp;&amp;amp; $DSPATH&#x2F;configure --with-openldap --enable-debug --enable-asan --prefix=&#x2F;opt&#x2F;dirsrv&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;make -C ~&#x2F;build&#x2F;ds
&lt;&#x2F;span&gt;&lt;span&gt;sudo make -C ~&#x2F;build&#x2F;ds install
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;NOTE: Thanks to Viktor for the tip about yum-builddep working without a
spec file.&lt;&#x2F;p&gt;
&lt;p&gt;If you are still missing packages, these commands are rough, but work.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;sudo yum install `grep &amp;quot;^BuildRequires&amp;quot; $DSPATH&#x2F;rpm&#x2F;389-ds-base.spec.in | awk &amp;#39;{ print $2 }&amp;#39; | grep -v &amp;quot;^&#x2F;&amp;quot;`
&lt;&#x2F;span&gt;&lt;span&gt;sudo yum install `grep &amp;quot;^Requires:&amp;quot; $DSPATH&#x2F;ds&#x2F;rpm&#x2F;389-ds-base.spec.in | awk &amp;#39;{ print $2 $3 $4 $5 $6 $7 }&amp;#39; | grep -v &amp;quot;^&#x2F;&amp;quot; | grep -v &amp;quot;name&amp;quot;`
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now with that out the way, we can get into it. Setup the ds install:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;sudo &#x2F;opt&#x2F;dirsrv&#x2F;sbin&#x2F;setup-ds.pl --debug General.StrictHostChecking=false
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If you have enabled ASAN you may notice that the install freezes trying
to start slapd. That&#x27;s okay, at this point you can control C it. If
setup-ds.pl finishes, even better.&lt;&#x2F;p&gt;
&lt;p&gt;Now lets run the instance up:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;sudo -s
&lt;&#x2F;span&gt;&lt;span&gt;export ASAN_SYMBOLIZER_PATH=&#x2F;usr&#x2F;bin&#x2F;llvm-symbolizer
&lt;&#x2F;span&gt;&lt;span&gt;export ASAN_OPTIONS=symbolize=1
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;opt&#x2F;dirsrv&#x2F;sbin&#x2F;ns-slapd -d 0 -D &#x2F;opt&#x2F;dirsrv&#x2F;etc&#x2F;dirsrv&#x2F;slapd-localhost
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[08&#x2F;Dec&#x2F;2015:13:09:01 +1000] - 389-Directory&#x2F;1.3.5 B2015.342.252 starting up
&lt;&#x2F;span&gt;&lt;span&gt;=================================================================
&lt;&#x2F;span&gt;&lt;span&gt;==28682== ERROR: AddressSanitizer: unknown-crash on address 0x7fff49a54ff0 at pc 0x7f59bc0f719f bp 0x7fff49a54c80 sp 0x7fff49a54c28
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Uh oh! We have a crash. Lets work it out.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;=================================================================
&lt;&#x2F;span&gt;&lt;span&gt;==28682== ERROR: AddressSanitizer: unknown-crash on address 0x7fff49a54ff0 at pc 0x7f59bc0f719f bp 0x7fff49a54c80 sp 0x7fff49a54c28
&lt;&#x2F;span&gt;&lt;span&gt;WRITE of size 513 at 0x7fff49a54ff0 thread T0
&lt;&#x2F;span&gt;&lt;span&gt;    #0 0x7f59bc0f719e in scanf_common &#x2F;usr&#x2F;src&#x2F;debug&#x2F;gcc-4.8.3-20140911&#x2F;obj-x86_64-redhat-linux&#x2F;x86_64-redhat-linux&#x2F;libsanitizer&#x2F;asan&#x2F;..&#x2F;..&#x2F;..&#x2F;..&#x2F;libsanitizer&#x2F;sanitizer_common&#x2F;sanitizer_common_interceptors_scanf.inc:305
&lt;&#x2F;span&gt;&lt;span&gt;    #1 0x7f59bc0f78b6 in __interceptor_vsscanf &#x2F;usr&#x2F;src&#x2F;debug&#x2F;gcc-4.8.3-20140911&#x2F;obj-x86_64-redhat-linux&#x2F;x86_64-redhat-linux&#x2F;libsanitizer&#x2F;asan&#x2F;..&#x2F;..&#x2F;..&#x2F;..&#x2F;libsanitizer&#x2F;sanitizer_common&#x2F;sanitizer_common_interceptors.inc:262
&lt;&#x2F;span&gt;&lt;span&gt;    #2 0x7f59bc0f79e9 in __interceptor_sscanf &#x2F;usr&#x2F;src&#x2F;debug&#x2F;gcc-4.8.3-20140911&#x2F;obj-x86_64-redhat-linux&#x2F;x86_64-redhat-linux&#x2F;libsanitizer&#x2F;asan&#x2F;..&#x2F;..&#x2F;..&#x2F;..&#x2F;libsanitizer&#x2F;sanitizer_common&#x2F;sanitizer_common_interceptors.inc:297
&lt;&#x2F;span&gt;&lt;span&gt;    #3 0x7f59b141e060 in read_metadata.isra.5 &#x2F;home&#x2F;wibrown&#x2F;development&#x2F;389ds&#x2F;ds&#x2F;ldap&#x2F;servers&#x2F;slapd&#x2F;back-ldbm&#x2F;dblayer.c:5268
&lt;&#x2F;span&gt;&lt;span&gt;    #4 0x7f59b1426b63 in dblayer_start &#x2F;home&#x2F;wibrown&#x2F;development&#x2F;389ds&#x2F;ds&#x2F;ldap&#x2F;servers&#x2F;slapd&#x2F;back-ldbm&#x2F;dblayer.c:1587
&lt;&#x2F;span&gt;&lt;span&gt;    #5 0x7f59b14d698e in ldbm_back_start &#x2F;home&#x2F;wibrown&#x2F;development&#x2F;389ds&#x2F;ds&#x2F;ldap&#x2F;servers&#x2F;slapd&#x2F;back-ldbm&#x2F;start.c:225
&lt;&#x2F;span&gt;&lt;span&gt;    #6 0x7f59bbd2dc60 in plugin_call_func &#x2F;home&#x2F;wibrown&#x2F;development&#x2F;389ds&#x2F;ds&#x2F;ldap&#x2F;servers&#x2F;slapd&#x2F;plugin.c:1920
&lt;&#x2F;span&gt;&lt;span&gt;    #7 0x7f59bbd2e8a7 in plugin_call_one &#x2F;home&#x2F;wibrown&#x2F;development&#x2F;389ds&#x2F;ds&#x2F;ldap&#x2F;servers&#x2F;slapd&#x2F;plugin.c:1870
&lt;&#x2F;span&gt;&lt;span&gt;    #8 0x7f59bbd2e8a7 in plugin_dependency_startall.isra.10.constprop.13 &#x2F;home&#x2F;wibrown&#x2F;development&#x2F;389ds&#x2F;ds&#x2F;ldap&#x2F;servers&#x2F;slapd&#x2F;plugin.c:1679
&lt;&#x2F;span&gt;&lt;span&gt;    #9 0x4121c5 in main &#x2F;home&#x2F;wibrown&#x2F;development&#x2F;389ds&#x2F;ds&#x2F;ldap&#x2F;servers&#x2F;slapd&#x2F;main.c:1054
&lt;&#x2F;span&gt;&lt;span&gt;    #10 0x7f59b8df5af4 in __libc_start_main &#x2F;usr&#x2F;src&#x2F;debug&#x2F;glibc-2.17-c758a686&#x2F;csu&#x2F;libc-start.c:274
&lt;&#x2F;span&gt;&lt;span&gt;    #11 0x4133b4 in _start (&#x2F;opt&#x2F;dirsrv&#x2F;sbin&#x2F;ns-slapd+0x4133b4)
&lt;&#x2F;span&gt;&lt;span&gt;Address 0x7fff49a54ff0 is located at offset 448 in frame &amp;lt;read_metadata.isra.5&amp;gt; of T0&amp;#39;s stack:
&lt;&#x2F;span&gt;&lt;span&gt;  This frame has 7 object(s):
&lt;&#x2F;span&gt;&lt;span&gt;    [32, 33) &amp;#39;delimiter&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;    [96, 100) &amp;#39;count&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;    [160, 168) &amp;#39;buf&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;    [224, 256) &amp;#39;prfinfo&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;    [288, 416) &amp;#39;value&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;    [448, 960) &amp;#39;attribute&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;    [992, 5088) &amp;#39;filename&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;HINT: this may be a false positive if your program uses some custom stack unwind mechanism or swapcontext
&lt;&#x2F;span&gt;&lt;span&gt;      (longjmp and C++ exceptions *are* supported)
&lt;&#x2F;span&gt;&lt;span&gt;SUMMARY: AddressSanitizer: unknown-crash &#x2F;usr&#x2F;src&#x2F;debug&#x2F;gcc-4.8.3-20140911&#x2F;obj-x86_64-redhat-linux&#x2F;x86_64-redhat-linux&#x2F;libsanitizer&#x2F;asan&#x2F;..&#x2F;..&#x2F;..&#x2F;..&#x2F;libsanitizer&#x2F;sanitizer_common&#x2F;sanitizer_common_interceptors_scanf.inc:305 scanf_common
&lt;&#x2F;span&gt;&lt;span&gt;Shadow bytes around the buggy address:
&lt;&#x2F;span&gt;&lt;span&gt;  0x1000693429a0: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
&lt;&#x2F;span&gt;&lt;span&gt;  0x1000693429b0: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
&lt;&#x2F;span&gt;&lt;span&gt;  0x1000693429c0: 00 00 00 00 00 00 f1 f1 f1 f1 01 f4 f4 f4 f2 f2
&lt;&#x2F;span&gt;&lt;span&gt;  0x1000693429d0: f2 f2 04 f4 f4 f4 f2 f2 f2 f2 00 f4 f4 f4 f2 f2
&lt;&#x2F;span&gt;&lt;span&gt;  0x1000693429e0: f2 f2 00 00 00 00 f2 f2 f2 f2 00 00 00 00 00 00
&lt;&#x2F;span&gt;&lt;span&gt;=&amp;gt;0x1000693429f0: 00 00 00 00 00 00 00 00 00 00 f2 f2 f2 f2[00]00
&lt;&#x2F;span&gt;&lt;span&gt;  0x100069342a00: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
&lt;&#x2F;span&gt;&lt;span&gt;  0x100069342a10: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
&lt;&#x2F;span&gt;&lt;span&gt;  0x100069342a20: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
&lt;&#x2F;span&gt;&lt;span&gt;  0x100069342a30: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 f2 f2
&lt;&#x2F;span&gt;&lt;span&gt;  0x100069342a40: f2 f2 00 00 00 00 00 00 00 00 00 00 00 00 00 00
&lt;&#x2F;span&gt;&lt;span&gt;Shadow byte legend (one shadow byte represents 8 application bytes):
&lt;&#x2F;span&gt;&lt;span&gt;  Addressable:           00
&lt;&#x2F;span&gt;&lt;span&gt;  Partially addressable: 01 02 03 04 05 06 07 
&lt;&#x2F;span&gt;&lt;span&gt;  Heap left redzone:     fa
&lt;&#x2F;span&gt;&lt;span&gt;  Heap righ redzone:     fb
&lt;&#x2F;span&gt;&lt;span&gt;  Freed Heap region:     fd
&lt;&#x2F;span&gt;&lt;span&gt;  Stack left redzone:    f1
&lt;&#x2F;span&gt;&lt;span&gt;  Stack mid redzone:     f2
&lt;&#x2F;span&gt;&lt;span&gt;  Stack right redzone:   f3
&lt;&#x2F;span&gt;&lt;span&gt;  Stack partial redzone: f4
&lt;&#x2F;span&gt;&lt;span&gt;  Stack after return:    f5
&lt;&#x2F;span&gt;&lt;span&gt;  Stack use after scope: f8
&lt;&#x2F;span&gt;&lt;span&gt;  Global redzone:        f9
&lt;&#x2F;span&gt;&lt;span&gt;  Global init order:     f6
&lt;&#x2F;span&gt;&lt;span&gt;  Poisoned by user:      f7
&lt;&#x2F;span&gt;&lt;span&gt;  ASan internal:         fe
&lt;&#x2F;span&gt;&lt;span&gt;==28682== ABORTING
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;First lets focus on the stack. Specifically:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;WRITE of size 513 at 0x7fff49a54ff0 thread T0
&lt;&#x2F;span&gt;&lt;span&gt;    #0 0x7f59bc0f719e in scanf_common &#x2F;usr&#x2F;src&#x2F;debug&#x2F;gcc-4.8.3-20140911&#x2F;obj-x86_64-redhat-linux&#x2F;x86_64-redhat-linux&#x2F;libsanitizer&#x2F;asan&#x2F;..&#x2F;..&#x2F;..&#x2F;..&#x2F;libsanitizer&#x2F;sanitizer_common&#x2F;sanitizer_common_interceptors_scanf.inc:305
&lt;&#x2F;span&gt;&lt;span&gt;    #1 0x7f59bc0f78b6 in __interceptor_vsscanf &#x2F;usr&#x2F;src&#x2F;debug&#x2F;gcc-4.8.3-20140911&#x2F;obj-x86_64-redhat-linux&#x2F;x86_64-redhat-linux&#x2F;libsanitizer&#x2F;asan&#x2F;..&#x2F;..&#x2F;..&#x2F;..&#x2F;libsanitizer&#x2F;sanitizer_common&#x2F;sanitizer_common_interceptors.inc:262
&lt;&#x2F;span&gt;&lt;span&gt;    #2 0x7f59bc0f79e9 in __interceptor_sscanf &#x2F;usr&#x2F;src&#x2F;debug&#x2F;gcc-4.8.3-20140911&#x2F;obj-x86_64-redhat-linux&#x2F;x86_64-redhat-linux&#x2F;libsanitizer&#x2F;asan&#x2F;..&#x2F;..&#x2F;..&#x2F;..&#x2F;libsanitizer&#x2F;sanitizer_common&#x2F;sanitizer_common_interceptors.inc:297
&lt;&#x2F;span&gt;&lt;span&gt;    #3 0x7f59b141e060 in read_metadata.isra.5 &#x2F;home&#x2F;wibrown&#x2F;development&#x2F;389ds&#x2F;ds&#x2F;ldap&#x2F;servers&#x2F;slapd&#x2F;back-ldbm&#x2F;dblayer.c:5268
&lt;&#x2F;span&gt;&lt;span&gt;    #4 0x7f59b1426b63 in dblayer_start &#x2F;home&#x2F;wibrown&#x2F;development&#x2F;389ds&#x2F;ds&#x2F;ldap&#x2F;servers&#x2F;slapd&#x2F;back-ldbm&#x2F;dblayer.c:1587
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now, we can ignore frame 0,1,2. These are all in asan. But, we do own
code in frame 3. So lets take a look there as our first port of call.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;vim ldap&#x2F;servers&#x2F;slapd&#x2F;back-ldbm&#x2F;dblayer.c +5268
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;5262             if (NULL != nextline) {                                              
&lt;&#x2F;span&gt;&lt;span&gt;5263                 *nextline++ = &amp;#39;\0&amp;#39;;                                              
&lt;&#x2F;span&gt;&lt;span&gt;5264                 while (&amp;#39;\n&amp;#39; == *nextline) {                                      
&lt;&#x2F;span&gt;&lt;span&gt;5265                     nextline++;                                                  
&lt;&#x2F;span&gt;&lt;span&gt;5266                 }                                                                
&lt;&#x2F;span&gt;&lt;span&gt;5267             }                                                                    
&lt;&#x2F;span&gt;&lt;span&gt;5268             sscanf(thisline,&amp;quot;%512[a-z]%c%128s&amp;quot;,attribute,&amp;amp;delimiter,value);      &#x2F;* &amp;lt;---- THIS LINE *&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;5269             if (0 == strcmp(&amp;quot;cachesize&amp;quot;,attribute)) {                            
&lt;&#x2F;span&gt;&lt;span&gt;5270                 priv-&amp;gt;dblayer_previous_cachesize = strtoul(value, NULL, 10);     
&lt;&#x2F;span&gt;&lt;span&gt;5271             } else if (0 == strcmp(&amp;quot;ncache&amp;quot;,attribute)) {                        
&lt;&#x2F;span&gt;&lt;span&gt;5272                 number = atoi(value);                                            
&lt;&#x2F;span&gt;&lt;span&gt;5273                 priv-&amp;gt;dblayer_previous_ncache = number;                          
&lt;&#x2F;span&gt;&lt;span&gt;5274             } else if (0 == strcmp(&amp;quot;version&amp;quot;,attribute)) { 
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;So the crash is that we write of size 513 here. Lets look at the
function sscanf, to see what&#x27;s happening.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;man sscanf
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;int sscanf(const char *str, const char *format, ...);
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;span&gt;The scanf() family of functions scans input according to format as described below
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;So, we know that we are writing something too large here. Lets checkout
the size of our values at that point.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;gdb &#x2F;opt&#x2F;dirsrv&#x2F;sbin&#x2F;ns-slapd
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Reading symbols from &#x2F;opt&#x2F;dirsrv&#x2F;sbin&#x2F;ns-slapd...done.
&lt;&#x2F;span&gt;&lt;span&gt;(gdb) set args -d 0 -D &#x2F;opt&#x2F;dirsrv&#x2F;etc&#x2F;dirsrv&#x2F;slapd-localhost
&lt;&#x2F;span&gt;&lt;span&gt;(gdb) break dblayer.c:5268
&lt;&#x2F;span&gt;&lt;span&gt;No source file named dblayer.c.
&lt;&#x2F;span&gt;&lt;span&gt;Make breakpoint pending on future shared library load? (y or [n]) y
&lt;&#x2F;span&gt;&lt;span&gt;Breakpoint 1 (dblayer.c:5268) pending.
&lt;&#x2F;span&gt;&lt;span&gt;(gdb) run
&lt;&#x2F;span&gt;&lt;span&gt;Starting program: &#x2F;opt&#x2F;dirsrv&#x2F;sbin&#x2F;ns-slapd -d 0 -D &#x2F;opt&#x2F;dirsrv&#x2F;etc&#x2F;dirsrv&#x2F;slapd-localhost
&lt;&#x2F;span&gt;&lt;span&gt;[Thread debugging using libthread_db enabled]
&lt;&#x2F;span&gt;&lt;span&gt;Using host libthread_db library &amp;quot;&#x2F;lib64&#x2F;libthread_db.so.1&amp;quot;.
&lt;&#x2F;span&gt;&lt;span&gt;Detaching after fork from child process 28690.
&lt;&#x2F;span&gt;&lt;span&gt;[08&#x2F;Dec&#x2F;2015:13:18:08 +1000] - slapd_nss_init: chmod failed for file &#x2F;opt&#x2F;dirsrv&#x2F;etc&#x2F;dirsrv&#x2F;slapd-localhost&#x2F;cert8.db error (2) No such file or directory.
&lt;&#x2F;span&gt;&lt;span&gt;[08&#x2F;Dec&#x2F;2015:13:18:08 +1000] - slapd_nss_init: chmod failed for file &#x2F;opt&#x2F;dirsrv&#x2F;etc&#x2F;dirsrv&#x2F;slapd-localhost&#x2F;key3.db error (2) No such file or directory.
&lt;&#x2F;span&gt;&lt;span&gt;[08&#x2F;Dec&#x2F;2015:13:18:08 +1000] - slapd_nss_init: chmod failed for file &#x2F;opt&#x2F;dirsrv&#x2F;etc&#x2F;dirsrv&#x2F;slapd-localhost&#x2F;secmod.db error (2) No such file or directory.
&lt;&#x2F;span&gt;&lt;span&gt;[08&#x2F;Dec&#x2F;2015:13:18:08 +1000] - 389-Directory&#x2F;1.3.5 B2015.342.252 starting up
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Breakpoint 1, read_metadata (li=0x6028000121c0) at &#x2F;home&#x2F;wibrown&#x2F;development&#x2F;389ds&#x2F;ds&#x2F;ldap&#x2F;servers&#x2F;slapd&#x2F;back-ldbm&#x2F;dblayer.c:5268
&lt;&#x2F;span&gt;&lt;span&gt;5268                sscanf(thisline,&amp;quot;%512[a-z]%c%128s&amp;quot;,attribute,&amp;amp;delimiter,value);
&lt;&#x2F;span&gt;&lt;span&gt;Missing separate debuginfos, use: debuginfo-install sqlite-3.7.17-6.el7_1.1.x86_64
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If you are missing more debuginfo, install them, and re-run.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;(gdb) set print repeats 20
&lt;&#x2F;span&gt;&lt;span&gt;(gdb) print thisline
&lt;&#x2F;span&gt;&lt;span&gt;$6 = 0x600c0015e900 &amp;quot;cachesize:10000000\nncache:0\nversion:5\nlocks:10000\n&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;(gdb) print attribute
&lt;&#x2F;span&gt;&lt;span&gt;$7 = &amp;quot;\200\275\377\377\377\177\000\000p\275\377\377\377\177\000\000\301\066\031\020\000\000\000\000\243|\023\352\377\177\000\000\377\377\377\377\000\000\000\000\000\253bu\256\066\357oPBS\362\377\177\000\000p\277\377\377\377\177\000\000\300\317\377\377\377\177\000\000\320\356\a\000\b`\000\000\060\277\377\377\377\177\000\000\003\000\000\000\000\000\000\000\346w\377\177\000\020\000\000\262AT\362\377\177\000\000\340-T\362\377\177\000\000p\277\377\377\377\177\000\000\247\277\377\377\377\177\000\000\000\020\000\000\377\177\000\000*\021\346\364&amp;#39;\000\200&amp;lt;\240\300L\352\377\177\000\000\000\000\000\000\000\000\000\000\000\253bu\256\066\357o\003\000\000\000\000\000\000\000\210\275U\362\377\177\000\000i\000\020\000\000\000\000\000&amp;quot;...
&lt;&#x2F;span&gt;&lt;span&gt;(gdb) print &amp;amp;delimiter
&lt;&#x2F;span&gt;&lt;span&gt;$8 = 0x7fffffffbbb0 &amp;quot;*\021\346\364\377\177&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;(gdb) print value
&lt;&#x2F;span&gt;&lt;span&gt;$9 = &amp;quot;A\000\000\000\000\000\000\000\070\276\377\377\377\177\000\000\020\276\377\377\377\177\000\000\001\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\330\000\001\000F`\000\000\200\375\000\000F`\000\000\257O\336\367\377\177\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\001\000\000\000\377\177\000\000\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000\000\200\375\000\000F`\000\000\306c%\352\377\177\000\000\236\061T\362\377\177\000&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Some of these are some chunky values! Okay, lets try and see which one
is a bit too big.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;(gdb) print sizeof(attribute)
&lt;&#x2F;span&gt;&lt;span&gt;$10 = 512
&lt;&#x2F;span&gt;&lt;span&gt;(gdb) print sizeof(&amp;amp;delimiter)
&lt;&#x2F;span&gt;&lt;span&gt;$11 = 8
&lt;&#x2F;span&gt;&lt;span&gt;(gdb) print sizeof(value)
&lt;&#x2F;span&gt;&lt;span&gt;$12 = 128
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;So, if our write is size 513, the closest is probably the attribute
variable. But it&#x27;s only size 512? How is this causing an issue?&lt;&#x2F;p&gt;
&lt;p&gt;Well, if we look at the sscanf man page again for the substitution that
attribute will land in (%512[a-z]) we see:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;Matches a nonempty sequence of characters from the specified set of accepted characters
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;span&gt;must be enough room for  all the characters in the string, plus a terminating null byte.
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;So, we have space for 512 chars, which is the size of the attribute
block, but we don&#x27;t have space for the null byte! So lets add it in:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;5194     char attribute[513];                                                         
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If we keep looking at the man page we see another error too for %128s&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;...next pointer must be a pointer to character array that is long enough to hold the input sequence and the terminating null byte (&amp;#39;\0&amp;#39;), which is added automatically.
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;So lets preemptively fix that too.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;5195     char value[129], delimiter;                                                  
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now rebuild&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;make -C ~&#x2F;build&#x2F;ds
&lt;&#x2F;span&gt;&lt;span&gt;sudo make -C ~&#x2F;build&#x2F;ds install
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Lets run slapd and see if it fixed it:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;sudo -s
&lt;&#x2F;span&gt;&lt;span&gt;export ASAN_SYMBOLIZER_PATH=&#x2F;usr&#x2F;bin&#x2F;llvm-symbolizer
&lt;&#x2F;span&gt;&lt;span&gt;export ASAN_OPTIONS=symbolize=1
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;opt&#x2F;dirsrv&#x2F;sbin&#x2F;ns-slapd -d 0 -D &#x2F;opt&#x2F;dirsrv&#x2F;etc&#x2F;dirsrv&#x2F;slapd-localhost
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;I0&amp;gt; &#x2F;opt&#x2F;dirsrv&#x2F;sbin&#x2F;ns-slapd -d 0 -D &#x2F;opt&#x2F;dirsrv&#x2F;etc&#x2F;dirsrv&#x2F;slapd-localhost
&lt;&#x2F;span&gt;&lt;span&gt;[08&#x2F;Dec&#x2F;2015:13:47:20 +1000] - slapd_nss_init: chmod failed for file &#x2F;opt&#x2F;dirsrv&#x2F;etc&#x2F;dirsrv&#x2F;slapd-localhost&#x2F;cert8.db error (2) No such file or directory.
&lt;&#x2F;span&gt;&lt;span&gt;[08&#x2F;Dec&#x2F;2015:13:47:20 +1000] - slapd_nss_init: chmod failed for file &#x2F;opt&#x2F;dirsrv&#x2F;etc&#x2F;dirsrv&#x2F;slapd-localhost&#x2F;key3.db error (2) No such file or directory.
&lt;&#x2F;span&gt;&lt;span&gt;[08&#x2F;Dec&#x2F;2015:13:47:20 +1000] - slapd_nss_init: chmod failed for file &#x2F;opt&#x2F;dirsrv&#x2F;etc&#x2F;dirsrv&#x2F;slapd-localhost&#x2F;secmod.db error (2) No such file or directory.
&lt;&#x2F;span&gt;&lt;span&gt;[08&#x2F;Dec&#x2F;2015:13:47:20 +1000] - 389-Directory&#x2F;1.3.5 B2015.342.344 starting up
&lt;&#x2F;span&gt;&lt;span&gt;[08&#x2F;Dec&#x2F;2015:13:47:27 +1000] - slapd started.  Listening on All Interfaces port 389 for LDAP requests
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Format this into a patch with git:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;git commit -a
&lt;&#x2F;span&gt;&lt;span&gt;git format-patch HEAD~1
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;My patch looks like this&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;From eab0f0e9fc24c1915d2767a87a8f089f6d820955 Mon Sep 17 00:00:00 2001
&lt;&#x2F;span&gt;&lt;span&gt;From: William Brown &amp;lt;firstyear at redhat.com&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;Date: Tue, 8 Dec 2015 13:52:29 +1000
&lt;&#x2F;span&gt;&lt;span&gt;Subject: [PATCH] Ticket 48372 - ASAN invalid write in dblayer.c
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Bug Description:  During server start up we attempt to write 513 bytes to a
&lt;&#x2F;span&gt;&lt;span&gt;buffer that is only 512 bytes long.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Fix Description:  Increase the size of the buffer that sscanf writes into.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;https:&#x2F;&#x2F;fedorahosted.org&#x2F;389&#x2F;ticket&#x2F;48372
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Author: wibrown
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Review by: ???
&lt;&#x2F;span&gt;&lt;span&gt;---
&lt;&#x2F;span&gt;&lt;span&gt; ldap&#x2F;servers&#x2F;slapd&#x2F;back-ldbm&#x2F;dblayer.c | 4 ++--
&lt;&#x2F;span&gt;&lt;span&gt; 1 file changed, 2 insertions(+), 2 deletions(-)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;diff --git a&#x2F;ldap&#x2F;servers&#x2F;slapd&#x2F;back-ldbm&#x2F;dblayer.c b&#x2F;ldap&#x2F;servers&#x2F;slapd&#x2F;back-ldbm&#x2F;dblayer.c
&lt;&#x2F;span&gt;&lt;span&gt;index 33506f4..9168c8c 100644
&lt;&#x2F;span&gt;&lt;span&gt;--- a&#x2F;ldap&#x2F;servers&#x2F;slapd&#x2F;back-ldbm&#x2F;dblayer.c
&lt;&#x2F;span&gt;&lt;span&gt;+++ b&#x2F;ldap&#x2F;servers&#x2F;slapd&#x2F;back-ldbm&#x2F;dblayer.c
&lt;&#x2F;span&gt;&lt;span&gt;@@ -5191,8 +5191,8 @@ static int read_metadata(struct ldbminfo *li)
&lt;&#x2F;span&gt;&lt;span&gt;     PRFileInfo64 prfinfo;
&lt;&#x2F;span&gt;&lt;span&gt;     int return_value = 0;
&lt;&#x2F;span&gt;&lt;span&gt;     PRInt32 byte_count = 0;
&lt;&#x2F;span&gt;&lt;span&gt;-    char attribute[512];
&lt;&#x2F;span&gt;&lt;span&gt;-    char value[128], delimiter;
&lt;&#x2F;span&gt;&lt;span&gt;+    char attribute[513];
&lt;&#x2F;span&gt;&lt;span&gt;+    char value[129], delimiter;
&lt;&#x2F;span&gt;&lt;span&gt;     int number = 0;
&lt;&#x2F;span&gt;&lt;span&gt;     dblayer_private *priv = (dblayer_private *)li-&amp;gt;li_dblayer_private;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;-- 
&lt;&#x2F;span&gt;&lt;span&gt;2.5.0
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;One more bug fixed! Lets get it commited. If you don&#x27;t have a FAS
account, please email the git format-patch output to
&lt;a href=&quot;mailto:389-devel@lists.fedoraproject.org&quot;&gt;389-devel@lists.fedoraproject.org&lt;&#x2F;a&gt; else, raise a ticket on
&lt;a href=&quot;https:&#x2F;&#x2F;fedorahosted.org&#x2F;389&quot;&gt;https:&#x2F;&#x2F;fedorahosted.org&#x2F;389&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;43&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>ns-slapd access log notes field</title>
          <pubDate>Fri, 04 Dec 2015 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2015-12-04-ns-slapd-access-log-notes-field/</link>
          <guid>https://fy.blackhats.net.au/blog/2015-12-04-ns-slapd-access-log-notes-field/</guid>
          <description>&lt;h1 id=&quot;ns-slapd-access-log-notes-field&quot;&gt;ns-slapd access log notes field&lt;&#x2F;h1&gt;
&lt;p&gt;It would appear we don&#x27;t have any documentation for the tricky little
notes field in ns-slapd.&lt;&#x2F;p&gt;
&lt;p&gt;Sometimes in a search you&#x27;ll see:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;[26&#x2F;Nov&#x2F;2015:10:22:00 +1000] conn=5 op=1 SRCH base=&amp;quot;&amp;quot; scope=0 notes=&amp;quot;U&amp;quot; filter=&amp;quot;(cn=foo)&amp;quot; attrs=&amp;quot;cn&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;See the notes=&amp;quot;U&amp;quot;? Well, it turns out it&#x27;s the DS trying to help you
out.&lt;&#x2F;p&gt;
&lt;p&gt;First, the two to look out for are notes=U and notes=A.&lt;&#x2F;p&gt;
&lt;p&gt;notes=A is BAD. You never want to get this one. It means that all
candidate attributes in the filter are unindexed, so we need to make a
full table scan. This can quickly hit the nsslapd-lookthroughlimit.&lt;&#x2F;p&gt;
&lt;p&gt;To rectify this, look at the search, and identify the attributes. Look
them up in cn=schema:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ldapsearch -H ldap:&#x2F;&#x2F;localhost -b &amp;#39;cn=schema&amp;#39; -x &amp;#39;(objectClass=*)&amp;#39; attributeTypes
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;And make sure it has an equality syntax:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;attributeTypes: ( 2.5.4.3 NAME ( &amp;#39;cn&amp;#39; &amp;#39;commonName&amp;#39; )  SUP name EQUALITY caseIg
&lt;&#x2F;span&gt;&lt;span&gt; noreMatch SUBSTR caseIgnoreSubstringsMatch SYNTAX 1.3.6.1.4.1.1466.115.121.1.
&lt;&#x2F;span&gt;&lt;span&gt; 15 X-ORIGIN &amp;#39;RFC 4519&amp;#39; X-DEPRECATED &amp;#39;commonName&amp;#39; )
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If you don&#x27;t have an equality syntax, DO NOT ADD AN INDEX. Terrible
things will happen!&lt;&#x2F;p&gt;
&lt;p&gt;notes=U means one of two things. It means that a candidate attribute in
the filter is unindexed, but there is still an indexed candidate. Or it
means that the search has hit the idlistscanlimit.&lt;&#x2F;p&gt;
&lt;p&gt;If you have the query like below, check your nsslapd indexes. cn is
probably indexed, but then you need to add the index for sn. Follow the
rules as above, and make sure it has an equality syntax. :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&amp;quot;(|(cn=foo)(sn=bar))&amp;quot; 
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Second, if that&#x27;s not the issue, and you think you are hitting
idlistscanlimit, you can either:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Adjust it globally&lt;&#x2F;li&gt;
&lt;li&gt;Adjust it for the single entry&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Doing it on the entry, can cause the query to become sometimes more
efficient, because you can de-preference certain indexes. There is more
to read about here in the &amp;lt;a
href=&amp;quot;&lt;a href=&quot;http:&#x2F;&#x2F;www.port389.org&#x2F;docs&#x2F;389ds&#x2F;design&#x2F;fine-grained-id-list-size.html&quot;&gt;http:&#x2F;&#x2F;www.port389.org&#x2F;docs&#x2F;389ds&#x2F;design&#x2F;fine-grained-id-list-size.html&lt;&#x2F;a&gt;&amp;quot;&amp;gt;id
scan limit docs&amp;lt;&#x2F;a&amp;gt;.&lt;&#x2F;p&gt;
&lt;p&gt;Remember to test offline, in a production replica!&lt;&#x2F;p&gt;
&lt;p&gt;40&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>The hidden log features of ns-slapd</title>
          <pubDate>Fri, 04 Dec 2015 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2015-12-04-the-hidden-log-features-of-ns-slapd/</link>
          <guid>https://fy.blackhats.net.au/blog/2015-12-04-the-hidden-log-features-of-ns-slapd/</guid>
          <description>&lt;h1 id=&quot;the-hidden-log-features-of-ns-slapd&quot;&gt;The hidden log features of ns-slapd&lt;&#x2F;h1&gt;
&lt;p&gt;This week I discovered (Or dug up: ns-slapd is old) that we have two
hidden logging features. In fact searching for one of them yields no
results, searching the other shows a document that says it&#x27;s
undocumented.&lt;&#x2F;p&gt;
&lt;p&gt;This post hopes to rectify that.&lt;&#x2F;p&gt;
&lt;p&gt;In ns-slapd, during a normal operation you can see what a connected
client is searching in the access log, or what they are changing based
on the audit log.&lt;&#x2F;p&gt;
&lt;p&gt;If on a configuration for a plugin you need to diagnose these operations
you can&#x27;t do this... At least that&#x27;s what the documentation tells
you.&lt;&#x2F;p&gt;
&lt;p&gt;You can enable logging for search operations on a plugin through the
value:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;nsslapd-logAccess: on
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You can enabled logging for mod&#x2F;modrdn&#x2F;del&#x2F;add operations on a plugin
through the value:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;nsslapd-logAudit: on
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This will yield logs such as:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;time: 20151204143353
&lt;&#x2F;span&gt;&lt;span&gt;dn: uid=test1,ou=People,dc=example,dc=com
&lt;&#x2F;span&gt;&lt;span&gt;result: 0
&lt;&#x2F;span&gt;&lt;span&gt;changetype: modify
&lt;&#x2F;span&gt;&lt;span&gt;delete: memberOf
&lt;&#x2F;span&gt;&lt;span&gt;-
&lt;&#x2F;span&gt;&lt;span&gt;replace: modifiersname
&lt;&#x2F;span&gt;&lt;span&gt;modifiersname: cn=MemberOf Plugin,cn=plugins,cn=config
&lt;&#x2F;span&gt;&lt;span&gt;-
&lt;&#x2F;span&gt;&lt;span&gt;replace: modifytimestamp
&lt;&#x2F;span&gt;&lt;span&gt;modifytimestamp: 20151204043353Z
&lt;&#x2F;span&gt;&lt;span&gt;-
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;time: 20151204143353
&lt;&#x2F;span&gt;&lt;span&gt;dn: cn=Test Managers,ou=Groups,dc=example,dc=com
&lt;&#x2F;span&gt;&lt;span&gt;result: 0
&lt;&#x2F;span&gt;&lt;span&gt;changetype: modify
&lt;&#x2F;span&gt;&lt;span&gt;delete: member
&lt;&#x2F;span&gt;&lt;span&gt;member: uid=test1,ou=People,dc=example,dc=com
&lt;&#x2F;span&gt;&lt;span&gt;-
&lt;&#x2F;span&gt;&lt;span&gt;replace: modifiersname
&lt;&#x2F;span&gt;&lt;span&gt;modifiersname: cn=directory manager
&lt;&#x2F;span&gt;&lt;span&gt;-
&lt;&#x2F;span&gt;&lt;span&gt;replace: modifytimestamp
&lt;&#x2F;span&gt;&lt;span&gt;modifytimestamp: 20151204043353Z
&lt;&#x2F;span&gt;&lt;span&gt;-
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Finally, a new option has been added that will enable both on all
plugins in the server.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;nsslapd-plugin-logging: on
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;All of these configurations are bound by and respect the following
settings:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;nsslapd-accesslog-logging-enabled
&lt;&#x2F;span&gt;&lt;span&gt;nsslapd-auditlog-logging-enabled
&lt;&#x2F;span&gt;&lt;span&gt;nsslapd-auditfaillog-logging-enabled
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
</description>
      </item>
      <item>
          <title>Where does that attribute belong?</title>
          <pubDate>Fri, 04 Dec 2015 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2015-12-04-where-does-that-attribute-belong/</link>
          <guid>https://fy.blackhats.net.au/blog/2015-12-04-where-does-that-attribute-belong/</guid>
          <description>&lt;h1 id=&quot;where-does-that-attribute-belong&quot;&gt;Where does that attribute belong?&lt;&#x2F;h1&gt;
&lt;p&gt;A lot of the time in ldap, you spend your time scratching your head
thinking &amp;quot;Hey, I wish I knew what objectclass I needed for attribute
X&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;Yes, you can go through the schema, grep out what objectclasses. But
it&#x27;s a bit tedious, and it&#x27;s also not very accessible.&lt;&#x2F;p&gt;
&lt;p&gt;In lib389 I have written a pair of tools to help with this.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;lib389&#x2F;clitools&#x2F;ds_schema_attributetype_list.py
&lt;&#x2F;span&gt;&lt;span&gt;lib389&#x2F;clitools&#x2F;ds_schema_attributetype_query.py
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;List does what you expect: It lists the attributes available on a
server, but does so neatly compared to ldapsearch -b cn=schema. The
output for comparison:&lt;&#x2F;p&gt;
&lt;p&gt;ldapsearch -b &#x27;cn=schema&#x27; -x &#x27;(objectClass=*)&#x27; attributeTypes :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;span&gt;attributeTypes: ( 1.2.840.113556.1.2.102 NAME &amp;#39;memberOf&amp;#39; DESC &amp;#39;Group that the 
&lt;&#x2F;span&gt;&lt;span&gt; entry belongs to&amp;#39; SYNTAX 1.3.6.1.4.1.1466.115.121.1.12 X-ORIGIN &amp;#39;Netscape Del
&lt;&#x2F;span&gt;&lt;span&gt; egated Administrator&amp;#39; )
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;python lib389&#x2F;clitools&#x2F;ds_schema_attributetype_list.py -i localhost :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;( 1.2.840.113556.1.2.102 NAME &amp;#39;memberOf&amp;#39; DESC &amp;#39;Group that the entry belongs to&amp;#39; SYNTAX 1.3.6.1.4.1.1466.115.121.1.12 X-ORIGIN &amp;#39;Netscape Delegated Administrator&amp;#39; )
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The big difference is that it&#x27;s on one line: Much easier to grep
through.&lt;&#x2F;p&gt;
&lt;p&gt;The real gem is the query tool.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;python lib389&#x2F;clitools&#x2F;ds_schema_attributetype_query.py -i localhost -a memberOf
&lt;&#x2F;span&gt;&lt;span&gt;( 1.2.840.113556.1.2.102 NAME &amp;#39;memberOf&amp;#39; DESC &amp;#39;Group that the entry belongs to&amp;#39; SYNTAX 1.3.6.1.4.1.1466.115.121.1.12 X-ORIGIN &amp;#39;Netscape Delegated Administrator&amp;#39; )
&lt;&#x2F;span&gt;&lt;span&gt;MUST
&lt;&#x2F;span&gt;&lt;span&gt;MAY
&lt;&#x2F;span&gt;&lt;span&gt;( 2.16.840.1.113730.3.2.130 NAME &amp;#39;inetUser&amp;#39; DESC &amp;#39;Auxiliary class which must be present in an entry for delivery of subscriber services&amp;#39; SUP top AUXILIARY MAY ( uid $ inetUserStatus $ inetUserHttpURL $ userPassword $ memberOf ) )
&lt;&#x2F;span&gt;&lt;span&gt;( 2.16.840.1.113730.3.2.112 NAME &amp;#39;inetAdmin&amp;#39; DESC &amp;#39;Marker for an administrative group or user&amp;#39; SUP top AUXILIARY MAY ( aci $ memberOf $ adminRole ) )
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Shows you the attribute, and exactly which objectClasses MAY and MUST
host this attribute. Additionally, because we give you the objectClasses
too, you can see the implications of which one you want to enable an add
to your object.&lt;&#x2F;p&gt;
&lt;p&gt;Happy schema querying.&lt;&#x2F;p&gt;
&lt;p&gt;&amp;lt;pre&amp;gt;EDIT 2015-12-07 &amp;lt;&#x2F;pre&amp;gt; Viktor A pointed out that you can do the
following:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ldapsearch -o ldif-wrap=no -x -b &amp;#39;cn=schema&amp;#39;  &amp;#39;(objectClass=*)&amp;#39; attributeTypes
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;span&gt;attributeTypes: ( 2.16.840.1.113730.3.1.612 NAME &amp;#39;generation&amp;#39; DESC &amp;#39;Netscape defined attribute type&amp;#39; SYNTAX 1.3.6.1.4.1.1466.115.121.1.26 X-ORIGIN &amp;#39;Netscape Directory Server&amp;#39; )
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&#x2F;pre&amp;gt; 
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;This will put all the results onto one line rather than wrapping at 80. Additionally, if you find results that are base64ed:
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;un64ldif () {
&lt;&#x2F;span&gt;&lt;span&gt; while read l; do
&lt;&#x2F;span&gt;&lt;span&gt;  echo &amp;quot;$l&amp;quot; | grep &amp;#39;^\([^:]\+: \|$\)&amp;#39; || \
&lt;&#x2F;span&gt;&lt;span&gt;   echo &amp;quot;${l%%:: *}: $(base64 -d &amp;lt;&amp;lt;&amp;lt; &amp;quot;${l#*:: }&amp;quot;)&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt; done
&lt;&#x2F;span&gt;&lt;span&gt; return 0
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Thanks for the comment! 41&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Ldap post read control</title>
          <pubDate>Thu, 26 Nov 2015 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2015-11-26-ldap-post-read-control/</link>
          <guid>https://fy.blackhats.net.au/blog/2015-11-26-ldap-post-read-control/</guid>
          <description>&lt;h1 id=&quot;ldap-post-read-control&quot;&gt;Ldap post read control&lt;&#x2F;h1&gt;
&lt;p&gt;This was a bit of a pain to use in python.&lt;&#x2F;p&gt;
&lt;p&gt;If we want to modify and entry and immediately check it&#x27;s entryUSN so
that we can track the update status of objects in ldap, we can use the
post read control so that after the add&#x2F;mod&#x2F;modrdn is complete, we can
immediately check the result of usn atomically. This lets us compare
entryusn to know if the object has changed or not.&lt;&#x2F;p&gt;
&lt;p&gt;To use in python:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&amp;gt;&amp;gt;&amp;gt; conn.modify_ext( &amp;#39;cn=Directory Administrators,dc=example,dc=com&amp;#39;,
&lt;&#x2F;span&gt;&lt;span&gt;      ldap.modlist.modifyModlist({}, {&amp;#39;description&amp;#39; : [&amp;#39;oeusoeutlnsoe&amp;#39;] } ),
&lt;&#x2F;span&gt;&lt;span&gt;     [PostReadControl(criticality=True,attrList=[&amp;#39;nsUniqueId&amp;#39;])]  
&lt;&#x2F;span&gt;&lt;span&gt;     ) 
&lt;&#x2F;span&gt;&lt;span&gt;6
&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;&amp;gt;&amp;gt; _,_,_,resp_ctrls = conn.result3(6)
&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;&amp;gt;&amp;gt; resp_ctrls
&lt;&#x2F;span&gt;&lt;span&gt;[&amp;lt;ldap.controls.readentry.PostReadControl instance at 0x2389cf8&amp;gt;]
&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;&amp;gt;&amp;gt; resp_ctrls[0].dn
&lt;&#x2F;span&gt;&lt;span&gt;&amp;#39;cn=Directory Administrators,dc=example,dc=com&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt;&amp;gt;&amp;gt; resp_ctrls[0].entry
&lt;&#x2F;span&gt;&lt;span&gt;{&amp;#39;nsUniqueId&amp;#39;: [&amp;#39;826cc526-8caf11e5-93ba8a51-c5ee9f85&amp;#39;]}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;See also,
&lt;a href=&quot;http:&#x2F;&#x2F;www.python-ldap.org&#x2F;doc&#x2F;html&#x2F;ldap-controls.html&quot;&gt;PostRead&lt;&#x2F;a&gt; and
&lt;a href=&quot;http:&#x2F;&#x2F;www.python-ldap.org&#x2F;doc&#x2F;html&#x2F;ldap.html&quot;&gt;python-ldap&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Magic script for post install interface configuration</title>
          <pubDate>Thu, 26 Nov 2015 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2015-11-26-magic-script-for-post-install-interface-configuration/</link>
          <guid>https://fy.blackhats.net.au/blog/2015-11-26-magic-script-for-post-install-interface-configuration/</guid>
          <description>&lt;h1 id=&quot;magic-script-for-post-install-interface-configuration&quot;&gt;Magic script for post install interface configuration&lt;&#x2F;h1&gt;
&lt;p&gt;Generally on a network we can&#x27;t always trust dhcp or rtadvd to be there
for servers.&lt;&#x2F;p&gt;
&lt;p&gt;So here is a magic script that will generate an ifcfg based on these
parameters when the server first runs. It helps if you register off the
mac to a dhcp entry too.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;DEV=$(ip route | grep ^default | sed &amp;#39;s&#x2F;^.* dev &#x2F;&#x2F;;s&#x2F; .*$&#x2F;&#x2F;&amp;#39;|head -1)
&lt;&#x2F;span&gt;&lt;span&gt;if [ -n &amp;quot;$DEV&amp;quot; ]
&lt;&#x2F;span&gt;&lt;span&gt;then
&lt;&#x2F;span&gt;&lt;span&gt;     IP_AND_PREFIX_LEN=$(ip -f inet addr show dev $DEV | grep &amp;#39;inet &amp;#39;| head -1 | sed &amp;#39;s&#x2F;^ *inet *&#x2F;&#x2F;;s&#x2F; .*$&#x2F;&#x2F;&amp;#39;)
&lt;&#x2F;span&gt;&lt;span&gt;     IP=$(echo ${IP_AND_PREFIX_LEN} | cut -f1 -d&amp;#39;&#x2F;&amp;#39;)
&lt;&#x2F;span&gt;&lt;span&gt;     MASK=$(ipcalc -m ${IP_AND_PREFIX_LEN} | sed &amp;#39;s&#x2F;^.*=&#x2F;&#x2F;&amp;#39;)
&lt;&#x2F;span&gt;&lt;span&gt;     GW=$(ip route | grep default | head -1 | sed &amp;#39;s&#x2F;^.*via &#x2F;&#x2F;;s&#x2F; .*$&#x2F;&#x2F;&amp;#39;)
&lt;&#x2F;span&gt;&lt;span&gt;     IP6_PREFIX=$(ip -f inet6 addr show dev $DEV | grep &amp;#39;inet6 &amp;#39;| head -1 | sed &amp;#39;s&#x2F;^ *inet6 *&#x2F;&#x2F;;s&#x2F; .*$&#x2F;&#x2F;&amp;#39;)
&lt;&#x2F;span&gt;&lt;span&gt;     IP6=$(echo ${IP6_PREFIX} | cut -f1 -d&amp;#39;&#x2F;&amp;#39;)
&lt;&#x2F;span&gt;&lt;span&gt;     MASK6=$(echo ${IP6_PREFIX} | cut -f2 -d&amp;#39;&#x2F;&amp;#39;)
&lt;&#x2F;span&gt;&lt;span&gt;     GW6=$(ip -6 route | grep default | head -1 | sed &amp;#39;s&#x2F;^.*via &#x2F;&#x2F;;s&#x2F; .*$&#x2F;&#x2F;&amp;#39;)
&lt;&#x2F;span&gt;&lt;span&gt;     MAC=$(ip link show dev ${DEV} | grep &amp;#39;link&#x2F;ether &amp;#39;| head -1 | sed &amp;#39;s&#x2F;^ *link\&#x2F;ether *&#x2F;&#x2F;;s&#x2F; .*$&#x2F;&#x2F;&amp;#39;)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;cat &amp;gt; &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-${DEV} &amp;lt;&amp;lt; DEVEOF
&lt;&#x2F;span&gt;&lt;span&gt;# Generated by magic
&lt;&#x2F;span&gt;&lt;span&gt;DEVICE=${DEV}
&lt;&#x2F;span&gt;&lt;span&gt;ONBOOT=yes
&lt;&#x2F;span&gt;&lt;span&gt;NETBOOT=no
&lt;&#x2F;span&gt;&lt;span&gt;BOOTPROTO=static
&lt;&#x2F;span&gt;&lt;span&gt;TYPE=Ethernet
&lt;&#x2F;span&gt;&lt;span&gt;NAME=${DEV}
&lt;&#x2F;span&gt;&lt;span&gt;DEFROUTE=yes
&lt;&#x2F;span&gt;&lt;span&gt;IPV4_FAILURE_FATAL=yes
&lt;&#x2F;span&gt;&lt;span&gt;IPV6_FAILURE_FATAL=yes
&lt;&#x2F;span&gt;&lt;span&gt;IPV6INIT=yes
&lt;&#x2F;span&gt;&lt;span&gt;PEERDNS=no
&lt;&#x2F;span&gt;&lt;span&gt;PEERROUTES=no
&lt;&#x2F;span&gt;&lt;span&gt;IPV6_AUTOCONF=no
&lt;&#x2F;span&gt;&lt;span&gt;HWADDR=${MAC}
&lt;&#x2F;span&gt;&lt;span&gt;IPADDR=${IP}
&lt;&#x2F;span&gt;&lt;span&gt;GATEWAY=${GW}
&lt;&#x2F;span&gt;&lt;span&gt;NETMASK=${MASK}
&lt;&#x2F;span&gt;&lt;span&gt;IPV6ADDR=${IP6}
&lt;&#x2F;span&gt;&lt;span&gt;#PREFIX=${MASK6}
&lt;&#x2F;span&gt;&lt;span&gt;IPV6_DEFAULTGW=${GW6}
&lt;&#x2F;span&gt;&lt;span&gt;DNS1=PUT YOUR DNS SERVER IP HERE
&lt;&#x2F;span&gt;&lt;span&gt;DNS2=PUT YOUR DNS SERVER IP HERE
&lt;&#x2F;span&gt;&lt;span&gt;#NM_CONTROLLED=no
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;DEVEOF
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    #Done
&lt;&#x2F;span&gt;&lt;span&gt;fi
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
</description>
      </item>
      <item>
          <title>python gssapi with flask and s4u2proxy</title>
          <pubDate>Thu, 26 Nov 2015 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2015-11-26-python-gssapi-with-flask-and-s4u2proxy/</link>
          <guid>https://fy.blackhats.net.au/blog/2015-11-26-python-gssapi-with-flask-and-s4u2proxy/</guid>
          <description>&lt;h1 id=&quot;python-gssapi-with-flask-and-s4u2proxy&quot;&gt;python gssapi with flask and s4u2proxy&lt;&#x2F;h1&gt;
&lt;p&gt;&lt;a href=&quot;&#x2F;blog&#x2F;html&#x2F;2017&#x2F;05&#x2F;23&#x2F;kerberos_why_the_world_moved_on.html&quot;&gt;UPDATE: 2019 I don&#x27;t recommend using kerberos - read more
here.&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I have recently been implementing gssapi negotiate support in a flask
application at work. In almost every case I advise that you use
mod-auth-gssapi: It&#x27;s just better.&lt;&#x2F;p&gt;
&lt;p&gt;But if you have a use case where you cannot avoid implementing you own,
there are some really gotchas in using python-gssapi.&lt;&#x2F;p&gt;
&lt;p&gt;Python-gssapi is the updated, newer, better gssapi module for python,
essentially obsoleting python-kerberos. It will have python 3 support
and is more full featured.&lt;&#x2F;p&gt;
&lt;p&gt;However, like everything to do with gssapi, it&#x27;s fiendishly annoying to
use, and lacks a lot in terms of documentation and examples.&lt;&#x2F;p&gt;
&lt;p&gt;The hardest parts:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Knowing how to complete the negotiation with the data set in headers
by the client&lt;&#x2F;li&gt;
&lt;li&gt;Finding that python-gssapi expects you to base64 decode the request&lt;&#x2F;li&gt;
&lt;li&gt;Finding how to destroy credentials&lt;&#x2F;li&gt;
&lt;li&gt;Getting the delegated credentials into a ccache&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Now, a thing to remember is that here, if your kdc support it, you will
be using s4u2proxy automatically. If you want to know more, and you are
using freeipa, you can look into &lt;a href=&quot;http:&#x2F;&#x2F;www.freeipa.org&#x2F;page&#x2F;V4&#x2F;Service_Constraint_Delegation&quot;&gt;constrained
delegation&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;Here is how I implemented the negotiate handler in flask.&lt;&#x2F;p&gt;
&lt;p&gt;:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;def _negotiate_start(req):
&lt;&#x2F;span&gt;&lt;span&gt;    # This assumes a realm. You can leave this unset to use the default ream from krb5.conf iirc.
&lt;&#x2F;span&gt;&lt;span&gt;    svc_princ = gssnames.Name(&amp;#39;HTTP&#x2F;%s@EXAMPLE.COM&amp;#39;% (socket.gethostname()))
&lt;&#x2F;span&gt;&lt;span&gt;    server_creds = gsscreds.Credentials(usage=&amp;#39;accept&amp;#39;, name=svc_princ)
&lt;&#x2F;span&gt;&lt;span&gt;    context = gssctx.SecurityContext(creds=server_creds)
&lt;&#x2F;span&gt;&lt;span&gt;    # Yay! Undocumented gssapi magic. No indication that you need to b64 decode.
&lt;&#x2F;span&gt;&lt;span&gt;    context.step(base64.b64decode(req))
&lt;&#x2F;span&gt;&lt;span&gt;    deleg_creds = context.delegated_creds
&lt;&#x2F;span&gt;&lt;span&gt;    CCACHE = &amp;#39;MEMORY:ccache_rest389_%s&amp;#39; % deleg_creds.name
&lt;&#x2F;span&gt;&lt;span&gt;    store = {&amp;#39;ccache&amp;#39;: CCACHE}
&lt;&#x2F;span&gt;&lt;span&gt;    deleg_creds.store(store, overwrite=True)
&lt;&#x2F;span&gt;&lt;span&gt;    os.environ[&amp;#39;KRB5CCNAME&amp;#39;] = CCACHE
&lt;&#x2F;span&gt;&lt;span&gt;    # Return the context, so we can free it later.
&lt;&#x2F;span&gt;&lt;span&gt;    return context
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;def _negotiate_end(context):
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    # tell python-gssapi to free gss_cred_id_t
&lt;&#x2F;span&gt;&lt;span&gt;    deleg_creds = context.delegated_creds
&lt;&#x2F;span&gt;&lt;span&gt;    del(deleg_creds)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;def _connection(f, *args, **kwargs):
&lt;&#x2F;span&gt;&lt;span&gt;    retval = None
&lt;&#x2F;span&gt;&lt;span&gt;    negotiate = False
&lt;&#x2F;span&gt;&lt;span&gt;    headers = Headers()  # Allows a multivalue header response.
&lt;&#x2F;span&gt;&lt;span&gt;    # Request comes from **kwargs
&lt;&#x2F;span&gt;&lt;span&gt;    authorization = request.headers.get(&amp;quot;Authorization&amp;quot;, None)
&lt;&#x2F;span&gt;&lt;span&gt;    try:
&lt;&#x2F;span&gt;&lt;span&gt;        if authorization is not None:
&lt;&#x2F;span&gt;&lt;span&gt;            values = authorization.split()
&lt;&#x2F;span&gt;&lt;span&gt;            if values[0] == &amp;#39;Negotiate&amp;#39;:
&lt;&#x2F;span&gt;&lt;span&gt;                # If this is valid, it sets KRB5CCNAME
&lt;&#x2F;span&gt;&lt;span&gt;                negotiate = _negotiate_start(values[1])
&lt;&#x2F;span&gt;&lt;span&gt;        # This is set by mod_auth_gssapi if you are using that instead.
&lt;&#x2F;span&gt;&lt;span&gt;        if request.headers.get(&amp;quot;Krb5Ccname&amp;quot;, &amp;#39;(null)&amp;#39;) != &amp;#39;(null)&amp;#39;:
&lt;&#x2F;span&gt;&lt;span&gt;            os.environ[&amp;#39;KRB5CCNAME&amp;#39;] = request.headers.get(&amp;quot;Krb5Ccname&amp;quot;, None)
&lt;&#x2F;span&gt;&lt;span&gt;        if os.environ.get(&amp;#39;KRB5CCNAME&amp;#39;, &amp;#39;&amp;#39;) != &amp;#39;&amp;#39;:
&lt;&#x2F;span&gt;&lt;span&gt;            pass
&lt;&#x2F;span&gt;&lt;span&gt;            # Do something with the krb creds here, db connection etc.
&lt;&#x2F;span&gt;&lt;span&gt;            retval = f(dir_srv_conn, *args, **kwargs)
&lt;&#x2F;span&gt;&lt;span&gt;        else:
&lt;&#x2F;span&gt;&lt;span&gt;            headers.add(&amp;#39;WWW-Authenticate&amp;#39;, &amp;#39;Negotiate&amp;#39;)
&lt;&#x2F;span&gt;&lt;span&gt;            retval = Response(&amp;quot;Unauthorized&amp;quot;, 401, headers)
&lt;&#x2F;span&gt;&lt;span&gt;    finally:
&lt;&#x2F;span&gt;&lt;span&gt;        if negotiate is not False:
&lt;&#x2F;span&gt;&lt;span&gt;            _negotiate_end(negotiate)
&lt;&#x2F;span&gt;&lt;span&gt;        if os.environ.get(&amp;#39;KRB5CCNAME&amp;#39;, None) is not None:
&lt;&#x2F;span&gt;&lt;span&gt;            os.environ[&amp;#39;KRB5CCNAME&amp;#39;] = &amp;#39;&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;    return retval
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;def authenticateConnection(f):
&lt;&#x2F;span&gt;&lt;span&gt;    @wraps(f)
&lt;&#x2F;span&gt;&lt;span&gt;    def decorator(*args, **kwargs):
&lt;&#x2F;span&gt;&lt;span&gt;        return _connection(f, *args, **kwargs)
&lt;&#x2F;span&gt;&lt;span&gt;    return decorator
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;@app.route(&amp;#39;&#x2F;&amp;#39;, methods[&amp;#39;GET&amp;#39;])
&lt;&#x2F;span&gt;&lt;span&gt;@authenticateConnection
&lt;&#x2F;span&gt;&lt;span&gt;def index():
&lt;&#x2F;span&gt;&lt;span&gt;    pass
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
</description>
      </item>
      <item>
          <title>Managing replication conflicts for humans in 389</title>
          <pubDate>Wed, 25 Nov 2015 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2015-11-25-managing-replication-conflicts-for-humans-in-389/</link>
          <guid>https://fy.blackhats.net.au/blog/2015-11-25-managing-replication-conflicts-for-humans-in-389/</guid>
          <description>&lt;h1 id=&quot;managing-replication-conflicts-for-humans-in-389&quot;&gt;Managing replication conflicts for humans in 389&lt;&#x2F;h1&gt;
&lt;p&gt;I would like to thank side_control at runlevelone dot net for putting me
onto this challenge.&lt;&#x2F;p&gt;
&lt;p&gt;If we have a replication conflict in 389, we generall have two results.
A and B. In the case A is the live object and B is the conflict, and we
want to keep A as live object, it&#x27;s as easy as:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;dn: idnsname=_kerberos._udp.Default-First-Site-Name._sites.dc._msdcs+nsuniqueid=910d8837-4c3c11e5-83eea63b-366c3f94,idnsname=lab.example.lan.,cn=dns,dc=lab,dc=example,dc=lan
&lt;&#x2F;span&gt;&lt;span&gt;changetype: delete
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;But say we want to swap them over: We want to keep B, but A is live. How
do we recover this?&lt;&#x2F;p&gt;
&lt;p&gt;I plan to make a tool to do this, because it&#x27;s a right pain.&lt;&#x2F;p&gt;
&lt;p&gt;This is the only way I got it to work, but I suspect there is a shortcut
somewhere that doesn&#x27;t need the blackmagic that is extensibleObject.
(If you use extensibleObject in production I will come for your
personally.)&lt;&#x2F;p&gt;
&lt;p&gt;First, we need to get the object out of being a multivalued rdn object
so we can manipulate it easier. We give it a cn to match it&#x27;s uniqueId.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;dn: idnsname=_kerberos._udp.dc._msdcs+nsuniqueid=910d8842-4c3c11e5-83eea63b-366c3f94,idnsname=lab.example.lan.,cn=dns,dc=lab,dc=example,dc=lan
&lt;&#x2F;span&gt;&lt;span&gt;changetype: modify
&lt;&#x2F;span&gt;&lt;span&gt;add: cn
&lt;&#x2F;span&gt;&lt;span&gt;cn: 910d8842-4c3c11e5-83eea63b-366c3f94
&lt;&#x2F;span&gt;&lt;span&gt;-
&lt;&#x2F;span&gt;&lt;span&gt;replace: objectClass
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: extensibleObject
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: idnsrecord
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: top
&lt;&#x2F;span&gt;&lt;span&gt;-
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;dn: idnsname=_kerberos._udp.dc._msdcs+nsuniqueid=910d8842-4c3c11e5-83eea63b-366c3f94,idnsname=lab.example.lan.,cn=dns,dc=lab,dc=example,dc=lan
&lt;&#x2F;span&gt;&lt;span&gt;changetype: modrdn
&lt;&#x2F;span&gt;&lt;span&gt;newrdn: cn=910d8842-4c3c11e5-83eea63b-366c3f94
&lt;&#x2F;span&gt;&lt;span&gt;deleteoldrdn: 0
&lt;&#x2F;span&gt;&lt;span&gt;newsuperior:
&lt;&#x2F;span&gt;&lt;span&gt;idnsname=lab.example.lan.,cn=dns,dc=lab,dc=example,dc=lan
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now, we can get rid of the repl conflict:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;dn: cn=910d8842-4c3c11e5-83eea63b-366c3f94,idnsname=lab.example.lan.,cn=dns,dc=lab,dc=example,dc=lan
&lt;&#x2F;span&gt;&lt;span&gt;changetype: modify
&lt;&#x2F;span&gt;&lt;span&gt;delete: nsds5ReplConflict
&lt;&#x2F;span&gt;&lt;span&gt;nsds5ReplConflict:
&lt;&#x2F;span&gt;&lt;span&gt;namingConflictidnsname=_kerberos._udp.dc._msdcs,idnsname=lab.example.lan.,cn=dns,dc=lab,dc=example,dc=lan
&lt;&#x2F;span&gt;&lt;span&gt;-
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;We have &amp;quot;B&amp;quot; ready to go. So lets get A out of the way, and drop B in.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;dn: idnsname=_kerberos._udp.Default-First-Site-Name._sites.dc._msdcs+nsuniqueid=910d8837-4c3c11e5-83eea63b-366c3f94,idnsname=lab.example.lan.,cn=dns,dc=lab,dc=example,dc=lan
&lt;&#x2F;span&gt;&lt;span&gt;changetype: delete
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;dn: cn=910d8842-4c3c11e5-83eea63b-366c3f94,idnsname=lab.example.lan.,cn=dns,dc=lab,dc=example,dc=lan
&lt;&#x2F;span&gt;&lt;span&gt;changetype: modrdn
&lt;&#x2F;span&gt;&lt;span&gt;newrdn: idnsName=_kerberos._udp.dc._msdcs
&lt;&#x2F;span&gt;&lt;span&gt;deleteoldrdn: 0
&lt;&#x2F;span&gt;&lt;span&gt;newsuperior: idnsname=lab.example.lan.,cn=dns,dc=lab,dc=example,dc=lan
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Finally, we need to fix the objectClass and get rid of the cn.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;dn: idnsName=_kerberos._udp.dc._msdcs,idnsname=lab.example.lan.,cn=dns,dc=lab,dc=example,dc=lan
&lt;&#x2F;span&gt;&lt;span&gt;changetype: modify
&lt;&#x2F;span&gt;&lt;span&gt;delete: cn
&lt;&#x2F;span&gt;&lt;span&gt;cn: 910d8842-4c3c11e5-83eea63b-366c3f94
&lt;&#x2F;span&gt;&lt;span&gt;-
&lt;&#x2F;span&gt;&lt;span&gt;replace: objectClass
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: idnsrecord
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: top
&lt;&#x2F;span&gt;&lt;span&gt;-
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;I think a tool to do this would be really helpful.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Securing RHEL - CentOS - Fedora</title>
          <pubDate>Sun, 15 Nov 2015 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2015-11-15-securing-rhel-centos-fedora/</link>
          <guid>https://fy.blackhats.net.au/blog/2015-11-15-securing-rhel-centos-fedora/</guid>
          <description>&lt;h1 id=&quot;securing-rhel-centos-fedora&quot;&gt;Securing RHEL - CentOS - Fedora&lt;&#x2F;h1&gt;
&lt;p&gt;We&#x27;ve had a prompting to investigate our OS security at my work. As a
result, I&#x27;ve been given a pretty open mandate to investigate and
deliver some simple changes that help lock down our systems and make
measurable changes to security and incident analysis.&lt;&#x2F;p&gt;
&lt;p&gt;First, I used some common sense. Second, I did my research. Third, I
used tools to help look at things that I would otherwise have missed.&lt;&#x2F;p&gt;
&lt;p&gt;The best tool I used was certainly OpenSCAP. Very simple to use, and
gives some really basic recommendations that just make sense. Some of
it&#x27;s answers I took with a grain of salt. For example, account lockout
modules in pam aren&#x27;t needed, as we handle this via our directory
services. But it can highlight areas you may have missed.&lt;&#x2F;p&gt;
&lt;p&gt;To run a scap scan:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;yum install scap-security-guide openscap openscap-scanner
&lt;&#x2F;span&gt;&lt;span&gt;FEDORA
&lt;&#x2F;span&gt;&lt;span&gt;oscap xccdf eval --profile xccdf_org.ssgproject.content_profile_common --results &#x2F;tmp&#x2F;`hostname`-ssg-results.xml \
&lt;&#x2F;span&gt;&lt;span&gt;--report &#x2F;tmp&#x2F;`hostname`-ssg-results.html &#x2F;usr&#x2F;share&#x2F;xml&#x2F;scap&#x2F;ssg&#x2F;content&#x2F;ssg-fedora-ds.xml
&lt;&#x2F;span&gt;&lt;span&gt;RHEL &#x2F; CENTOS
&lt;&#x2F;span&gt;&lt;span&gt;oscap xccdf eval --profile xccdf_org.ssgproject.content_profile_common --results &#x2F;tmp&#x2F;`hostname`-ssg-results.xml \
&lt;&#x2F;span&gt;&lt;span&gt;--report &#x2F;tmp&#x2F;`hostname`-ssg-results.html &#x2F;usr&#x2F;share&#x2F;xml&#x2F;scap&#x2F;ssg&#x2F;content&#x2F;ssg-rhel7-ds.xml
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Then view the output in a web browser.&lt;&#x2F;p&gt;
&lt;p&gt;Here is what I came up with.&lt;&#x2F;p&gt;
&lt;p&gt;-- Partitioning --------------------&lt;&#x2F;p&gt;
&lt;p&gt;Sadly, you need to reinstall for these, but worth rolling out for
&amp;quot;future builds&amp;quot;. Here is my partition section from ks.conf. Especially
important is putting audit on its own partition.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# Partition clearing information                                                                                
&lt;&#x2F;span&gt;&lt;span&gt;bootloader --location=mbr                                                                                       
&lt;&#x2F;span&gt;&lt;span&gt;clearpart --initlabel --all                                                                                     
&lt;&#x2F;span&gt;&lt;span&gt;# Disk partitioning information                                                                                 
&lt;&#x2F;span&gt;&lt;span&gt;part &#x2F;boot --fstype=ext4 --size=512 --asprimary --fsoptions=x-systemd.automount,nodev,nosuid,defaults
&lt;&#x2F;span&gt;&lt;span&gt;# LVM                                                                                                           
&lt;&#x2F;span&gt;&lt;span&gt;part pv.2 --size=16384 --grow --asprimary                                                                       
&lt;&#x2F;span&gt;&lt;span&gt;volgroup vg00 pv.2                                                                                              
&lt;&#x2F;span&gt;&lt;span&gt;logvol swap --fstype=swap --size=2048 --name=swap_lv --vgname=vg00               
&lt;&#x2F;span&gt;&lt;span&gt;logvol &#x2F; --fstype=xfs --size=512 --name=root_lv --vgname=vg00 --fsoptions=defaults
&lt;&#x2F;span&gt;&lt;span&gt;logvol &#x2F;usr --fstype=xfs --size=3072 --name=usr_lv --vgname=vg00 --fsoptions=nodev,defaults
&lt;&#x2F;span&gt;&lt;span&gt;logvol &#x2F;home --fstype=&amp;quot;xfs&amp;quot; --size=512 --name=home_lv --vgname=vg00 --fsoptions=nodev,nosuid,defaults
&lt;&#x2F;span&gt;&lt;span&gt;logvol &#x2F;var  --fstype=xfs --size=3072 --name=var_lv --vgname=vg00 --fsoptions=nodev,nosuid,noexec,defaults
&lt;&#x2F;span&gt;&lt;span&gt;logvol &#x2F;var&#x2F;log --fstype=&amp;quot;xfs&amp;quot; --size=1536 --name=var_log_lv --vgname=vg00 --fsoptions=nodev,nosuid,noexec,defaults
&lt;&#x2F;span&gt;&lt;span&gt;logvol &#x2F;var&#x2F;log&#x2F;audit --fstype=&amp;quot;xfs&amp;quot; --size=512 --name=var_log_audit_lv --vgname=vg00 --fsoptions=nodev,nosuid,noexec,defaults
&lt;&#x2F;span&gt;&lt;span&gt;logvol &#x2F;srv --fstype=&amp;quot;xfs&amp;quot; --size=512 --name=srv_lv --vgname=vg00 --fsoptions=nodev,nosuid,defaults
&lt;&#x2F;span&gt;&lt;span&gt;logvol &#x2F;opt --fstype=&amp;quot;xfs&amp;quot; --size=512 --name=opt_lv --vgname=vg00 --fsoptions=nodev,nosuid,defaults
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;With &#x2F;tmp, if you mount this, and run redhat satellite, you need to be
careful. Satellite expects to be able to execute out of &#x2F;tmp, so don&#x27;t
set noexec on that partition!&lt;&#x2F;p&gt;
&lt;p&gt;-- SSH keys ----------------&lt;&#x2F;p&gt;
&lt;p&gt;It&#x27;s just good practice to use these. It saves typing in a password to
a prompt which helps to limit credential exposure. We are enabling LDAP
backed SSH keys now to make this easier in our workplace.&lt;&#x2F;p&gt;
&lt;p&gt;-- SELinux ---------------&lt;&#x2F;p&gt;
&lt;p&gt;SELinux isn&#x27;t perfect by any means, but it helps a lot. It can make the
work of an attacker more complex, and it can help prevent data leakage
via the network. Consider that by default httpd_t cannot make outgoing
network connections. This is awesome to prevent data being leaked back
to attackers. Well worth the time to setup these policies correctly.&lt;&#x2F;p&gt;
&lt;p&gt;If you have to set permissive to make an application work, do it on a
per-domain basis with:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;semanage permissive -a httpd_t
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This way the protections on all other processes are not removed.&lt;&#x2F;p&gt;
&lt;p&gt;On some of my systems I even run confined staff users to help prevent
mistakes &#x2F; malware from users. I manage this via FreeIPA.&lt;&#x2F;p&gt;
&lt;p&gt;-- Auditing ----------------&lt;&#x2F;p&gt;
&lt;p&gt;This allows us to see who &#x2F; what is altering things on our system. We
extended the core auditing rules to include a few extras.&lt;&#x2F;p&gt;
&lt;p&gt;&#x2F;etc&#x2F;audit&#x2F;rules.d&#x2F;audit.rules&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# This file contains the auditctl rules that are loaded
&lt;&#x2F;span&gt;&lt;span&gt;# whenever the audit daemon is started via the initscripts.
&lt;&#x2F;span&gt;&lt;span&gt;# The rules are simply the parameters that would be passed
&lt;&#x2F;span&gt;&lt;span&gt;# to auditctl.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# First rule - delete all
&lt;&#x2F;span&gt;&lt;span&gt;-D
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Increase the buffers to survive stress events.
&lt;&#x2F;span&gt;&lt;span&gt;# Make this bigger for busy systems
&lt;&#x2F;span&gt;&lt;span&gt;-b 8192
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;#
&lt;&#x2F;span&gt;&lt;span&gt;# Feel free to add below this line. See auditctl man page
&lt;&#x2F;span&gt;&lt;span&gt;-w &#x2F;etc&#x2F; -p wa -k etc_modification
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Detect login log tampering
&lt;&#x2F;span&gt;&lt;span&gt;-w &#x2F;var&#x2F;log&#x2F;faillog -p wa -k logins
&lt;&#x2F;span&gt;&lt;span&gt;-w &#x2F;var&#x2F;log&#x2F;lastlog -p wa -k logins
&lt;&#x2F;span&gt;&lt;span&gt;-w &#x2F;var&#x2F;run&#x2F;utmp -p wa -k session
&lt;&#x2F;span&gt;&lt;span&gt;-w &#x2F;var&#x2F;log&#x2F;btmp -p wa -k session
&lt;&#x2F;span&gt;&lt;span&gt;-w &#x2F;var&#x2F;log&#x2F;wtmp -p wa -k session
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# audit_time_rules
&lt;&#x2F;span&gt;&lt;span&gt;## REMOVE STIME ON RHEL
&lt;&#x2F;span&gt;&lt;span&gt;#-a always,exit -F arch=b32 -S stime -S adjtimex -S settimeofday -S clock_settime -k audit_time_rules
&lt;&#x2F;span&gt;&lt;span&gt;#-a always,exit -F arch=b64 -S stime -S adjtimex -S settimeofday -S clock_settime -k audit_time_rules
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# audit_rules_networkconfig_modification
&lt;&#x2F;span&gt;&lt;span&gt;-a always,exit -F arch=b32 -S sethostname -S setdomainname -k audit_rules_networkconfig_modification
&lt;&#x2F;span&gt;&lt;span&gt;-a always,exit -F arch=b64 -S sethostname -S setdomainname -k audit_rules_networkconfig_modification
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Audit kernel module manipulation
&lt;&#x2F;span&gt;&lt;span&gt;-a always,exit -F arch=b32 -S init_module -S delete_module -k modules
&lt;&#x2F;span&gt;&lt;span&gt;-a always,exit -F arch=b64 -S init_module -S delete_module -k modules
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;################################################################################
&lt;&#x2F;span&gt;&lt;span&gt;# These are super paranoid rules at this point. Only use if you are willing to take
&lt;&#x2F;span&gt;&lt;span&gt;# a 3% to 10% perf degredation.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Perhaps remove the uid limits on some of these actions? We often get attacked via services, not users. These rules are more for workstations...
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;#-a always,exit -F arch=b32 -S chmod -S chown -S fchmod -S fchmodat -S fchown -S fchownat -S fremovexattr -S fsetxattr -S lchown -S lremovexattr -S lsetxattr -S removexattr -S setxattr -F auid&amp;gt;=500 -F auid!=4294967295 -k perm_mod
&lt;&#x2F;span&gt;&lt;span&gt;#-a always,exit -F arch=b32 -S creat -S open -S openat -S open_by_handle_at -S truncate -S ftruncate -F exit=-EACCES -F auid&amp;gt;=500 -F auid!=4294967295 -k access
&lt;&#x2F;span&gt;&lt;span&gt;#-a always,exit -F arch=b32 -S creat -S open -S openat -S open_by_handle_at -S truncate -S ftruncate -F exit=-EPERM -F auid&amp;gt;=500 -F auid!=4294967295 -k access
&lt;&#x2F;span&gt;&lt;span&gt;#-a always,exit -F arch=b32 -S rmdir -S unlink -S unlinkat -S rename -S renameat -F auid&amp;gt;=500 -F auid!=4294967295 -k delete
&lt;&#x2F;span&gt;&lt;span&gt;# This rule is more useful on a workstation with automount ...
&lt;&#x2F;span&gt;&lt;span&gt;#-a always,exit -F arch=b32 -S mount -F auid&amp;gt;=500 -F auid!=4294967295 -k export
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;#-a always,exit -F arch=b64 -S chmod -S chown -S fchmod -S fchmodat -S fchown -S fchownat -S fremovexattr -S fsetxattr -S lchown -S lremovexattr -S lsetxattr -S removexattr -S setxattr -F auid&amp;gt;=500 -F auid!=4294967295 -k perm_mod
&lt;&#x2F;span&gt;&lt;span&gt;#-a always,exit -F arch=b64 -S creat -S open -S openat -S open_by_handle_at -S truncate -S ftruncate -F exit=-EACCES -F auid&amp;gt;=500 -F auid!=4294967295 -k access
&lt;&#x2F;span&gt;&lt;span&gt;#-a always,exit -F arch=b64 -S creat -S open -S openat -S open_by_handle_at -S truncate -S ftruncate -F exit=-EPERM -F auid&amp;gt;=500 -F auid!=4294967295 -k access
&lt;&#x2F;span&gt;&lt;span&gt;#-a always,exit -F arch=b64 -S rmdir -S unlink -S unlinkat -S rename -S renameat -F auid&amp;gt;=500 -F auid!=4294967295 -k delete
&lt;&#x2F;span&gt;&lt;span&gt;# This rule is more useful on a workstation with automount ...
&lt;&#x2F;span&gt;&lt;span&gt;#-a always,exit -F arch=b64 -S mount -F auid&amp;gt;=500 -F auid!=4294967295 -k export
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# This setting means you need a reboot to changed audit rules.
&lt;&#x2F;span&gt;&lt;span&gt;#  probably worth doing .... 
&lt;&#x2F;span&gt;&lt;span&gt;#-e 2
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;To handle all the extra events I increased my audit logging sizes&lt;&#x2F;p&gt;
&lt;p&gt;&#x2F;etc&#x2F;audit&#x2F;auditd.conf :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;log_file = &#x2F;var&#x2F;log&#x2F;audit&#x2F;audit.log                                                                             
&lt;&#x2F;span&gt;&lt;span&gt;log_format = RAW                                                                                                
&lt;&#x2F;span&gt;&lt;span&gt;log_group = root                                                                                                
&lt;&#x2F;span&gt;&lt;span&gt;priority_boost = 4                                                                                              
&lt;&#x2F;span&gt;&lt;span&gt;flush = INCREMENTAL                                                                                             
&lt;&#x2F;span&gt;&lt;span&gt;freq = 20                                                                                                       
&lt;&#x2F;span&gt;&lt;span&gt;num_logs = 5                                                                                                    
&lt;&#x2F;span&gt;&lt;span&gt;disp_qos = lossy                                                                                                
&lt;&#x2F;span&gt;&lt;span&gt;dispatcher = &#x2F;sbin&#x2F;audispd                                                                                      
&lt;&#x2F;span&gt;&lt;span&gt;name_format = NONE                                                                                              
&lt;&#x2F;span&gt;&lt;span&gt;max_log_file = 20                                                                  
&lt;&#x2F;span&gt;&lt;span&gt;max_log_file_action = ROTATE                                                                                    
&lt;&#x2F;span&gt;&lt;span&gt;space_left = 100                                                                                                
&lt;&#x2F;span&gt;&lt;span&gt;space_left_action = EMAIL                                                                                       
&lt;&#x2F;span&gt;&lt;span&gt;action_mail_acct = root                                                                                         
&lt;&#x2F;span&gt;&lt;span&gt;admin_space_left = 75                                                                                           
&lt;&#x2F;span&gt;&lt;span&gt;admin_space_left_action = SUSPEND                                                                               
&lt;&#x2F;span&gt;&lt;span&gt;admin_space_left_action = email                                                                                 
&lt;&#x2F;span&gt;&lt;span&gt;disk_full_action = SUSPEND                                                                                      
&lt;&#x2F;span&gt;&lt;span&gt;disk_error_action = SUSPEND                                                                                     
&lt;&#x2F;span&gt;&lt;span&gt;tcp_listen_queue = 5                                                                                            
&lt;&#x2F;span&gt;&lt;span&gt;tcp_max_per_addr = 1                                                                                            
&lt;&#x2F;span&gt;&lt;span&gt;tcp_client_max_idle = 0                                                                                         
&lt;&#x2F;span&gt;&lt;span&gt;enable_krb5 = no                                                                                                
&lt;&#x2F;span&gt;&lt;span&gt;krb5_principal = auditd  
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;-- PAM and null passwords
------------------------------&lt;&#x2F;p&gt;
&lt;p&gt;Scap noticed that the default config of password-auth-ac contained
nullok on some lines. Remove this:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;BEFORE
&lt;&#x2F;span&gt;&lt;span&gt;auth        sufficient    pam_unix.so nullok try_first_pass
&lt;&#x2F;span&gt;&lt;span&gt;AFTER
&lt;&#x2F;span&gt;&lt;span&gt;auth        sufficient    pam_unix.so try_first_pass
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;-- Firewall (Backups, SMH, NRPE)
-------------------------------------&lt;&#x2F;p&gt;
&lt;p&gt;Backup clients (Amanda, netbackup, commvault) tend to have very high
privilege, no SELinux, and are security swiss cheese. Similar is true
for vendor systems like HP system management homepage, and NRPE
(nagios). It&#x27;s well worth locking these down. Before we had blanket
&amp;quot;port open&amp;quot; rules, now these are tighter.&lt;&#x2F;p&gt;
&lt;p&gt;In iptables, you should use the &amp;quot;-s&amp;quot; to specify a source range these
are allowed to connect from. The smaller the range, the better.&lt;&#x2F;p&gt;
&lt;p&gt;In firewalld, you need to use the rich language. Which is a bit more
verbose, and finicky than iptables. My rules end up as: :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;rule family=&amp;quot;ipv4&amp;quot; source address=&amp;quot;10.0.0.0&#x2F;24&amp;quot; port port=&amp;quot;2381&amp;quot; protocol=&amp;quot;tcp&amp;quot; accept
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;For example. Use the firewalld-cmd with the --add-rich-rule, or use
ansibles rich_rule options.&lt;&#x2F;p&gt;
&lt;p&gt;-- AIDE (HIDS) -------------------&lt;&#x2F;p&gt;
&lt;p&gt;Aide is a fantastic and simple file integrity checker. I have an ansible
role that I can tack onto the end of all my playbooks to automatically
update the AIDE database so that it stays consistent with changes, but
will allow us to see out of band changes.&lt;&#x2F;p&gt;
&lt;p&gt;The default AIDE config often picks up files that change frequently. I
have an aide.conf that still provides function, but without triggering
false alarms. I include aide-local.conf so that other teams &#x2F; staff can
add application specific aide monitoring that doesn&#x27;t conflict with my
work.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# Example configuration file for AIDE.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;@@define DBDIR &#x2F;var&#x2F;lib&#x2F;aide
&lt;&#x2F;span&gt;&lt;span&gt;@@define LOGDIR &#x2F;var&#x2F;log&#x2F;aide
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# The location of the database to be read.
&lt;&#x2F;span&gt;&lt;span&gt;database=file:@@{DBDIR}&#x2F;aide.db.gz
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# The location of the database to be written.
&lt;&#x2F;span&gt;&lt;span&gt;#database_out=sql:host:port:database:login_name:passwd:table
&lt;&#x2F;span&gt;&lt;span&gt;#database_out=file:aide.db.new
&lt;&#x2F;span&gt;&lt;span&gt;database_out=file:@@{DBDIR}&#x2F;aide.db.new.gz
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Whether to gzip the output to database
&lt;&#x2F;span&gt;&lt;span&gt;gzip_dbout=yes
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Default.
&lt;&#x2F;span&gt;&lt;span&gt;verbose=5
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;#report_url=file:@@{LOGDIR}&#x2F;aide.log
&lt;&#x2F;span&gt;&lt;span&gt;report_url=stdout
&lt;&#x2F;span&gt;&lt;span&gt;#report_url=stderr
&lt;&#x2F;span&gt;&lt;span&gt;#NOT IMPLEMENTED report_url=mailto:root@foo.com
&lt;&#x2F;span&gt;&lt;span&gt;report_url=syslog:LOG_AUTH
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# These are the default rules.
&lt;&#x2F;span&gt;&lt;span&gt;#
&lt;&#x2F;span&gt;&lt;span&gt;#p:      permissions
&lt;&#x2F;span&gt;&lt;span&gt;#i:      inode:
&lt;&#x2F;span&gt;&lt;span&gt;#n:      number of links
&lt;&#x2F;span&gt;&lt;span&gt;#u:      user
&lt;&#x2F;span&gt;&lt;span&gt;#g:      group
&lt;&#x2F;span&gt;&lt;span&gt;#s:      size
&lt;&#x2F;span&gt;&lt;span&gt;#b:      block count
&lt;&#x2F;span&gt;&lt;span&gt;#m:      mtime
&lt;&#x2F;span&gt;&lt;span&gt;#a:      atime
&lt;&#x2F;span&gt;&lt;span&gt;#c:      ctime
&lt;&#x2F;span&gt;&lt;span&gt;#S:      check for growing size
&lt;&#x2F;span&gt;&lt;span&gt;#acl:           Access Control Lists
&lt;&#x2F;span&gt;&lt;span&gt;#selinux        SELinux security context
&lt;&#x2F;span&gt;&lt;span&gt;#xattrs:        Extended file attributes
&lt;&#x2F;span&gt;&lt;span&gt;#md5:    md5 checksum
&lt;&#x2F;span&gt;&lt;span&gt;#sha1:   sha1 checksum
&lt;&#x2F;span&gt;&lt;span&gt;#sha256:        sha256 checksum
&lt;&#x2F;span&gt;&lt;span&gt;#sha512:        sha512 checksum
&lt;&#x2F;span&gt;&lt;span&gt;#rmd160: rmd160 checksum
&lt;&#x2F;span&gt;&lt;span&gt;#tiger:  tiger checksum
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;#haval:  haval checksum (MHASH only)
&lt;&#x2F;span&gt;&lt;span&gt;#gost:   gost checksum (MHASH only)
&lt;&#x2F;span&gt;&lt;span&gt;#crc32:  crc32 checksum (MHASH only)
&lt;&#x2F;span&gt;&lt;span&gt;#whirlpool:     whirlpool checksum (MHASH only)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;FIPSR = p+i+n+u+g+s+m+c+acl+selinux+xattrs+sha256
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Fips without time because of some database&#x2F;sqlite issues
&lt;&#x2F;span&gt;&lt;span&gt;FIPSRMT = p+i+n+u+g+s+acl+selinux+xattrs+sha256
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;#R:             p+i+n+u+g+s+m+c+acl+selinux+xattrs+md5
&lt;&#x2F;span&gt;&lt;span&gt;#L:             p+i+n+u+g+acl+selinux+xattrs
&lt;&#x2F;span&gt;&lt;span&gt;#E:             Empty group
&lt;&#x2F;span&gt;&lt;span&gt;#&amp;gt;:             Growing logfile p+u+g+i+n+S+acl+selinux+xattrs
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# You can create custom rules like this.
&lt;&#x2F;span&gt;&lt;span&gt;# With MHASH...
&lt;&#x2F;span&gt;&lt;span&gt;# ALLXTRAHASHES = sha1+rmd160+sha256+sha512+whirlpool+tiger+haval+gost+crc32
&lt;&#x2F;span&gt;&lt;span&gt;ALLXTRAHASHES = sha1+rmd160+sha256+sha512+tiger
&lt;&#x2F;span&gt;&lt;span&gt;# Everything but access time (Ie. all changes)
&lt;&#x2F;span&gt;&lt;span&gt;EVERYTHING = R+ALLXTRAHASHES
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Sane, with multiple hashes
&lt;&#x2F;span&gt;&lt;span&gt;# NORMAL = R+rmd160+sha256+whirlpool
&lt;&#x2F;span&gt;&lt;span&gt;NORMAL = FIPSR+sha512
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# For directories, don&amp;#39;t bother doing hashes
&lt;&#x2F;span&gt;&lt;span&gt;DIR = p+i+n+u+g+acl+selinux+xattrs
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Access control only
&lt;&#x2F;span&gt;&lt;span&gt;PERMS = p+i+u+g+acl+selinux+xattrs
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Logfile are special, in that they often change
&lt;&#x2F;span&gt;&lt;span&gt;LOG = &amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Just do sha256 and sha512 hashes
&lt;&#x2F;span&gt;&lt;span&gt;LSPP = FIPSR+sha512
&lt;&#x2F;span&gt;&lt;span&gt;LSPPMT = FIPSRMT+sha512
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Some files get updated automatically, so the inode&#x2F;ctime&#x2F;mtime change
&lt;&#x2F;span&gt;&lt;span&gt;# but we want to know when the data inside them changes
&lt;&#x2F;span&gt;&lt;span&gt;DATAONLY =  p+n+u+g+s+acl+selinux+xattrs+sha256
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Next decide what directories&#x2F;files you want in the database.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;boot   NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;bin    NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;sbin   NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;usr&#x2F;bin NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;usr&#x2F;sbin NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;lib    NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;lib64  NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;# These may be too variable
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;opt    NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;srv    NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;# These are too volatile
&lt;&#x2F;span&gt;&lt;span&gt;# We can check USR if we want, but it doesn&amp;#39;t net us much.
&lt;&#x2F;span&gt;&lt;span&gt;#&#x2F;usr    NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;!&#x2F;usr&#x2F;src
&lt;&#x2F;span&gt;&lt;span&gt;!&#x2F;usr&#x2F;tmp
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Check only permissions, inode, user and group for &#x2F;etc, but
&lt;&#x2F;span&gt;&lt;span&gt;# cover some important files closely.
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc    PERMS
&lt;&#x2F;span&gt;&lt;span&gt;!&#x2F;etc&#x2F;mtab
&lt;&#x2F;span&gt;&lt;span&gt;# Ignore backup files
&lt;&#x2F;span&gt;&lt;span&gt;!&#x2F;etc&#x2F;.*~
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;exports  NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;fstab    NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;passwd   NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;group    NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;gshadow  NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;shadow   NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;security&#x2F;opasswd   NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;hosts.allow   NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;hosts.deny    NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;sudoers NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;sudoers.d NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;skel NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;logrotate.d NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;resolv.conf DATAONLY
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;nscd.conf NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;securetty NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Shell&#x2F;X starting files
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;profile NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;bashrc NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;bash_completion.d&#x2F; NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;login.defs NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;zprofile NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;zshrc NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;zlogin NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;zlogout NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;profile.d&#x2F; NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;X11&#x2F; NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Pkg manager
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;yum.conf NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;yumex.conf NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;yumex.profiles.conf NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;yum&#x2F; NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;yum.repos.d&#x2F; NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Ignore lvm files that change regularly
&lt;&#x2F;span&gt;&lt;span&gt;!&#x2F;etc&#x2F;lvm&#x2F;archive
&lt;&#x2F;span&gt;&lt;span&gt;!&#x2F;etc&#x2F;lvm&#x2F;backup
&lt;&#x2F;span&gt;&lt;span&gt;!&#x2F;etc&#x2F;lvm&#x2F;cache
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Don&amp;#39;t scan log by default, because not everything is a &amp;quot;growing log file&amp;quot;.
&lt;&#x2F;span&gt;&lt;span&gt;!&#x2F;var&#x2F;log   LOG
&lt;&#x2F;span&gt;&lt;span&gt;!&#x2F;var&#x2F;run&#x2F;utmp LOG
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# This gets new&#x2F;removes-old filenames daily
&lt;&#x2F;span&gt;&lt;span&gt;!&#x2F;var&#x2F;log&#x2F;sa
&lt;&#x2F;span&gt;&lt;span&gt;# As we are checking it, we&amp;#39;ve truncated yesterdays size to zero.
&lt;&#x2F;span&gt;&lt;span&gt;!&#x2F;var&#x2F;log&#x2F;aide.log
&lt;&#x2F;span&gt;&lt;span&gt;!&#x2F;var&#x2F;log&#x2F;journal
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# LSPP rules...
&lt;&#x2F;span&gt;&lt;span&gt;# AIDE produces an audit record, so this becomes perpetual motion.
&lt;&#x2F;span&gt;&lt;span&gt;# &#x2F;var&#x2F;log&#x2F;audit&#x2F; LSPP
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;audit&#x2F; LSPP
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;audisp&#x2F; LSPP
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;libaudit.conf LSPP
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;usr&#x2F;sbin&#x2F;stunnel LSPP
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;var&#x2F;spool&#x2F;at LSPP
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;at.allow LSPP
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;at.deny LSPP
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;cron.allow LSPP
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;cron.deny LSPP
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;cron.d&#x2F; LSPP
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;cron.daily&#x2F; LSPP
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;cron.hourly&#x2F; LSPP
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;cron.monthly&#x2F; LSPP
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;cron.weekly&#x2F; LSPP
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;crontab LSPP
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;var&#x2F;spool&#x2F;cron&#x2F;root LSPP
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;login.defs LSPP
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;securetty LSPP
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;var&#x2F;log&#x2F;faillog LSPP
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;var&#x2F;log&#x2F;lastlog LSPP
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;hosts LSPP
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;sysconfig LSPP
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;inittab LSPP
&lt;&#x2F;span&gt;&lt;span&gt;#&#x2F;etc&#x2F;grub&#x2F; LSPP
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;rc.d LSPP
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;ld.so.conf LSPP
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;localtime LSPP
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;sysctl.conf LSPP
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;modprobe.conf LSPP
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;pam.d LSPP
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;security LSPP
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;aliases LSPP
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;postfix LSPP
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;ssh&#x2F;sshd_config LSPP
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;ssh&#x2F;ssh_config LSPP
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;stunnel LSPP
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;vsftpd.ftpusers LSPP
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;vsftpd LSPP
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;issue LSPP
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;issue.net LSPP
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;cups LSPP
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Check our key stores for tampering.
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;pki LSPPMT
&lt;&#x2F;span&gt;&lt;span&gt;!&#x2F;etc&#x2F;pki&#x2F;nssdb&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;pki&#x2F;nssdb&#x2F;cert8.db LSPP
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;pki&#x2F;nssdb&#x2F;cert9.db LSPP
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;pki&#x2F;nssdb&#x2F;key3.db LSPP
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;pki&#x2F;nssdb&#x2F;key4.db LSPP
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;pki&#x2F;nssdb&#x2F;pkcs11.txt LSPP
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;pki&#x2F;nssdb&#x2F;secmod.db LSPP
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Check ldap and auth configurations.
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;openldap LSPP
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;etc&#x2F;sssd LSPP
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Ignore the prelink cache as it changes.
&lt;&#x2F;span&gt;&lt;span&gt;!&#x2F;etc&#x2F;prelink.cache
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# With AIDE&amp;#39;s default verbosity level of 5, these would give lots of
&lt;&#x2F;span&gt;&lt;span&gt;# warnings upon tree traversal. It might change with future version.
&lt;&#x2F;span&gt;&lt;span&gt;#
&lt;&#x2F;span&gt;&lt;span&gt;#=&#x2F;lost\+found    DIR
&lt;&#x2F;span&gt;&lt;span&gt;#=&#x2F;home           DIR
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Ditto &#x2F;var&#x2F;log&#x2F;sa reason...
&lt;&#x2F;span&gt;&lt;span&gt;!&#x2F;var&#x2F;log&#x2F;and-httpd
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;#&#x2F;root   NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;# Admins dot files constantly change, just check PERMS
&lt;&#x2F;span&gt;&lt;span&gt;#&#x2F;root&#x2F;\..* PERMS
&lt;&#x2F;span&gt;&lt;span&gt;# Check root sensitive files
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;root&#x2F;.ssh&#x2F; NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;root&#x2F;.bash_profile NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;root&#x2F;.bashrc NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;root&#x2F;.cshrc NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;root&#x2F;.tcshrc NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;root&#x2F;.zshrc NORMAL
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;@@include &#x2F;etc&#x2F;aide-local.conf
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;-- Time ------------&lt;&#x2F;p&gt;
&lt;p&gt;Make sure you run an NTP client. I&#x27;m a fan of chrony these days, as
it&#x27;s syncs quickly and reliably.&lt;&#x2F;p&gt;
&lt;p&gt;-- Collect core dumps and abrt
-----------------------------------&lt;&#x2F;p&gt;
&lt;p&gt;Install and run kdump and abrtd so you can analyse why something
crashed, to determine if it was malicious or not.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;yum install kexec-tools abrt abrt-cli
&lt;&#x2F;span&gt;&lt;span&gt;systemctl enable abrtd
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;At the same time, you need to alter kdump.conf to dump correctly&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;xfs &#x2F;dev&#x2F;os_vg&#x2F;var_lv                                                            
&lt;&#x2F;span&gt;&lt;span&gt;path &#x2F;crash                                                                      
&lt;&#x2F;span&gt;&lt;span&gt;core_collector makedumpfile -l --message-level 7 -d 23,31                        
&lt;&#x2F;span&gt;&lt;span&gt;default reboot   
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Finally, append crashkernel=auto to your grub commandline.&lt;&#x2F;p&gt;
&lt;p&gt;-- Sysctl --------------&lt;&#x2F;p&gt;
&lt;p&gt;These are an evolved set of sysctls and improvements to our base install
that help tune some basic network and other areas to strengthen the
network stack and base OS.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# Ensure ASLR
&lt;&#x2F;span&gt;&lt;span&gt;kernel.randomize_va_space = 2
&lt;&#x2F;span&gt;&lt;span&gt;# limit access to dmesg
&lt;&#x2F;span&gt;&lt;span&gt;## does this affect ansible facts
&lt;&#x2F;span&gt;&lt;span&gt;kernel.dmesg_restrict = 1
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Prevent suid binaries core dumping. Helps to prevent memory &#x2F; data leaks
&lt;&#x2F;span&gt;&lt;span&gt;fs.suid_dumpable = 0
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# https:&#x2F;&#x2F;www.kernel.org&#x2F;doc&#x2F;Documentation&#x2F;networking&#x2F;ip-sysctl.txt
&lt;&#x2F;span&gt;&lt;span&gt;# Controls IP packet forwarding
&lt;&#x2F;span&gt;&lt;span&gt;net.ipv4.ip_forward = 0
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Controls source route verification
&lt;&#x2F;span&gt;&lt;span&gt;net.ipv4.conf.default.rp_filter = 1
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Do not accept source routing
&lt;&#x2F;span&gt;&lt;span&gt;net.ipv4.conf.default.accept_source_route = 0
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Controls the System Request debugging functionality of the kernel
&lt;&#x2F;span&gt;&lt;span&gt;kernel.sysrq = 0
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Controls whether core dumps will append the PID to the core filename.
&lt;&#x2F;span&gt;&lt;span&gt;# Useful for debugging multi-threaded applications.
&lt;&#x2F;span&gt;&lt;span&gt;kernel.core_uses_pid = 1
&lt;&#x2F;span&gt;&lt;span&gt;# Decrease the time default value for tcp_fin_timeout connection
&lt;&#x2F;span&gt;&lt;span&gt;net.ipv4.tcp_fin_timeout = 35
&lt;&#x2F;span&gt;&lt;span&gt;# Decrease the time default value for tcp_keepalive_time connection
&lt;&#x2F;span&gt;&lt;span&gt;net.ipv4.tcp_keepalive_time = 600
&lt;&#x2F;span&gt;&lt;span&gt;# Provide more ports and timewait buckets to increase connectivity
&lt;&#x2F;span&gt;&lt;span&gt;net.ipv4.ip_local_port_range = 8192 61000
&lt;&#x2F;span&gt;&lt;span&gt;net.ipv4.tcp_max_tw_buckets = 1000000
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;## Network Hardening ##
&lt;&#x2F;span&gt;&lt;span&gt;net.ipv4.tcp_max_syn_backlog = 4096
&lt;&#x2F;span&gt;&lt;span&gt;net.ipv4.conf.all.accept_redirects = 0
&lt;&#x2F;span&gt;&lt;span&gt;net.ipv4.conf.all.secure_redirects = 0
&lt;&#x2F;span&gt;&lt;span&gt;net.ipv4.conf.default.accept_redirects = 0
&lt;&#x2F;span&gt;&lt;span&gt;net.ipv4.conf.default.secure_redirects = 0
&lt;&#x2F;span&gt;&lt;span&gt;net.ipv4.icmp_echo_ignore_broadcasts = 1
&lt;&#x2F;span&gt;&lt;span&gt;net.ipv4.conf.all.send_redirects = 0
&lt;&#x2F;span&gt;&lt;span&gt;net.ipv4.conf.default.send_redirects = 0
&lt;&#x2F;span&gt;&lt;span&gt;net.ipv4.icmp_ignore_bogus_error_responses = 1
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;net.nf_conntrack_max = 262144
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
</description>
      </item>
      <item>
          <title>KRB5 setup for ldap server testing</title>
          <pubDate>Thu, 05 Nov 2015 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2015-11-05-krb5-setup-for-ldap-server-testing/</link>
          <guid>https://fy.blackhats.net.au/blog/2015-11-05-krb5-setup-for-ldap-server-testing/</guid>
          <description>&lt;h1 id=&quot;krb5-setup-for-ldap-server-testing&quot;&gt;KRB5 setup for ldap server testing&lt;&#x2F;h1&gt;
&lt;p&gt;UPDATE: 2019 this is now automated, but I &lt;a href=&quot;&#x2F;blog&#x2F;html&#x2F;2017&#x2F;05&#x2F;23&#x2F;kerberos_why_the_world_moved_on.html&quot;&gt;don&#x27;t recommend using
kerberos - read more
here.&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;This will eventually get automated, but here is a quick krb recipe for
testing. Works in docker containers too!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;krb5-without-ldap-backend&quot;&gt;-- krb5 without ldap backend.&lt;&#x2F;h2&gt;
&lt;p&gt;Add kerberos.example.com as an entry to &#x2F;etc&#x2F;hosts for this local
machine. It should be the first entry.&lt;&#x2F;p&gt;
&lt;p&gt;Edit &#x2F;etc&#x2F;krb5.conf.d&#x2F;example.com&lt;&#x2F;p&gt;
&lt;p&gt;NOTE: This doesn&#x27;t work, you need to add it to krb5.conf. Why doesn&#x27;t
it work?&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;[realms]
&lt;&#x2F;span&gt;&lt;span&gt;EXAMPLE.COM = {
&lt;&#x2F;span&gt;&lt;span&gt; kdc = kerberos.example.com
&lt;&#x2F;span&gt;&lt;span&gt; admin_server = kerberos.example.com
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[domain_realm]
&lt;&#x2F;span&gt;&lt;span&gt;.example.com = EXAMPLE.COM
&lt;&#x2F;span&gt;&lt;span&gt;example.com = EXAMPLE.COM
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Edit &#x2F;var&#x2F;kerberos&#x2F;krb5kdc&#x2F;kdc.conf&lt;&#x2F;p&gt;
&lt;p&gt;# Note, I think the defalt kdc.conf is good. :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;[kdcdefaults]
&lt;&#x2F;span&gt;&lt;span&gt; kdc_ports = 88
&lt;&#x2F;span&gt;&lt;span&gt; kdc_tcp_ports = 88
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[realms]
&lt;&#x2F;span&gt;&lt;span&gt; EXAMPLE.COM = {
&lt;&#x2F;span&gt;&lt;span&gt;  #master_key_type = aes256-cts
&lt;&#x2F;span&gt;&lt;span&gt;  acl_file = &#x2F;var&#x2F;kerberos&#x2F;krb5kdc&#x2F;kadm5.acl
&lt;&#x2F;span&gt;&lt;span&gt;  dict_file = &#x2F;usr&#x2F;share&#x2F;dict&#x2F;words
&lt;&#x2F;span&gt;&lt;span&gt;  admin_keytab = &#x2F;var&#x2F;kerberos&#x2F;krb5kdc&#x2F;kadm5.keytab
&lt;&#x2F;span&gt;&lt;span&gt;  supported_enctypes = aes256-cts:normal aes128-cts:normal des3-hmac-sha1:normal arcfour-hmac:normal camellia256-cts:normal camellia128-cts:normal des-hmac-sha1:normal des-cbc-md5:normal des-cbc-crc:normal
&lt;&#x2F;span&gt;&lt;span&gt; }
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now setup the database.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;usr&#x2F;sbin&#x2F;kdb5_util create -r EXAMPLE.COM -s  # Prompts for password. Is there a way to avoid prompt?
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Edit &#x2F;var&#x2F;kerberos&#x2F;krb5kdc&#x2F;kadm5.acl&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;usr&#x2F;sbin&#x2F;kadmin.local -r EXAMPLE.COM -q listprincs
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Add our LDAP servers&lt;&#x2F;p&gt;
&lt;p&gt;# There is a way to submit these on the CLI, but I get kadmin.local:
Cannot find master key record in database while initializing
kadmin.local interface&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;usr&#x2F;sbin&#x2F;kadmin.local -r EXAMPLE.COM                                                                
&lt;&#x2F;span&gt;&lt;span&gt;add_principal -randkey ldap&#x2F;kerberos.example.com@EXAMPLE.COM
&lt;&#x2F;span&gt;&lt;span&gt;ktadd -k &#x2F;opt&#x2F;dirsrv&#x2F;etc&#x2F;dirsrv&#x2F;slapd-localhost&#x2F;ldap.keytab ldap&#x2F;kerberos.example.com
&lt;&#x2F;span&gt;&lt;span&gt;add_principal -pw password client
&lt;&#x2F;span&gt;&lt;span&gt;exit
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Start the kdc&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;usr&#x2F;sbin&#x2F;krb5kdc -P &#x2F;var&#x2F;run&#x2F;krb5kdc.pid -r EXAMPLE.COM
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;OR&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# You need to edit &#x2F;etc&#x2F;sysconfig&#x2F;krb5kdc and put -r EXAMPLE.COM into args
&lt;&#x2F;span&gt;&lt;span&gt;systemctl start krb5kdc
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;KRB5_TRACE=&#x2F;tmp&#x2F;foo kinit client@EXAMPLE.COM
&lt;&#x2F;span&gt;&lt;span&gt;klist
&lt;&#x2F;span&gt;&lt;span&gt;Ticket cache: KEYRING:persistent:0:0
&lt;&#x2F;span&gt;&lt;span&gt;Default principal: client@EXAMPLE.COM
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Valid starting     Expires            Service principal
&lt;&#x2F;span&gt;&lt;span&gt;05&#x2F;11&#x2F;15 11:35:37  06&#x2F;11&#x2F;15 11:35:37  krbtgt&#x2F;EXAMPLE.COM@EXAMPLE.COM
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now setup the DS instance.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# Note, might be dirsrv in newer installs.
&lt;&#x2F;span&gt;&lt;span&gt;chown nobody: &#x2F;opt&#x2F;dirsrv&#x2F;etc&#x2F;dirsrv&#x2F;slapd-localhost&#x2F;ldap.keytab
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Add:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;KRB5_KTNAME=&#x2F;opt&#x2F;dirsrv&#x2F;etc&#x2F;dirsrv&#x2F;slapd-localhost&#x2F;ldap.keytab ; export KRB5_KTNAME    
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;To &#x2F;opt&#x2F;dirsrv&#x2F;etc&#x2F;sysconfig&#x2F;dirsrv-localhost&lt;&#x2F;p&gt;
&lt;p&gt;Now restart the DS&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;opt&#x2F;dirsrv&#x2F;etc&#x2F;rc.d&#x2F;init.d&#x2F;dirsrv restart
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Add a client object:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;uid=client,ou=People,dc=example,dc=com
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: top
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: account
&lt;&#x2F;span&gt;&lt;span&gt;uid: client
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now check the GSSAPI is working.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ldapwhoami -Y GSSAPI -H ldap:&#x2F;&#x2F;kerberos.example.com:389    
&lt;&#x2F;span&gt;&lt;span&gt;SASL&#x2F;GSSAPI authentication started
&lt;&#x2F;span&gt;&lt;span&gt;SASL username: client@EXAMPLE.COM
&lt;&#x2F;span&gt;&lt;span&gt;SASL SSF: 56
&lt;&#x2F;span&gt;&lt;span&gt;SASL data security layer installed.
&lt;&#x2F;span&gt;&lt;span&gt;dn: uid=client,ou=people,dc=example,dc=com
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;All ready to go!&lt;&#x2F;p&gt;
&lt;p&gt;I have created some helpers in lib389 that are able to do this now.&lt;&#x2F;p&gt;
&lt;p&gt;TODO: How to setup krb5 with ldap backend.&lt;&#x2F;p&gt;
&lt;p&gt;create instance:&lt;&#x2F;p&gt;
&lt;p&gt;&#x2F;opt&#x2F;dirsrv&#x2F;sbin&#x2F;setup-ds.pl --silent --debug
--file=&#x2F;home&#x2F;wibrown&#x2F;development&#x2F;389ds&#x2F;setup.inf&lt;&#x2F;p&gt;
&lt;p&gt;Now, add the krb5 schema&lt;&#x2F;p&gt;
&lt;p&gt;cd &#x2F;opt&#x2F;dirsrv&#x2F;etc&#x2F;dirsrv&#x2F;slapd-localhost&#x2F;schema ln -s
..&#x2F;..&#x2F;..&#x2F;..&#x2F;..&#x2F;..&#x2F;usr&#x2F;share&#x2F;doc&#x2F;krb5-server-ldap&#x2F;60kerberos.ldif&lt;&#x2F;p&gt;
&lt;p&gt;&#x2F;opt&#x2F;dirsrv&#x2F;etc&#x2F;rc.d&#x2F;init.d&#x2F;dirsrv restart&lt;&#x2F;p&gt;
&lt;p&gt;Query the schema:&lt;&#x2F;p&gt;
&lt;p&gt;python
&#x2F;home&#x2F;wibrown&#x2F;development&#x2F;389ds&#x2F;lib389&#x2F;clitools&#x2F;ds_schema_attributetype_list.py
| grep krb&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Debugging 389ds tests</title>
          <pubDate>Mon, 03 Aug 2015 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2015-08-03-debugging-389ds-tests/</link>
          <guid>https://fy.blackhats.net.au/blog/2015-08-03-debugging-389ds-tests/</guid>
          <description>&lt;h1 id=&quot;debugging-389ds-tests&quot;&gt;Debugging 389ds tests&lt;&#x2F;h1&gt;
&lt;p&gt;I&#x27;ve always found when writing tests for 389ds that&#x27;s it&#x27;s really
handy to have the ldif of data and the logs from a unit test available.
However, by default, these are stored.&lt;&#x2F;p&gt;
&lt;p&gt;I discovered that if you add instance.backupFS() just before your
instance.delete() you can keep a full dump of the data and logs from the
instance.&lt;&#x2F;p&gt;
&lt;p&gt;It can also be useful to call db2ldif before you run the backup so that
you have a human readable copy of the data on hand as well.&lt;&#x2F;p&gt;
&lt;p&gt;I&#x27;ve found the best pattern is:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;def tearDown(self):
&lt;&#x2F;span&gt;&lt;span&gt;    if self.instance.exists():
&lt;&#x2F;span&gt;&lt;span&gt;        self.instance.db2ldif(bename=&amp;#39;userRoot&amp;#39;, suffixes=[DEFAULT_SUFFIX], excludeSuffixes=[], encrypt=False, \
&lt;&#x2F;span&gt;&lt;span&gt;            repl_data=False, outputfile=&amp;#39;%s&#x2F;ldif&#x2F;%s.ldif&amp;#39; % (self.instance.dbdir,INSTANCE_SERVERID ))
&lt;&#x2F;span&gt;&lt;span&gt;        self.instance.clearBackupFS()
&lt;&#x2F;span&gt;&lt;span&gt;        self.instance.backupFS()
&lt;&#x2F;span&gt;&lt;span&gt;        self.instance.delete()
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This puts an ldif dump of the DB into the backup path, we then clear old
backups for our test instance (else it won&#x27;t over-write them), finally,
we actually do the backup. You should see:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;snip ...
&lt;&#x2F;span&gt;&lt;span&gt;DEBUG:lib389:backupFS add = &#x2F;var&#x2F;lib&#x2F;dirsrv&#x2F;slapd-effectiverightsds&#x2F;ldif&#x2F;effectiverightsds.ldif (&#x2F;)
&lt;&#x2F;span&gt;&lt;span&gt;snip ...
&lt;&#x2F;span&gt;&lt;span&gt;INFO:lib389:backupFS: archive done : &#x2F;tmp&#x2F;slapd-effectiverightsds.bck&#x2F;backup_08032015_092510.tar.gz
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Then you can extract this in &#x2F;tmp&#x2F;slapd-instance, and examine your logs
and the ldif of what was really in your ldap server at the time.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>mod selinux on rhel7</title>
          <pubDate>Mon, 03 Aug 2015 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2015-08-03-mod-selinux-on-rhel7/</link>
          <guid>https://fy.blackhats.net.au/blog/2015-08-03-mod-selinux-on-rhel7/</guid>
          <description>&lt;h1 id=&quot;mod-selinux-on-rhel7&quot;&gt;mod selinux on rhel7&lt;&#x2F;h1&gt;
&lt;p&gt;I have now compiled and testing mod_selinux on el7. I&#x27;m trying to get
this into EPEL now.&lt;&#x2F;p&gt;
&lt;p&gt;To test this once you have done a build.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;#!&#x2F;usr&#x2F;bin&#x2F;env python
&lt;&#x2F;span&gt;&lt;span&gt;import cgi
&lt;&#x2F;span&gt;&lt;span&gt;import cgitb; cgitb.enable()  # for troubleshooting
&lt;&#x2F;span&gt;&lt;span&gt;import selinux
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;print &amp;quot;Content-type: text&#x2F;html&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;print
&lt;&#x2F;span&gt;&lt;span&gt;print &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;html&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;head&amp;gt;&amp;lt;title&amp;gt;Selinux CGI context&amp;lt;&#x2F;title&amp;gt;&amp;lt;&#x2F;head&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;body&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;  &amp;lt;p&amp;gt;Current context is %s&amp;lt;&#x2F;p&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&#x2F;body&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&#x2F;html&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;&amp;quot;&amp;quot; % cgi.escape(str(selinux.getcon()))
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Put this cgi into:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;var&#x2F;www&#x2F;cgi-bin&#x2F;selinux-c1.cgi
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;var&#x2F;www&#x2F;cgi-bin&#x2F;selinux-c2.cgi
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;var&#x2F;www&#x2F;cgi-bin&#x2F;selinux-c3.cgi
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now, install and configure httpd.&lt;&#x2F;p&gt;
&lt;p&gt;&#x2F;etc&#x2F;httpd&#x2F;conf.d&#x2F;mod_selinux.conf&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&amp;lt;VirtualHost *:80&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt; DocumentRoot          &#x2F;var&#x2F;www&#x2F;html
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;lt;LocationMatch &#x2F;cgi-bin&#x2F;selinux-c2.cgi&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;    selinuxDomainVal    *:s0:c2
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;lt;&#x2F;LocationMatch&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;lt;LocationMatch &#x2F;cgi-bin&#x2F;selinux-c3.cgi&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;    selinuxDomainVal    *:s0:c3
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;lt;&#x2F;LocationMatch&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&#x2F;VirtualHost&amp;gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now when you load each page you should see different contexts such as:
&amp;quot;Current context is [0,
&#x27;system_u:system_r:httpd_sys_script_t:s0:c3&#x27;]&amp;quot;&lt;&#x2F;p&gt;
&lt;p&gt;You can easily extend these location-match based contexts onto django
project urls etc. Consider you have a file upload. You place that into
c1, and then have all other processes in c2. If the url needs to look at
the file, then you place that in c1 also.&lt;&#x2F;p&gt;
&lt;p&gt;Alternately, you can use this for virtualhost isolation, or even if you
feel game, write new policies to allow more complex rules within your
application.&lt;&#x2F;p&gt;
&lt;p&gt;34&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Ovirt with ldap authentication source</title>
          <pubDate>Wed, 15 Jul 2015 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2015-07-15-ovirt-with-ldap-authentication-source/</link>
          <guid>https://fy.blackhats.net.au/blog/2015-07-15-ovirt-with-ldap-authentication-source/</guid>
          <description>&lt;h1 id=&quot;ovirt-with-ldap-authentication-source&quot;&gt;Ovirt with ldap authentication source&lt;&#x2F;h1&gt;
&lt;p&gt;I want ovirt to auth to our work&#x27;s ldap server, but the default engine
domain system expects you to have kerberos. There is however a new AAA
module that you can use.&lt;&#x2F;p&gt;
&lt;p&gt;First, install it&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;yum install ovirt-engine-extension-aaa-ldap
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;So we have a look at the package listing to see what could be a good
example:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;rpm -ql ovirt-engine-extension-aaa-ldap
&lt;&#x2F;span&gt;&lt;span&gt;....
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;usr&#x2F;share&#x2F;ovirt-engine-extension-aaa-ldap&#x2F;examples&#x2F;simple&#x2F;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;So we copy our example in place:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;cp -r &#x2F;usr&#x2F;share&#x2F;ovirt-engine-extension-aaa-ldap&#x2F;examples&#x2F;simple&#x2F;* &#x2F;etc&#x2F;ovirt-engine&#x2F;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now we edit the values in &#x2F;etc&#x2F;ovirt-engine&#x2F;aaa&#x2F;profile1.properties to
match our site, then restart the engine service.&lt;&#x2F;p&gt;
&lt;p&gt;Finally, we need to login is as our admin user, then go to configure and
assign our user a role. This should allow them to login.&lt;&#x2F;p&gt;
&lt;p&gt;I&#x27;m seeing some issues with group permissions at the moment, but I
suspect that is a schema mismatch issue.&lt;&#x2F;p&gt;
&lt;p&gt;This was a really valuable resource.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;access.redhat.com&#x2F;documentation&#x2F;en-US&#x2F;Red_Hat_Enterprise_Virtualization&#x2F;3.5&#x2F;html&#x2F;Administration_Guide&#x2F;sect-Directory_Users.html&quot;&gt;access.redhat.com&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Spamassasin with postfix</title>
          <pubDate>Fri, 10 Jul 2015 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2015-07-10-spamassasin-with-postfix/</link>
          <guid>https://fy.blackhats.net.au/blog/2015-07-10-spamassasin-with-postfix/</guid>
          <description>&lt;h1 id=&quot;spamassasin-with-postfix&quot;&gt;Spamassasin with postfix&lt;&#x2F;h1&gt;
&lt;p&gt;I run my own email servers for the fun of it, and to learn about the
best practices etc. I&#x27;ve learnt a lot about email as a result so the
exercise has paid off.&lt;&#x2F;p&gt;
&lt;p&gt;For about 2 years, I had no spam at all. But for some reason about 5
months ago, suddenly my email address was found, and spam ensued. I
didn&#x27;t want to spend my life hand filtering out the spam, so enter
spamasssasin.&lt;&#x2F;p&gt;
&lt;p&gt;My mail server config itself is the subject of a different post. Today
is just about integrating in spamassassin with postfix.&lt;&#x2F;p&gt;
&lt;p&gt;First, make sure we have all the packages we need. I&#x27;m a centos&#x2F;fedora
user, so adjust as needed.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;yum install postfix spamass-milter spamassassin
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The default spamassassin configuration is good, but I&#x27;m always open to
ideas on how to improve it.&lt;&#x2F;p&gt;
&lt;p&gt;Now we configure postfix to pass mail through the spamassasin milter.&lt;&#x2F;p&gt;
&lt;p&gt;postfix&#x2F;main.cf :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;smtpd_milters = unix:&#x2F;run&#x2F;spamass-milter&#x2F;postfix&#x2F;sock
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now, enable our spamassasin and postfix service&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;systemctl enable spamass-milter
&lt;&#x2F;span&gt;&lt;span&gt;systemctl enable postfix
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now when you recieve email from spamers, they should be tagged with
[SPAM].&lt;&#x2F;p&gt;
&lt;p&gt;I use dovecot sieve filters on my mailbox to sort these emails out into
a separate spam folder.&lt;&#x2F;p&gt;
&lt;p&gt;One of the best things that I learnt with spamassassin is that it&#x27;s
bayesian filters are very powerful if you train them.&lt;&#x2F;p&gt;
&lt;p&gt;So I setup a script to help me train the spamassasin bayesian filters.
This relies heavily on you as a user manually moving spam that is
&amp;quot;missed&amp;quot; from your inbox into your spam folder. You must move it all
else this process doesn&#x27;t work!&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;cd &#x2F;var&#x2F;lib&#x2F;dovecot&#x2F;vmail&#x2F;william
&lt;&#x2F;span&gt;&lt;span&gt;sa-learn --progress --no-sync --ham {.,.INBOX.archive}&#x2F;{cur,new}
&lt;&#x2F;span&gt;&lt;span&gt;sa-learn --progress --no-sync --spam .INBOX.spam&#x2F;{cur,new}
&lt;&#x2F;span&gt;&lt;span&gt;sa-learn --progress --sync
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;First, we learn &amp;quot;real&amp;quot; messages from our inbox and our inbox archive.
Then we learn spam from our spam folders. Finally, we commit the new
bayes database.&lt;&#x2F;p&gt;
&lt;p&gt;This could be extended to multiple users with:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;cd &#x2F;var&#x2F;lib&#x2F;dovecot&#x2F;vmail&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;sa-learn --progress --no-sync --ham {william,otheruser}&#x2F;{.,.INBOX.archive}&#x2F;{cur,new}
&lt;&#x2F;span&gt;&lt;span&gt;sa-learn --progress --no-sync --spam {william,otheruser}&#x2F;.INBOX.spam&#x2F;{cur,new}
&lt;&#x2F;span&gt;&lt;span&gt;sa-learn --progress --sync
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Of course, this completely relies on that user ALSO classifying their
mail correctly!&lt;&#x2F;p&gt;
&lt;p&gt;However, all users will benefit from the &amp;quot;learning&amp;quot; of a few dedicated
users.&lt;&#x2F;p&gt;
&lt;p&gt;Some other golden tips for blocking spam, are to set these in postfix&#x27;s
main.cf. Most spammers will violate some of these rules at some point. I
often see many blocked because of the invalid helo rules.&lt;&#x2F;p&gt;
&lt;p&gt;Note, I don&#x27;t do &amp;quot;permit networks&amp;quot; because of the way my load
balancer is configured.&lt;&#x2F;p&gt;
&lt;p&gt;main.cf :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;smtpd_delay_reject = yes
&lt;&#x2F;span&gt;&lt;span&gt;smtpd_helo_required = yes
&lt;&#x2F;span&gt;&lt;span&gt;smtpd_helo_restrictions =
&lt;&#x2F;span&gt;&lt;span&gt;    reject_non_fqdn_helo_hostname,
&lt;&#x2F;span&gt;&lt;span&gt;    reject_invalid_helo_hostname,
&lt;&#x2F;span&gt;&lt;span&gt;    permit
&lt;&#x2F;span&gt;&lt;span&gt;smtpd_relay_restrictions = permit_sasl_authenticated reject_unauth_destination reject_non_fqdn_recipient reject_unknown_recipient_domain reject_unknown_sender_domain
&lt;&#x2F;span&gt;&lt;span&gt;smtpd_sender_restrictions =
&lt;&#x2F;span&gt;&lt;span&gt;    reject_non_fqdn_sender,
&lt;&#x2F;span&gt;&lt;span&gt;    reject_unknown_sender_domain,
&lt;&#x2F;span&gt;&lt;span&gt;    permit
&lt;&#x2F;span&gt;&lt;span&gt;smtpd_recipient_restrictions = reject_unauth_pipelining reject_non_fqdn_recipient reject_unknown_recipient_domain permit_sasl_authenticated reject_unauth_destination permit
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Happy spam hunting!&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>SSH keys in ldap</title>
          <pubDate>Fri, 10 Jul 2015 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2015-07-10-ssh-keys-in-ldap/</link>
          <guid>https://fy.blackhats.net.au/blog/2015-07-10-ssh-keys-in-ldap/</guid>
          <description>&lt;h1 id=&quot;ssh-keys-in-ldap&quot;&gt;SSH keys in ldap&lt;&#x2F;h1&gt;
&lt;p&gt;At the dawn of time, we all used passwords to access systems. It was
good, but having to type your password tens, hundreds of times a day got
old. So along comes ssh keys. However, as we have grown the number of
systems we have it&#x27;s hard to put your ssh key on all systems easily.
Then let alone the mess of needing to revoke an ssh key if it were
compromised.&lt;&#x2F;p&gt;
&lt;p&gt;Wouldn&#x27;t it be easier if we could store one copy of your public key,
and make it available to all systems? When you revoke that key in one
location, it revokes on all systems?&lt;&#x2F;p&gt;
&lt;p&gt;Enter ssh public keys in ldap.&lt;&#x2F;p&gt;
&lt;p&gt;I think that FreeIPA is a great project, and they enable this by
default. However, we all don&#x27;t have the luxury of just setting up IPA.
We have existing systems to maintain, in my case, 389ds.&lt;&#x2F;p&gt;
&lt;p&gt;So I had to work out how to setup this system myself.&lt;&#x2F;p&gt;
&lt;p&gt;First, you need to setup the LDAP server parts. I applied this ldif:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;dn: cn=schema
&lt;&#x2F;span&gt;&lt;span&gt;changetype: modify
&lt;&#x2F;span&gt;&lt;span&gt;add: attributetypes
&lt;&#x2F;span&gt;&lt;span&gt;attributetypes: ( 1.3.6.1.4.1.24552.500.1.1.1.13 NAME &amp;#39;sshPublicKey&amp;#39; DESC &amp;#39;MANDATORY: OpenSSH Public key&amp;#39; EQUALITY octetStringMatch SYNTAX 1.3.6.1.4.1.1466.115.121.1.40 )
&lt;&#x2F;span&gt;&lt;span&gt;-
&lt;&#x2F;span&gt;&lt;span&gt;add: objectclasses
&lt;&#x2F;span&gt;&lt;span&gt;objectClasses: ( 1.3.6.1.4.1.24552.500.1.1.2.0 NAME &amp;#39;ldapPublicKey&amp;#39; SUP top AUXILIARY DESC &amp;#39;MANDATORY: OpenSSH LPK objectclass&amp;#39; MUST ( uid ) MAY ( sshPublicKey ) )
&lt;&#x2F;span&gt;&lt;span&gt;-
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;dn: cn=sshpublickey,cn=default indexes,cn=config,cn=ldbm database,cn=plugins,cn=config
&lt;&#x2F;span&gt;&lt;span&gt;changetype: add
&lt;&#x2F;span&gt;&lt;span&gt;cn: sshpublickey
&lt;&#x2F;span&gt;&lt;span&gt;nsIndexType: eq
&lt;&#x2F;span&gt;&lt;span&gt;nsIndexType: pres
&lt;&#x2F;span&gt;&lt;span&gt;nsSystemIndex: false
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: top
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: nsIndex
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;dn: cn=sshpublickey_self_manage,ou=groups,dc=example,dc=com
&lt;&#x2F;span&gt;&lt;span&gt;changetype: add
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: top
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: groupofuniquenames
&lt;&#x2F;span&gt;&lt;span&gt;cn: sshpublickey_self_manage
&lt;&#x2F;span&gt;&lt;span&gt;description: Members of this group gain the ability to edit their own sshPublicKey field
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;dn: dc=example,dc=com
&lt;&#x2F;span&gt;&lt;span&gt;changetype: modify
&lt;&#x2F;span&gt;&lt;span&gt;add: aci
&lt;&#x2F;span&gt;&lt;span&gt;aci: (targetattr = &amp;quot;sshPublicKey&amp;quot;) (version 3.0; acl &amp;quot;Allow members of sshpublickey_self_manage to edit their keys&amp;quot;; allow(write) (groupdn = &amp;quot;ldap:&#x2F;&#x2F;&#x2F;cn=sshpublickey_self_manage,ou=groups,dc=example,dc=com&amp;quot; and userdn=&amp;quot;ldap:&#x2F;&#x2F;&#x2F;self&amp;quot; ); )
&lt;&#x2F;span&gt;&lt;span&gt;-
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;For the keen eyed, this is the schema from openssd-ldap but with the
objectClass altered to MAY instead of MUST take sshPublicKey. This
allows me to add the objectClass to our staff accounts, without needing
to set a key for them.&lt;&#x2F;p&gt;
&lt;p&gt;Members of the group in question can now self edit their ssh key. It
will look like :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;dn: uid=william,ou=People,dc=example,dc=com
&lt;&#x2F;span&gt;&lt;span&gt;sshPublicKey: ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDI&#x2F;xgEMzqNwkXMIjjdDO2+xfru
&lt;&#x2F;span&gt;&lt;span&gt; HK248uIKZ2CHFGIM+BlEhBjqvLpbrFZDYVsme8997p98ENPHGItFch87GCbRhWrpDHINQAnMQkLvD
&lt;&#x2F;span&gt;&lt;span&gt; eykE1CpYpMWaeyygRZwCUaFfYJD3OgxVoqcUpAc8ZvtGQmHpo++RD5WPNedXOeq&#x2F;vZzEPbp96ndOn
&lt;&#x2F;span&gt;&lt;span&gt; b3WejCxl a1176360@strawberry
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now we configure SSSD.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;[domain&#x2F;foo]
&lt;&#x2F;span&gt;&lt;span&gt;ldap_account_expire_policy = rhds
&lt;&#x2F;span&gt;&lt;span&gt;ldap_access_order = filter, expire
&lt;&#x2F;span&gt;&lt;span&gt;ldap_user_ssh_public_key = sshPublicKey
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[sssd]
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;span&gt;services = nss, pam, ssh
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The expire policy is extremely important. In 389ds we set nsAccountLock
to true to lock out an account. Normally this would cause the password
auth to fail, effectively denying access to servers.&lt;&#x2F;p&gt;
&lt;p&gt;However, with ssh keys, this process bypasses the password
authentication mechanism. So a valid ssh key could still access a server
even if the account lock was set.&lt;&#x2F;p&gt;
&lt;p&gt;So we setup this policy, to make sure that the account is locked out
from servers even if ssh key authentication is used.&lt;&#x2F;p&gt;
&lt;p&gt;This configuration can be tested by running:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;sss_ssh_authorizedkeys william
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You should see a public key.&lt;&#x2F;p&gt;
&lt;p&gt;Finally, we configure sshd to check for these keys&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;AuthorizedKeysCommand &#x2F;usr&#x2F;bin&#x2F;sss_ssh_authorizedkeys
&lt;&#x2F;span&gt;&lt;span&gt;AuthorizedKeysCommandUser root
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now you should be able to ssh into your systems.&lt;&#x2F;p&gt;
&lt;p&gt;It&#x27;s a really simple setup to achieve this, and can have some really
great outcomes in the business.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>FreeIPA: Giving permissions to service accounts.</title>
          <pubDate>Mon, 06 Jul 2015 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2015-07-06-freeipa-giving-permissions-to-service-accounts/</link>
          <guid>https://fy.blackhats.net.au/blog/2015-07-06-freeipa-giving-permissions-to-service-accounts/</guid>
          <description>&lt;h1 id=&quot;freeipa-giving-permissions-to-service-accounts&quot;&gt;FreeIPA: Giving permissions to service accounts.&lt;&#x2F;h1&gt;
&lt;p&gt;&lt;a href=&quot;&#x2F;blog&#x2F;html&#x2F;2019&#x2F;07&#x2F;10&#x2F;i_no_longer_recommend_freeipa.html&quot;&gt;I no longer recommend using FreeIPA - Read more
here!&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;I was setting up FreeRADIUS to work with MSCHAPv2 with FreeIPA (Oh god
you&#x27;re a horrible human being I hear you say).&lt;&#x2F;p&gt;
&lt;p&gt;To do this, you need to do a few things, the main one being allowing a
service account a read permission to a normally hidden attribute.
However, service accounts don&#x27;t normally have the ability to be added
to permission classes.&lt;&#x2F;p&gt;
&lt;p&gt;First, to enable this setup, you need to install freeipa-adtrust and do
the initial setup.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;yum install freeipa-server-trust-ad freeradius
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;ipa-adtrust-install
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now change an accounts password, then as cn=Directory Manager look at
the account. You should see ipaNTHash on the account now.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ldapsearch -H ldap:&#x2F;&#x2F;ipa.example.com -x -D &amp;#39;cn=Directory Manager&amp;#39; -W -LLL -Z &amp;#39;(uid=username)&amp;#39; ipaNTHash
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now we setup the permission and a role to put the service accounts into.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ipa permission-add &amp;#39;ipaNTHash service read&amp;#39; --attrs=ipaNTHash --type=user  --right=read
&lt;&#x2F;span&gt;&lt;span&gt;ipa privilege-add &amp;#39;Radius services&amp;#39; --desc=&amp;#39;Privileges needed to allow radiusd servers to operate&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;ipa privilege-add-permission &amp;#39;Radius services&amp;#39; --permissions=&amp;#39;ipaNTHash service read&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;ipa role-add &amp;#39;Radius server&amp;#39; --desc=&amp;quot;Radius server role&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;ipa role-add-privilege --privileges=&amp;quot;Radius services&amp;quot; &amp;#39;Radius server&amp;#39;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Next, we add the service account.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ipa service-add &amp;#39;radius&#x2F;host.ipa.example.net.au&amp;#39;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Most services should be able to use the service account with either the
keytab for client authentication, or for at least the service to
authenticate to ldap. This is how you get the keytab.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ipa-getkeytab -p &amp;#39;radius&#x2F;host.ipa.example.net.au&amp;#39; -s host.ipa.example.net.au -k &#x2F;root&#x2F;radiusd.keytab
&lt;&#x2F;span&gt;&lt;span&gt;kinit -t &#x2F;root&#x2F;radiusd.keytab -k radius&#x2F;host.ipa.example.net.au
&lt;&#x2F;span&gt;&lt;span&gt;ldapwhoami -Y GSSAPI
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If you plan to use this account with something like radius that only
accepts a password, here is how you can set one.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;dn: krbprincipalname=radius&#x2F;host.ipa.example.net.au@IPA.EXAMPLE.NET.AU,cn=services,\
&lt;&#x2F;span&gt;&lt;span&gt;cn=accounts,dc=ipa,dc=example,dc=net,dc=au
&lt;&#x2F;span&gt;&lt;span&gt;changetype: modify
&lt;&#x2F;span&gt;&lt;span&gt;add: objectClass
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: simpleSecurityObject
&lt;&#x2F;span&gt;&lt;span&gt;-
&lt;&#x2F;span&gt;&lt;span&gt;add: userPassword
&lt;&#x2F;span&gt;&lt;span&gt;userPassword: &amp;lt;The service account password&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;ldapmodify -f &amp;lt;path&#x2F;to&#x2F;ldif&amp;gt; -D &amp;#39;cn=Directory Manager&amp;#39; -W -H ldap:&#x2F;&#x2F;host.ipa.example.net.au -Z
&lt;&#x2F;span&gt;&lt;span&gt;ldapwhoami -Z -D &amp;#39;krbprincipalname=radius&#x2F;host.ipa.example.net.au@IPA.EXAMPLE.NET.AU,\
&lt;&#x2F;span&gt;&lt;span&gt;cn=services,cn=accounts,dc=ipa,dc=example,dc=net,dc=au&amp;#39; -W 
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;For either whoami test you should see a dn like:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;krbprincipalname=radius&#x2F;host.ipa.example.net.au@IPA.EXAMPLE.NET.AU,cn=services,cn=accounts,dc=ipa,dc=example,dc=net,dc=au
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Finally, we have to edit the cn=Radius server object and add the service
account. This is what the object should look like in the end:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# Radius server, roles, accounts, ipa.example.net.au
&lt;&#x2F;span&gt;&lt;span&gt;dn: cn=Radius server,cn=roles,cn=accounts,dc=ipa,dc=example,dc=net,dc=au
&lt;&#x2F;span&gt;&lt;span&gt;memberOf: cn=Radius services,cn=privileges,cn=pbac,dc=ipa,dc=example,dc=net,
&lt;&#x2F;span&gt;&lt;span&gt; dc=au
&lt;&#x2F;span&gt;&lt;span&gt;memberOf: cn=ipaNTHash service read,cn=permissions,cn=pbac,dc=ipa,dc=example
&lt;&#x2F;span&gt;&lt;span&gt; ,dc=net,dc=au
&lt;&#x2F;span&gt;&lt;span&gt;description: Radius server role
&lt;&#x2F;span&gt;&lt;span&gt;cn: Radius server
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: groupofnames
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: nestedgroup
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: top
&lt;&#x2F;span&gt;&lt;span&gt;member: krbprincipalname=radius&#x2F;host.ipa.example.net.au@IPA.EXAMPLE.NET.AU
&lt;&#x2F;span&gt;&lt;span&gt; ,cn=services,cn=accounts,dc=ipa,dc=example,dc=net,dc=au
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now you should be able to use the service account to search and show
ipaNTHash on objects.&lt;&#x2F;p&gt;
&lt;p&gt;If you use this as your identify in raddb&#x2F;mods-avaliable&#x2F;ldap, and set
control:NT-Password := &#x27;ipaNTHash&#x27; in the update section, you should
be able to use this as an ldap backend for MSCHAPv2. I will write a more
complete blog on the radius half of this setup later.&lt;&#x2F;p&gt;
&lt;p&gt;NOTES: Thanks to afayzullin for noting the deprecation of --permission
with ipa permission-add. This has been updated to --right as per his
suggestion. Additional thanks for pointing out I should include the
command to do the directory manager ldapsearch for ipanthash.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>OpenBSD relayd</title>
          <pubDate>Sun, 05 Jul 2015 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2015-07-05-openbsd-relayd/</link>
          <guid>https://fy.blackhats.net.au/blog/2015-07-05-openbsd-relayd/</guid>
          <description>&lt;h1 id=&quot;openbsd-relayd&quot;&gt;OpenBSD relayd&lt;&#x2F;h1&gt;
&lt;p&gt;I&#x27;ve been using OpenBSD 5.7 as my network router for a while, and I&#x27;m
always impressed by the tools avaliable.&lt;&#x2F;p&gt;
&lt;p&gt;Instead of using direct ipv6 forwarding, or NAT port forwards for
services, I&#x27;ve found it a lot easier to use the OpenBSD relayd software
to listen on my ingress port, then to relay the traffic in.
Additionally, this allows relayd to listen on ipv4 and ipv6 and to
rewrite connections to the backend to be purely ipv6.&lt;&#x2F;p&gt;
&lt;p&gt;This helps to keep my pf.conf small and clean, and just focussed on
security and inter-vlan &#x2F; vrf traffic.&lt;&#x2F;p&gt;
&lt;p&gt;The only changes to pf.conf needed are:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;anchor &amp;quot;relayd&#x2F;*&amp;quot; rtable 0
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The relayd.conf man page is fantastic and detailed. Read through it for
help, but my basic config is:&lt;&#x2F;p&gt;
&lt;p&gt;:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ext_addr=&amp;quot;ipv4&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;ext_addr6=&amp;quot;ipv6&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;smtp_port=&amp;quot;25&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;smtp_addr=&amp;quot;2001:db8:0::2&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;table &amp;lt;smtp&amp;gt; { $smtp_addr }
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;protocol &amp;quot;tcp_service&amp;quot; {
&lt;&#x2F;span&gt;&lt;span&gt;   tcp { nodelay, socket buffer 65536 }
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;relay &amp;quot;smtp_ext_forwarder&amp;quot; {
&lt;&#x2F;span&gt;&lt;span&gt;   listen on $ext_addr port $smtp_port
&lt;&#x2F;span&gt;&lt;span&gt;   listen on $ext_addr6 port $smtp_port
&lt;&#x2F;span&gt;&lt;span&gt;   protocol &amp;quot;tcp_service&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;   forward to &amp;lt;smtp&amp;gt; port $smtp_port check tcp
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;That&#x27;s it! Additionally, a great benefit is that when the SMTP server
goes away, the check tcp will notice the server is down and drop the
service. This means that you won&#x27;t have external network traffic able
to poke your boxes when services are down or have been re-iped and
someone forgets to disable the load balancer configs.&lt;&#x2F;p&gt;
&lt;p&gt;This also gives me lots of visibility into the service and connected
hosts:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;relayctl show sum
&lt;&#x2F;span&gt;&lt;span&gt;Id      Type            Name                            Avlblty Status
&lt;&#x2F;span&gt;&lt;span&gt;1       relay           smtp_ext_forwarder                      active
&lt;&#x2F;span&gt;&lt;span&gt;1       table           smtp:25                                 active (1 hosts)
&lt;&#x2F;span&gt;&lt;span&gt;1       host            2001:db8:0::2                           99.97%  up
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;relayctl show sessions
&lt;&#x2F;span&gt;&lt;span&gt;session 0:53840 X.X.X.X:3769 -&amp;gt; 2001:db8:0::2:25     RUNNING
&lt;&#x2F;span&gt;&lt;span&gt;        age 00:00:01, idle 00:00:01, relay 1, pid 19574
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;So relayd has simplified my router configuration for external services
and allows me to see and migrate services internally without fuss of my
external configuration.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>OpenBSD BGP and VRFs</title>
          <pubDate>Sat, 04 Jul 2015 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2015-07-04-openbsd-bgp-and-vrfs/</link>
          <guid>https://fy.blackhats.net.au/blog/2015-07-04-openbsd-bgp-and-vrfs/</guid>
          <description>&lt;h1 id=&quot;openbsd-bgp-and-vrfs&quot;&gt;OpenBSD BGP and VRFs&lt;&#x2F;h1&gt;
&lt;p&gt;VRFs, or in OpenBSD rdomains, are a simple, yet powerful (and sometimes
confusing) topic.&lt;&#x2F;p&gt;
&lt;p&gt;Simply, when you have a normal router or operating system, you have a
single router table. You have network devices attached into this routing
table, traffic may be sent between those interfaces, or they may exit
via a default route.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;10.0.1.1&#x2F;24
&lt;&#x2F;span&gt;&lt;span&gt;eth0 --&amp;gt;   |           |
&lt;&#x2F;span&gt;&lt;span&gt;10.0.2.1&#x2F;24| rdomain 0 | --&amp;gt; pppoe0 default route
&lt;&#x2F;span&gt;&lt;span&gt;eth1 --&amp;gt;   |           |
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;So in this example, traffic from 10.0.1.1 can flow to 10.0.2.1 and vice
versa. Traffic that matches neither of these will be sent down the
pppoe0 default route.&lt;&#x2F;p&gt;
&lt;p&gt;Now, lets show what that looks like with two rdomains:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;10.0.1.1&#x2F;24
&lt;&#x2F;span&gt;&lt;span&gt;eth0 --&amp;gt;   |           |
&lt;&#x2F;span&gt;&lt;span&gt;10.0.2.1&#x2F;24| rdomain 0 | --&amp;gt; pppoe0 default route
&lt;&#x2F;span&gt;&lt;span&gt;eth1 --&amp;gt;   |           |
&lt;&#x2F;span&gt;&lt;span&gt;           -------------
&lt;&#x2F;span&gt;&lt;span&gt;10.0.3.1&#x2F;24|           |
&lt;&#x2F;span&gt;&lt;span&gt;eth2 --&amp;gt;   | rdomain 1 |
&lt;&#x2F;span&gt;&lt;span&gt;10.0.4.1&#x2F;24|           |
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now, in our example, traffic for interfaces on rdomain 0 will flow to
each other as normal. At the same time, traffic between devices in
rdomain 1 will flow correctly also. However, no traffic BETWEEN rdomain
0 and rdomain 1 is permitted.&lt;&#x2F;p&gt;
&lt;p&gt;This also means you could do:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;10.0.1.1&#x2F;24
&lt;&#x2F;span&gt;&lt;span&gt;eth0 --&amp;gt;   |           |
&lt;&#x2F;span&gt;&lt;span&gt;10.0.2.1&#x2F;24| rdomain 0 | --&amp;gt; pppoe0 default route
&lt;&#x2F;span&gt;&lt;span&gt;eth1 --&amp;gt;   |           |
&lt;&#x2F;span&gt;&lt;span&gt;           -------------
&lt;&#x2F;span&gt;&lt;span&gt;10.0.3.1&#x2F;24|           |
&lt;&#x2F;span&gt;&lt;span&gt;eth2 --&amp;gt;   | rdomain 1 | --&amp;gt; pppoe1 different default route
&lt;&#x2F;span&gt;&lt;span&gt;10.0.4.1&#x2F;24|           |
&lt;&#x2F;span&gt;&lt;span&gt;eth3 --&amp;gt;   |           |
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;So some networks have one default route, while other networks have a
different default route. Guest networks come to mind ;)&lt;&#x2F;p&gt;
&lt;p&gt;Or you can do:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;10.0.1.1&#x2F;24
&lt;&#x2F;span&gt;&lt;span&gt;eth0 --&amp;gt;   |           |
&lt;&#x2F;span&gt;&lt;span&gt;10.0.2.1&#x2F;24| rdomain 0 | 
&lt;&#x2F;span&gt;&lt;span&gt;eth1 --&amp;gt;   |           |
&lt;&#x2F;span&gt;&lt;span&gt;           -------------
&lt;&#x2F;span&gt;&lt;span&gt;10.0.1.1&#x2F;24|           |
&lt;&#x2F;span&gt;&lt;span&gt;eth2 --&amp;gt;   | rdomain 1 |
&lt;&#x2F;span&gt;&lt;span&gt;10.0.2.1&#x2F;24|           |
&lt;&#x2F;span&gt;&lt;span&gt;eth3 --&amp;gt;   |           |
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Note that now our ipv4 ip ranges over lap: However, because the traffic
entered an interface on a specific rdomain, the traffic will always stay
in that rdomain. Traffic from eth1 to 10.0.1.1&#x2F;24 will always go to
eth0. Never eth2, as that would be crossing rdomains.&lt;&#x2F;p&gt;
&lt;p&gt;So rdomains are really powerful for network isolation, security,
multiple routers or allowing overlapping ip ranges to be reused.&lt;&#x2F;p&gt;
&lt;p&gt;Now, we change to a different tact: BGP. BGP is the border gateway
protocol. It allows two routers to distribute routes between them so
they are aware of and able to route traffic correctly. For example.&lt;&#x2F;p&gt;
&lt;p&gt;:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;10.0.1.0&#x2F;24|          |   IC   |          | 10.0.2.0&#x2F;24
&lt;&#x2F;span&gt;&lt;span&gt;eth0 --&amp;gt;   | router A | &amp;lt;----&amp;gt; | router B | &amp;lt;-- eth1
&lt;&#x2F;span&gt;&lt;span&gt;           |          |        |          |
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Normally with no assistance router A and B could only see each other via
the interconnect IC. 10.0.1.0&#x2F;24 is a mystery to router B, as is
10.0.2.0&#x2F;24 from router A. They just aren&#x27;t connected so they can&#x27;t
route traffic.&lt;&#x2F;p&gt;
&lt;p&gt;By enabling BGP from A to B over the interconnect, router A can discover
the networks attached to router B and vice versa. With this information,
both routers can correctly send traffic destined to the other via the IC
as they now know the correct destinations and connections.&lt;&#x2F;p&gt;
&lt;p&gt;There are plenty of documents on enabling both of these technologies in
isolation: However, I had a hard time finding a document that showed how
we do both at the same time. I wanted to build:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;router A               router B
&lt;&#x2F;span&gt;&lt;span&gt;10.0.1.1&#x2F;24                                      10.0.3.1&#x2F;24
&lt;&#x2F;span&gt;&lt;span&gt;eth0 --&amp;gt;   |           |    IC1   |           |  &amp;lt;-- eth0
&lt;&#x2F;span&gt;&lt;span&gt;10.0.2.1&#x2F;24| rdomain 0 |  &amp;lt;----&amp;gt;  | rdomain 0 |  10.0.4.1&#x2F;24
&lt;&#x2F;span&gt;&lt;span&gt;eth1 --&amp;gt;   |           |          |           |  &amp;lt;-- eth1
&lt;&#x2F;span&gt;&lt;span&gt;-------------          -------------
&lt;&#x2F;span&gt;&lt;span&gt;10.0.1.1&#x2F;24|           |    IC2   |           |  10.0.3.1&#x2F;24
&lt;&#x2F;span&gt;&lt;span&gt;eth2 --&amp;gt;   | rdomain 1 |  &amp;lt;----&amp;gt;  | rdomain 1 |  &amp;lt;-- eth2
&lt;&#x2F;span&gt;&lt;span&gt;10.0.2.1&#x2F;24|           |          |           |  10.0.4.1&#x2F;24
&lt;&#x2F;span&gt;&lt;span&gt;eth3 --&amp;gt;   |           |          |           |  &amp;lt;-- eth3
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;So I wanted the networks of rdomain 0 from router A to be exported to
rdomain 0 of router B, and the networks of router A rdomain 1 to be
exported into router B rdomain 1.&lt;&#x2F;p&gt;
&lt;p&gt;The way this is achieved is with BGP communities. The BGP router makes a
single connection from router A to router B. The BGPd process on A, is
aware of rdomains and is able to read the complete system rdomain state.
Each rdomains route table is exported into a community. For example, you
would have AS:0 and AS:1 in my example. On the recieving router, the
contents of the community are imported to the assocated rdomain. For
example, community AS:0 would be imported to rdomain 0.&lt;&#x2F;p&gt;
&lt;p&gt;Now, ignoring all the other configuration of interfaces with rdomains
and pf, here is what a basic BGP configuration would look like for
router A:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;AS 64524
&lt;&#x2F;span&gt;&lt;span&gt;router-id 172.24.17.1
&lt;&#x2F;span&gt;&lt;span&gt;fib-update yes
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;rdomain 0 {
&lt;&#x2F;span&gt;&lt;span&gt;        rd 64523:0
&lt;&#x2F;span&gt;&lt;span&gt;        import-target rt 64524:0
&lt;&#x2F;span&gt;&lt;span&gt;        export-target rt 64524:0
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;        network inet connected
&lt;&#x2F;span&gt;&lt;span&gt;        network 0.0.0.0&#x2F;0
&lt;&#x2F;span&gt;&lt;span&gt;        network inet6 connected
&lt;&#x2F;span&gt;&lt;span&gt;        network ::&#x2F;0
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;rdomain 1 {
&lt;&#x2F;span&gt;&lt;span&gt;        rd 64523:1
&lt;&#x2F;span&gt;&lt;span&gt;        import-target rt 64524:1
&lt;&#x2F;span&gt;&lt;span&gt;        export-target rt 64524:1
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;        network inet connected
&lt;&#x2F;span&gt;&lt;span&gt;        #network 0.0.0.0&#x2F;0
&lt;&#x2F;span&gt;&lt;span&gt;        network inet6 connected
&lt;&#x2F;span&gt;&lt;span&gt;        #network ::&#x2F;0
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;group ibgp {
&lt;&#x2F;span&gt;&lt;span&gt;        announce IPv4 unicast
&lt;&#x2F;span&gt;&lt;span&gt;        announce IPv6 unicast
&lt;&#x2F;span&gt;&lt;span&gt;        remote-as 64524
&lt;&#x2F;span&gt;&lt;span&gt;        neighbor 2001:db8:0:17::2 {
&lt;&#x2F;span&gt;&lt;span&gt;            descr &amp;quot;selena&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;        }
&lt;&#x2F;span&gt;&lt;span&gt;        neighbor 172.24.17.2 {
&lt;&#x2F;span&gt;&lt;span&gt;            descr &amp;quot;selena&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;        }
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;deny from any
&lt;&#x2F;span&gt;&lt;span&gt;allow from any inet prefixlen 8 - 24
&lt;&#x2F;span&gt;&lt;span&gt;allow from any inet6 prefixlen 16 - 48
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# accept a default route (since the previous rule blocks this)
&lt;&#x2F;span&gt;&lt;span&gt;#allow from any prefix 0.0.0.0&#x2F;0
&lt;&#x2F;span&gt;&lt;span&gt;#allow from any prefix ::&#x2F;0
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# filter bogus networks according to RFC5735
&lt;&#x2F;span&gt;&lt;span&gt;#deny from any prefix 0.0.0.0&#x2F;8 prefixlen &amp;gt;= 8           # &amp;#39;this&amp;#39; network [RFC1122]
&lt;&#x2F;span&gt;&lt;span&gt;deny from any prefix 10.0.0.0&#x2F;8 prefixlen &amp;gt;= 8          # private space [RFC1918]
&lt;&#x2F;span&gt;&lt;span&gt;deny from any prefix 100.64.0.0&#x2F;10 prefixlen &amp;gt;= 10      # CGN Shared [RFC6598]
&lt;&#x2F;span&gt;&lt;span&gt;deny from any prefix 127.0.0.0&#x2F;8 prefixlen &amp;gt;= 8         # localhost [RFC1122]
&lt;&#x2F;span&gt;&lt;span&gt;deny from any prefix 169.254.0.0&#x2F;16 prefixlen &amp;gt;= 16     # link local [RFC3927]
&lt;&#x2F;span&gt;&lt;span&gt;deny from any prefix 172.16.0.0&#x2F;12 prefixlen &amp;gt;= 12      # private space [RFC1918]
&lt;&#x2F;span&gt;&lt;span&gt;deny from any prefix 192.0.2.0&#x2F;24 prefixlen &amp;gt;= 24       # TEST-NET-1 [RFC5737]
&lt;&#x2F;span&gt;&lt;span&gt;deny from any prefix 192.168.0.0&#x2F;16 prefixlen &amp;gt;= 16     # private space [RFC1918]
&lt;&#x2F;span&gt;&lt;span&gt;deny from any prefix 198.18.0.0&#x2F;15 prefixlen &amp;gt;= 15      # benchmarking [RFC2544]
&lt;&#x2F;span&gt;&lt;span&gt;deny from any prefix 198.51.100.0&#x2F;24 prefixlen &amp;gt;= 24    # TEST-NET-2 [RFC5737]
&lt;&#x2F;span&gt;&lt;span&gt;deny from any prefix 203.0.113.0&#x2F;24 prefixlen &amp;gt;= 24     # TEST-NET-3 [RFC5737]
&lt;&#x2F;span&gt;&lt;span&gt;deny from any prefix 224.0.0.0&#x2F;4 prefixlen &amp;gt;= 4         # multicast
&lt;&#x2F;span&gt;&lt;span&gt;deny from any prefix 240.0.0.0&#x2F;4 prefixlen &amp;gt;= 4         # reserved
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# filter bogus IPv6 networks according to IANA
&lt;&#x2F;span&gt;&lt;span&gt;#deny from any prefix ::&#x2F;8 prefixlen &amp;gt;= 8
&lt;&#x2F;span&gt;&lt;span&gt;deny from any prefix 0100::&#x2F;64 prefixlen &amp;gt;= 64          # Discard-Only [RFC6666]
&lt;&#x2F;span&gt;&lt;span&gt;deny from any prefix 2001:2::&#x2F;48 prefixlen &amp;gt;= 48        # BMWG [RFC5180]
&lt;&#x2F;span&gt;&lt;span&gt;deny from any prefix 2001:10::&#x2F;28 prefixlen &amp;gt;= 28       # ORCHID [RFC4843]
&lt;&#x2F;span&gt;&lt;span&gt;deny from any prefix 2001:db8::&#x2F;32 prefixlen &amp;gt;= 32      # docu range [RFC3849]
&lt;&#x2F;span&gt;&lt;span&gt;deny from any prefix 3ffe::&#x2F;16 prefixlen &amp;gt;= 16          # old 6bone
&lt;&#x2F;span&gt;&lt;span&gt;deny from any prefix fc00::&#x2F;7 prefixlen &amp;gt;= 7            # unique local unicast
&lt;&#x2F;span&gt;&lt;span&gt;deny from any prefix fe80::&#x2F;10 prefixlen &amp;gt;= 10          # link local unicast
&lt;&#x2F;span&gt;&lt;span&gt;deny from any prefix fec0::&#x2F;10 prefixlen &amp;gt;= 10          # old site local unicast
&lt;&#x2F;span&gt;&lt;span&gt;deny from any prefix ff00::&#x2F;8 prefixlen &amp;gt;= 8            # multicast
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;allow from any prefix 2001:db8:0::&#x2F;56 prefixlen &amp;gt;= 64
&lt;&#x2F;span&gt;&lt;span&gt;# This allow should override the deny 172.16.0.0&#x2F;12 above.
&lt;&#x2F;span&gt;&lt;span&gt;allow from any prefix 172.24.0.0&#x2F;16 prefixlen &amp;gt;= 24      # private space [RFC1918]
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;So lets break this down.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;AS 64524
&lt;&#x2F;span&gt;&lt;span&gt;router-id 172.24.17.1
&lt;&#x2F;span&gt;&lt;span&gt;fib-update yes
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This configuration snippet defines our AS, our router ID and that we
want to update the routing tables (forwarding information base)&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;rdomain 0 {
&lt;&#x2F;span&gt;&lt;span&gt;        rd 64523:0
&lt;&#x2F;span&gt;&lt;span&gt;        import-target rt 64524:0
&lt;&#x2F;span&gt;&lt;span&gt;        export-target rt 64524:0
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;        network inet connected
&lt;&#x2F;span&gt;&lt;span&gt;        network 0.0.0.0&#x2F;0
&lt;&#x2F;span&gt;&lt;span&gt;        network inet6 connected
&lt;&#x2F;span&gt;&lt;span&gt;        network ::&#x2F;0
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This looks similar to the configuration of rdomain 1. We define the
community with the rd statement, route distinguisher. We define that we
will only be importing routes from the AS:community identifier provided
by the other BGP instance. We also define that we are exporting our
routes from this rdomain to the specified AS:community.&lt;&#x2F;p&gt;
&lt;p&gt;Finally, we define the networks that we will advertise in BGP. We could
define these manually, or by stating network inet[6] connected, we
automatically will export any interface that exists within this rdomain.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;group ibgp {
&lt;&#x2F;span&gt;&lt;span&gt;        announce IPv4 unicast
&lt;&#x2F;span&gt;&lt;span&gt;        announce IPv6 unicast
&lt;&#x2F;span&gt;&lt;span&gt;        remote-as 64524
&lt;&#x2F;span&gt;&lt;span&gt;        neighbor 2001:db8:0:17::2 {
&lt;&#x2F;span&gt;&lt;span&gt;            descr &amp;quot;selena&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;        }
&lt;&#x2F;span&gt;&lt;span&gt;        neighbor 172.24.17.2 {
&lt;&#x2F;span&gt;&lt;span&gt;            descr &amp;quot;selena&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;        }
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This defines our connection to the other bgp neighbour. A big gotcha
here is that BGP4 only exports ipv4 routes over an ipv4 connection, and
ipv6 over an ipv6 connection. You must therefore define both ipv4 and
ipv6 to export both types of routers to the other router.&lt;&#x2F;p&gt;
&lt;p&gt;Finally, the allow &#x2F; deny statements filter the valid networks that we
accept for fib updates. This should always be defined to guarantee that
your don&#x27;t accidentally accept routes that should not be present.&lt;&#x2F;p&gt;
&lt;p&gt;Router B has a nearly identical configuration, just change the neighbour
definitions over.&lt;&#x2F;p&gt;
&lt;p&gt;Happy routing!&lt;&#x2F;p&gt;
&lt;p&gt;UPDATE: Thanks to P. Caetano for advice on improving the filter
allow&#x2F;deny section.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>OpenBSD nat64</title>
          <pubDate>Sat, 04 Jul 2015 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2015-07-04-openbsd-nat64/</link>
          <guid>https://fy.blackhats.net.au/blog/2015-07-04-openbsd-nat64/</guid>
          <description>&lt;h1 id=&quot;openbsd-nat64&quot;&gt;OpenBSD nat64&lt;&#x2F;h1&gt;
&lt;p&gt;I&#x27;m a bit of a fan of ipv6. I would like to move as many of my systems
to be ipv6-only but in the current world of dual stack that&#x27;s just not
completely possible. Nat64 helps allow ipv6 hosts connect to the ipv4
internet.&lt;&#x2F;p&gt;
&lt;p&gt;Normally you have:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ipv4 &amp;lt;-- | ------- |--&amp;gt; ipv4 internet
&lt;&#x2F;span&gt;&lt;span&gt;         |         |
&lt;&#x2F;span&gt;&lt;span&gt;host     | gateway |
&lt;&#x2F;span&gt;&lt;span&gt;         |         |
&lt;&#x2F;span&gt;&lt;span&gt;ipv6 &amp;lt;-- | ------- |--&amp;gt; ipv6 internet
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The two protocols are kept seperate, and you need both to connect to the
network.&lt;&#x2F;p&gt;
&lt;p&gt;In a Nat64 setup, your gate way defines a magic prefix that is routed to
it, that is at least a &#x2F;96 - in other words, it contains a &#x2F;32 that you
can populate with ipv4 addresses. So at home I have a &#x2F;56:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;2001:db8::&#x2F;56
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Inside of this I have reserved a network:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;2001:db8:0:64::&#x2F;64
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now, if you change the last 32 bits to an ipv4 address such as:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;2001:db8:0:64::8.8.8.8
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Or in &amp;quot;pure&amp;quot; ipv6&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;2001:db8:0:64::808:808
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This traffic is sent via the default route, and the gateway picks it up.
It sees the prefix of 2001:db8:0:64::&#x2F;96 on the packet, it then removes
the last 32 bits and forms an ipv4 address. The data of the packet is
encapsulated to ipv4, a session table built and the data sent out. When
a response comes back, the session table is consulted, the data is
mapped back to the origin ipv6 address and re-encapsulated back to the
client.&lt;&#x2F;p&gt;
&lt;p&gt;Thus you see:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ping6 2001:db8:0:64::8.8.8.8  
&lt;&#x2F;span&gt;&lt;span&gt;PING 2001:db8:0:64::8.8.8.8(2001:db8:0:64::808:808) 56 data bytes
&lt;&#x2F;span&gt;&lt;span&gt;64 bytes from 2001:db8:0:64::808:808: icmp_seq=1 ttl=57 time=123 ms
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Or from our previous diagram, you can now construct:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ipv4  X  |     ---- | --&amp;gt; ipv4 internet
&lt;&#x2F;span&gt;&lt;span&gt;         |    &#x2F;     |
&lt;&#x2F;span&gt;&lt;span&gt;host     |   &#x2F;      |
&lt;&#x2F;span&gt;&lt;span&gt;         |  &#x2F;       |
&lt;&#x2F;span&gt;&lt;span&gt;ipv6 &amp;lt;-- | -------- | --&amp;gt; ipv6 internet
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;However, you need a supporting technology. If you were to use this
normally, applications don&#x27;t know how to attach the ipv4 data into the
ipv6 prefix. So you need to support this application with DNS64. This
allows hostnames that have no AAAA record, to automatically have the A
data appended to the Nat64 prefix. For example with out DNS64:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;dig www.adelaide.edu.au  +short A
&lt;&#x2F;span&gt;&lt;span&gt;129.127.144.141
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;dig www.adelaide.edu.au  +short AAAA
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now, if we add DNS64&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;dig www.adelaide.edu.au  +short AAAA
&lt;&#x2F;span&gt;&lt;span&gt;2001:db8:0:64::817f:908d
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now we can contact this:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ping6 www.adelaide.edu.au
&lt;&#x2F;span&gt;&lt;span&gt;PING 2001:db8:0:64::129.127.144.141(2001:db8:0:64::817f:908d) 56 data bytes
&lt;&#x2F;span&gt;&lt;span&gt;64 bytes from 2001:db8:0:64::817f:908d: icmp_seq=1 ttl=64 time=130 ms
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;So, lets get into the meat of the configuration.&lt;&#x2F;p&gt;
&lt;p&gt;First, you need a working Nat64. I&#x27;m using openBSD 5.7 on my router, so
this is configured purely in pf.conf&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;pass in quick on $interface_int_r0 inet6 from any to 2001:db8:0:64::&#x2F;96 af-to inet from (egress:0) keep state rtable 0
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;That&#x27;s all it is! Provided you have working ipv6 already, the addition
of this will enable a &#x2F;96 to now function as your nat64 prefix.
Remember, you DO NOT need this &#x2F;96 on an interface or routed. It exists
&amp;quot;in the ether&amp;quot; and pf recognises traffic to the prefix and will
automatically convert it to ipv4 traffic exiting on your egress device.&lt;&#x2F;p&gt;
&lt;p&gt;Next you need to configure dns64. I like bind9 so here is the config you
need:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;options {
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;&#x2F;.... snip .....
&lt;&#x2F;span&gt;&lt;span&gt;            dns64 2001:db8:0:64::&#x2F;96 {
&lt;&#x2F;span&gt;&lt;span&gt;                clients { any; };
&lt;&#x2F;span&gt;&lt;span&gt;                &#x2F;&#x2F;Exclude prviate networks we connect to.
&lt;&#x2F;span&gt;&lt;span&gt;                mapped { !172.24.0.0&#x2F;16; !10.0.0.0&#x2F;8; any; };
&lt;&#x2F;span&gt;&lt;span&gt;                suffix ::;
&lt;&#x2F;span&gt;&lt;span&gt;                recursive-only yes;
&lt;&#x2F;span&gt;&lt;span&gt;        };
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Once you restart named, you will have working DNS64, and able to contact
the ipv4 internet from ipv4 hosts.&lt;&#x2F;p&gt;
&lt;p&gt;The only gotcha I have found is with VPNs. When you VPN from the site or
into the site with DNS64&#x2F;Nat64, often you will find that your DNS will
resolve hosts to ipv6 addresses, for example, 2001:db8:0:64::10.0.0.1
and then will be put onto your network egress port, rather than down the
VPN: Not ideal at all! So I exclude the ipv4 ranges from my local
networks and my work place to avoid these issues.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Unit testing LDAP acis for fun and profit</title>
          <pubDate>Sat, 04 Jul 2015 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2015-07-04-unit-testing-ldap-acis-for-fun-and-profit/</link>
          <guid>https://fy.blackhats.net.au/blog/2015-07-04-unit-testing-ldap-acis-for-fun-and-profit/</guid>
          <description>&lt;h1 id=&quot;unit-testing-ldap-acis-for-fun-and-profit&quot;&gt;Unit testing LDAP acis for fun and profit&lt;&#x2F;h1&gt;
&lt;p&gt;My workplace is a reasonably sized consumer of 389ds. We use it for
storing pretty much all our most important identity data from allowing
people to authenticate, to group and course membership, to email routing
and even internet access.&lt;&#x2F;p&gt;
&lt;p&gt;As a result, it&#x27;s a really important service to maintain. We need to
treat it as one of the most security sensitive services we run. The
definition of security I always come back to is &amp;quot;availability,
integrity and confidentiality&amp;quot;. Now, we have a highly available
environment, and we use TLS with our data to ensure confidentiality of
results and queries. Integrity however, is the main target of this post.&lt;&#x2F;p&gt;
&lt;p&gt;LDAP allows objects that exist with in the directory to &amp;quot;bind&amp;quot;
(authenticate) and then to manipulate other objects in the directories.
A set of ACIs (Access Control Instructions) define what objects can
modify other objects and their attributes.&lt;&#x2F;p&gt;
&lt;p&gt;ACIs are probably one of the most complex parts in a directory server
environment to &amp;quot;get right&amp;quot; (With the exception maybe of VLV).&lt;&#x2F;p&gt;
&lt;p&gt;I noticed during a security review of our directories ACIs that took the
following pattern.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;aci: (targetattr !=&amp;quot;cn&amp;quot;)(version 3.0;acl &amp;quot;Self write all but cn&amp;quot;;allow (write)(userdn = &amp;quot;ldap:&#x2F;&#x2F;&#x2F;self&amp;quot;);)
&lt;&#x2F;span&gt;&lt;span&gt;aci: (targetattr !=&amp;quot;sn&amp;quot;)(version 3.0;acl &amp;quot;Self write all but sn&amp;quot;;allow (write)(userdn = &amp;quot;ldap:&#x2F;&#x2F;&#x2F;self&amp;quot;);)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now, the rules in question we had were more complex and had more rules,
but at their essence looked like this. Seems like an innocuous set of
rules. &amp;quot;Allow self write to everything but sn&amp;quot; and &amp;quot;Allow self write
to everything but cn&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;So at the end we expect to see we can write everything but sn and cn.&lt;&#x2F;p&gt;
&lt;p&gt;Lets use the ldap effective permissions capability to check this:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;usr&#x2F;lib64&#x2F;mozldap&#x2F;ldapsearch -D &amp;#39;cn=Directory Manager&amp;#39; -w - -b &amp;#39;cn=test,ou=people,dc=example,dc=net,dc=au&amp;#39; \
&lt;&#x2F;span&gt;&lt;span&gt;-J &amp;quot;1.3.6.1.4.1.42.2.27.9.5.2:false:dn: cn=test,ou=people,dc=example,dc=net,dc=au&amp;quot; &amp;quot;(objectClass=*)&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;version: 1
&lt;&#x2F;span&gt;&lt;span&gt;dn: cn=test,ou=People,dc=example,dc=net,dc=au
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: top
&lt;&#x2F;span&gt;&lt;span&gt;objectClass: person
&lt;&#x2F;span&gt;&lt;span&gt;cn: test
&lt;&#x2F;span&gt;&lt;span&gt;sn: test
&lt;&#x2F;span&gt;&lt;span&gt;userPassword: 
&lt;&#x2F;span&gt;&lt;span&gt;entryLevelRights: v
&lt;&#x2F;span&gt;&lt;span&gt;attributeLevelRights: objectClass:rscwo, cn:rscwo, sn:rscwo, userPassword:wo
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;What! Why does cn have r[ead] s[search] c[ompare] w[rite]
o[bliterate]? That was denied? Same for SN.&lt;&#x2F;p&gt;
&lt;p&gt;Well, LDAP treats ACIs as a positive union.&lt;&#x2F;p&gt;
&lt;p&gt;So we have:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;aci 1 = ( objectclass, sn, userpassword)
&lt;&#x2F;span&gt;&lt;span&gt;aci 2 = ( objectclass, cn, userpassword)
&lt;&#x2F;span&gt;&lt;span&gt;aci 1 U aci 2 = ( objectclass, sn, cn, userpassword )
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;As a result, our seemingly secure rules, actually were conflicting and
causing our directory to be highly insecure!&lt;&#x2F;p&gt;
&lt;p&gt;So, easy to change this: First we invert the rules (be explicit in all
things) to say targetattr = &amp;quot;userpassword&amp;quot; for example. We shouldn&#x27;t
use != rules because they can even conflict between groups and self.&lt;&#x2F;p&gt;
&lt;p&gt;How do we detect these issues though?&lt;&#x2F;p&gt;
&lt;p&gt;I wrote a python library called usl (university simple ldap). In this I
have a toolset for unit testing our ldap acis.&lt;&#x2F;p&gt;
&lt;p&gt;We create a py.test testcase, that states for some set of objects, they
should have access to some set of attributes on a second set of objects.
IE group admins should have rscwo on all other objects.&lt;&#x2F;p&gt;
&lt;p&gt;We can then run these tests and determine if this is or isn&#x27;t the case.
For example, if we wrote two test cases for the above to test that
&amp;quot;self has rscwo to all attributes or self except sn which should be
rsc&amp;quot; and a second test &amp;quot;self has rscwo to all attributes or self
except cn which should be rsc&amp;quot;. Our test cases would have failed, and
we would be alerted to these issues.&lt;&#x2F;p&gt;
&lt;p&gt;As a result of these tests for our acis I was able to find many more
security issues: Such as users who could self modify groups, self modify
acis, account lockouts of other users, or even turn themselves into a
container object and create children. At the worst one aci actually
allowed objects to edit their own aci&#x27;s which would have allowed them
to give themself more access potentially. The largest offender were
rules that defined targetattr != rules: Often these were actually
allowing access to write attributes that administrators would over look.&lt;&#x2F;p&gt;
&lt;p&gt;For example, the rule above allowing all write except cn, would actually
allow access to nsAccountLock, nsSizeLimit and other object attributes
that don&#x27;t show up on first inspection. The complete list is below.
(Note the addition of the &#x27;+&#x27; )&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;usr&#x2F;lib64&#x2F;mozldap&#x2F;ldapsearch -D &amp;#39;cn=Directory Manager&amp;#39; -w - -b &amp;#39;cn=test,ou=people,dc=example,dc=net,dc=au&amp;#39; \
&lt;&#x2F;span&gt;&lt;span&gt;-J &amp;quot;1.3.6.1.4.1.42.2.27.9.5.2:false:dn: cn=test,ou=people,dc=example,dc=net,dc=au&amp;quot; &amp;quot;(objectClass=*)&amp;quot; &amp;#39;+&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;version: 1
&lt;&#x2F;span&gt;&lt;span&gt;dn: cn=test,ou=People,dc=example,dc=net,dc=au
&lt;&#x2F;span&gt;&lt;span&gt;entryLevelRights: v
&lt;&#x2F;span&gt;&lt;span&gt;attributeLevelRights: nsPagedLookThroughLimit:rscwo, passwordGraceUserTime:rsc
&lt;&#x2F;span&gt;&lt;span&gt; wo, pwdGraceUserTime:rscwo, modifyTimestamp:rscwo, passwordExpWarned:rscwo, 
&lt;&#x2F;span&gt;&lt;span&gt; pwdExpirationWarned:rscwo, internalModifiersName:rscwo, entrydn:rscwo, dITCo
&lt;&#x2F;span&gt;&lt;span&gt; ntentRules:rscwo, supportedLDAPVersion:rscwo, altServer:rscwo, vendorName:rs
&lt;&#x2F;span&gt;&lt;span&gt; cwo, aci:rscwo, nsSizeLimit:rscwo, attributeTypes:rscwo, acctPolicySubentry:
&lt;&#x2F;span&gt;&lt;span&gt; rscwo, nsAccountLock:rscwo, passwordExpirationTime:rscwo, entryid:rscwo, mat
&lt;&#x2F;span&gt;&lt;span&gt; chingRuleUse:rscwo, nsIDListScanLimit:rscwo, nsSchemaCSN:rscwo, nsRole:rscwo
&lt;&#x2F;span&gt;&lt;span&gt; , retryCountResetTime:rscwo, tombstoneNumSubordinates:rscwo, supportedFeatur
&lt;&#x2F;span&gt;&lt;span&gt; es:rscwo, ldapSchemas:rscwo, copiedFrom:rscwo, nsPagedIDListScanLimit:rscwo,
&lt;&#x2F;span&gt;&lt;span&gt;  internalCreatorsName:rscwo, nsUniqueId:rscwo, lastLoginTime:rscwo, creators
&lt;&#x2F;span&gt;&lt;span&gt; Name:rscwo, passwordRetryCount:rscwo, dncomp:rscwo, vendorVersion:rscwo, nsT
&lt;&#x2F;span&gt;&lt;span&gt; imeLimit:rscwo, passwordHistory:rscwo, pwdHistory:rscwo, objectClasses:rscwo
&lt;&#x2F;span&gt;&lt;span&gt; , nscpEntryDN:rscwo, subschemaSubentry:rscwo, hasSubordinates:rscwo, pwdpoli
&lt;&#x2F;span&gt;&lt;span&gt; cysubentry:rscwo, structuralObjectClass:rscwo, nsPagedSizeLimit:rscwo, nsRol
&lt;&#x2F;span&gt;&lt;span&gt; eDN:rscwo, createTimestamp:rscwo, accountUnlockTime:rscwo, dITStructureRules
&lt;&#x2F;span&gt;&lt;span&gt; :rscwo, supportedSASLMechanisms:rscwo, supportedExtension:rscwo, copyingFrom
&lt;&#x2F;span&gt;&lt;span&gt; :rscwo, nsLookThroughLimit:rscwo, nsds5ReplConflict:rscwo, modifiersName:rsc
&lt;&#x2F;span&gt;&lt;span&gt; wo, matchingRules:rscwo, governingStructureRule:rscwo, entryusn:rscwo, nssla
&lt;&#x2F;span&gt;&lt;span&gt; pd-return-default-opattr:rscwo, parentid:rscwo, pwdUpdateTime:rscwo, support
&lt;&#x2F;span&gt;&lt;span&gt; edControl:rscwo, passwordAllowChangeTime:rscwo, nsBackendSuffix:rscwo, nsIdl
&lt;&#x2F;span&gt;&lt;span&gt; eTimeout:rscwo, nameForms:rscwo, ldapSyntaxes:rscwo, numSubordinates:rscwo, 
&lt;&#x2F;span&gt;&lt;span&gt; namingContexts:rscwo
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;As a result of unit testing our ldap aci&#x27;s we were able to find many
many loop holes in our security, and then we were able to
programatically close them all down. Reading the ACI&#x27;s by hand revealed
some issues, but by testing the &amp;quot;expected&amp;quot; aci versus actual behaviour
highlighted our edge cases and the complex interactions of LDAP systems.&lt;&#x2F;p&gt;
&lt;p&gt;I will clean up and publish the usl tool set in the future to help other
people test their own LDAP secuity controls.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>PPP on OpenBSD with Internode</title>
          <pubDate>Sat, 30 May 2015 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2015-05-30-ppp-on-openbsd-with-internode/</link>
          <guid>https://fy.blackhats.net.au/blog/2015-05-30-ppp-on-openbsd-with-internode/</guid>
          <description>&lt;h1 id=&quot;ppp-on-openbsd-with-internode&quot;&gt;PPP on OpenBSD with Internode&lt;&#x2F;h1&gt;
&lt;p&gt;It&#x27;s taken me some time to get this to work nicely.&lt;&#x2F;p&gt;
&lt;p&gt;First, you&#x27;ll need to install OpenBSD 56 or 57.&lt;&#x2F;p&gt;
&lt;p&gt;Once done, you need to configure your ethernet interface facing your
router that you would have setup in pppoe bridge mode.&lt;&#x2F;p&gt;
&lt;p&gt;&#x2F;etc&#x2F;hostname.vio0 :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;rdomain 0
&lt;&#x2F;span&gt;&lt;span&gt;inet 172.24.17.1 255.255.255.0 NONE
&lt;&#x2F;span&gt;&lt;span&gt;inet6 2001:db8:17::1 64
&lt;&#x2F;span&gt;&lt;span&gt;up
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;NOTE: You can ignore the rdomain statement, but I&#x27;ll cover these is a
later blog post.&lt;&#x2F;p&gt;
&lt;p&gt;Now you need to configure the pppoe interface.&lt;&#x2F;p&gt;
&lt;p&gt;&#x2F;etc&#x2F;hostname.pppoe0 :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;!&#x2F;bin&#x2F;sleep 10
&lt;&#x2F;span&gt;&lt;span&gt;rdomain 0
&lt;&#x2F;span&gt;&lt;span&gt;inet 0.0.0.0 255.255.255.255 NONE pppoedev vio0 authproto chap authname &amp;#39;USERNAME@internode.on.net&amp;#39; authkey &amp;#39;PASSWORD&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;dest 0.0.0.1
&lt;&#x2F;span&gt;&lt;span&gt;inet6 eui64
&lt;&#x2F;span&gt;&lt;span&gt;up
&lt;&#x2F;span&gt;&lt;span&gt;!&#x2F;sbin&#x2F;route -T 0 add default -ifp pppoe0 0.0.0.1
&lt;&#x2F;span&gt;&lt;span&gt;!if [ -f &#x2F;tmp&#x2F;dhcp6c ] ; then kill -9 `cat &#x2F;tmp&#x2F;dhcp6c`; fi
&lt;&#x2F;span&gt;&lt;span&gt;!&#x2F;bin&#x2F;sleep 5
&lt;&#x2F;span&gt;&lt;span&gt;!&#x2F;usr&#x2F;local&#x2F;sbin&#x2F;dhcp6c -c &#x2F;etc&#x2F;dhcp6c.conf -p &#x2F;tmp&#x2F;dhcp6c pppoe0
&lt;&#x2F;span&gt;&lt;span&gt;!&#x2F;sbin&#x2F;route -T 0 add -inet6 default -ifp pppoe0 fe80::
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;That&#x27;s quite the interface config!&lt;&#x2F;p&gt;
&lt;p&gt;You need the first sleep to make sure that vio0 is up before this
interface starts. Horrible, but it works.&lt;&#x2F;p&gt;
&lt;p&gt;Then you define the interface in the same rdomain, and inet6 eui64 is
needed so that you can actually get a dhcp6 lease. Then you bring up the
interface. Dest is needed to say that the remote router is the device
connected at the other end of the tunnel. We manually add the default
route for ipv4, and we start the dhcp6c client (After killing any
existing ones). Finally, we add the ipv6 default route down the
interface&lt;&#x2F;p&gt;
&lt;p&gt;Now, the contents of dhcp6c.conf are below:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# tun0&#x2F;pppoe0 is the PPPoE interface
&lt;&#x2F;span&gt;&lt;span&gt;interface pppoe0 {
&lt;&#x2F;span&gt;&lt;span&gt;  send ia-pd 0;
&lt;&#x2F;span&gt;&lt;span&gt;};
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# em1 is the modem interface
&lt;&#x2F;span&gt;&lt;span&gt;interface vio0 {
&lt;&#x2F;span&gt;&lt;span&gt;  information-only;
&lt;&#x2F;span&gt;&lt;span&gt;};
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;id-assoc pd {
&lt;&#x2F;span&gt;&lt;span&gt;# em0 is the interface to the internal network
&lt;&#x2F;span&gt;&lt;span&gt;  prefix-interface vio0 {
&lt;&#x2F;span&gt;&lt;span&gt;    sla-id 23;
&lt;&#x2F;span&gt;&lt;span&gt;    sla-len 8;
&lt;&#x2F;span&gt;&lt;span&gt;  };
&lt;&#x2F;span&gt;&lt;span&gt;};
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;These are already configured to make the correct request to internode
for a &#x2F;56. If you only get a &#x2F;64 you need to tweak sla-len.&lt;&#x2F;p&gt;
&lt;p&gt;Most of this is well documented, but the real gotchas are in the
hostname.pppoe0 script, especially around the addition of the default
route and the addition of dhcp6c.&lt;&#x2F;p&gt;
&lt;p&gt;If you are running PF, besides normal NAT setup etc, you&#x27;ll need this
for IPv6 to work:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;interface_ext_r0=&amp;quot;{pppoe0}&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;pass in quick on $interface_ext_r0 inet6 proto udp from fe80::&#x2F;64 port 547 to fe80::&#x2F;64 port 546 keep state rtable 0
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
</description>
      </item>
      <item>
          <title>Fabric starting guide</title>
          <pubDate>Mon, 29 Sep 2014 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2014-09-29-fabric-starting-guide/</link>
          <guid>https://fy.blackhats.net.au/blog/2014-09-29-fabric-starting-guide/</guid>
          <description>&lt;h1 id=&quot;fabric-starting-guide&quot;&gt;Fabric starting guide&lt;&#x2F;h1&gt;
&lt;p&gt;After the BB14 conf, I am posting some snippets of fabric tasks. Good
luck! Feel free to email me if you have questions.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# Fabric snippets post BB14 conf
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# It should be obvious, but no warranty, expressed or otherwise is provided
&lt;&#x2F;span&gt;&lt;span&gt;# with this code. Use at your own risk. Always read and understand code before
&lt;&#x2F;span&gt;&lt;span&gt;# running it in your environment. Test test test.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# William Brown, Geraint Draheim and others: University of Adelaide
&lt;&#x2F;span&gt;&lt;span&gt;# william at adelaide.edu.au
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;####################################################################
&lt;&#x2F;span&gt;&lt;span&gt;#### WARNING: THIS CODE MAY NOT RUN DUE TO LACK OF IMPORT, DEPENDENCIES.
&lt;&#x2F;span&gt;&lt;span&gt;#### OR OTHER ENVIRONMENTAL CHANGES. THIS IS INTENTIONAL. YOU SHOULD
&lt;&#x2F;span&gt;&lt;span&gt;#### ADAPT SOME OF THESE TO YOUR OWN ENVIRONMENT AND UNDERSTAND THE CODE
&lt;&#x2F;span&gt;&lt;span&gt;####################################################################
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;## Decorators. These provide wrappers to functions to allow you to enforce state
&lt;&#x2F;span&gt;&lt;span&gt;# checks and warnings to users before they run. Here are some of the most useful
&lt;&#x2F;span&gt;&lt;span&gt;# we have developed.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;def rnt_verbose(func):
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    When added to a function, this will add implementation of a global VERBOSE
&lt;&#x2F;span&gt;&lt;span&gt;    flag. The reason it&amp;#39;s not a default, is because not every function is
&lt;&#x2F;span&gt;&lt;span&gt;    converted to use it yet. Just run command:verbose=1
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    @wraps(func)
&lt;&#x2F;span&gt;&lt;span&gt;    def inner(*args, **kwargs):
&lt;&#x2F;span&gt;&lt;span&gt;        if kwargs.pop(&amp;quot;verbose&amp;quot;, None) is not None:
&lt;&#x2F;span&gt;&lt;span&gt;            global VERBOSE
&lt;&#x2F;span&gt;&lt;span&gt;            VERBOSE = True
&lt;&#x2F;span&gt;&lt;span&gt;        return func(*args, **kwargs)
&lt;&#x2F;span&gt;&lt;span&gt;    return inner
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;## IMPORTANT NOTE: This decorator MUST be before @parallel
&lt;&#x2F;span&gt;&lt;span&gt;def rnt_imsure(warning=None):
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    This is a useful decorator that enforces the user types a message into
&lt;&#x2F;span&gt;&lt;span&gt;    the console before the task will run. This is invaluable for high risk
&lt;&#x2F;span&gt;&lt;span&gt;    tasks, essentially forcing that the user MUST take responsibility for their
&lt;&#x2F;span&gt;&lt;span&gt;    actions.
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    def decorator(func):
&lt;&#x2F;span&gt;&lt;span&gt;        @wraps(func)
&lt;&#x2F;span&gt;&lt;span&gt;        def inner(*args, **kwargs):
&lt;&#x2F;span&gt;&lt;span&gt;            # pylint: disable=global-statement
&lt;&#x2F;span&gt;&lt;span&gt;            global IMSURE_WARNING
&lt;&#x2F;span&gt;&lt;span&gt;            print(&amp;quot;Forcing task to run in serial&amp;quot;)
&lt;&#x2F;span&gt;&lt;span&gt;            if kwargs.pop(&amp;quot;imsure&amp;quot;, None) is None and IMSURE_WARNING is False:
&lt;&#x2F;span&gt;&lt;span&gt;                if warning is not None:
&lt;&#x2F;span&gt;&lt;span&gt;                    print(warning)
&lt;&#x2F;span&gt;&lt;span&gt;                cont = getpass(&amp;#39;If you are sure, type &amp;quot;I know what I am doing.&amp;quot; #&amp;#39;)
&lt;&#x2F;span&gt;&lt;span&gt;                if cont == &amp;#39;I know what I am doing.&amp;#39;:
&lt;&#x2F;span&gt;&lt;span&gt;                    IMSURE_WARNING = True
&lt;&#x2F;span&gt;&lt;span&gt;                    print(&amp;#39;continuing in 5 seconds ...&amp;#39;)
&lt;&#x2F;span&gt;&lt;span&gt;                    time.sleep(5)
&lt;&#x2F;span&gt;&lt;span&gt;                    print(&amp;quot;Starting ...&amp;quot;)
&lt;&#x2F;span&gt;&lt;span&gt;                else:
&lt;&#x2F;span&gt;&lt;span&gt;                    print(&amp;#39;Exiting : No actions were taken&amp;#39;)
&lt;&#x2F;span&gt;&lt;span&gt;                    sys.exit(1)
&lt;&#x2F;span&gt;&lt;span&gt;            return func(*args, **kwargs)
&lt;&#x2F;span&gt;&lt;span&gt;        inner.parallel = False
&lt;&#x2F;span&gt;&lt;span&gt;        inner.serial = True
&lt;&#x2F;span&gt;&lt;span&gt;        return inner
&lt;&#x2F;span&gt;&lt;span&gt;    return decorator
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;def rnt_untested(func):
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    This decorator wraps functions that we consider new and untested. It gives
&lt;&#x2F;span&gt;&lt;span&gt;    a large, visual warning to the user that this is the case, and allows
&lt;&#x2F;span&gt;&lt;span&gt;    5 seconds for them to ctrl+c before continuing.
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    @wraps(func)
&lt;&#x2F;span&gt;&lt;span&gt;    def inner(*args, **kwargs):
&lt;&#x2F;span&gt;&lt;span&gt;        dragon = &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt; ____________________________________
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F; THIS IS AN UNTESTED TASK. THERE    \\
&lt;&#x2F;span&gt;&lt;span&gt;\\ ARE DRAGONS IN THESE PARTS         &#x2F;
&lt;&#x2F;span&gt;&lt;span&gt; ------------------------------------
&lt;&#x2F;span&gt;&lt;span&gt;      \\                   &#x2F; \\  &#x2F;&#x2F;\\
&lt;&#x2F;span&gt;&lt;span&gt;       \\    |\\___&#x2F;|      &#x2F;   \\&#x2F;&#x2F;  \\\\
&lt;&#x2F;span&gt;&lt;span&gt;            &#x2F;0  0  \\__  &#x2F;    &#x2F;&#x2F;  | \\ \\
&lt;&#x2F;span&gt;&lt;span&gt;           &#x2F;     &#x2F;  \\&#x2F;_&#x2F;    &#x2F;&#x2F;   |  \\  \\
&lt;&#x2F;span&gt;&lt;span&gt;           @_^_@&amp;#39;&#x2F;   \\&#x2F;_   &#x2F;&#x2F;    |   \\   \\
&lt;&#x2F;span&gt;&lt;span&gt;           &#x2F;&#x2F;_^_&#x2F;     \\&#x2F;_ &#x2F;&#x2F;     |    \\    \\
&lt;&#x2F;span&gt;&lt;span&gt;        ( &#x2F;&#x2F;) |        \\&#x2F;&#x2F;&#x2F;      |     \\     \\
&lt;&#x2F;span&gt;&lt;span&gt;      ( &#x2F; &#x2F;) _|_ &#x2F;   )  &#x2F;&#x2F;       |      \\     _\\
&lt;&#x2F;span&gt;&lt;span&gt;    ( &#x2F;&#x2F; &#x2F;) &amp;#39;&#x2F;,_ _ _&#x2F;  ( ; -.    |    _ _\\.-~        .-~~~^-.
&lt;&#x2F;span&gt;&lt;span&gt;  (( &#x2F; &#x2F; )) ,-{        _      `-.|.-~-.           .~         `.
&lt;&#x2F;span&gt;&lt;span&gt; (( &#x2F;&#x2F; &#x2F; ))  &amp;#39;&#x2F;\\      &#x2F;                 ~-. _ .-~      .-~^-.  \\
&lt;&#x2F;span&gt;&lt;span&gt; (( &#x2F;&#x2F;&#x2F; ))      `.   {            }                   &#x2F;      \\  \\
&lt;&#x2F;span&gt;&lt;span&gt;  (( &#x2F; ))     .----~-.\\        \\-&amp;#39;                 .~         \\  `. \\^-.
&lt;&#x2F;span&gt;&lt;span&gt;             &#x2F;&#x2F;&#x2F;.----..&amp;gt;        \\             _ -~             `.  ^-`  ^-_
&lt;&#x2F;span&gt;&lt;span&gt;               &#x2F;&#x2F;&#x2F;-._ _ _ _ _ _ _}^ - - - - ~                     ~-- ,.-~
&lt;&#x2F;span&gt;&lt;span&gt;                                                                  &#x2F;.-~
&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;        # pylint: disable=global-statement
&lt;&#x2F;span&gt;&lt;span&gt;        global DRAGON_WARNING
&lt;&#x2F;span&gt;&lt;span&gt;        if not DRAGON_WARNING:
&lt;&#x2F;span&gt;&lt;span&gt;            print(dragon)
&lt;&#x2F;span&gt;&lt;span&gt;            if kwargs.pop(&amp;quot;dragon&amp;quot;, None) is None:
&lt;&#x2F;span&gt;&lt;span&gt;                time.sleep(5)
&lt;&#x2F;span&gt;&lt;span&gt;            print(&amp;quot;RAWR: Your problem now!!!&amp;quot;)
&lt;&#x2F;span&gt;&lt;span&gt;            DRAGON_WARNING = True
&lt;&#x2F;span&gt;&lt;span&gt;        return func(*args, **kwargs)
&lt;&#x2F;span&gt;&lt;span&gt;    return inner
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;#################################################
&lt;&#x2F;span&gt;&lt;span&gt;# Atomic locking functions. Provides a full lock, and a read lock. This is so 
&lt;&#x2F;span&gt;&lt;span&gt;# that multiple systems, users etc can access servers, but the servers allow
&lt;&#x2F;span&gt;&lt;span&gt;# one and only one action to be occuring.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;ATOMIC_LOCK = &amp;quot;&#x2F;tmp&#x2F;fsm_atomic.lock&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;ATOMIC_FLOCK = &amp;quot;&#x2F;tmp&#x2F;fsm_atomic.flock&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;ATOMIC_LOCK_HOSTS = {}
&lt;&#x2F;span&gt;&lt;span&gt;LOCAL_HOSTNAME = socket.gethostname()
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;class AtomicException(Exception):
&lt;&#x2F;span&gt;&lt;span&gt;    pass
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;@task
&lt;&#x2F;span&gt;&lt;span&gt;def lock():
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    usage: lock
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    WARNING: DO NOT RUN THIS BY HAND UNLESS YOU KNOW WHAT YOU ARE DOING!!!
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    Will create the atomic FSM lock. This prevents any other atomic function 
&lt;&#x2F;span&gt;&lt;span&gt;    from being able to run.
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    ### I cannot stress enough, do not change this. 
&lt;&#x2F;span&gt;&lt;span&gt;    result = run(&amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;        (
&lt;&#x2F;span&gt;&lt;span&gt;            flock -n 9 || exit 1
&lt;&#x2F;span&gt;&lt;span&gt;            touch {lock}
&lt;&#x2F;span&gt;&lt;span&gt;            echo {hostname} &amp;gt; {lock}
&lt;&#x2F;span&gt;&lt;span&gt;        ) 9&amp;gt;{flock}
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&amp;quot;&amp;quot;.format(lock=ATOMIC_LOCK, flock=ATOMIC_FLOCK, hostname=LOCAL_HOSTNAME)  )
&lt;&#x2F;span&gt;&lt;span&gt;    if result.return_code == 0:
&lt;&#x2F;span&gt;&lt;span&gt;        return True
&lt;&#x2F;span&gt;&lt;span&gt;    return False
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;@task
&lt;&#x2F;span&gt;&lt;span&gt;def unlock():
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    usage: unlock
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    WARNING: DO NOT RUN THIS BY HAND UNLESS YOU KNOW WHAT YOU ARE DOING!!!
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    Will remove the atomic FSM lock. This allows any other atomic function 
&lt;&#x2F;span&gt;&lt;span&gt;    from to run.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    Only run this if you are sure that it needs to clean out a stale lock. The 
&lt;&#x2F;span&gt;&lt;span&gt;    fsm atomic wrapper is VERY GOOD at cleaning up after itself. Only a kill -9
&lt;&#x2F;span&gt;&lt;span&gt;    to the fabric job will prevent it removing the atomic lock. Check what 
&lt;&#x2F;span&gt;&lt;span&gt;    you are doing! Look inside of &#x2F;tmp&#x2F;fsm_atomic.lock to see who holds the lock right now! 
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    ### I cannot stress enough, do not change this. 
&lt;&#x2F;span&gt;&lt;span&gt;    result = run(&amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;            rm {lock}
&lt;&#x2F;span&gt;&lt;span&gt;        &amp;quot;&amp;quot;&amp;quot;.format(lock=ATOMIC_LOCK))
&lt;&#x2F;span&gt;&lt;span&gt;    if result == 0:
&lt;&#x2F;span&gt;&lt;span&gt;        return True
&lt;&#x2F;span&gt;&lt;span&gt;    return False
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;def _lock_check():
&lt;&#x2F;span&gt;&lt;span&gt;    # pylint: disable=global-statement
&lt;&#x2F;span&gt;&lt;span&gt;    global ATOMIC_LOCK_HOSTS
&lt;&#x2F;span&gt;&lt;span&gt;    atomic_lock = False
&lt;&#x2F;span&gt;&lt;span&gt;    t_owner = False
&lt;&#x2F;span&gt;&lt;span&gt;    if ATOMIC_LOCK_HOSTS.has_key(env.host_string):
&lt;&#x2F;span&gt;&lt;span&gt;        atomic_lock = ATOMIC_LOCK_HOSTS[env.host_string]
&lt;&#x2F;span&gt;&lt;span&gt;        t_owner = True
&lt;&#x2F;span&gt;&lt;span&gt;    if not atomic_lock:
&lt;&#x2F;span&gt;&lt;span&gt;        with hide(&amp;#39;warnings&amp;#39;, &amp;#39;running&amp;#39;):
&lt;&#x2F;span&gt;&lt;span&gt;            result = get(ATOMIC_LOCK, local_path=&amp;quot;&#x2F;tmp&#x2F;{host}&#x2F;{page}&amp;quot;.format(
&lt;&#x2F;span&gt;&lt;span&gt;                page=&amp;quot;fsm_atomic.lock&amp;quot;, host=env.host))
&lt;&#x2F;span&gt;&lt;span&gt;            if len(result) != 0:
&lt;&#x2F;span&gt;&lt;span&gt;                atomic_lock = True
&lt;&#x2F;span&gt;&lt;span&gt;    return atomic_lock, t_owner
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;def noop(*args, **kwargs):
&lt;&#x2F;span&gt;&lt;span&gt;    log_local(&amp;#39;No-op for %s&amp;#39; % env.host_string, &amp;#39;NOTICE&amp;#39;)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;def rnt_fsm_atomic_r(func):
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    This decorator wraps functions that relate to the FSM and changing of state. 
&lt;&#x2F;span&gt;&lt;span&gt;    It triggers an atomic lock in the FSM to prevent other state changes occuring
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    Fsm atomic tasks can be nested, only the top level task will manage the lock.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    If the lock is already taken, we will NOT allow the task to run.
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    @wraps(func)
&lt;&#x2F;span&gt;&lt;span&gt;    def inner(*args, **kwargs):
&lt;&#x2F;span&gt;&lt;span&gt;        #If ATOMIC_LOCK_HOSTS then we own the lock, so we can use it.
&lt;&#x2F;span&gt;&lt;span&gt;        # ELSE if we don&amp;#39;t hold ATOMIC_LOCK_HOSTS we should check. 
&lt;&#x2F;span&gt;&lt;span&gt;        # Really, only the outer most wrapper should check .... 
&lt;&#x2F;span&gt;&lt;span&gt;        with settings(warn_only=True):
&lt;&#x2F;span&gt;&lt;span&gt;            # pylint: disable=global-statement
&lt;&#x2F;span&gt;&lt;span&gt;            global ATOMIC_LOCK_HOSTS
&lt;&#x2F;span&gt;&lt;span&gt;            #We DO care about the thread owner. Consider an exclusive lock above
&lt;&#x2F;span&gt;&lt;span&gt;            # a read lock. If we didn&amp;#39;t check that we own that exclusive lock,
&lt;&#x2F;span&gt;&lt;span&gt;            # we wouldn&amp;#39;t be able to run.
&lt;&#x2F;span&gt;&lt;span&gt;            (atomic_lock, t_owner) = _lock_check()
&lt;&#x2F;span&gt;&lt;span&gt;            allow_run = False
&lt;&#x2F;span&gt;&lt;span&gt;            if not atomic_lock or (atomic_lock and t_owner):
&lt;&#x2F;span&gt;&lt;span&gt;                ### We can run
&lt;&#x2F;span&gt;&lt;span&gt;                allow_run = True
&lt;&#x2F;span&gt;&lt;span&gt;                pass
&lt;&#x2F;span&gt;&lt;span&gt;            elif atomic_lock and not t_owner:
&lt;&#x2F;span&gt;&lt;span&gt;                ### We can&amp;#39;t run. The lock is held, and we don&amp;#39;t own it.
&lt;&#x2F;span&gt;&lt;span&gt;                log_local(&amp;#39;ATOMIC LOCK EXISTS, CANNOT RUN %s&amp;#39; % env.host_string, &amp;#39;NOTICE&amp;#39;)
&lt;&#x2F;span&gt;&lt;span&gt;            elif atomic_lock and t_owner:
&lt;&#x2F;span&gt;&lt;span&gt;                #### THIS SHOULDN&amp;#39;T HAPPEN EVER
&lt;&#x2F;span&gt;&lt;span&gt;                log_local(&amp;#39;ATOMIC LOCK STATE IS INVALID PLEASE CHECK&amp;#39;, &amp;#39;CRITICAL&amp;#39;)
&lt;&#x2F;span&gt;&lt;span&gt;                raise AtomicException(&amp;quot;CRITICAL: ATOIC LOCK STATE IS INVALID PLEASE CHECK, CANNOT RUN %s&amp;quot; % env.host_string)
&lt;&#x2F;span&gt;&lt;span&gt;            elif not atomic_lock and not t_owner:
&lt;&#x2F;span&gt;&lt;span&gt;                ### This means there is no lock, and we don&amp;#39;t own one. We can run.
&lt;&#x2F;span&gt;&lt;span&gt;                pass
&lt;&#x2F;span&gt;&lt;span&gt;            try:
&lt;&#x2F;span&gt;&lt;span&gt;                if allow_run:
&lt;&#x2F;span&gt;&lt;span&gt;                    return func(*args, **kwargs)
&lt;&#x2F;span&gt;&lt;span&gt;                else:
&lt;&#x2F;span&gt;&lt;span&gt;                    return noop(*args, **kwargs)
&lt;&#x2F;span&gt;&lt;span&gt;            finally:
&lt;&#x2F;span&gt;&lt;span&gt;                pass
&lt;&#x2F;span&gt;&lt;span&gt;    return inner
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;def rnt_fsm_atomic_exc(func):
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    This decorator wraps functions that relate to the FSM and changing of state. 
&lt;&#x2F;span&gt;&lt;span&gt;    It triggers an atomic lock in the FSM to prevent other state changes occuring
&lt;&#x2F;span&gt;&lt;span&gt;    until the task is complete.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    Fsm atomic tasks can be nested, only the top level task will manage the lock.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    If the lock is already taken, we will NOT allow the task to run.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    State is passed to nested calls that also need an atomic lock.
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    @wraps(func)
&lt;&#x2F;span&gt;&lt;span&gt;    def inner(*args, **kwargs):
&lt;&#x2F;span&gt;&lt;span&gt;        with settings(warn_only=True):
&lt;&#x2F;span&gt;&lt;span&gt;            # pylint: disable=global-statement
&lt;&#x2F;span&gt;&lt;span&gt;            global ATOMIC_LOCK_HOSTS
&lt;&#x2F;span&gt;&lt;span&gt;            (atomic_lock, t_owner) = _lock_check()
&lt;&#x2F;span&gt;&lt;span&gt;            atomic_lock_owner = False
&lt;&#x2F;span&gt;&lt;span&gt;            allow_run = False
&lt;&#x2F;span&gt;&lt;span&gt;            if atomic_lock and t_owner:
&lt;&#x2F;span&gt;&lt;span&gt;                #We have the lock, do nothing.
&lt;&#x2F;span&gt;&lt;span&gt;                pass
&lt;&#x2F;span&gt;&lt;span&gt;                allow_run = True
&lt;&#x2F;span&gt;&lt;span&gt;            elif atomic_lock and not t_owner:
&lt;&#x2F;span&gt;&lt;span&gt;                #Someone else has it, error.
&lt;&#x2F;span&gt;&lt;span&gt;                log_local(&amp;#39;ATOMIC LOCK EXISTS, CANNOT RUN %s&amp;#39; % env.host_string, &amp;#39;IMPORTANT&amp;#39;)
&lt;&#x2F;span&gt;&lt;span&gt;            elif not atomic_lock and t_owner:
&lt;&#x2F;span&gt;&lt;span&gt;                #Error, can&amp;#39;t be in this state.
&lt;&#x2F;span&gt;&lt;span&gt;                log_local(&amp;#39;ATOMIC LOCK STATE IS INVALID PLEASE CHECK&amp;#39;, &amp;#39;CRITICAL&amp;#39;)
&lt;&#x2F;span&gt;&lt;span&gt;                raise AtomicException(&amp;quot;CRITICAL: ATOMIC LOCK STATE IS INVALID PLEASE CHECK, CANNOT RUN %s&amp;quot; % env.host_string)
&lt;&#x2F;span&gt;&lt;span&gt;            elif not atomic_lock and not t_owner:
&lt;&#x2F;span&gt;&lt;span&gt;                # Create the lock.
&lt;&#x2F;span&gt;&lt;span&gt;                if not lock():
&lt;&#x2F;span&gt;&lt;span&gt;                    log_local(&amp;#39;LOCK TAKEN BY ANOTHER PROCESS&amp;#39;, &amp;#39;IMPORTANT&amp;#39;)
&lt;&#x2F;span&gt;&lt;span&gt;                    raise AtomicException(&amp;quot;CRITICAL: LOCK TAKEN BY ANOTHER PROCESS&amp;quot;)
&lt;&#x2F;span&gt;&lt;span&gt;                ATOMIC_LOCK_HOSTS[env.host_string] = True
&lt;&#x2F;span&gt;&lt;span&gt;                atomic_lock_owner = True
&lt;&#x2F;span&gt;&lt;span&gt;                allow_run = True
&lt;&#x2F;span&gt;&lt;span&gt;            try:
&lt;&#x2F;span&gt;&lt;span&gt;                if allow_run:
&lt;&#x2F;span&gt;&lt;span&gt;                    return func(*args, **kwargs)
&lt;&#x2F;span&gt;&lt;span&gt;                else:
&lt;&#x2F;span&gt;&lt;span&gt;                    return noop(*args, **kwargs)
&lt;&#x2F;span&gt;&lt;span&gt;            finally:
&lt;&#x2F;span&gt;&lt;span&gt;                if atomic_lock_owner:
&lt;&#x2F;span&gt;&lt;span&gt;                    unlock()
&lt;&#x2F;span&gt;&lt;span&gt;                    ATOMIC_LOCK_HOSTS[env.host_string] = False
&lt;&#x2F;span&gt;&lt;span&gt;    return inner
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;##################################################
&lt;&#x2F;span&gt;&lt;span&gt;# Basic service management.
&lt;&#x2F;span&gt;&lt;span&gt;#
&lt;&#x2F;span&gt;&lt;span&gt;## This is how you should start. Basic start, stop, and status commands.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;@task
&lt;&#x2F;span&gt;&lt;span&gt;@parallel
&lt;&#x2F;span&gt;&lt;span&gt;def start():
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    usage: start
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    Start the MapleTA database, tomcat and webserver
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    sudo(&amp;#39;service postgresql start&amp;#39;)
&lt;&#x2F;span&gt;&lt;span&gt;    sudo(&amp;#39;service tomcat6 start&amp;#39;)
&lt;&#x2F;span&gt;&lt;span&gt;    sudo(&amp;#39;service httpd start&amp;#39;)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;@task
&lt;&#x2F;span&gt;&lt;span&gt;@parallel
&lt;&#x2F;span&gt;&lt;span&gt;def stop():
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    usage: stop
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    Stop the MapleTA webserver, tomcat and database
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    sudo(&amp;#39;service httpd stop&amp;#39;)
&lt;&#x2F;span&gt;&lt;span&gt;    sudo(&amp;#39;service tomcat6 stop&amp;#39;)
&lt;&#x2F;span&gt;&lt;span&gt;    sudo(&amp;#39;service postgresql stop&amp;#39;)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;@task
&lt;&#x2F;span&gt;&lt;span&gt;def restart():
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    usage: restart
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    Restart the MapleTA database, tomcat and webserver
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    stop()
&lt;&#x2F;span&gt;&lt;span&gt;    start()
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;@task
&lt;&#x2F;span&gt;&lt;span&gt;def status():
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    usage: status
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    Check the status of MapleTA
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    sudo(&amp;#39;service postgresql status&amp;#39;)
&lt;&#x2F;span&gt;&lt;span&gt;    sudo(&amp;#39;service tomcat6 status&amp;#39;)
&lt;&#x2F;span&gt;&lt;span&gt;    sudo(&amp;#39;service httpd status&amp;#39;)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;##################################
&lt;&#x2F;span&gt;&lt;span&gt;# Some blackboard tasks. These rely on some of the above decorators.
&lt;&#x2F;span&gt;&lt;span&gt;#
&lt;&#x2F;span&gt;&lt;span&gt;### These are well developed, and sometimes rely on code not provided here. This
&lt;&#x2F;span&gt;&lt;span&gt;# in very intentional so that you can read it and get ideas of HOW you should 
&lt;&#x2F;span&gt;&lt;span&gt;# build code that works in your environment.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Also shows the usage of decorators and how you should use them to protent tasks
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;###################################
&lt;&#x2F;span&gt;&lt;span&gt;# Helpers
&lt;&#x2F;span&gt;&lt;span&gt;###################################
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;def config_key(key):
&lt;&#x2F;span&gt;&lt;span&gt;    if key.endswith(&amp;#39;=&amp;#39;) is False:
&lt;&#x2F;span&gt;&lt;span&gt;        key += &amp;#39;=&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;    return run(&amp;quot;egrep &amp;#39;{key}&amp;#39; {bbconfig} | cut -f2 -d\= &amp;quot;.format(key=key, bbconfig=BB_CONFIG))
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# return blackboard database instance
&lt;&#x2F;span&gt;&lt;span&gt;@task
&lt;&#x2F;span&gt;&lt;span&gt;@rnt_help
&lt;&#x2F;span&gt;&lt;span&gt;def get_db_instance():
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    usage: get_db_instance
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    Display the servers current DB instance &#x2F; SID
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    x = config_key(&amp;#39;bbconfig.database.server.instancename&amp;#39;)
&lt;&#x2F;span&gt;&lt;span&gt;    return x
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;@task
&lt;&#x2F;span&gt;&lt;span&gt;def get_db_credentials():
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    usage: get_db_credentials
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    This will retrieve the DB username and password from the BB server, and 
&lt;&#x2F;span&gt;&lt;span&gt;    return them as a dict {hostname:X, sid:X, username:X, password:X}
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    creds = {&amp;#39;hostname&amp;#39; : None,
&lt;&#x2F;span&gt;&lt;span&gt;             &amp;#39;sid&amp;#39; : None,
&lt;&#x2F;span&gt;&lt;span&gt;             &amp;#39;username&amp;#39; : None,
&lt;&#x2F;span&gt;&lt;span&gt;             &amp;#39;password&amp;#39; : None}
&lt;&#x2F;span&gt;&lt;span&gt;    with hide(&amp;#39;everything&amp;#39;):
&lt;&#x2F;span&gt;&lt;span&gt;        creds[&amp;#39;hostname&amp;#39;] = config_key(&amp;#39;bbconfig.database.server.fullhostname&amp;#39;)
&lt;&#x2F;span&gt;&lt;span&gt;        #TODO: Remove this sid appending line
&lt;&#x2F;span&gt;&lt;span&gt;        creds[&amp;#39;sid&amp;#39;] = config_key(&amp;#39;bbconfig.database.server.instancename&amp;#39;) + &amp;#39;.blackboard.inc&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;        creds[&amp;#39;username&amp;#39;] = config_key(&amp;#39;antargs.default.vi.db.name&amp;#39;)
&lt;&#x2F;span&gt;&lt;span&gt;        creds[&amp;#39;password&amp;#39;] = config_key(&amp;#39;antargs.default.vi.db.password&amp;#39;)
&lt;&#x2F;span&gt;&lt;span&gt;    return creds
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;@task
&lt;&#x2F;span&gt;&lt;span&gt;@parallel
&lt;&#x2F;span&gt;&lt;span&gt;@rnt_fsm_atomic_exc
&lt;&#x2F;span&gt;&lt;span&gt;def force_stop():
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    usage: force_stop -&amp;gt; atomic
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    Stop blackboard services on hosts in PARALLEL. This WILL bring down all
&lt;&#x2F;span&gt;&lt;span&gt;    hosts FAST. This does NOT gracefully remove from the pool. This DOES NOT
&lt;&#x2F;span&gt;&lt;span&gt;    check the sis integration queue.
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    log_blackboard(&amp;quot;Stopping BB&amp;quot;, level=&amp;#39;NOTICE&amp;#39;)
&lt;&#x2F;span&gt;&lt;span&gt;    if test_processes(quit=False) is True:
&lt;&#x2F;span&gt;&lt;span&gt;        sudo(&amp;#39;&#x2F;data&#x2F;blackboard&#x2F;bbctl stop&amp;#39;)
&lt;&#x2F;span&gt;&lt;span&gt;        time.sleep(30)
&lt;&#x2F;span&gt;&lt;span&gt;        cleanup_processes()
&lt;&#x2F;span&gt;&lt;span&gt;        test_processes()
&lt;&#x2F;span&gt;&lt;span&gt;    log_blackboard(&amp;quot;Stopped&amp;quot;, level=&amp;#39;SUCCESS&amp;#39;)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;@task
&lt;&#x2F;span&gt;&lt;span&gt;@serial
&lt;&#x2F;span&gt;&lt;span&gt;@rnt_fsm_atomic_exc
&lt;&#x2F;span&gt;&lt;span&gt;def force_restart():
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    usage: restart -&amp;gt; atomic
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    Restart blackboard systems in SERIAL. This is a dumb rolling restart. This
&lt;&#x2F;span&gt;&lt;span&gt;    DOES NOT remove from the pool and DOES NOT check the SIS queue
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    log_blackboard(&amp;quot;Trying to force restart blackboard&amp;quot;, level=&amp;#39;NOTICE&amp;#39;)
&lt;&#x2F;span&gt;&lt;span&gt;    force_stop()
&lt;&#x2F;span&gt;&lt;span&gt;    time.sleep(60)
&lt;&#x2F;span&gt;&lt;span&gt;    start()
&lt;&#x2F;span&gt;&lt;span&gt;    log_blackboard(&amp;quot;force restart complete&amp;quot;, level=&amp;#39;SUCCESS&amp;#39;)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;@task
&lt;&#x2F;span&gt;&lt;span&gt;@rnt_imsure()
&lt;&#x2F;span&gt;&lt;span&gt;def pushconfigupdates():
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    usage: pushconfigupdates
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    Run the pushconfigupdates tool on a system.
&lt;&#x2F;span&gt;&lt;span&gt;Warning! Running PushConfigUpdates.sh deploys changes to bb-config.properties!
&lt;&#x2F;span&gt;&lt;span&gt;* This will result in an outage to the host(s) on which it is run!
&lt;&#x2F;span&gt;&lt;span&gt;* Be careful that bb-config.properties, and the xythos.properties configuration
&lt;&#x2F;span&gt;&lt;span&gt;files point to the correct database before you run this!
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    sudo(&amp;#39;&#x2F;data&#x2F;blackboard&#x2F;tools&#x2F;admin&#x2F;PushConfigUpdates.sh&amp;#39;)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;@rnt_fsm_atomic_exc
&lt;&#x2F;span&gt;&lt;span&gt;def _compress_and_delete(path, fileglob, zipage=7, rmage=3660):
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    This will compress logs up to 7 days, and delete older than 62 days.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    The pattern is taken as:
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &#x2F;a&#x2F;b*&#x2F;c&#x2F;d.*.txt
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    This is passed to find which will carry out the actions as sudo.
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    with settings(warn_only=True):
&lt;&#x2F;span&gt;&lt;span&gt;        sudo(&amp;quot;find {path} -mtime +{zipage} -name &amp;#39;{fileglob}&amp;#39;  -exec gzip &amp;#39;{{}}&amp;#39; \;&amp;quot;.format(path=path, fileglob=fileglob, zipage=zipage))
&lt;&#x2F;span&gt;&lt;span&gt;        sudo(&amp;quot;find {path} -mtime +{rmage} -name &amp;#39;{fileglob}.gz&amp;#39;  -exec rm &amp;#39;{{}}&amp;#39; \;&amp;quot;.format(path=path, fileglob=fileglob, rmage=rmage))
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;@task
&lt;&#x2F;span&gt;&lt;span&gt;@rnt_help
&lt;&#x2F;span&gt;&lt;span&gt;@rnt_fsm_atomic_exc
&lt;&#x2F;span&gt;&lt;span&gt;def rotate_tomcat_logs():
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    usage: rotate_tomcat_logs -&amp;gt; atomic
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    This will rotate the tomcat logs in &#x2F;data&#x2F;blackboard&#x2F;logs&#x2F;tomcat.
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    log_blackboard(level=&amp;quot;NOTICE&amp;quot;)
&lt;&#x2F;span&gt;&lt;span&gt;    with settings(warn_only=True):
&lt;&#x2F;span&gt;&lt;span&gt;        for pattern in [&amp;#39;stdout-stderr-*.log&amp;#39;, &amp;#39;bb-access-log.*.txt&amp;#39;,
&lt;&#x2F;span&gt;&lt;span&gt;                &amp;#39;activemq.txt.*.txt&amp;#39;, &amp;#39;catalina-log.txt.*.txt&amp;#39;, &amp;#39;gc.*.txt&amp;#39;,
&lt;&#x2F;span&gt;&lt;span&gt;                &amp;#39;thread_dump*.txt&amp;#39;, &amp;#39;*.hprof&amp;#39; ]:
&lt;&#x2F;span&gt;&lt;span&gt;            _compress_and_delete(&amp;quot;&#x2F;data&#x2F;blackboard&#x2F;logs&#x2F;tomcat&#x2F;&amp;quot;, pattern)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
</description>
      </item>
      <item>
          <title>Render errors on websites</title>
          <pubDate>Fri, 25 Jul 2014 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2014-07-25-render-errors-on-websites/</link>
          <guid>https://fy.blackhats.net.au/blog/2014-07-25-render-errors-on-websites/</guid>
          <description>&lt;h1 id=&quot;render-errors-on-websites&quot;&gt;Render errors on websites&lt;&#x2F;h1&gt;
&lt;p&gt;some websites always give me weird rendering, such as % signs for
buttons etc. I have finally looked into this, and realised I&#x27;m missing
a font set. To fix this, just do:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;yum install entypo-fonts
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
</description>
      </item>
      <item>
          <title>NSS-OpenSSL Command How to: The complete list.</title>
          <pubDate>Thu, 10 Jul 2014 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2014-07-10-nss-openssl-command-how-to-the-complete-list/</link>
          <guid>https://fy.blackhats.net.au/blog/2014-07-10-nss-openssl-command-how-to-the-complete-list/</guid>
          <description>&lt;h1 id=&quot;nss-openssl-command-how-to-the-complete-list&quot;&gt;NSS-OpenSSL Command How to: The complete list.&lt;&#x2F;h1&gt;
&lt;p&gt;I am sick and tired of the lack of documentation for how to actually use
OpenSSL and NSS to achieve things. Be it missing small important options
like &amp;quot;subjectAltNames&amp;quot; in nss commands or openssls cryptic settings.
Here is my complete list of everything you would ever want to do with
OpenSSL and NSS.&lt;&#x2F;p&gt;
&lt;p&gt;References:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http:&#x2F;&#x2F;www.mozilla.org&#x2F;projects&#x2F;security&#x2F;pki&#x2F;nss&#x2F;tools&#x2F;certutil.html&quot;&gt;certutil
mozilla&lt;&#x2F;a&gt;.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;developer.mozilla.org&#x2F;en-US&#x2F;docs&#x2F;NSS_reference&#x2F;NSS_tools_:_certutil&quot;&gt;nss
tools&lt;&#x2F;a&gt;.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;www.openssl.org&#x2F;docs&#x2F;apps&#x2F;openssl.html&quot;&gt;openssl&lt;&#x2F;a&gt;.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;nss-specific&quot;&gt;Nss specific&lt;&#x2F;h2&gt;
&lt;h2 id=&quot;db-creation-and-basic-listing&quot;&gt;DB creation and basic listing&lt;&#x2F;h2&gt;
&lt;p&gt;Create a new certificate database if one doesn&#x27;t exist (You should see
key3.db, secmod.db and cert8.db if one exists). :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -N -d . 
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;List all certificates in a database :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -L -d .
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;List all private keys in a database :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -K -d . [-f pwdfile.txt]
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;I have created a password file, which consists of random data on one
line in a plain text file. Something like below would suffice.
Alternately you can enter a password when prompted by the certutil
commands. If you wish to use this for apache start up, you need to use
pin.txt :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;echo &amp;quot;Password&amp;quot; &amp;gt; pwdfile.txt
&lt;&#x2F;span&gt;&lt;span&gt;echo &amp;quot;internal:Password&amp;quot; &amp;gt; pin.txt
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;importing-certificates-to-nss&quot;&gt;Importing certificates to NSS&lt;&#x2F;h2&gt;
&lt;p&gt;Import the signed certificate into the requesters database.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -A -n &amp;quot;Server-cert&amp;quot; -t &amp;quot;,,&amp;quot; -i nss.dev.example.com.crt -d .
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Import an openSSL generated key and certificate into an NSS database. :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;openssl pkcs12 -export -in server.crt -inkey server.key -out server.p12 -name Test-Server-Cert
&lt;&#x2F;span&gt;&lt;span&gt;pk12util -i server.p12 -d . -k pwdfile.txt
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;importing-a-ca-certificate&quot;&gt;Importing a CA certificate&lt;&#x2F;h2&gt;
&lt;p&gt;Import the CA public certificate into the requesters database. :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -A -n &amp;quot;CAcert&amp;quot; -t &amp;quot;C,,&amp;quot; -i &#x2F;etc&#x2F;pki&#x2F;CA&#x2F;nss&#x2F;ca.crt -d .
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;exporting-certificates&quot;&gt;Exporting certificates&lt;&#x2F;h2&gt;
&lt;p&gt;Export a secret key and certificate from an NSS database for use with
openssl. :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;pk12util -o server-export.p12 -d . -k pwdfile.txt -n Test-Server-Cert
&lt;&#x2F;span&gt;&lt;span&gt;openssl pkcs12 -in server-export.p12 -out file.pem -nodes
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Note that file.pem contains both the CA cert, cert and private key. You
can view just the private key with: :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;openssl pkcs12 -in server-export.p12 -out file.pem -nocerts -nodes
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Or just the cert and CAcert with :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;openssl pkcs12 -in server-export.p12 -out file.pem -nokeys -nodes
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You can easily make ASCII formatted PEM from here.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;both-nss-and-openssl&quot;&gt;Both NSS and OpenSSL&lt;&#x2F;h2&gt;
&lt;h2 id=&quot;self-signed-certificates&quot;&gt;Self signed certificates&lt;&#x2F;h2&gt;
&lt;p&gt;Create a self signed certificate.&lt;&#x2F;p&gt;
&lt;p&gt;For nss, note the -n, which creates a &amp;quot;nickname&amp;quot; (And should be
unique) and is how applications reference your certificate and key. Also
note the -s line, and the CN options. Finally, note the first line has
the option -g, which defines the number of bits in the created
certificate. :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -S -f pwdfile.txt -d . -t &amp;quot;C,,&amp;quot; -x -n &amp;quot;Server-Cert&amp;quot; -g 2048\
&lt;&#x2F;span&gt;&lt;span&gt;-s &amp;quot;CN=nss.dev.example.com,O=Testing,L=example,ST=South Australia,C=AU&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;openssl req -x509 -newkey rsa:2048 -keyout key.pem -out cert.pem -days
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;certutil -S -f pwdfile.txt -d . -t &amp;quot;C,,&amp;quot; -x -n &amp;quot;Server-Cert2&amp;quot; \
&lt;&#x2F;span&gt;&lt;span&gt;-s &amp;quot;CN=nss2.dev.example.com,O=Testing,L=example,ST=South Australia,C=AU&amp;quot; 
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;subjectaltnames&quot;&gt;SubjectAltNames&lt;&#x2F;h2&gt;
&lt;p&gt;To add subject alternative names, use a comma seperated list with the
option -8 IE: :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -S -f pwdfile.txt -d . -t &amp;quot;C,,&amp;quot; -x -n &amp;quot;Server-Cert&amp;quot; -g 2048\
&lt;&#x2F;span&gt;&lt;span&gt;-s &amp;quot;CN=nss.dev.example.com,O=Testing,L=example,ST=South Australia,C=AU&amp;quot; \
&lt;&#x2F;span&gt;&lt;span&gt;-8 &amp;quot;nss.dev.example.com,nss-alt.dev.example.com&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;For OpenSSL this is harder:&lt;&#x2F;p&gt;
&lt;p&gt;First, you need to create an altnames.cnf :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;[req]
&lt;&#x2F;span&gt;&lt;span&gt;req_extensions = v3_req
&lt;&#x2F;span&gt;&lt;span&gt;nsComment = &amp;quot;Certificate&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;distinguished_name  = req_distinguished_name
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[ req_distinguished_name ]
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;countryName                     = Country Name (2 letter code)
&lt;&#x2F;span&gt;&lt;span&gt;countryName_default             = AU
&lt;&#x2F;span&gt;&lt;span&gt;countryName_min                 = 2
&lt;&#x2F;span&gt;&lt;span&gt;countryName_max                 = 2
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;stateOrProvinceName             = State or Province Name (full name)
&lt;&#x2F;span&gt;&lt;span&gt;stateOrProvinceName_default     = South Australia
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;localityName                    = Locality Name (eg, city)
&lt;&#x2F;span&gt;&lt;span&gt;localityName_default            = example&#x2F;streetAddress=Level
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;0.organizationName              = Organization Name (eg, company)
&lt;&#x2F;span&gt;&lt;span&gt;0.organizationName_default      = example
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;organizationalUnitName          = Organizational Unit Name (eg, section)
&lt;&#x2F;span&gt;&lt;span&gt;organizationalUnitName_default = TS
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;commonName                      = Common Name (eg, your name or your server\&amp;#39;s hostname)
&lt;&#x2F;span&gt;&lt;span&gt;commonName_max                  = 64
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[ v3_req ]
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;# Extensions to add to a certificate request
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;basicConstraints = CA:FALSE
&lt;&#x2F;span&gt;&lt;span&gt;keyUsage = nonRepudiation, digitalSignature, keyEncipherment
&lt;&#x2F;span&gt;&lt;span&gt;subjectAltName = @alt_names
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[alt_names]
&lt;&#x2F;span&gt;&lt;span&gt;DNS.1 = server1.yourdomain.tld
&lt;&#x2F;span&gt;&lt;span&gt;DNS.2 = mail.yourdomain.tld
&lt;&#x2F;span&gt;&lt;span&gt;DNS.3 = www.yourdomain.tld
&lt;&#x2F;span&gt;&lt;span&gt;DNS.4 = www.sub.yourdomain.tld
&lt;&#x2F;span&gt;&lt;span&gt;DNS.5 = mx.yourdomain.tld
&lt;&#x2F;span&gt;&lt;span&gt;DNS.6 = support.yourdomain.tld
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now you run a similar command to before with: :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;openssl req -x509 -newkey rsa:2048 -keyout key.pem -out cert.pem -days -config altnames.cnf
&lt;&#x2F;span&gt;&lt;span&gt;openssl req -key key.pem -out cert.csr -days -config altnames.cnf -new
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;check-a-certificate-belongs-to-a-specific-key&quot;&gt;Check a certificate belongs to a specific key&lt;&#x2F;h2&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;openssl rsa -noout -modulus -in client.key | openssl sha1
&lt;&#x2F;span&gt;&lt;span&gt;openssl req -noout -modulus -in client.csr | openssl sha1
&lt;&#x2F;span&gt;&lt;span&gt;openssl x509 -noout -modulus -in client.crt | openssl sha1
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;view-a-certificate&quot;&gt;View a certificate&lt;&#x2F;h2&gt;
&lt;p&gt;View the cert :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -L -d . -n Test-Cert
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;openssl x509 -noout -text -in client.crt
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;View the cert in ASCII PEM form (This can be redirected to a file for
use with openssl)&lt;&#x2F;p&gt;
&lt;p&gt;::&lt;&#x2F;p&gt;
&lt;p&gt;:   certutil -L -d . -n Test-Cert -a certutil -L -d . -n Test-Cert -a &amp;gt;
cert.pem&lt;&#x2F;p&gt;
&lt;h2 id=&quot;creating-a-csr&quot;&gt;Creating a CSR&lt;&#x2F;h2&gt;
&lt;p&gt;In a second, seperate database to your CA.&lt;&#x2F;p&gt;
&lt;p&gt;Create a new certificate request. Again, remember -8 for subjectAltName
:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -d . -R -o nss.dev.example.com.csr -f pwdfile.txt \
&lt;&#x2F;span&gt;&lt;span&gt;-s &amp;quot;CN=nss.dev.example.com,O=Testing,L=example,ST=South Australia,C=AU&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Using openSSL create a server key, and make a CSR :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;openssl genrsa -out client.key 2048
&lt;&#x2F;span&gt;&lt;span&gt;openssl req -new -key client.key -out client.csr
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;self-signed-ca&quot;&gt;Self signed CA&lt;&#x2F;h2&gt;
&lt;p&gt;Create a self signed CA (In a different database from the one used by
httpd.) :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -S -n CAissuer -t &amp;quot;C,C,C&amp;quot; -x -f pwdfile.txt -d . \
&lt;&#x2F;span&gt;&lt;span&gt;-s &amp;quot;CN=ca.nss.dev.example.com,O=Testing,L=example,ST=South Australia,C=AU&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;OpenSSL is the same as a self signed cert. :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;openssl req -x509 -newkey rsa:2048 -keyout key.pem -out cert.pem -days
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;signing-with-the-ca&quot;&gt;Signing with the CA&lt;&#x2F;h2&gt;
&lt;p&gt;Create a certificate in the same database, and sign it with the CAissuer
certificate. :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -S -n Test-Cert -t &amp;quot;,,&amp;quot; -c CAissuer -f pwdfile.txt -d . \
&lt;&#x2F;span&gt;&lt;span&gt;-s &amp;quot;CN=test.nss.dev.example.com,O=Testing,L=example,ST=South Australia,C=AU&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If from a CSR, review the CSR you have recieved. :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;usr&#x2F;lib[64]&#x2F;nss&#x2F;unsupported-tools&#x2F;derdump -i &#x2F;etc&#x2F;httpd&#x2F;alias&#x2F;nss.dev.example.com.csr
&lt;&#x2F;span&gt;&lt;span&gt;openssl req -inform DER -text -in &#x2F;etc&#x2F;httpd&#x2F;alias&#x2F;nss.dev.example.com.csr  ## if from nss
&lt;&#x2F;span&gt;&lt;span&gt;openssl req -inform PEM -text -in server.csr  ## if from openssl
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;On the CA, sign the CSR. :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -C -d . -f pwdfile.txt -i &#x2F;etc&#x2F;httpd&#x2F;alias&#x2F;nss.dev.example.com.csr \
&lt;&#x2F;span&gt;&lt;span&gt;-o &#x2F;etc&#x2F;httpd&#x2F;alias&#x2F;nss.dev.example.com.crt -c CAissuer
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;For openssl CSR, note the use of -a that allows an ASCII formatted PEM
input, and will create and ASCII PEM certificate output. :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -C -d . -f pwdfile.txt -i server.csr -o server.crt -a -c CAissuer
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;### Note, you may need a caserial file ... 
&lt;&#x2F;span&gt;&lt;span&gt;openssl x509 -req -days 1024 -in client.csr -CA root.crt -CAkey root.key -out client.crt
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;check-validity-of-a-certificate&quot;&gt;Check validity of a certificate&lt;&#x2F;h2&gt;
&lt;p&gt;Test the new cert for validity as an SSL server. This assumes the CA
cert is in the DB. (Else you need openssl or to import it) :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -V -d . -n Test-Cert -u V
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;openssl verify -verbose -CAfile ca.crt client.crt
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;export-the-ca-certificate&quot;&gt;Export the CA certificate&lt;&#x2F;h2&gt;
&lt;p&gt;Export the CA public certificate :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -L -d . -n CAissuer -r &amp;gt; ca.crt
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;nss-sqlite-db&quot;&gt;NSS sqlite db&lt;&#x2F;h2&gt;
&lt;p&gt;Finally, these commands all use the old DBM formatted NSS databases. To
use the new &amp;quot;shareable&amp;quot; sqlite formatting, follow the steps found from
&lt;a href=&quot;https:&#x2F;&#x2F;blogs.oracle.com&#x2F;meena&#x2F;entry&#x2F;what_s_new_in_nss&quot;&gt;this blog
post&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;How to upgrade from cert8.db to cert9.db&lt;&#x2F;p&gt;
&lt;p&gt;You can either use environment variables or use sql: prefix in database
directory parameter of certutil:&lt;&#x2F;p&gt;
&lt;p&gt;::&lt;&#x2F;p&gt;
&lt;p&gt;:   $export NSS_DEFAULT_DB_TYPE=sql $certutil -K -d &#x2F;tmp&#x2F;nss -X&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&amp;gt; OR
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;\$certutil -K -d sql:&#x2F;tmp&#x2F;nss -X
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;When you upgrade these are the files you get&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;key3.db -&amp;gt; key4.db
&lt;&#x2F;span&gt;&lt;span&gt;cert8.db -&amp;gt; cert9.db
&lt;&#x2F;span&gt;&lt;span&gt;secmod.db -&amp;gt; pkcs11.txt
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The contents of the pkcs11.txt files are basically identical to the
contents of the old secmod.db, just not in the old Berkeley DB format.
If you run the command &amp;quot;$modutil -dbdir DBDIR -rawlist&amp;quot; on an older
secmod.db file, you should get output similar to what you see in
pkcs11.txt.&lt;&#x2F;p&gt;
&lt;p&gt;What needs to be done in programs &#x2F; C code&lt;&#x2F;p&gt;
&lt;p&gt;Either add environment variable NSS_DEFAULT_DB_TYPE &amp;quot;sql&amp;quot;&lt;&#x2F;p&gt;
&lt;p&gt;NSS_Initialize call in &lt;a href=&quot;https:&#x2F;&#x2F;developer.mozilla.org&#x2F;en&#x2F;NSS_Initialize&quot;&gt;https:&#x2F;&#x2F;developer.mozilla.org&#x2F;en&#x2F;NSS_Initialize&lt;&#x2F;a&gt;
takes this &amp;quot;configDir&amp;quot; parameter as shown below.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;NSS_Initialize(configDir, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;secmod.db&amp;quot;, NSS_INIT_READONLY);
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;For cert9.db, change this first parameter to &amp;quot;sql:&amp;quot; + configDir (like
&amp;quot;sql:&#x2F;tmp&#x2F;nss&#x2F;&amp;quot;) i.e. prefix &amp;quot;sql:&amp;quot; in the directory name where
these NSS Databases exist. This code will work with cert8.db as well if
cert9.db is not present.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;wiki.mozilla.org&#x2F;NSS_Shared_DB&quot;&gt;https:&#x2F;&#x2F;wiki.mozilla.org&#x2F;NSS_Shared_DB&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;display-a-human-readable-certificate-from-an-ssl-socket&quot;&gt;Display a human readable certificate from an SSL socket&lt;&#x2F;h2&gt;
&lt;p&gt;Note: port 636 is LDAPS, but all SSL sockets are supported. For TLS only
a limited set of protocols are supported. Add -starttls to the command.
See man 1 s_client.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;openssl s_client -connect ldap.example.com:636
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[ant@ant-its-example-edu-au ~]$ echo -n | openssl s_client -connect ldap.example.com:636 | sed -ne &amp;#39;&#x2F;-BEGIN CERTIFICATE-&#x2F;,&#x2F;-END CERTIFICATE-&#x2F;p&amp;#39; | openssl x509 -noout -text
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;depth=3 C = SE, O = AddTrust AB, OU = AddTrust External TTP Network, CN = AddTrust External CA Root
&lt;&#x2F;span&gt;&lt;span&gt;verify return:1
&lt;&#x2F;span&gt;&lt;span&gt;depth=2 C = US, ST = UT, L = Salt Lake City, O = The USERTRUST Network, OU = http:&#x2F;&#x2F;www.usertrust.com, CN = UTN-USERFirst-Hardware
&lt;&#x2F;span&gt;&lt;span&gt;verify return:1
&lt;&#x2F;span&gt;&lt;span&gt;depth=1 C = AU, O = AusCERT, OU = Certificate Services, CN = AusCERT Server CA
&lt;&#x2F;span&gt;&lt;span&gt;verify return:1
&lt;&#x2F;span&gt;&lt;span&gt;depth=0 C = AU, postalCode = 5000, ST = South Australia, L = example, street = Level, street = Place, O =Example, OU = Technology Services, CN = ldap.example.com
&lt;&#x2F;span&gt;&lt;span&gt;verify return:1
&lt;&#x2F;span&gt;&lt;span&gt;DONE
&lt;&#x2F;span&gt;&lt;span&gt;Certificate:
&lt;&#x2F;span&gt;&lt;span&gt;    Data:
&lt;&#x2F;span&gt;&lt;span&gt;        Version: 3 (0x2)
&lt;&#x2F;span&gt;&lt;span&gt;        Serial Number:
&lt;&#x2F;span&gt;&lt;span&gt;    Signature Algorithm: sha1WithRSAEncryption
&lt;&#x2F;span&gt;&lt;span&gt;        Issuer: C=AU, O=AusCERT, OU=Certificate Services, CN=AusCERT Server CA
&lt;&#x2F;span&gt;&lt;span&gt;        Validity
&lt;&#x2F;span&gt;&lt;span&gt;            Not Before: XX
&lt;&#x2F;span&gt;&lt;span&gt;            Not After : XX
&lt;&#x2F;span&gt;&lt;span&gt;        Subject: C=AU&#x2F;postalCode=5000, ST=South Australia, L=example&#x2F;street=Level &#x2F;street=Place, O=Example, OU=Technology Services, CN=ldap.example.com
&lt;&#x2F;span&gt;&lt;span&gt;        Subject Public Key Info:
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;snip&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;            X509v3 Subject Alternative Name: 
&lt;&#x2F;span&gt;&lt;span&gt;                DNS:ldap.example.com
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;snip&amp;gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You can use this to display a CA chain if you can&#x27;t get it from other
locations.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;openssl s_client -connect ldap.example.com:636 -showcerts
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;mod-nss&quot;&gt;mod_nss&lt;&#x2F;h2&gt;
&lt;p&gt;To configure mod_nss, you should have a configuration similar to below -
Most of this is the standard nss.conf that comes with mod_nss, but note
the changes to NSSNickname, and the modified NSSPassPhraseDialog and
NSSRandomSeed values. There is documentation on the NSSCipherSuite that
can be found by running &amp;quot;rpm -qd mod_nss&amp;quot;. Finally, make sure that
apache has read access to the database files and the pin.txt file. If
you leave NSSPassPhraseDialog as &amp;quot;builtin&amp;quot;, you cannot start httpd
from systemctl. You must run apachectl so that you can enter the NSS
database password on apache startup.&lt;&#x2F;p&gt;
&lt;p&gt;NOTE: mod_nss &lt;em&gt;DOES NOT&lt;&#x2F;em&gt; support SNI.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;LoadModule nss_module modules&#x2F;libmodnss.so
&lt;&#x2F;span&gt;&lt;span&gt;Listen 8443
&lt;&#x2F;span&gt;&lt;span&gt;NameVirtualHost *:8443
&lt;&#x2F;span&gt;&lt;span&gt;AddType application&#x2F;x-x509-ca-cert .crt
&lt;&#x2F;span&gt;&lt;span&gt;AddType application&#x2F;x-pkcs7-crl    .crl
&lt;&#x2F;span&gt;&lt;span&gt;NSSPassPhraseDialog  file:&#x2F;etc&#x2F;httpd&#x2F;alias&#x2F;pin.txt
&lt;&#x2F;span&gt;&lt;span&gt;NSSPassPhraseHelper &#x2F;usr&#x2F;sbin&#x2F;nss_pcache
&lt;&#x2F;span&gt;&lt;span&gt;NSSSessionCacheSize 10000
&lt;&#x2F;span&gt;&lt;span&gt;NSSSessionCacheTimeout 100
&lt;&#x2F;span&gt;&lt;span&gt;NSSSession3CacheTimeout 86400
&lt;&#x2F;span&gt;&lt;span&gt;NSSEnforceValidCerts off
&lt;&#x2F;span&gt;&lt;span&gt;NSSRandomSeed startup file:&#x2F;dev&#x2F;urandom 512
&lt;&#x2F;span&gt;&lt;span&gt;NSSRenegotiation off
&lt;&#x2F;span&gt;&lt;span&gt;NSSRequireSafeNegotiation off
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;VirtualHost *:8443&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;ServerName nss.dev.example.com:8443
&lt;&#x2F;span&gt;&lt;span&gt;ServerAlias nss.dev.example.com
&lt;&#x2F;span&gt;&lt;span&gt;ErrorLog &#x2F;etc&#x2F;httpd&#x2F;logs&#x2F;nss1_error_log
&lt;&#x2F;span&gt;&lt;span&gt;TransferLog &#x2F;etc&#x2F;httpd&#x2F;logs&#x2F;nss1_access_log
&lt;&#x2F;span&gt;&lt;span&gt;LogLevel warn
&lt;&#x2F;span&gt;&lt;span&gt;NSSEngine on
&lt;&#x2F;span&gt;&lt;span&gt;NSSProtocol TLSv1
&lt;&#x2F;span&gt;&lt;span&gt;NSSNickname Server-cert
&lt;&#x2F;span&gt;&lt;span&gt;NSSCertificateDatabase &#x2F;etc&#x2F;httpd&#x2F;alias
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;Files ~ &amp;quot;\.(cgi|shtml|phtml|php3?)$&amp;quot;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;    NSSOptions +StdEnvVars
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&#x2F;Files&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;Directory &amp;quot;&#x2F;var&#x2F;www&#x2F;cgi-bin&amp;quot;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;    NSSOptions +StdEnvVars
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&#x2F;Directory&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&#x2F;VirtualHost&amp;gt;                                  
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
</description>
      </item>
      <item>
          <title>Linux remote desktop from GDM</title>
          <pubDate>Wed, 19 Jun 2013 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2013-06-19-linux-remote-desktop-from-gdm/</link>
          <guid>https://fy.blackhats.net.au/blog/2013-06-19-linux-remote-desktop-from-gdm/</guid>
          <description>&lt;h1 id=&quot;linux-remote-desktop-from-gdm&quot;&gt;Linux remote desktop from GDM&lt;&#x2F;h1&gt;
&lt;p&gt;For quite some time I have wanted to be able to create thin linux
workstations that automatically connect to a remote display manager of
some kind for the relevant desktop services. This has always been
somewhat of a mystery to me, but I found the final answer to be quite
simple.&lt;&#x2F;p&gt;
&lt;p&gt;First, you need a system like a windows Remote Desktop server, or xrdp
server configured. Make sure that you can connect and login to it.&lt;&#x2F;p&gt;
&lt;p&gt;Now install your thin client. I used CentOS with a minimal desktop
install to give me an X server.&lt;&#x2F;p&gt;
&lt;p&gt;Install the &amp;quot;rdesktop&amp;quot; package on your thin client.&lt;&#x2F;p&gt;
&lt;p&gt;Now you need to add the Remote Desktop session type.&lt;&#x2F;p&gt;
&lt;p&gt;Create the file &amp;quot;&#x2F;usr&#x2F;bin&#x2F;rdesktop-session&amp;quot; (Or &#x2F;opt or &#x2F;srv. Up to
you - but make sure it&#x27;s executable)&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;#!&#x2F;bin&#x2F;bash
&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;usr&#x2F;bin&#x2F;rdesktop -d domain.example.com -b -a 32 -x lan -f termserv.example.com
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now you need to create a session type that GDM will recognise. Put this
into &amp;quot;&#x2F;usr&#x2F;share&#x2F;xsessions&#x2F;rdesktop.desktop&amp;quot;. These options could be
improved etc.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;[Desktop Entry]
&lt;&#x2F;span&gt;&lt;span&gt;Name=RDesktop
&lt;&#x2F;span&gt;&lt;span&gt;Comment=This session logs you into RDesktop
&lt;&#x2F;span&gt;&lt;span&gt;Exec=&#x2F;usr&#x2F;bin&#x2F;rdesktop-session
&lt;&#x2F;span&gt;&lt;span&gt;TryExec=&#x2F;usr&#x2F;bin&#x2F;rdesktop-session
&lt;&#x2F;span&gt;&lt;span&gt;Terminal=True
&lt;&#x2F;span&gt;&lt;span&gt;Type=Application
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[Window Manager]
&lt;&#x2F;span&gt;&lt;span&gt;SessionManaged=true
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Create a user who will automatically connect to the TS.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;useradd remote_login
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Configure GDM to automatically login after a time delay. The reason for
the time delay, is so that after the rdesktop session is over, at the
GDM display, a staff member can shutdown the thin client.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;[daemon]
&lt;&#x2F;span&gt;&lt;span&gt;TimedLoginEnable=True
&lt;&#x2F;span&gt;&lt;span&gt;TimedLogin=remote_login
&lt;&#x2F;span&gt;&lt;span&gt;TimedLoginDelay=15
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Finally, set the remote login user&#x27;s session to RDesktop
&amp;quot;&#x2F;home&#x2F;remote_login&#x2F;.dmrc&amp;quot;&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;[Desktop]
&lt;&#x2F;span&gt;&lt;span&gt;Session=rdesktop
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;And that&#x27;s it!&lt;&#x2F;p&gt;
&lt;p&gt;If you are using windows terminal services, you will notice that the
login times out after about a minute, GDM will reset, wait 15 seconds
and connect again, causing a loop of this action. To prevent this, you
should extend the windows server login timeout. On the terminal server:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\Terminal Server\WinStations\[[Connection endpoint]]\LogonTimeout (DWord, seconds for timeout)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;[[Connection endpoint]] is the name in RD Session Host
configurations : I had rebuilt mine as default and was wondering why
this no longer worked. This way you can apply the logon timeout to
different session connections.&lt;&#x2F;p&gt;
&lt;p&gt;Update: Actually, it needs to be RDP-Tcp regardless of the connection
endpoint. Bit silly.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Akonadi mariadb on ZFS</title>
          <pubDate>Fri, 24 May 2013 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2013-05-24-akonadi-mariadb-on-zfs/</link>
          <guid>https://fy.blackhats.net.au/blog/2013-05-24-akonadi-mariadb-on-zfs/</guid>
          <description>&lt;h1 id=&quot;akonadi-mariadb-on-zfs&quot;&gt;Akonadi mariadb on ZFS&lt;&#x2F;h1&gt;
&lt;p&gt;I have recently bit the bullet and decided to do some upgrades to my
laptop. The main focus was getting ZFS as my home drive.&lt;&#x2F;p&gt;
&lt;p&gt;In doing so Akonadi, the PIM service for kmail broke.&lt;&#x2F;p&gt;
&lt;p&gt;After some investigation, it is because zfs does not support AIO with
maria db.&lt;&#x2F;p&gt;
&lt;p&gt;To fix this add to ~&#x2F;.local&#x2F;share&#x2F;akonadi&#x2F;myself.conf :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;innodb_use_native_aio=0
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
</description>
      </item>
      <item>
          <title>MBP b43 wireless</title>
          <pubDate>Thu, 02 May 2013 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2013-05-02-mbp-b43-wireless/</link>
          <guid>https://fy.blackhats.net.au/blog/2013-05-02-mbp-b43-wireless/</guid>
          <description>&lt;h1 id=&quot;mbp-b43-wireless&quot;&gt;MBP b43 wireless&lt;&#x2F;h1&gt;
&lt;p&gt;I have found recently after about 3.7 that b43 wireless with most access
points is quite flakey. Thankfully, a fellow student, Kram found this
great blog post about getting it to work.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;http:&#x2F;&#x2F;www.rdoxenham.com&#x2F;?p=317&quot;&gt;blog here&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;For the moment, you have to rebuild the module by hand on update, but
it&#x27;s a make, make install, dracut away.&lt;&#x2F;p&gt;
&lt;p&gt;The only thing missed is that at the end:&lt;&#x2F;p&gt;
&lt;p&gt;Put the blacklist options into their own wl.conf rather than the main
blacklist for finding them.&lt;&#x2F;p&gt;
&lt;p&gt;You need to rebuild your dracut image. The following should work:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;cd &#x2F;boot&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;mv initramfs-[current kernel here] initramfs-[kernel].back
&lt;&#x2F;span&gt;&lt;span&gt;dracut
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
</description>
      </item>
      <item>
          <title>Changing SSSD cert</title>
          <pubDate>Thu, 25 Apr 2013 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2013-04-25-changing-sssd-cert/</link>
          <guid>https://fy.blackhats.net.au/blog/2013-04-25-changing-sssd-cert/</guid>
          <description>&lt;h1 id=&quot;changing-sssd-cert&quot;&gt;Changing SSSD cert&lt;&#x2F;h1&gt;
&lt;p&gt;After re-provisioning my Samba 4 domain, I found SSSD giving m a strange
error: :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ldap_install_tls failed: [Connect error]
&lt;&#x2F;span&gt;&lt;span&gt; [TLS error -8054:You are attempting to import a cert with the same issuer&#x2F;serial as an existing cert, but that is not the same cert.]
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;It seems SSSD caches the ca cert of your ldap service (even if you
change the SSSD domain name). I couldn&#x27;t find where to flush this, but
changing some of the tls options will fix it.&lt;&#x2F;p&gt;
&lt;p&gt;In SSSD.conf:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ldap_id_use_start_tls = True
&lt;&#x2F;span&gt;&lt;span&gt;ldap_tls_cacertdir = &#x2F;usr&#x2F;local&#x2F;samba&#x2F;private&#x2F;tls
&lt;&#x2F;span&gt;&lt;span&gt;ldap_tls_reqcert = demand
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now to make the cacertdir work you need to run&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;cacertdir_rehash &#x2F;usr&#x2F;local&#x2F;samba&#x2F;private&#x2F;tls
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Your SSSD should now be working again.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Virtual hosted django</title>
          <pubDate>Mon, 18 Feb 2013 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2013-02-18-virtual-hosted-django/</link>
          <guid>https://fy.blackhats.net.au/blog/2013-02-18-virtual-hosted-django/</guid>
          <description>&lt;h1 id=&quot;virtual-hosted-django&quot;&gt;Virtual hosted django&lt;&#x2F;h1&gt;
&lt;p&gt;Recently I have been trying to host multiple django applications on a
single apache instance.&lt;&#x2F;p&gt;
&lt;p&gt;Sometimes, you would find that the page from a different vhost would
load incorrectly. This is due to the way that WSGI handles work thread
pools.&lt;&#x2F;p&gt;
&lt;p&gt;To fix it.&lt;&#x2F;p&gt;
&lt;p&gt;In your &#x2F;etc&#x2F;httpd&#x2F;conf.d&#x2F;wsgi.conf Make sure to comment out the
WSGIPythonPath line. :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;#WSGIPythonPath
&lt;&#x2F;span&gt;&lt;span&gt;WSGISocketPrefix run&#x2F;wsgi
&lt;&#x2F;span&gt;&lt;span&gt;#You can add many process groups. 
&lt;&#x2F;span&gt;&lt;span&gt;WSGIDaemonProcess group_wsgi python-path=&amp;quot;&#x2F;var&#x2F;www&#x2F;django&#x2F;group&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now in your VHost add the line (If your script alias is &amp;quot;&#x2F;&amp;quot;) :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&amp;lt;location &amp;quot;&#x2F;&amp;quot;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;WSGIProcessGroup group_wsgi
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&#x2F;location&amp;gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
</description>
      </item>
      <item>
          <title>Steam Linux Beta on Fedora 18 (x86 64 or x86)</title>
          <pubDate>Fri, 07 Dec 2012 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2012-12-07-steam-linux-beta-on-fedora-18-x86-64-or-x86/</link>
          <guid>https://fy.blackhats.net.au/blog/2012-12-07-steam-linux-beta-on-fedora-18-x86-64-or-x86/</guid>
          <description>&lt;h1 id=&quot;steam-linux-beta-on-fedora-18-x86-64-or-x86&quot;&gt;Steam Linux Beta on Fedora 18 (x86 64 or x86)&lt;&#x2F;h1&gt;
&lt;p&gt;These instructions are old! Use this instead:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;wget http:&#x2F;&#x2F;spot.fedorapeople.org&#x2F;steam&#x2F;steam.repo -O &#x2F;etc&#x2F;yum.repos.d&#x2F;steam.repo
&lt;&#x2F;span&gt;&lt;span&gt;yum install steam
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;OLD METHOD below&lt;&#x2F;p&gt;
&lt;p&gt;Get the .deb.&lt;&#x2F;p&gt;
&lt;p&gt;Unpack it with :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;ar x steam.deb
&lt;&#x2F;span&gt;&lt;span&gt;tar -xvzf data.tar.gz -C &#x2F;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now install&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;yum install glibc.i686 \
&lt;&#x2F;span&gt;&lt;span&gt;libX11.i686 \
&lt;&#x2F;span&gt;&lt;span&gt;libstdc++.i686 \
&lt;&#x2F;span&gt;&lt;span&gt;mesa-libGL.i686 \
&lt;&#x2F;span&gt;&lt;span&gt;mesa-dri-drivers.i686 \
&lt;&#x2F;span&gt;&lt;span&gt;libtxc_dxtn.i686 \
&lt;&#x2F;span&gt;&lt;span&gt;libXrandr.i686 \
&lt;&#x2F;span&gt;&lt;span&gt;pango.i686 \
&lt;&#x2F;span&gt;&lt;span&gt;gtk2.i686 \
&lt;&#x2F;span&gt;&lt;span&gt;alsa-lib.i686 \
&lt;&#x2F;span&gt;&lt;span&gt;nss.i686 \
&lt;&#x2F;span&gt;&lt;span&gt;libpng12.i686 \
&lt;&#x2F;span&gt;&lt;span&gt;openal-soft.i686 \
&lt;&#x2F;span&gt;&lt;span&gt;pulseaudio-libs.i686
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now you should be able to run the steam client from &#x2F;usr&#x2F;bin&#x2F;steam or
from the Applications - Games menu&lt;&#x2F;p&gt;
&lt;p&gt;If you have issues, try :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;cd ~&#x2F;.local&#x2F;share&#x2F;Steam
&lt;&#x2F;span&gt;&lt;span&gt;LD_DEBUG=&amp;quot;libs&amp;quot; .&#x2F;steam.sh
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;To see what is going on. Sometimes you will see something like :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;9228:   trying file=tls&#x2F;i686&#x2F;sse2&#x2F;libGL.so.1
&lt;&#x2F;span&gt;&lt;span&gt;9228:   trying file=tls&#x2F;i686&#x2F;libGL.so.1
&lt;&#x2F;span&gt;&lt;span&gt;9228:   trying file=tls&#x2F;sse2&#x2F;libGL.so.1
&lt;&#x2F;span&gt;&lt;span&gt;9228:   trying file=tls&#x2F;libGL.so.1
&lt;&#x2F;span&gt;&lt;span&gt;9228:   trying file=i686&#x2F;sse2&#x2F;libGL.so.1
&lt;&#x2F;span&gt;&lt;span&gt;9228:   trying file=i686&#x2F;libGL.so.1
&lt;&#x2F;span&gt;&lt;span&gt;9228:   trying file=sse2&#x2F;libGL.so.1
&lt;&#x2F;span&gt;&lt;span&gt;9228:   trying file=libGL.so.1
&lt;&#x2F;span&gt;&lt;span&gt;9228:  search cache=&#x2F;etc&#x2F;ld.so.cache
&lt;&#x2F;span&gt;&lt;span&gt;9228:  search path=&#x2F;lib&#x2F;i686:&#x2F;lib&#x2F;sse2:&#x2F;lib:&#x2F;usr&#x2F;lib&#x2F;i686:&#x2F;usr&#x2F;lib&#x2F;sse2:&#x2F;usr&#x2F;lib      (system search path)
&lt;&#x2F;span&gt;&lt;span&gt;9228:   trying file=&#x2F;lib&#x2F;i686&#x2F;libGL.so.1
&lt;&#x2F;span&gt;&lt;span&gt;9228:   trying file=&#x2F;lib&#x2F;sse2&#x2F;libGL.so.1
&lt;&#x2F;span&gt;&lt;span&gt;9228:   trying file=&#x2F;lib&#x2F;libGL.so.1
&lt;&#x2F;span&gt;&lt;span&gt;9228:   trying file=&#x2F;usr&#x2F;lib&#x2F;i686&#x2F;libGL.so.1
&lt;&#x2F;span&gt;&lt;span&gt;9228:   trying file=&#x2F;usr&#x2F;lib&#x2F;sse2&#x2F;libGL.so.1
&lt;&#x2F;span&gt;&lt;span&gt;9228:   trying file=&#x2F;usr&#x2F;lib&#x2F;libGL.so.1
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;And the steam client will then hang, or say &amp;quot;Error loading
steamui.so&amp;quot;. It is because you are missing libGL.so.1 in this case.&lt;&#x2F;p&gt;
&lt;p&gt;running ldd against the files in &amp;quot;.local&#x2F;share&#x2F;Steam&#x2F;ubuntu12_32&#x2F;&amp;quot;
should reveal most of the deps you need.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>NSS commands and how to</title>
          <pubDate>Tue, 01 May 2012 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2012-05-01-nss-commands-and-how-to/</link>
          <guid>https://fy.blackhats.net.au/blog/2012-05-01-nss-commands-and-how-to/</guid>
          <description>&lt;h1 id=&quot;nss-commands-and-how-to&quot;&gt;NSS commands and how to&lt;&#x2F;h1&gt;
&lt;p&gt;I have collated some knowledge on how to use NSS and it&#x27;s tools for
some general purpose usage, including mod_nss.&lt;&#x2F;p&gt;
&lt;p&gt;Much of this is just assembling the contents of the &lt;a href=&quot;http:&#x2F;&#x2F;www.mozilla.org&#x2F;projects&#x2F;security&#x2F;pki&#x2F;nss&#x2F;tools&#x2F;certutil.html&quot;&gt;certutil
documentation&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;In this I have NOT documented the process of deleting certificates,
changing trust settings of existing certificates or changing key3.db
passwords.&lt;&#x2F;p&gt;
&lt;p&gt;Create a new certificate database if one doesn&#x27;t exist (You should see
key3.db, secmod.db and cert8.db if one exists).&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -N -d . 
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;List all certificates in a database&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -L -d .
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;List all private keys in a database&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -K -d . [-f pwdfile.txt]
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;I have created a password file, which consists of random data on one
line in a plain text file. Something like below would suffice.
Alternately you can enter a password when prompted by the certutil
commands. If you wish to use this for apache start up, you need to use
pin.txt&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;echo &amp;quot;soeihcoraiocrthhrcrcae aoriao htuathhhohodrrcrcgg89y99itantmnomtn&amp;quot; &amp;gt; pwdfile.txt
&lt;&#x2F;span&gt;&lt;span&gt;echo &amp;quot;internal:soeihcoraiocrthhrcrcae aoriao htuathhhohodrrcrcgg89y99itantmnomtn&amp;quot; &amp;gt; pin.txt
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Create a self signed certificate in your database. Note the -n, which
creates a &amp;quot;nickname&amp;quot; (And should be unique) and is how applications
reference your certificate and key. Also note the -s line, and the CN
options. Finally, note the first line has the option -g, which defines
the number of bits in the created certificate.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -S -f pwdfile.txt -d . -t &amp;quot;C,,&amp;quot; -x -n &amp;quot;Server-Cert&amp;quot; -g 2048\
&lt;&#x2F;span&gt;&lt;span&gt;-s &amp;quot;CN=nss.dev.example.com,O=Testing,L=Adelaide,ST=South Australia,C=AU&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;certutil -S -f pwdfile.txt -d . -t &amp;quot;C,,&amp;quot; -x -n &amp;quot;Server-Cert2&amp;quot; \
&lt;&#x2F;span&gt;&lt;span&gt;-s &amp;quot;CN=nss2.dev.example.com,O=Testing,L=Adelaide,ST=South Australia,C=AU&amp;quot; 
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;To add subject alternative names, use a comma seperated list with the
option -8 IE&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -S -f pwdfile.txt -d . -t &amp;quot;C,,&amp;quot; -x -n &amp;quot;Server-Cert&amp;quot; -g 2048\
&lt;&#x2F;span&gt;&lt;span&gt;-s &amp;quot;CN=nss.dev.example.com,O=Testing,L=Adelaide,ST=South Australia,C=AU&amp;quot; \
&lt;&#x2F;span&gt;&lt;span&gt;-8 &amp;quot;nss.dev.example.com,nss-alt.dev.example.com&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Create a self signed CA (In a different database from the one used by
httpd.)&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -S -n CAissuer -t &amp;quot;C,C,C&amp;quot; -x -f pwdfile.txt -d . \
&lt;&#x2F;span&gt;&lt;span&gt;-s &amp;quot;CN=ca.nss.dev.example.com,O=Testing,L=Adelaide,ST=South Australia,C=AU&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Create a certificate in the same database, and sign it with the CAissuer
certificate.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -S -n Test-Cert -t &amp;quot;,,&amp;quot; -c CAissuer -f pwdfile.txt -d . \
&lt;&#x2F;span&gt;&lt;span&gt;-s &amp;quot;CN=test.nss.dev.example.com,O=Testing,L=Adelaide,ST=South Australia,C=AU&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Test the new cert for validity as an SSL server.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -V -d . -n Test-Cert -u V
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;View the new cert&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -L -d . -n Test-Cert
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;View the cert in ASCII form (This can be redirected to a file for use
with openssl)&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -L -d . -n Test-Cert -a
&lt;&#x2F;span&gt;&lt;span&gt;certutil -L -d . -n Test-Cert -a &amp;gt; cert.pem
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;In a second, seperate database to your CA.&lt;&#x2F;p&gt;
&lt;p&gt;Create a new certificate request. Again, remember -8 for subjectAltName&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -d . -R -o nss.dev.example.com.csr -f pwdfile.txt \
&lt;&#x2F;span&gt;&lt;span&gt;-s &amp;quot;CN=nss.dev.example.com,O=Testing,L=Adelaide,ST=South Australia,C=AU&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;On the CA, review the CSR you have recieved.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;usr&#x2F;lib[64]&#x2F;nss&#x2F;unsupported-tools&#x2F;derdump -i &#x2F;etc&#x2F;httpd&#x2F;alias&#x2F;nss.dev.example.com.csr
&lt;&#x2F;span&gt;&lt;span&gt;openssl req -inform DER -text -in &#x2F;etc&#x2F;httpd&#x2F;alias&#x2F;nss.dev.example.com.csr
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;On the CA, sign the CSR.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -C -d . -f pwdfile.txt -i &#x2F;etc&#x2F;httpd&#x2F;alias&#x2F;nss.dev.example.com.csr \
&lt;&#x2F;span&gt;&lt;span&gt;-o &#x2F;etc&#x2F;httpd&#x2F;alias&#x2F;nss.dev.example.com.crt -c CAissuer
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Export the CA public certificate&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -L -d . -n CAissuer -r &amp;gt; ca.crt
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Import the CA public certificate into the requestors database.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -A -n &amp;quot;CAcert&amp;quot; -t &amp;quot;C,,&amp;quot; -i &#x2F;etc&#x2F;pki&#x2F;CA&#x2F;nss&#x2F;ca.crt -d .
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Import the signed certificate into the requestors database.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -A -n &amp;quot;Server-cert&amp;quot; -t &amp;quot;,,&amp;quot; -i nss.dev.example.com.crt -d .
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Using openSSL create a server key, and make a CSR&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;openssl genrsa -out server.key 2048
&lt;&#x2F;span&gt;&lt;span&gt;openssl req -new -key server.key -out server.csr
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;On the CA, review the CSR.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;openssl req -inform PEM -text -in server.csr
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;On the CA, sign the request. Note the use of -a that allows an ASCII
formatted PEM input, and will create and ASCII PEM certificate output.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;certutil -C -d . -f pwdfile.txt -i server.csr -o server.crt -a -c CAissuer
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Import an openSSL generated key and certificate into an NSS database.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;openssl pkcs12 -export -in server.crt -inkey server.key -out server.p12 -name Test-Server-Cert
&lt;&#x2F;span&gt;&lt;span&gt;pk12util -i server.p12 -d . -k pwdfile.txt
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Export a secret key and certificate from an NSS database for use with
openssl.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;pk12util -o server-export.p12 -d . -k pwdfile.txt -n Test-Server-Cert
&lt;&#x2F;span&gt;&lt;span&gt;openssl pkcs12 -in server-export.p12 -out file.pem -nodes
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Note that file.pem contains both the CA cert, cert and private key. You
can view just the private key with:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;openssl pkcs12 -in server-export.p12 -out file.pem -nocerts -nodes
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Or just the cert and CAcert with&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;openssl pkcs12 -in server-export.p12 -out file.pem -nokeys -nodes
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You can easily make ASCII formatted PEM from here.&lt;&#x2F;p&gt;
&lt;p&gt;Finally, these commands all use the old DBM formatted NSS databases. To
use the new &amp;quot;shareable&amp;quot; sqlite formatting, follow the steps found from
&lt;a href=&quot;https:&#x2F;&#x2F;blogs.oracle.com&#x2F;meena&#x2F;entry&#x2F;what_s_new_in_nss1&quot;&gt;this blog
post&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;To configure mod_nss, you should have a configuration similar to below -
Most of this is the standard nss.conf that comes with mod_nss, but note
the changes to NSSNickname, and the modified NSSPassPhraseDialog and
NSSRandomSeed values. There is documentation on the NSSCipherSuite that
can be found by running &amp;quot;rpm -qd mod_nss&amp;quot;. Finally, make sure that
apache has read access to the database files and the pin.txt file. If
you leave NSSPassPhraseDialog as &amp;quot;builtin&amp;quot;, you cannot start httpd
from systemctl. You must run apachectl so that you can enter the NSS
database password on apache startup.&lt;&#x2F;p&gt;
&lt;p&gt;NOTE: mod_nss &lt;em&gt;might&lt;&#x2F;em&gt; support SNI. In my testing and examples, this
works to create multiple sites via SNI, however, other developers claim
this is not a supported feature. I have had issues with it in other
instances also. For now, I would avoid it.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;LoadModule nss_module modules&#x2F;libmodnss.so
&lt;&#x2F;span&gt;&lt;span&gt;Listen 8443
&lt;&#x2F;span&gt;&lt;span&gt;NameVirtualHost *:8443
&lt;&#x2F;span&gt;&lt;span&gt;AddType application&#x2F;x-x509-ca-cert .crt
&lt;&#x2F;span&gt;&lt;span&gt;AddType application&#x2F;x-pkcs7-crl    .crl
&lt;&#x2F;span&gt;&lt;span&gt;NSSPassPhraseDialog  file:&#x2F;etc&#x2F;httpd&#x2F;alias&#x2F;pin.txt
&lt;&#x2F;span&gt;&lt;span&gt;NSSPassPhraseHelper &#x2F;usr&#x2F;sbin&#x2F;nss_pcache
&lt;&#x2F;span&gt;&lt;span&gt;NSSSessionCacheSize 10000
&lt;&#x2F;span&gt;&lt;span&gt;NSSSessionCacheTimeout 100
&lt;&#x2F;span&gt;&lt;span&gt;NSSSession3CacheTimeout 86400
&lt;&#x2F;span&gt;&lt;span&gt;NSSEnforceValidCerts off
&lt;&#x2F;span&gt;&lt;span&gt;NSSRandomSeed startup file:&#x2F;dev&#x2F;urandom 512
&lt;&#x2F;span&gt;&lt;span&gt;NSSRenegotiation off
&lt;&#x2F;span&gt;&lt;span&gt;NSSRequireSafeNegotiation off
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;VirtualHost *:8443&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;ServerName nss.dev.example.com:8443
&lt;&#x2F;span&gt;&lt;span&gt;ServerAlias nss.dev.example.com
&lt;&#x2F;span&gt;&lt;span&gt;ErrorLog &#x2F;etc&#x2F;httpd&#x2F;logs&#x2F;nss1_error_log
&lt;&#x2F;span&gt;&lt;span&gt;TransferLog &#x2F;etc&#x2F;httpd&#x2F;logs&#x2F;nss1_access_log
&lt;&#x2F;span&gt;&lt;span&gt;LogLevel warn
&lt;&#x2F;span&gt;&lt;span&gt;NSSEngine on
&lt;&#x2F;span&gt;&lt;span&gt;NSSCipherSuite +rsa_rc4_128_md5,+rsa_rc4_128_sha,+rsa_3des_sha,+fips_3des_sha,+rsa_aes_128_sha,+rsa_aes_256_sha,\
&lt;&#x2F;span&gt;&lt;span&gt;-rsa_des_sha,-rsa_rc4_40_md5,-rsa_rc2_40_md5,-rsa_null_md5,-rsa_null_sha,-fips_des_sha,-fortezza,-fortezza_rc4_128_sha,\
&lt;&#x2F;span&gt;&lt;span&gt;-fortezza_null,-rsa_des_56_sha,-rsa_rc4_56_sha
&lt;&#x2F;span&gt;&lt;span&gt;NSSProtocol SSLv3,TLSv1
&lt;&#x2F;span&gt;&lt;span&gt;NSSNickname Server-cert
&lt;&#x2F;span&gt;&lt;span&gt;NSSCertificateDatabase &#x2F;etc&#x2F;httpd&#x2F;alias
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;Files ~ &amp;quot;\.(cgi|shtml|phtml|php3?)$&amp;quot;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;    NSSOptions +StdEnvVars
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&#x2F;Files&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;Directory &amp;quot;&#x2F;var&#x2F;www&#x2F;cgi-bin&amp;quot;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;    NSSOptions +StdEnvVars
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&#x2F;Directory&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&#x2F;VirtualHost&amp;gt;                                  
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;VirtualHost *:8443&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;ServerName nss2.dev.example.com:8443
&lt;&#x2F;span&gt;&lt;span&gt;ServerAlias nss2.dev.example.com
&lt;&#x2F;span&gt;&lt;span&gt;ErrorLog &#x2F;etc&#x2F;httpd&#x2F;logs&#x2F;nss2_error_log
&lt;&#x2F;span&gt;&lt;span&gt;TransferLog &#x2F;etc&#x2F;httpd&#x2F;logs&#x2F;nss2_access_log
&lt;&#x2F;span&gt;&lt;span&gt;LogLevel warn
&lt;&#x2F;span&gt;&lt;span&gt;NSSEngine on
&lt;&#x2F;span&gt;&lt;span&gt;NSSCipherSuite +rsa_rc4_128_md5,+rsa_rc4_128_sha,+rsa_3des_sha,+fips_3des_sha,+rsa_aes_128_sha,+rsa_aes_256_sha,\
&lt;&#x2F;span&gt;&lt;span&gt;-rsa_des_sha,-rsa_rc4_40_md5,-rsa_rc2_40_md5,-rsa_null_md5,-rsa_null_sha,-fips_des_sha,-fortezza,-fortezza_rc4_128_sha,\
&lt;&#x2F;span&gt;&lt;span&gt;-fortezza_null,-rsa_des_56_sha,-rsa_rc4_56_sha
&lt;&#x2F;span&gt;&lt;span&gt;NSSProtocol SSLv3,TLSv1
&lt;&#x2F;span&gt;&lt;span&gt;NSSNickname Server-Cert2
&lt;&#x2F;span&gt;&lt;span&gt;NSSCertificateDatabase &#x2F;etc&#x2F;httpd&#x2F;alias
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;Files ~ &amp;quot;\.(cgi|shtml|phtml|php3?)$&amp;quot;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;    NSSOptions +StdEnvVars
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&#x2F;Files&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;Directory &amp;quot;&#x2F;var&#x2F;www&#x2F;cgi-bin&amp;quot;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;    NSSOptions +StdEnvVars
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&#x2F;Directory&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&#x2F;VirtualHost&amp;gt; 
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
</description>
      </item>
      <item>
          <title>Slow mac sleep</title>
          <pubDate>Thu, 26 Apr 2012 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2012-04-26-slow-mac-sleep/</link>
          <guid>https://fy.blackhats.net.au/blog/2012-04-26-slow-mac-sleep/</guid>
          <description>&lt;h1 id=&quot;slow-mac-sleep&quot;&gt;Slow mac sleep&lt;&#x2F;h1&gt;
&lt;p&gt;Recently, I have noticed that my shiny macbook pro 8,2, with 16GB of ram
and it&#x27;s super fast intel SSD, was taking quite a long time to sleep -
near 20 seconds to more than a minute in some cases. This caused me
frustration to no avail.&lt;&#x2F;p&gt;
&lt;p&gt;However, recently, in an attempt to reclaim disk space from the SSD, in
the form of a wasted 16GB chunk in &#x2F;private&#x2F;var&#x2F;vm&#x2F;sleepimage . This
lead me to read the documentation on pmutil.&lt;&#x2F;p&gt;
&lt;p&gt;hibernate mode is set to 3 by default - this means that when you close
the lid on your MBP, it dumps the contents of ram to sleepimage, and
then suspends to ram. This means in the case that you lose power while
suspended, you can still restore your laptop state safely. I don&#x27;t feel
I need this, so I ran the following. :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;sudo pmset -a hibernatemode 0
&lt;&#x2F;span&gt;&lt;span&gt;sudo rm &#x2F;private&#x2F;var&#x2F;vm&#x2F;sleepimage
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now I have saved 16GB of my SSD (And read write cycles) and my MBP
sleeps in 2 seconds flat.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Samba 4 Internal DNS use</title>
          <pubDate>Mon, 16 Apr 2012 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2012-04-16-samba-4-internal-dns-use/</link>
          <guid>https://fy.blackhats.net.au/blog/2012-04-16-samba-4-internal-dns-use/</guid>
          <description>&lt;h1 id=&quot;samba-4-internal-dns-use&quot;&gt;Samba 4 Internal DNS use&lt;&#x2F;h1&gt;
&lt;p&gt;It took me a while to find this in an email from a mailing list.&lt;&#x2F;p&gt;
&lt;p&gt;To use the internal DNS from samba4 rather than attempting to use BIND9
append the line &amp;quot;--dns-backend=SAMBA_INTERNAL&amp;quot; to your provision
step.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Mod Selinux with Django</title>
          <pubDate>Sun, 15 Apr 2012 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2012-04-15-mod-selinux-with-django/</link>
          <guid>https://fy.blackhats.net.au/blog/2012-04-15-mod-selinux-with-django/</guid>
          <description>&lt;h1 id=&quot;mod-selinux-with-django&quot;&gt;Mod Selinux with Django&lt;&#x2F;h1&gt;
&lt;p&gt;Django with mod_selinux&lt;&#x2F;p&gt;
&lt;p&gt;The mod_selinux module allows you to confine a spawned apache process
into a specific selinux context. For example, you can do this via
virtual hosts, or by LocationMatch directives.&lt;&#x2F;p&gt;
&lt;p&gt;Part of my curiosity wanted to see how this works. So I made up a small
django application that would tell you the selinux context of an URL.&lt;&#x2F;p&gt;
&lt;p&gt;Install mod_selinux first&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;yum install mod_selinux mod_wsgi
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now we create a VirtualHost that we can use for the test application&lt;&#x2F;p&gt;
&lt;p&gt;:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;NameVirtualHost *:80
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;VirtualHost *:80&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;    ServerAdmin william@firstyear.id.au
&lt;&#x2F;span&gt;&lt;span&gt;    DocumentRoot &#x2F;var&#x2F;empty
&lt;&#x2F;span&gt;&lt;span&gt;    ServerName 172.16.209.150
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;lt;LocationMatch &#x2F;selinux&#x2F;test&#x2F;c2&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;    selinuxDomainVal    *:s0:c2
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;lt;&#x2F;LocationMatch&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;lt;LocationMatch &#x2F;selinux&#x2F;test&#x2F;c3&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;    selinuxDomainVal    *:s0:c3
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;lt;&#x2F;LocationMatch&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    #Alias &#x2F;robots.txt &#x2F;usr&#x2F;local&#x2F;wsgi&#x2F;static&#x2F;robots.txt
&lt;&#x2F;span&gt;&lt;span&gt;    #Alias &#x2F;favicon.ico &#x2F;usr&#x2F;local&#x2F;wsgi&#x2F;static&#x2F;favicon.ico
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    AliasMatch ^&#x2F;([^&#x2F;]*\.css) &#x2F;var&#x2F;www&#x2F;django_base&#x2F;static&#x2F;styles&#x2F;$1
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    Alias &#x2F;media&#x2F; &#x2F;var&#x2F;www&#x2F;django_base&#x2F;media&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;    Alias &#x2F;static&#x2F; &#x2F;var&#x2F;www&#x2F;django_base&#x2F;static&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;lt;Directory &#x2F;var&#x2F;www&#x2F;django_base&#x2F;static&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;    Order deny,allow
&lt;&#x2F;span&gt;&lt;span&gt;    Allow from all
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;lt;&#x2F;Directory&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;lt;Directory &#x2F;var&#x2F;www&#x2F;django_base&#x2F;media&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;    Order deny,allow
&lt;&#x2F;span&gt;&lt;span&gt;    Allow from all
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;lt;&#x2F;Directory&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    WSGIScriptAlias &#x2F; &#x2F;var&#x2F;www&#x2F;django_base&#x2F;django_base&#x2F;wsgi.py
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;lt;Directory &#x2F;var&#x2F;www&#x2F;django_base&#x2F;scripts&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;    Order allow,deny
&lt;&#x2F;span&gt;&lt;span&gt;    Allow from all
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;lt;&#x2F;Directory&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&#x2F;VirtualHost&amp;gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;We also need to alter &#x2F;etc&#x2F;httpd&#x2F;conf.d&#x2F;mod_selinux.conf to have MCS
labels.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;selinuxServerDomain     *:s0:c0.c100
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;And finally, download the (now sadly lost) tar ball, and unpack it to
&#x2F;var&#x2F;www&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;cd &#x2F;var&#x2F;www
&lt;&#x2F;span&gt;&lt;span&gt;tar -xvzf django_selinux_test.tar.gz
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now, navigating to the right URL will show you the different SELinux
contexts&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;http:&#x2F;&#x2F;localhost&#x2F;selinux&#x2F;test&#x2F;test&quot;&gt;http:&#x2F;&#x2F;localhost&#x2F;selinux&#x2F;test&#x2F;test&lt;&#x2F;a&gt; :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;Hello. Your processes context is [0, &amp;#39;system_u:system_r:httpd_t:s0:c0.c100&amp;#39;]
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&lt;a href=&quot;http:&#x2F;&#x2F;localhost&#x2F;selinux&#x2F;test&#x2F;c2&quot;&gt;http:&#x2F;&#x2F;localhost&#x2F;selinux&#x2F;test&#x2F;c2&lt;&#x2F;a&gt; :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;Hello. Your processes context is [0, &amp;#39;system_u:system_r:httpd_t:s0:c2&amp;#39;]
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&lt;a href=&quot;http:&#x2F;&#x2F;localhost&#x2F;selinux&#x2F;test&#x2F;c3&quot;&gt;http:&#x2F;&#x2F;localhost&#x2F;selinux&#x2F;test&#x2F;c3&lt;&#x2F;a&gt; :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;Hello. Your processes context is [0, &amp;#39;system_u:system_r:httpd_t:s0:c3&amp;#39;]
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The best part about this is that this context is passed via the local
unix socket to sepgsql - meaning that specific locations in your Django
application can have different SELinux MCS labels, allowing mandatory
access controls to tables and columns. Once I work out row-level
permissions in sepgsql, these will also be available to django processes
via this means.&lt;&#x2F;p&gt;
&lt;p&gt;Example of why you want this.&lt;&#x2F;p&gt;
&lt;p&gt;You have a shopping cart application. In your users profile page, you
allow access to that URL to view &#x2F; write to the credit card details of a
user. In the main application, this column is in a different MCS - So
exploitation of the django application, be it SQL injection, or remote
shell execution - the credit cards remain in a separate domain, and thus
inaccessible.&lt;&#x2F;p&gt;
&lt;p&gt;Additionally, these MCS labels are applied to files uploaded into &#x2F;media
for example, so you can use this to help restrict access to documents
etc.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>SEPGSQL - How to Fedora 16 - 17</title>
          <pubDate>Sun, 15 Apr 2012 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2012-04-15-sepgsql-how-to-fedora-16-17/</link>
          <guid>https://fy.blackhats.net.au/blog/2012-04-15-sepgsql-how-to-fedora-16-17/</guid>
          <description>&lt;h1 id=&quot;sepgsql-how-to-fedora-16-17&quot;&gt;SEPGSQL - How to Fedora 16 - 17&lt;&#x2F;h1&gt;
&lt;p&gt;First, we install what we will be using.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;yum install postgresql postgresql-server postgresql-contrib 
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;First, we want to setup sepgsql. sepgsql.so is part of the contrib
package. These modules are installed on a per database basis, so we need
to initdb first&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;postgresql-setup initdb
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Edit vim &#x2F;var&#x2F;lib&#x2F;pgsql&#x2F;data&#x2F;postgresql.conf +126&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;shared_preload_libraries = &amp;#39;sepgsql&amp;#39;            # (change requires restart)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now, we need to re-label all the default postgres tables.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;su postgres
&lt;&#x2F;span&gt;&lt;span&gt;export PGDATA=&#x2F;var&#x2F;lib&#x2F;pgsql&#x2F;data
&lt;&#x2F;span&gt;&lt;span&gt;for DBNAME in template0 template1 postgres; do postgres --single -F -c exit_on_error=true $DBNAME &#x2F;dev&#x2F;null; done
&lt;&#x2F;span&gt;&lt;span&gt;exit
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now we can start postgresql.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;systemctl start postgresql.service
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Moment of truth - time to find out if we have selinux contexts in
postgresql.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# su postgres
&lt;&#x2F;span&gt;&lt;span&gt;# psql -U postgres postgres -c &amp;#39;select sepgsql_getcon();&amp;#39;
&lt;&#x2F;span&gt;&lt;span&gt;could not change directory to &amp;quot;&#x2F;root&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;                    sepgsql_getcon                     
&lt;&#x2F;span&gt;&lt;span&gt;-------------------------------------------------------
&lt;&#x2F;span&gt;&lt;span&gt; unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023
&lt;&#x2F;span&gt;&lt;span&gt;(1 row)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;We can create a new database. Lets call it setest. We also add an apache
user for the django threads to connect to later. Finally, we want to
setup password authentication, and change ownership of the new setest db
to apache.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;createdb setest
&lt;&#x2F;span&gt;&lt;span&gt;createuser 
&lt;&#x2F;span&gt;&lt;span&gt;Enter name of role to add: apache
&lt;&#x2F;span&gt;&lt;span&gt;Shall the new role be a superuser? (y&#x2F;n) n
&lt;&#x2F;span&gt;&lt;span&gt;Shall the new role be allowed to create databases? (y&#x2F;n) n
&lt;&#x2F;span&gt;&lt;span&gt;Shall the new role be allowed to create more new roles? (y&#x2F;n) n
&lt;&#x2F;span&gt;&lt;span&gt;psql -U postgres template1 -c &amp;quot;alter user apache with password &amp;#39;password&amp;#39;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;psql -U postgres template1 -c &amp;quot;alter user postgres with password &amp;#39;password&amp;#39;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;psql -U postgres template1 -c &amp;quot;alter database setest owner to apache&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now we change our auth in postgres to be md5 in the file
$PGDATA&#x2F;pg_hdb.conf&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# &amp;quot;local&amp;quot; is for Unix domain socket connections only
&lt;&#x2F;span&gt;&lt;span&gt;local   all             all                                     md5
&lt;&#x2F;span&gt;&lt;span&gt;# IPv4 local connections:
&lt;&#x2F;span&gt;&lt;span&gt;host    all             all             127.0.0.1&#x2F;32            md5
&lt;&#x2F;span&gt;&lt;span&gt;# IPv6 local connections:
&lt;&#x2F;span&gt;&lt;span&gt;host    all             all             ::1&#x2F;128                 md5
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;systemctl restart postgresql.service
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now you should be able to login in with a password as both users.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;# psql -U postgres -W
&lt;&#x2F;span&gt;&lt;span&gt;Password for user postgres: 
&lt;&#x2F;span&gt;&lt;span&gt;psql (9.1.3)
&lt;&#x2F;span&gt;&lt;span&gt;Type &amp;quot;help&amp;quot; for help.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;postgres=# 
&lt;&#x2F;span&gt;&lt;span&gt;# psql -U apache -W setest
&lt;&#x2F;span&gt;&lt;span&gt;Password for user apache: 
&lt;&#x2F;span&gt;&lt;span&gt;psql (9.1.3)
&lt;&#x2F;span&gt;&lt;span&gt;Type &amp;quot;help&amp;quot; for help.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;setest=# 
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Lets also take this chance, to take a look at the per column and per
table selinux permissions.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;psql -U postgres -W setest -c &amp;quot;SELECT objtype, objname, label FROM pg_seclabels WHERE provider = &amp;#39;selinux&amp;#39; AND  objtype in (&amp;#39;table&amp;#39;, &amp;#39;column&amp;#39;)&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;To update these&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;SECURITY LABEL FOR selinux ON TABLE mytable IS &amp;#39;system_u:object_r:sepgsql_table_t:s0&amp;#39;;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;See
&lt;a href=&quot;http:&#x2F;&#x2F;www.postgresql.org&#x2F;docs&#x2F;9.1&#x2F;static&#x2F;sql-security-label.html&quot;&gt;also&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;This is very useful, especially if combined with my next blog post.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>DHCP6 server</title>
          <pubDate>Mon, 22 Aug 2011 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2011-08-22-dhcp6-server/</link>
          <guid>https://fy.blackhats.net.au/blog/2011-08-22-dhcp6-server/</guid>
          <description>&lt;h1 id=&quot;dhcp6-server&quot;&gt;DHCP6 server&lt;&#x2F;h1&gt;
&lt;p&gt;I have been battling with setting up one of these for a long time. It so
happens most areas of the internet, forget to mention one vital piece of
the DHCP6 puzzle - DHCP6 is not standalone. It is an addition to RADVD.
Thus you need to run both for it to work correctly.&lt;&#x2F;p&gt;
&lt;p&gt;Why would you want DHCP6 instead of RADVD? Well, RADVD may be good for
your simple home use with a few computers, and MDNS name resoultion. But
when you look at a business, a LAN party, or those who want DDNS
updates, it is essential.&lt;&#x2F;p&gt;
&lt;p&gt;First, we need to setup RADVD properly. The order of these directives is
&lt;em&gt;very&lt;&#x2F;em&gt; important.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;interface eth0
&lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;    AdvManagedFlag on;
&lt;&#x2F;span&gt;&lt;span&gt;    AdvOtherConfigFlag on;
&lt;&#x2F;span&gt;&lt;span&gt;    AdvSendAdvert on;
&lt;&#x2F;span&gt;&lt;span&gt;    MinRtrAdvInterval 5;
&lt;&#x2F;span&gt;&lt;span&gt;    MaxRtrAdvInterval 60;
&lt;&#x2F;span&gt;&lt;span&gt;    prefix 2001:db8:1234:4321&#x2F;64
&lt;&#x2F;span&gt;&lt;span&gt;    {
&lt;&#x2F;span&gt;&lt;span&gt;        AdvOnLink on;
&lt;&#x2F;span&gt;&lt;span&gt;        AdvAutonomous on;
&lt;&#x2F;span&gt;&lt;span&gt;        AdvRouterAddr on;
&lt;&#x2F;span&gt;&lt;span&gt;    };
&lt;&#x2F;span&gt;&lt;span&gt;};
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Next, we need to configure DHCP6. I am using the ISC-DHCP4 server. DHCP6
needs its own instance. Fedora provides a seperate script for this
(dhcpd6.service) that you can use. On other OSes&#x27; you may not have this
and will need to start DHCPD manually with the -6 flag. Here is the
config you need.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;server-name &amp;quot;server.example.com&amp;quot; ;
&lt;&#x2F;span&gt;&lt;span&gt;server-identifier server.example.com ;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;authoritative;
&lt;&#x2F;span&gt;&lt;span&gt;option dhcp6.name-servers 2001:db8:1234:4321::1 ;
&lt;&#x2F;span&gt;&lt;span&gt;ddns-update-style interim ;
&lt;&#x2F;span&gt;&lt;span&gt;ddns-domainname &amp;quot;example.com&amp;quot;;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;subnet6 2001:db8:1234:4321::&#x2F;64 {
&lt;&#x2F;span&gt;&lt;span&gt;        range6 2001:db8:1234:4321::10 2001:db8:1234:4321::110 ;
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now, since DHCP6 uses UDP &#x2F; TCP (Its layer 3, and runs across link
local), you must consider your firewall. On both client and server you
need to accept icmp6, port 546 and 547 from the following addresses&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;Server:
&lt;&#x2F;span&gt;&lt;span&gt;Source - fe80::&#x2F;16 
&lt;&#x2F;span&gt;&lt;span&gt;Destination - ff02::1:2
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Client
&lt;&#x2F;span&gt;&lt;span&gt;Source - ff02::1:2
&lt;&#x2F;span&gt;&lt;span&gt;Source - fe80::&#x2F;16 
&lt;&#x2F;span&gt;&lt;span&gt;Destination - fe80::&#x2F;16
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;A set of example iptables rules on the server side would be&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;-A INPUT -p ipv6-icmp -j ACCEPT
&lt;&#x2F;span&gt;&lt;span&gt;-A INPUT -s fe80::&#x2F;16 -d ff02::1:2 -i eth0 -p udp -m udp --dport 546 -j ACCEPT
&lt;&#x2F;span&gt;&lt;span&gt;-A INPUT -s fe80::&#x2F;16 -d ff02::1:2 -i eth0 -p tcp -m tcp --dport 546 -j ACCEPT
&lt;&#x2F;span&gt;&lt;span&gt;-A INPUT -s fe80::&#x2F;16 -d ff02::1:2 -i eth0 -p udp -m udp --dport 547 -j ACCEPT
&lt;&#x2F;span&gt;&lt;span&gt;-A INPUT -s fe80::&#x2F;16 -d ff02::1:2 -i eth0 -p tcp -m tcp --dport 547 -j ACCEPT
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;And similar enough for the client.&lt;&#x2F;p&gt;
&lt;p&gt;Now start radvd, dhcp6 and your firewalls. Then on your client run.
Enjoy your DHCP6! :&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;dhclient -d -v -6 interface
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;From here, it is very similar to DHCP4 to add things like DDNS updates
to your DHCP6 server.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Mod auth cas</title>
          <pubDate>Sun, 10 Jul 2011 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2011-07-10-mod-auth-cas/</link>
          <guid>https://fy.blackhats.net.au/blog/2011-07-10-mod-auth-cas/</guid>
          <description>&lt;h1 id=&quot;mod-auth-cas&quot;&gt;Mod auth cas&lt;&#x2F;h1&gt;
&lt;p&gt;Recently at UofA, It was mentioned in passing &amp;quot;Wouldn&#x27;t it be nice to
have &lt;a href=&quot;http:&#x2F;&#x2F;www.jasig.org&#x2F;cas&quot;&gt;CAS&lt;&#x2F;a&gt; auth on the webserver instead of
ldap basic auth?&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;&amp;quot;Yes, It would be &amp;quot;, I said. But it got me thinking about the issues
involved. While nice to use CAS, CAS only provides authentication, not
authorization. We rely on ldap attributes for determining access to
content.&lt;&#x2F;p&gt;
&lt;p&gt;After a few minutes of reading, I found the solution.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;installation&quot;&gt;Installation&lt;&#x2F;h2&gt;
&lt;p&gt;I tested this on CentOS 5 (As we use RHEL at work), so adjust this for
your needs.&lt;&#x2F;p&gt;
&lt;p&gt;If EPEL is not enabled you can enable it with this&lt;&#x2F;p&gt;
&lt;p&gt;&lt;a href=&quot;http:&#x2F;&#x2F;fedoraproject.org&#x2F;wiki&#x2F;EPEL&quot;&gt;EPEL&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;If you wish to only install the one package, you can set the repository
to disabled, and install with the following command&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;yum install --enablerepo=epel mod_auth_cas 
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Also install the ldap module. It is part of the base repo in RHEL.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;yum install mod_authz_ldap
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;configuration&quot;&gt;Configuration&lt;&#x2F;h2&gt;
&lt;p&gt;Stop your apache server&lt;&#x2F;p&gt;
&lt;p&gt;We need the modules to load in a certain order, so we need to rename our
configs.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;cd &#x2F;etc&#x2F;httpd&#x2F;conf.d&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;mv auth_cas.conf 00_auth_cas.conf
&lt;&#x2F;span&gt;&lt;span&gt;mv authz_ldap.conf 10_authz_ldap.conf
&lt;&#x2F;span&gt;&lt;span&gt;mv ssl.conf 20_ssl.conf
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;In &#x2F;etc&#x2F;httpd&#x2F;conf.d&#x2F;00_auth_cas.conf&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;#
&lt;&#x2F;span&gt;&lt;span&gt;# mod_auth_cas is an Apache 2.0&#x2F;2.2 compliant module that supports the
&lt;&#x2F;span&gt;&lt;span&gt;# CASv1 and CASv2 protocols
&lt;&#x2F;span&gt;&lt;span&gt;#
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;LoadModule auth_cas_module modules&#x2F;mod_auth_cas.so
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;IfModule mod_auth_cas.c&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;    CASVersion 2
&lt;&#x2F;span&gt;&lt;span&gt;    CASDebug On
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    # Validate the authenticity of the login.goshen.edu SSL certificate by
&lt;&#x2F;span&gt;&lt;span&gt;    # checking its chain of authority from the root CA.
&lt;&#x2F;span&gt;&lt;span&gt;    CASCertificatePath &#x2F;etc&#x2F;pki&#x2F;tls&#x2F;certs&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;    CASValidateServer Off
&lt;&#x2F;span&gt;&lt;span&gt;    CASValidateDepth 9
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    CASCookiePath &#x2F;var&#x2F;lib&#x2F;cas&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    CASLoginURL https:&#x2F;&#x2F;auth.example.com&#x2F;cas&#x2F;login
&lt;&#x2F;span&gt;&lt;span&gt;    CASValidateURL https:&#x2F;&#x2F;auth.example.com&#x2F;cas&#x2F;serviceValidate
&lt;&#x2F;span&gt;&lt;span&gt;    CASTimeout 7200
&lt;&#x2F;span&gt;&lt;span&gt;    CASIdleTimeout 7200
&lt;&#x2F;span&gt;&lt;span&gt;  &amp;lt;&#x2F;IfModule&amp;gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;DO NOT RESTART APACHE YET.&lt;&#x2F;p&gt;
&lt;p&gt;You need to create the cas tickets directory, else the module will barf.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;cd &#x2F;var&#x2F;lib
&lt;&#x2F;span&gt;&lt;span&gt;sudo mkdir cas
&lt;&#x2F;span&gt;&lt;span&gt;sudo chown apache:apache cas
&lt;&#x2F;span&gt;&lt;span&gt;sudo chmod 750 cas
&lt;&#x2F;span&gt;&lt;span&gt;sudo semanage fcontext -a -s system_u -t httpd_var_lib_t &#x2F;var&#x2F;lib&#x2F;cas
&lt;&#x2F;span&gt;&lt;span&gt;sudo restorecon -r -v .&#x2F;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This applies the needed SELinux policy to allow httpd to write to that
directory. If you have set SELinux to permissive or disabled, these
steps are worth taking incase you enable SELinux again in the future.&lt;&#x2F;p&gt;
&lt;p&gt;&amp;lt;strong&amp;gt;Configuration with LDAP authorization&amp;lt;&#x2F;strong&amp;gt;&lt;&#x2F;p&gt;
&lt;p&gt;Now we can add our ldap attributes we need. Check that
10_authz_ldap.conf matches the following&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;#
&lt;&#x2F;span&gt;&lt;span&gt;# mod_authz_ldap can be used to implement access control and 
&lt;&#x2F;span&gt;&lt;span&gt;# authenticate users against an LDAP database.
&lt;&#x2F;span&gt;&lt;span&gt;# 
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;LoadModule authz_ldap_module modules&#x2F;mod_authz_ldap.so
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;IfModule mod_authz_ldap.c&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;## Some commented code
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;&amp;lt;&#x2F;IfModule&amp;gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now, in your SSL Directory directive add&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&amp;lt;Directory &amp;quot;&#x2F;var&#x2F;www&#x2F;ms1&amp;quot;&amp;gt;
&lt;&#x2F;span&gt;&lt;span&gt;    Order allow,deny
&lt;&#x2F;span&gt;&lt;span&gt;    Allow from all
&lt;&#x2F;span&gt;&lt;span&gt;    AuthType CAS
&lt;&#x2F;span&gt;&lt;span&gt;    AuthName &amp;quot;TEST CAS AUTH&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;    AuthLDAPURL ldaps:&#x2F;&#x2F;ldap.example.com:636&#x2F;ou=People,dc=example,dc=com?uid?one?
&lt;&#x2F;span&gt;&lt;span&gt;    require ldap-filter &amp;amp;(uid=username)
&lt;&#x2F;span&gt;&lt;span&gt;  &amp;lt;&#x2F;Directory&amp;gt;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You can start apache again after reading the filter section&lt;&#x2F;p&gt;
&lt;h2 id=&quot;filter&quot;&gt;Filter&lt;&#x2F;h2&gt;
&lt;p&gt;This ldap filter can be anything you desire. It can be a list of UID&#x27;s,
sets of attributes, etc.&lt;&#x2F;p&gt;
&lt;p&gt;examples:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;#Will check for this attribute
&lt;&#x2F;span&gt;&lt;span&gt;&amp;amp;(department=marketing)
&lt;&#x2F;span&gt;&lt;span&gt;#Checks that one has both this class and this department
&lt;&#x2F;span&gt;&lt;span&gt;&amp;amp;(class=compsci1001)(department=marketing)
&lt;&#x2F;span&gt;&lt;span&gt;#Your name is either foo or bar
&lt;&#x2F;span&gt;&lt;span&gt;|(uid=foo)(uid=bar)
&lt;&#x2F;span&gt;&lt;span&gt;#These can be nested as well. This would allow anyone with attr and other attr OR the uid= foo into the site. 
&lt;&#x2F;span&gt;&lt;span&gt;|(&amp;amp;((attr=true)(other attr=true)) (uid=foo))
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You can read more about filters
&lt;a href=&quot;http:&#x2F;&#x2F;www.zytrax.com&#x2F;books&#x2F;ldap&#x2F;apa&#x2F;search.html&quot;&gt;here&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;Alternately, one can change the configuration to be like so&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;AuthLDAPURL ldaps:&#x2F;&#x2F;ldap.example.com:636&#x2F;ou=People,dc=example,dc=com?uid?one?(&amp;amp;(attr=foo)(attr=bar))
&lt;&#x2F;span&gt;&lt;span&gt;Require valid-user
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Note the filters are the same, but require the whole filter to be
enclosed in a set of ().&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>SELinux for postfix + dovecot</title>
          <pubDate>Tue, 05 Jul 2011 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://fy.blackhats.net.au/blog/2011-07-05-selinux-for-postfix-dovecot/</link>
          <guid>https://fy.blackhats.net.au/blog/2011-07-05-selinux-for-postfix-dovecot/</guid>
          <description>&lt;h1 id=&quot;selinux-for-postfix-dovecot&quot;&gt;SELinux for postfix + dovecot&lt;&#x2F;h1&gt;
&lt;blockquote&gt;
&lt;p&gt;I am currently in the middle of creating an email solution for the
doctors surgery that I work for. I have previously tried exchange, but
found it to slow, and unreliable for my needs. Instead, I have decided
to go with postfix + dovecot for the doctors needs.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;In my experimenting, I have been using a fedora VM, with SElinux
enabled. However, SELinux has decided to hate on everything I do for
this, and thus in my inability to accept defeat, I have created an
SELinux module that should allow postfix and dovecot to work as per
following &lt;a href=&quot;http:&#x2F;&#x2F;www.1a-centosserver.com&#x2F;centos_linux_mail_server&#x2F;centos_mail_server.php&quot;&gt;this email setup
guide&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;the module is&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;module postfixmysql 1.0;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;require {
&lt;&#x2F;span&gt;&lt;span&gt;    type mysqld_var_run_t;
&lt;&#x2F;span&gt;&lt;span&gt;    type postfix_map_t;
&lt;&#x2F;span&gt;&lt;span&gt;    type usr_t;
&lt;&#x2F;span&gt;&lt;span&gt;    type mysqld_t;
&lt;&#x2F;span&gt;&lt;span&gt;    type mysqld_db_t;
&lt;&#x2F;span&gt;&lt;span&gt;    type postfix_virtual_t;
&lt;&#x2F;span&gt;&lt;span&gt;    type postfix_smtpd_t;
&lt;&#x2F;span&gt;&lt;span&gt;    type postfix_cleanup_t;
&lt;&#x2F;span&gt;&lt;span&gt;    class sock_file write;
&lt;&#x2F;span&gt;&lt;span&gt;    class unix_stream_socket connectto;
&lt;&#x2F;span&gt;&lt;span&gt;    class file getattr;
&lt;&#x2F;span&gt;&lt;span&gt;    class dir search;
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;#============= postfix_cleanup_t ==============
&lt;&#x2F;span&gt;&lt;span&gt;allow postfix_cleanup_t mysqld_db_t:dir search;
&lt;&#x2F;span&gt;&lt;span&gt;allow postfix_cleanup_t mysqld_t:unix_stream_socket connectto;
&lt;&#x2F;span&gt;&lt;span&gt;allow postfix_cleanup_t mysqld_var_run_t:sock_file write;
&lt;&#x2F;span&gt;&lt;span&gt;allow postfix_cleanup_t usr_t:file getattr;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;#============= postfix_map_t ==============
&lt;&#x2F;span&gt;&lt;span&gt;allow postfix_map_t mysqld_db_t:dir search;
&lt;&#x2F;span&gt;&lt;span&gt;allow postfix_map_t mysqld_t:unix_stream_socket connectto;
&lt;&#x2F;span&gt;&lt;span&gt;allow postfix_map_t mysqld_var_run_t:sock_file write;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;#============= postfix_smtpd_t ==============
&lt;&#x2F;span&gt;&lt;span&gt;allow postfix_smtpd_t mysqld_db_t:dir search;
&lt;&#x2F;span&gt;&lt;span&gt;allow postfix_smtpd_t mysqld_t:unix_stream_socket connectto;
&lt;&#x2F;span&gt;&lt;span&gt;allow postfix_smtpd_t mysqld_var_run_t:sock_file write;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;#============= postfix_virtual_t ==============
&lt;&#x2F;span&gt;&lt;span&gt;allow postfix_virtual_t mysqld_db_t:dir search;
&lt;&#x2F;span&gt;&lt;span&gt;allow postfix_virtual_t mysqld_t:unix_stream_socket connectto;
&lt;&#x2F;span&gt;&lt;span&gt;allow postfix_virtual_t mysqld_var_run_t:sock_file write;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This can be built and installed with a command like such (as root)&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;checkmodule -M -m -o postfixmysql.mod postfixmysql.te; semodule_package -m postfixmysql.mod -o postfixmysql.pp; semodule -i postfixmysql.pp 
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
</description>
      </item>
    </channel>
</rss>
